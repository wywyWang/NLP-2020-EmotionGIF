{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from random import random\n",
    "import emoji\n",
    "from tqdm import notebook\n",
    "def tqdm(x, **kargs):\n",
    "    return notebook.tqdm(x, leave=False, **kargs)\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from collections import Counter, defaultdict\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, BertForMultipleChoice\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers.modeling_utils import PreTrainedModel\n",
    "from transformers import BertModel\n",
    "from torch.nn import BCEWithLogitsLoss, MultiLabelMarginLoss\n",
    "from transformers.modeling_bert import BertPreTrainedModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/minerva-ml/open-solution-toxic-comments/blob/master/external_data/apostrophes.json\n",
    "apostrophes = {\n",
    "  \"arent\": \"are not\",\n",
    "  \"cant\": \"cannot\",\n",
    "  \"couldnt\": \"could not\",\n",
    "  \"didnt\": \"did not\",\n",
    "  \"doesnt\": \"does not\",\n",
    "  \"dont\": \"do not\",\n",
    "  \"hadnt\": \"had not\",\n",
    "  \"hasnt\": \"has not\",\n",
    "  \"havent\": \"have not\",\n",
    "  \"hed\": \"he would\",\n",
    "  \"hell\": \"he will\",\n",
    "  \"hes\": \"he is\",\n",
    "  \"id\": \"I had\",\n",
    "  \"ill\": \"I will\",\n",
    "  \"im\": \"I am\",\n",
    "  \"isnt\": \"is not\",\n",
    "  \"its\": \"it is\",\n",
    "  \"itll\": \"it will\",\n",
    "  \"ive\": \"I have\",\n",
    "  \"lets\": \"let us\",\n",
    "  \"mightnt\": \"might not\",\n",
    "  \"mustnt\": \"must not\",\n",
    "  \"shant\": \"shall not\",\n",
    "  \"shed\" : \"she would\",\n",
    "  \"shell\": \"she will\",\n",
    "  \"shes\": \"she is\",\n",
    "  \"shouldnt\": \"should not\",\n",
    "  \"thats\": \"that is\",\n",
    "  \"theres\": \"there is\",\n",
    "  \"theyd\": \"they would\",\n",
    "  \"theyll\": \"they will\",\n",
    "  \"theyre\": \"they are\",\n",
    "  \"theyve\": \"they have\",\n",
    "  \"wed\": \"we would\",\n",
    "  \"were\": \"we are\",\n",
    "  \"werent\": \"were not\",\n",
    "  \"weve\": \"we have\",\n",
    "  \"whatll\": \"what will\",\n",
    "  \"whatre\": \"what are\",\n",
    "  \"whats\": \"what is\",\n",
    "  \"whatve\": \"what have\",\n",
    "  \"wheres\": \"where is\",\n",
    "  \"whod\": \"who would\",\n",
    "  \"wholl\": \"who will\",\n",
    "  \"whore\": \"who are\",\n",
    "  \"whos\": \"who is\",\n",
    "  \"whove\": \"who have\",\n",
    "  \"wont\": \"will not\",\n",
    "  \"wouldnt\": \"would not\",\n",
    "  \"youd\": \"you would\",\n",
    "  \"youll\": \"you will\",\n",
    "  \"youre\": \"you are\",\n",
    "  \"youve\": \"you have\",\n",
    "  \"re\":  \"are\",\n",
    "  \"wasnt\": \"was not\",\n",
    "  \"well\":  \"will\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/minerva-ml/open-solution-toxic-comments/blob/master/external_data/compiled_bad_words.txt\n",
    "compiled_bad_list = pd.read_csv('https://raw.githubusercontent.com/minerva-ml/open-solution-toxic-comments/master/external_data/compiled_bad_words.txt', header=None)\n",
    "compiled_bad_list = list(compiled_bad_list[0].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://github.com/kaymal/twitter-emotions/blob/master/data-preprocessing.ipynb\n",
    "def preprocess_tweet(tweet):\n",
    "    # To lowercase (not good for VADER)\n",
    "    tweet = tweet.lower()\n",
    "    \n",
    "    for bad_word in compiled_bad_list:\n",
    "        bad_candidate = ' ' + bad_word + ' '\n",
    "        tweet = tweet.replace(bad_candidate, ' ')\n",
    "        \n",
    "    # Replace emoji unicode to text\n",
    "#     tweet = emoji.demojize(tweet)\n",
    "#     tweet = tweet.replace('_', ' ')\n",
    "#     tweet = tweet.replace(':', ' ')\n",
    "    tweet = tweet.encode('ascii', 'ignore').decode('ascii')    \n",
    "    # Remove punctuation\n",
    "    tweet = tweet.replace('.', ' ')\n",
    "    tweet = tweet.replace(',', ' ')\n",
    "    \n",
    "    # Remove HTML special entities (e.g. &amp;)\n",
    "    tweet = re.sub(r'\\&\\w*;', '', tweet)\n",
    "    \n",
    "    # Replace apostrophes to original term\n",
    "    for key in apostrophes.keys():\n",
    "        tweet = tweet.replace(key, apostrophes[key])\n",
    "    \n",
    "    #Convert @username to \"user\"\n",
    "    tweet = re.sub('@[^\\s]+', 'user', tweet)\n",
    "    \n",
    "    # Remove whitespace (including new line characters)\n",
    "    tweet = re.sub(r'\\s\\s+', ' ', tweet)\n",
    "    \n",
    "#     # Remove single space remaining at the front of the tweet.\n",
    "#     tweet = tweet.lstrip(' ')\n",
    "    \n",
    "#     # Remove characters beyond Basic Multilingual Plane (BMP) of Unicode:\n",
    "#     tweet = ''.join(c for c in tweet if c <= '\\uFFFF')\n",
    "    \n",
    "#     # Convert hyperlinks ->>>> For now just replace with http\n",
    "#     tweet = re.sub(r'https?:\\/\\/.*\\/\\w*', 'http', tweet)\n",
    "\n",
    "#     #Remove @user\n",
    "#     tweet = re.sub('@[^\\s]+','',tweet)\n",
    "    \n",
    "#     # Remove tickers such as USD ($)\n",
    "#     tweet = re.sub(r'\\$\\w*', '', tweet)\n",
    "    \n",
    "#     # Remove hashtags (not good for VADER)\n",
    "#     tweet = re.sub(r'#\\w*', '', tweet)\n",
    "    \n",
    "#     # Remove Punctuation and split 's, 't, 've with a space for filter\n",
    "#     tweet = re.sub(r'[' + punctuation.replace('@', '') + ']+', ' ', tweet)\n",
    "    \n",
    "#     # Remove words with 2 or fewer letters\n",
    "#     tweet = re.sub(r'\\b\\w{1,2}\\b', '', tweet)\n",
    "\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_json('./source/train_gold.json', lines=True)\n",
    "df['text'] = df.text.apply(preprocess_tweet)\n",
    "df['reply'] = df.reply.apply(preprocess_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a toxic fav line is i just be chI willing like no tf you do not \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df['text'][173])\n",
    "print(df['reply'][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_type = pd.read_json('./source/categories.json', lines=True)\n",
    "categories_mapping = {v[0]: k for k, v in categories_type.to_dict('list').items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilabel classification of BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertForMultiLabelSequenceClassification(BertPreTrainedModel):\n",
    "    \"\"\"BERT model for classification. This module is composed of the BERT model with a linear layer on top of the pooled output. \"\"\" \n",
    "    def __init__(self, config, num_labels=43):\n",
    "        super(BertForMultiLabelSequenceClassification, self).__init__(config)\n",
    "        self.num_labels = num_labels\n",
    "        self.bert = BertModel(config)\n",
    "        self.dropout = torch.nn.Dropout(config.hidden_dropout_prob)\n",
    "#         self.dropout = torch.nn.Dropout(0.4)\n",
    "        self.classifier = torch.nn.Linear(config.hidden_size, num_labels)\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None):\n",
    "        _, pooled_output = self.bert(input_ids, token_type_ids, attention_mask)\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        if labels is not None:\n",
    "            loss_fct = BCEWithLogitsLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1, self.num_labels))\n",
    "            return loss\n",
    "        else:\n",
    "            return logits\n",
    "        \n",
    "    def freeze_bert_encoder(self):\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def unfreeze_bert_encoder(self):\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/jiesutd/pytorch-pretrained-BERT/blob/master/examples/lm_finetuning/pregenerate_training_data.py\n",
    "def truncate_seq_pair(tokens_a, tokens_b, max_num_tokens):\n",
    "    \"\"\"Truncates a pair of sequences to a maximum sequence length. Lifted from Google's BERT repo.\"\"\"\n",
    "    while True:\n",
    "        total_length = len(tokens_a) + len(tokens_b)\n",
    "        if total_length <= max_num_tokens:\n",
    "            break\n",
    "\n",
    "        trunc_tokens = tokens_a if len(tokens_a) > len(tokens_b) else tokens_b\n",
    "        assert len(trunc_tokens) >= 1\n",
    "\n",
    "        # We want to sometimes truncate from the front and sometimes from the\n",
    "        # back to add more randomness and avoid biases.\n",
    "        if random() < 0.5:\n",
    "            del trunc_tokens[0]\n",
    "        else:\n",
    "            trunc_tokens.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocess():\n",
    "    def __init__(self, epochs=6, batch_size=64, categories=None):\n",
    "        self.label = categories\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.model = BertForMultiLabelSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=len(categories), output_hidden_states=False)\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "#         self.tokenizer = TweetTokenizer()\n",
    "    \n",
    "    def tokenize(self, sentance):\n",
    "        return self.tokenizer.tokenize(sentance)\n",
    "    \n",
    "    def convert_features_to_tensors(self, corpus_text, corpus_reply, corpus_class):\n",
    "        df_tokenize = []\n",
    "        for sid, sentance in enumerate(corpus_text):\n",
    "            sentance_reply = corpus_reply[sid]\n",
    "            token_sentance = self.tokenize(sentance)\n",
    "            token_reply = self.tokenize(sentance_reply)\n",
    "            \n",
    "            # Since max length will > max_seq_length, need to truncate pairs\n",
    "            truncate_seq_pair(token_sentance, token_reply, max_seq_length - 3)\n",
    "            \n",
    "            first_sentance = ['[CLS]'] + token_sentance + ['[SEP]']\n",
    "            second_sentance = token_reply + ['[SEP]']\n",
    "            tokens = self.tokenizer.convert_tokens_to_ids(first_sentance + second_sentance)\n",
    "            len_first = len(first_sentance)\n",
    "            len_second = len(second_sentance)\n",
    "            tokens_tensor = torch.tensor(tokens)\n",
    "            segments_tensor = torch.tensor([0] * len_first + [1] * len_second, dtype=torch.long)\n",
    "            # Convert label to one hot encoding\n",
    "            label_onehot_tensor = torch.zeros([len(self.label)])\n",
    "            for each_class in corpus_class[sid]:\n",
    "                label_onehot_tensor[self.label[each_class]] = 1\n",
    "            df_tokenize.append([tokens_tensor, segments_tensor, label_onehot_tensor])\n",
    "        return df_tokenize\n",
    "    \n",
    "    def create_mini_batch(self, corpus):\n",
    "        tokens_tensors = [sentance[0] for sentance in corpus]\n",
    "        segments_tensors = [sentance[1] for sentance in corpus]\n",
    "        labels_tensors = torch.stack([sentance[2] for sentance in corpus])\n",
    "#         labels_tensors = labels_tensors.type(torch.LongTensor)\n",
    "        # zero padding\n",
    "        tokens_tensors = torch.nn.utils.rnn.pad_sequence(tokens_tensors, batch_first=True)\n",
    "        segments_tensors = torch.nn.utils.rnn.pad_sequence(segments_tensors, batch_first=True)\n",
    "        # attention masks to set non-zero padding position to one to let BERT focus on these tokens\n",
    "        masks_tensors = torch.zeros(tokens_tensors.shape, dtype=torch.long)\n",
    "        masks_tensors = masks_tensors.masked_fill(tokens_tensors != 0, 1)\n",
    "        return tokens_tensors, segments_tensors, masks_tensors, labels_tensors\n",
    "    \n",
    "    def train(self, training_data):\n",
    "        # let model training on GPU\n",
    "#         device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"device:\", device)\n",
    "        # Load pretrained model\n",
    "#         model_state_dict = torch.load('./models/bert_adam_4_2_0.331')\n",
    "#         self.model = BertForMultiLabelSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=len(self.label), state_dict=model_state_dict)\n",
    "        self.model = self.model.to(device)\n",
    "        # training mode\n",
    "        self.model.train()\n",
    "        # select adam as optimizer to update weights\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-5)\n",
    "        \n",
    "        for epoch in range(self.epochs):\n",
    "            running_loss = 0\n",
    "            for data in tqdm(training_data, desc='Training progress: '):\n",
    "                tokens_tensors, segments_tensors, masks_tensors, labels = [t.to(device) for t in data]\n",
    "                # Initial gradients\n",
    "                optimizer.zero_grad()\n",
    "                # forward pass\n",
    "                outputs = self.model(input_ids=tokens_tensors, \n",
    "                                token_type_ids=segments_tensors, \n",
    "                                attention_mask=masks_tensors, \n",
    "                                labels=labels)\n",
    "                loss = outputs\n",
    "                # backward\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                # Record current batch loss\n",
    "                running_loss += loss.item()\n",
    "            print(\"Epoch: {}, loss: {}\".format(epoch + 1, running_loss))\n",
    "        torch.save(self.model.state_dict(), './models/bert_adam_{}_{}'.format(self.epochs, self.batch_size))\n",
    "        # Calculate classification accuracy\n",
    "#         _, acc = self.get_predictions(model, training_data, True)\n",
    "        return self.model\n",
    "    \n",
    "    def baseline(self, corpus_text, corpus_reply, corpus_class):\n",
    "        df_tokenize = self.convert_features_to_tensors(corpus_text, corpus_reply, corpus_class)\n",
    "        train_loader = torch.utils.data.DataLoader(df_tokenize, batch_size=self.batch_size, collate_fn=self.create_mini_batch)\n",
    "        tuned_model = self.train(train_loader)\n",
    "        return tuned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0525 17:33:28.716817 139714465597248 configuration_utils.py:285] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/ino/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "I0525 17:33:28.717755 139714465597248 configuration_utils.py:321] Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\",\n",
      "    \"15\": \"LABEL_15\",\n",
      "    \"16\": \"LABEL_16\",\n",
      "    \"17\": \"LABEL_17\",\n",
      "    \"18\": \"LABEL_18\",\n",
      "    \"19\": \"LABEL_19\",\n",
      "    \"20\": \"LABEL_20\",\n",
      "    \"21\": \"LABEL_21\",\n",
      "    \"22\": \"LABEL_22\",\n",
      "    \"23\": \"LABEL_23\",\n",
      "    \"24\": \"LABEL_24\",\n",
      "    \"25\": \"LABEL_25\",\n",
      "    \"26\": \"LABEL_26\",\n",
      "    \"27\": \"LABEL_27\",\n",
      "    \"28\": \"LABEL_28\",\n",
      "    \"29\": \"LABEL_29\",\n",
      "    \"30\": \"LABEL_30\",\n",
      "    \"31\": \"LABEL_31\",\n",
      "    \"32\": \"LABEL_32\",\n",
      "    \"33\": \"LABEL_33\",\n",
      "    \"34\": \"LABEL_34\",\n",
      "    \"35\": \"LABEL_35\",\n",
      "    \"36\": \"LABEL_36\",\n",
      "    \"37\": \"LABEL_37\",\n",
      "    \"38\": \"LABEL_38\",\n",
      "    \"39\": \"LABEL_39\",\n",
      "    \"40\": \"LABEL_40\",\n",
      "    \"41\": \"LABEL_41\",\n",
      "    \"42\": \"LABEL_42\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_15\": 15,\n",
      "    \"LABEL_16\": 16,\n",
      "    \"LABEL_17\": 17,\n",
      "    \"LABEL_18\": 18,\n",
      "    \"LABEL_19\": 19,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_20\": 20,\n",
      "    \"LABEL_21\": 21,\n",
      "    \"LABEL_22\": 22,\n",
      "    \"LABEL_23\": 23,\n",
      "    \"LABEL_24\": 24,\n",
      "    \"LABEL_25\": 25,\n",
      "    \"LABEL_26\": 26,\n",
      "    \"LABEL_27\": 27,\n",
      "    \"LABEL_28\": 28,\n",
      "    \"LABEL_29\": 29,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_30\": 30,\n",
      "    \"LABEL_31\": 31,\n",
      "    \"LABEL_32\": 32,\n",
      "    \"LABEL_33\": 33,\n",
      "    \"LABEL_34\": 34,\n",
      "    \"LABEL_35\": 35,\n",
      "    \"LABEL_36\": 36,\n",
      "    \"LABEL_37\": 37,\n",
      "    \"LABEL_38\": 38,\n",
      "    \"LABEL_39\": 39,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_40\": 40,\n",
      "    \"LABEL_41\": 41,\n",
      "    \"LABEL_42\": 42,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "I0525 17:33:29.024308 139714465597248 modeling_utils.py:617] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /home/ino/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "I0525 17:33:30.948047 139714465597248 modeling_utils.py:708] Weights of BertForMultiLabelSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
      "I0525 17:33:30.948703 139714465597248 modeling_utils.py:714] Weights from pretrained model not used in BertForMultiLabelSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "I0525 17:33:31.848117 139714465597248 tokenization_utils.py:1015] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/ino/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Training progress: ', max=125.0, style=ProgressStyle(desc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, loss: 52.024781197309494\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Training progress: ', max=125.0, style=ProgressStyle(desc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, loss: 25.68275313079357\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Training progress: ', max=125.0, style=ProgressStyle(desc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, loss: 19.717267021536827\n"
     ]
    }
   ],
   "source": [
    "max_seq_length = 512\n",
    "preprocess_module = Preprocess(epochs=3, batch_size=32, categories=categories_mapping)\n",
    "tuned_model = preprocess_module.baseline(df['text'], df['reply'], df['categories'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(tuned_model.state_dict(), 'test_bert')\n",
    "# # Load a trained model that you have fine-tuned\n",
    "# model_state_dict = torch.load(output_model_file)\n",
    "# model = BertForMultiLabelSequenceClassification.from_pretrained(args['bert_model'], num_labels = num_labels, state_dict=model_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0525 13:15:12.954169 140193940277056 configuration_utils.py:285] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/ino/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "I0525 13:15:12.959110 140193940277056 configuration_utils.py:321] Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\",\n",
      "    \"15\": \"LABEL_15\",\n",
      "    \"16\": \"LABEL_16\",\n",
      "    \"17\": \"LABEL_17\",\n",
      "    \"18\": \"LABEL_18\",\n",
      "    \"19\": \"LABEL_19\",\n",
      "    \"20\": \"LABEL_20\",\n",
      "    \"21\": \"LABEL_21\",\n",
      "    \"22\": \"LABEL_22\",\n",
      "    \"23\": \"LABEL_23\",\n",
      "    \"24\": \"LABEL_24\",\n",
      "    \"25\": \"LABEL_25\",\n",
      "    \"26\": \"LABEL_26\",\n",
      "    \"27\": \"LABEL_27\",\n",
      "    \"28\": \"LABEL_28\",\n",
      "    \"29\": \"LABEL_29\",\n",
      "    \"30\": \"LABEL_30\",\n",
      "    \"31\": \"LABEL_31\",\n",
      "    \"32\": \"LABEL_32\",\n",
      "    \"33\": \"LABEL_33\",\n",
      "    \"34\": \"LABEL_34\",\n",
      "    \"35\": \"LABEL_35\",\n",
      "    \"36\": \"LABEL_36\",\n",
      "    \"37\": \"LABEL_37\",\n",
      "    \"38\": \"LABEL_38\",\n",
      "    \"39\": \"LABEL_39\",\n",
      "    \"40\": \"LABEL_40\",\n",
      "    \"41\": \"LABEL_41\",\n",
      "    \"42\": \"LABEL_42\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_15\": 15,\n",
      "    \"LABEL_16\": 16,\n",
      "    \"LABEL_17\": 17,\n",
      "    \"LABEL_18\": 18,\n",
      "    \"LABEL_19\": 19,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_20\": 20,\n",
      "    \"LABEL_21\": 21,\n",
      "    \"LABEL_22\": 22,\n",
      "    \"LABEL_23\": 23,\n",
      "    \"LABEL_24\": 24,\n",
      "    \"LABEL_25\": 25,\n",
      "    \"LABEL_26\": 26,\n",
      "    \"LABEL_27\": 27,\n",
      "    \"LABEL_28\": 28,\n",
      "    \"LABEL_29\": 29,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_30\": 30,\n",
      "    \"LABEL_31\": 31,\n",
      "    \"LABEL_32\": 32,\n",
      "    \"LABEL_33\": 33,\n",
      "    \"LABEL_34\": 34,\n",
      "    \"LABEL_35\": 35,\n",
      "    \"LABEL_36\": 36,\n",
      "    \"LABEL_37\": 37,\n",
      "    \"LABEL_38\": 38,\n",
      "    \"LABEL_39\": 39,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_40\": 40,\n",
      "    \"LABEL_41\": 41,\n",
      "    \"LABEL_42\": 42,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "I0525 13:15:13.306703 140193940277056 modeling_utils.py:617] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /home/ino/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"architectures\": [\n",
       "    \"BertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"id2label\": {\n",
       "    \"0\": \"LABEL_0\",\n",
       "    \"1\": \"LABEL_1\",\n",
       "    \"2\": \"LABEL_2\",\n",
       "    \"3\": \"LABEL_3\",\n",
       "    \"4\": \"LABEL_4\",\n",
       "    \"5\": \"LABEL_5\",\n",
       "    \"6\": \"LABEL_6\",\n",
       "    \"7\": \"LABEL_7\",\n",
       "    \"8\": \"LABEL_8\",\n",
       "    \"9\": \"LABEL_9\",\n",
       "    \"10\": \"LABEL_10\",\n",
       "    \"11\": \"LABEL_11\",\n",
       "    \"12\": \"LABEL_12\",\n",
       "    \"13\": \"LABEL_13\",\n",
       "    \"14\": \"LABEL_14\",\n",
       "    \"15\": \"LABEL_15\",\n",
       "    \"16\": \"LABEL_16\",\n",
       "    \"17\": \"LABEL_17\",\n",
       "    \"18\": \"LABEL_18\",\n",
       "    \"19\": \"LABEL_19\",\n",
       "    \"20\": \"LABEL_20\",\n",
       "    \"21\": \"LABEL_21\",\n",
       "    \"22\": \"LABEL_22\",\n",
       "    \"23\": \"LABEL_23\",\n",
       "    \"24\": \"LABEL_24\",\n",
       "    \"25\": \"LABEL_25\",\n",
       "    \"26\": \"LABEL_26\",\n",
       "    \"27\": \"LABEL_27\",\n",
       "    \"28\": \"LABEL_28\",\n",
       "    \"29\": \"LABEL_29\",\n",
       "    \"30\": \"LABEL_30\",\n",
       "    \"31\": \"LABEL_31\",\n",
       "    \"32\": \"LABEL_32\",\n",
       "    \"33\": \"LABEL_33\",\n",
       "    \"34\": \"LABEL_34\",\n",
       "    \"35\": \"LABEL_35\",\n",
       "    \"36\": \"LABEL_36\",\n",
       "    \"37\": \"LABEL_37\",\n",
       "    \"38\": \"LABEL_38\",\n",
       "    \"39\": \"LABEL_39\",\n",
       "    \"40\": \"LABEL_40\",\n",
       "    \"41\": \"LABEL_41\",\n",
       "    \"42\": \"LABEL_42\"\n",
       "  },\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"label2id\": {\n",
       "    \"LABEL_0\": 0,\n",
       "    \"LABEL_1\": 1,\n",
       "    \"LABEL_10\": 10,\n",
       "    \"LABEL_11\": 11,\n",
       "    \"LABEL_12\": 12,\n",
       "    \"LABEL_13\": 13,\n",
       "    \"LABEL_14\": 14,\n",
       "    \"LABEL_15\": 15,\n",
       "    \"LABEL_16\": 16,\n",
       "    \"LABEL_17\": 17,\n",
       "    \"LABEL_18\": 18,\n",
       "    \"LABEL_19\": 19,\n",
       "    \"LABEL_2\": 2,\n",
       "    \"LABEL_20\": 20,\n",
       "    \"LABEL_21\": 21,\n",
       "    \"LABEL_22\": 22,\n",
       "    \"LABEL_23\": 23,\n",
       "    \"LABEL_24\": 24,\n",
       "    \"LABEL_25\": 25,\n",
       "    \"LABEL_26\": 26,\n",
       "    \"LABEL_27\": 27,\n",
       "    \"LABEL_28\": 28,\n",
       "    \"LABEL_29\": 29,\n",
       "    \"LABEL_3\": 3,\n",
       "    \"LABEL_30\": 30,\n",
       "    \"LABEL_31\": 31,\n",
       "    \"LABEL_32\": 32,\n",
       "    \"LABEL_33\": 33,\n",
       "    \"LABEL_34\": 34,\n",
       "    \"LABEL_35\": 35,\n",
       "    \"LABEL_36\": 36,\n",
       "    \"LABEL_37\": 37,\n",
       "    \"LABEL_38\": 38,\n",
       "    \"LABEL_39\": 39,\n",
       "    \"LABEL_4\": 4,\n",
       "    \"LABEL_40\": 40,\n",
       "    \"LABEL_41\": 41,\n",
       "    \"LABEL_42\": 42,\n",
       "    \"LABEL_5\": 5,\n",
       "    \"LABEL_6\": 6,\n",
       "    \"LABEL_7\": 7,\n",
       "    \"LABEL_8\": 8,\n",
       "    \"LABEL_9\": 9\n",
       "  },\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_state_dict = torch.load('./models/bert_adam_1_2')\n",
    "model = BertForMultiLabelSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=43, state_dict=model_state_dict)\n",
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tokenize = []\n",
    "for sid, sentance in enumerate(df['text']):\n",
    "    sentance_reply = df['reply'][sid]\n",
    "    token_sentance = preprocess_module.tokenize(sentance)\n",
    "    token_reply = preprocess_module.tokenize(sentance_reply)\n",
    "    \n",
    "    # Since max length will > max_seq_length, need to truncate pairs\n",
    "    truncate_seq_pair(token_sentance, token_reply, max_seq_length - 3)\n",
    "    \n",
    "    first_sentance = ['[CLS]'] + token_sentance + ['[SEP]']\n",
    "    second_sentance = token_reply + ['[SEP]']\n",
    "    tokens = preprocess_module.tokenizer.convert_tokens_to_ids(first_sentance + second_sentance)\n",
    "    len_first = len(first_sentance)\n",
    "    len_second = len(second_sentance)\n",
    "    tokens_tensor = torch.tensor(tokens)\n",
    "    segments_tensor = torch.tensor([0] * len_first + [1] * len_second, dtype=torch.long)\n",
    "    # Convert label to one hot encoding\n",
    "    label_onehot_tensor = torch.zeros([len(preprocess_module.label)])\n",
    "    for each_class in df['categories'][sid]:\n",
    "        label_onehot_tensor[preprocess_module.label[each_class]] = 1\n",
    "    df_tokenize.append([tokens_tensor, segments_tensor, label_onehot_tensor])\n",
    "train_loader = torch.utils.data.DataLoader(df_tokenize, batch_size=preprocess_module.batch_size, collate_fn=preprocess_module.create_mini_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'agree': 0,\n",
       " 'applause': 1,\n",
       " 'awww': 2,\n",
       " 'dance': 3,\n",
       " 'deal_with_it': 4,\n",
       " 'do_not_want': 5,\n",
       " 'eww': 6,\n",
       " 'eye_roll': 7,\n",
       " 'facepalm': 8,\n",
       " 'fist_bump': 9,\n",
       " 'good_luck': 10,\n",
       " 'happy_dance': 11,\n",
       " 'hearts': 12,\n",
       " 'high_five': 13,\n",
       " 'hug': 14,\n",
       " 'idk': 15,\n",
       " 'kiss': 16,\n",
       " 'mic_drop': 17,\n",
       " 'no': 18,\n",
       " 'oh_snap': 19,\n",
       " 'ok': 20,\n",
       " 'omg': 21,\n",
       " 'oops': 22,\n",
       " 'please': 23,\n",
       " 'popcorn': 24,\n",
       " 'scared': 25,\n",
       " 'seriously': 26,\n",
       " 'shocked': 27,\n",
       " 'shrug': 28,\n",
       " 'sigh': 29,\n",
       " 'slow_clap': 30,\n",
       " 'smh': 31,\n",
       " 'sorry': 32,\n",
       " 'thank_you': 33,\n",
       " 'thumbs_down': 34,\n",
       " 'thumbs_up': 35,\n",
       " 'want': 36,\n",
       " 'win': 37,\n",
       " 'wink': 38,\n",
       " 'yawn': 39,\n",
       " 'yes': 40,\n",
       " 'yolo': 41,\n",
       " 'you_got_this': 42}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model, dataloader, compute_acc=False):\n",
    "    predictions = None\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    avg_map = 0\n",
    "    total_predict = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Traverse all batches\n",
    "        for data in tqdm(dataloader, desc='Prediction progress: '):\n",
    "            # Move tensors to GPU if we can\n",
    "            if next(model.parameters()).is_cuda:\n",
    "                data = [t.to(\"cpu\") for t in data if t is not None]\n",
    "#                 data = [t.to(\"cuda:0\") for t in data if t is not None]\n",
    "\n",
    "\n",
    "            # 別忘記前 3 個 tensors 分別為 tokens, segments 以及 masks\n",
    "            # 且強烈建議在將這些 tensors 丟入 `model` 時指定對應的參數名稱\n",
    "            tokens_tensors, segments_tensors, masks_tensors = data[:3]\n",
    "            outputs = model(input_ids=tokens_tensors, \n",
    "                            token_type_ids=segments_tensors, \n",
    "                            attention_mask=masks_tensors)\n",
    "\n",
    "            logits = outputs\n",
    "            \n",
    "            logits = logits.sigmoid()\n",
    "            \n",
    "            sorted_logits, sorted_index = torch.sort(logits.data, descending=True)\n",
    "            \n",
    "            for eid, each_predict in enumerate(sorted_index.detach().numpy()):\n",
    "#             for eid, each_predict in enumerate(sorted_index.cpu().detach().numpy()):\n",
    "                predict_class = []\n",
    "                correct = 0\n",
    "                for key, value in categories_mapping.items():\n",
    "                    if value in each_predict[0:6]:\n",
    "                        if key == df['categories'][eid][0] and compute_acc is True:\n",
    "                            correct += 1\n",
    "                        predict_class.append(key)\n",
    "                avg_map += (correct / len(df['categories'][eid]))\n",
    "                \n",
    "#                 print(\"answer = {}\".format(df['categories'][eid]))\n",
    "#                 print(\"predict = {}\".format(predict_class))\n",
    "#                 print(\"each map = {}\".format(correct / len(df['categories'][eid])))\n",
    "                total_predict.append(predict_class)\n",
    "\n",
    "    avg_map /= len(df['categories'])\n",
    "    print(\"avg map = {}\".format(avg_map))\n",
    "\n",
    "    if compute_acc:\n",
    "        return total_predict, avg_map\n",
    "    return total_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Prediction progress: ', max=125.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg map = 0.3349322916666672\n"
     ]
    }
   ],
   "source": [
    "_, acc = get_predictions(tuned_model, train_loader, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev = pd.read_json('./source/dev_unlabeled.json', lines=True)\n",
    "df_dev_result = df_dev.copy()\n",
    "df_dev['text'] = df.text.apply(preprocess_tweet)\n",
    "df_dev['reply'] = df.reply.apply(preprocess_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mini_batch_dev(corpus):\n",
    "    tokens_tensors = [sentance[0] for sentance in corpus]\n",
    "    segments_tensors = [sentance[1] for sentance in corpus]\n",
    "    # zero padding\n",
    "    tokens_tensors = torch.nn.utils.rnn.pad_sequence(tokens_tensors, batch_first=True)\n",
    "    segments_tensors = torch.nn.utils.rnn.pad_sequence(segments_tensors, batch_first=True)\n",
    "    # attention masks to set non-zero padding position to one to let BERT focus on these tokens\n",
    "    masks_tensors = torch.zeros(tokens_tensors.shape, dtype=torch.long)\n",
    "    masks_tensors = masks_tensors.masked_fill(tokens_tensors != 0, 1)\n",
    "    return tokens_tensors, segments_tensors, masks_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev_tokenize = []\n",
    "for sid, sentance in enumerate(df_dev['text']):\n",
    "    sentance_reply = df['reply'][sid]\n",
    "    token_sentance = preprocess_module.tokenize(sentance)\n",
    "    token_reply = preprocess_module.tokenize(sentance_reply)\n",
    "    \n",
    "    # Since max length will > max_seq_length, need to truncate pairs\n",
    "    truncate_seq_pair(token_sentance, token_reply, max_seq_length - 3)\n",
    "    \n",
    "    first_sentance = ['[CLS]'] + token_sentance + ['[SEP]']\n",
    "    second_sentance = token_reply + ['[SEP]']\n",
    "    tokens = preprocess_module.tokenizer.convert_tokens_to_ids(first_sentance + second_sentance)\n",
    "    len_first = len(first_sentance)\n",
    "    len_second = len(second_sentance)\n",
    "    tokens_tensor = torch.tensor(tokens)\n",
    "    segments_tensor = torch.tensor([0] * len_first + [1] * len_second, dtype=torch.long)\n",
    "\n",
    "    df_dev_tokenize.append([tokens_tensor, segments_tensor])\n",
    "dev_loader = torch.utils.data.DataLoader(df_dev_tokenize, batch_size=preprocess_module.batch_size, collate_fn=create_mini_batch_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions_dev(model, dataloader, compute_acc=False):\n",
    "    predictions = None\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    avg_map = 0\n",
    "    total_predict = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # 遍巡整個資料集\n",
    "        for data in tqdm(dataloader, desc='Prediction progress: '):\n",
    "            # 將所有 tensors 移到 GPU 上\n",
    "            if next(model.parameters()).is_cuda:\n",
    "#                 data = [t.to(\"cpu\") for t in data if t is not None]\n",
    "                data = [t.to(\"cuda:0\") for t in data if t is not None]\n",
    "\n",
    "\n",
    "            # 別忘記前 3 個 tensors 分別為 tokens, segments 以及 masks\n",
    "            # 且強烈建議在將這些 tensors 丟入 `model` 時指定對應的參數名稱\n",
    "            tokens_tensors, segments_tensors, masks_tensors = data[:3]\n",
    "            outputs = model(input_ids=tokens_tensors, \n",
    "                            token_type_ids=segments_tensors, \n",
    "                            attention_mask=masks_tensors)\n",
    "\n",
    "            logits = outputs\n",
    "            \n",
    "            logits = logits.sigmoid()\n",
    "            \n",
    "            sorted_logits, sorted_index = torch.sort(logits.data, descending=True)\n",
    "            \n",
    "#             for eid, each_predict in enumerate(sorted_index.detach().numpy()):\n",
    "            for eid, each_predict in enumerate(sorted_index.cpu().detach().numpy()):\n",
    "                predict_class = []\n",
    "                for key, value in categories_mapping.items():\n",
    "                    if value in each_predict[0:6]:\n",
    "                        predict_class.append(key)\n",
    "                total_predict.append(predict_class)\n",
    "    return total_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Prediction progress: ', max=16.0, style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dev_predictions = get_predictions_dev(tuned_model, dev_loader, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev_result['categories'] = dev_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "      <th>reply</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32000</td>\n",
       "      <td>Drop your cash app, use hashtag #BailoutHumansNow</td>\n",
       "      <td>$tyratomaro #BailoutHumans</td>\n",
       "      <td>[agree, applause, facepalm, hug, omg, smh]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32001</td>\n",
       "      <td>After interviewing with a few incredible peopl...</td>\n",
       "      <td>CONGRATS!!!!!</td>\n",
       "      <td>[agree, applause, hug, shocked, smh, yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32002</td>\n",
       "      <td>I know GTC festival not happening next month b...</td>\n",
       "      <td></td>\n",
       "      <td>[applause, facepalm, hug, no, oops, yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32003</td>\n",
       "      <td>Lordy, my daughter just said, “I wonder how th...</td>\n",
       "      <td></td>\n",
       "      <td>[agree, applause, hug, seriously, smh, yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32004</td>\n",
       "      <td>THE UNEMPLOYMENT CLAIM SYSTEM SUCKS SO MUCH DICK</td>\n",
       "      <td>Watching everyone else get their weekly unempl...</td>\n",
       "      <td>[agree, applause, do_not_want, hug, smh, yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>35995</td>\n",
       "      <td>WHY TF DO LOCALS LIKE USING GIFS SO MUCH THEYR...</td>\n",
       "      <td></td>\n",
       "      <td>[agree, applause, facepalm, hug, no, yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>35996</td>\n",
       "      <td>Choose a gif that best describes the Republica...</td>\n",
       "      <td></td>\n",
       "      <td>[agree, applause, hug, omg, smh, yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>35997</td>\n",
       "      <td>fuck soon</td>\n",
       "      <td>When soon</td>\n",
       "      <td>[agree, applause, facepalm, hug, smh, yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>35998</td>\n",
       "      <td>SOMEBODY GIVE ME A HUG PLEASE \\n\\nI would real...</td>\n",
       "      <td>I hope you’re doing okay or will be okay!! Sen...</td>\n",
       "      <td>[agree, applause, facepalm, hug, thank_you, yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>35999</td>\n",
       "      <td>Alright, I gotta give my daughter a bath. \\n\\n...</td>\n",
       "      <td>pick meeee! haha $astich1997 but on a serious ...</td>\n",
       "      <td>[agree, applause, hug, omg, seriously, yes]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        idx                                               text  \\\n",
       "0     32000  Drop your cash app, use hashtag #BailoutHumansNow   \n",
       "1     32001  After interviewing with a few incredible peopl...   \n",
       "2     32002  I know GTC festival not happening next month b...   \n",
       "3     32003  Lordy, my daughter just said, “I wonder how th...   \n",
       "4     32004   THE UNEMPLOYMENT CLAIM SYSTEM SUCKS SO MUCH DICK   \n",
       "...     ...                                                ...   \n",
       "3995  35995  WHY TF DO LOCALS LIKE USING GIFS SO MUCH THEYR...   \n",
       "3996  35996  Choose a gif that best describes the Republica...   \n",
       "3997  35997                                          fuck soon   \n",
       "3998  35998  SOMEBODY GIVE ME A HUG PLEASE \\n\\nI would real...   \n",
       "3999  35999  Alright, I gotta give my daughter a bath. \\n\\n...   \n",
       "\n",
       "                                                  reply  \\\n",
       "0                            $tyratomaro #BailoutHumans   \n",
       "1                                         CONGRATS!!!!!   \n",
       "2                                                         \n",
       "3                                                         \n",
       "4     Watching everyone else get their weekly unempl...   \n",
       "...                                                 ...   \n",
       "3995                                                      \n",
       "3996                                                      \n",
       "3997                                          When soon   \n",
       "3998  I hope you’re doing okay or will be okay!! Sen...   \n",
       "3999  pick meeee! haha $astich1997 but on a serious ...   \n",
       "\n",
       "                                            categories  \n",
       "0           [agree, applause, facepalm, hug, omg, smh]  \n",
       "1            [agree, applause, hug, shocked, smh, yes]  \n",
       "2             [applause, facepalm, hug, no, oops, yes]  \n",
       "3          [agree, applause, hug, seriously, smh, yes]  \n",
       "4        [agree, applause, do_not_want, hug, smh, yes]  \n",
       "...                                                ...  \n",
       "3995         [agree, applause, facepalm, hug, no, yes]  \n",
       "3996             [agree, applause, hug, omg, smh, yes]  \n",
       "3997        [agree, applause, facepalm, hug, smh, yes]  \n",
       "3998  [agree, applause, facepalm, hug, thank_you, yes]  \n",
       "3999       [agree, applause, hug, omg, seriously, yes]  \n",
       "\n",
       "[4000 rows x 4 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev_result.to_json('./results/dev.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tokens_tensors.shape   = torch.Size([128, 145]) \n",
      "tensor([[  101,  2057,  2064,  ...,     0,     0,     0],\n",
      "        [  101,  2097,  2017,  ...,     0,     0,     0],\n",
      "        [  101,  3652,  2039,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 16392,  2007,  ...,     0,     0,     0],\n",
      "        [  101,  1045,  2165,  ...,     0,     0,     0],\n",
      "        [  101,  1030,  5795,  ...,     0,     0,     0]])\n",
      "------------------------\n",
      "segments_tensors.shape = torch.Size([128, 145])\n",
      "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]])\n",
      "------------------------\n",
      "masks_tensors.shape    = torch.Size([128, 145])\n",
      "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])\n",
      "------------------------\n",
      "tensor([[0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Only for testing successful running\n",
    "tokens_tensors, segments_tensors, \\\n",
    "    masks_tensors, label_ids = next(iter(train_loader))\n",
    "print(f\"\"\"\n",
    "tokens_tensors.shape   = {tokens_tensors.shape} \n",
    "{tokens_tensors}\n",
    "------------------------\n",
    "segments_tensors.shape = {segments_tensors.shape}\n",
    "{segments_tensors}\n",
    "------------------------\n",
    "masks_tensors.shape    = {masks_tensors.shape}\n",
    "{masks_tensors}\n",
    "------------------------\n",
    "{label_ids}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Emotions Unnormalized')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualization of training classes\n",
    "categories_dict = defaultdict(lambda: 0)\n",
    "for i in range(len(df)):\n",
    "    for each_category in df['categories'][i]:\n",
    "        categories_dict[each_category] += 1\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.barh(list(categories_dict.keys()), categories_dict.values())\n",
    "plt.title('Emotions Unnormalized')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
