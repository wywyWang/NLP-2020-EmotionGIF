{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from random import random\n",
    "import emoji\n",
    "from tqdm import notebook\n",
    "def tqdm(x, **kargs):\n",
    "    return notebook.tqdm(x, leave=False, **kargs)\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from collections import Counter, defaultdict\n",
    "import torch\n",
    "from torch.nn import BCEWithLogitsLoss, MultiLabelMarginLoss\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0528 05:51:09.214484 139967809861440 file_utils.py:39] PyTorch version 1.5.0 available.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel, BertTokenizer, BertForSequenceClassification\n",
    "from transformers.modeling_bert import BertPreTrainedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaModel, RobertaTokenizer, RobertaForSequenceClassification\n",
    "from transformers.modeling_roberta import ROBERTA_PRETRAINED_MODEL_ARCHIVE_MAP, RobertaClassificationHead\n",
    "from transformers.configuration_roberta import RobertaConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simpletransformers.classification import MultiLabelClassificationModel\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_json('./source/train_gold.json', lines=True)\n",
    "df_new = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "multi_hot = mlb.fit_transform(df_new['categories'].values)\n",
    "multi_hot_list = [list(_) for _ in multi_hot]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_new['labels'] = multi_hot_list\n",
    "df_new = df_new[['text', 'reply', 'labels']]\n",
    "df_new.columns = ['text_a', 'text_b', 'labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_a</th>\n",
       "      <th>text_b</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>we can all agree that any song by Niall Horan.</td>\n",
       "      <td>oui oui</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Will you be installing #ScottyFromMarketing's ...</td>\n",
       "      <td></td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Growing up my mum would call me a Nigga despit...</td>\n",
       "      <td>And he joins in??? Pour some hot grits on em</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rest your head on my chest when the world feel...</td>\n",
       "      <td>ðŸ˜‚ðŸ˜‚ðŸ˜‚ðŸ˜‚ðŸ˜‚</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Imagine Will Hernandez and Wills both doing a ...</td>\n",
       "      <td></td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              text_a  \\\n",
       "0     we can all agree that any song by Niall Horan.   \n",
       "1  Will you be installing #ScottyFromMarketing's ...   \n",
       "2  Growing up my mum would call me a Nigga despit...   \n",
       "3  Rest your head on my chest when the world feel...   \n",
       "4  Imagine Will Hernandez and Wills both doing a ...   \n",
       "\n",
       "                                         text_b  \\\n",
       "0                                       oui oui   \n",
       "1                                                 \n",
       "2  And he joins in??? Pour some hot grits on em   \n",
       "3                                         ðŸ˜‚ðŸ˜‚ðŸ˜‚ðŸ˜‚ðŸ˜‚   \n",
       "4                                                 \n",
       "\n",
       "                                              labels  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_args = {\n",
    "    \"output_dir\": \"outputs/\",\n",
    "    \"cache_dir\": \"cache/\",\n",
    "    \"best_model_dir\": \"outputs/best_model/\",\n",
    "\n",
    "    \"fp16\": False,\n",
    "    \"fp16_opt_level\": \"O1\",\n",
    "    \"max_seq_length\": 128,\n",
    "    \"train_batch_size\": 32,\n",
    "    \"eval_batch_size\": 32,\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"num_train_epochs\": 1,\n",
    "    \"weight_decay\": 0,\n",
    "    \"learning_rate\": 4e-5,\n",
    "    \"adam_epsilon\": 1e-8,\n",
    "    \"warmup_ratio\": 0.06,\n",
    "    \"warmup_steps\": 0,\n",
    "    \"max_grad_norm\": 1.0,\n",
    "    \"do_lower_case\": False,\n",
    "\n",
    "    \"logging_steps\": 50,\n",
    "    \"evaluate_during_training\": False,\n",
    "    \"evaluate_during_training_steps\": 2000,\n",
    "    \"evaluate_during_training_verbose\": False,\n",
    "    \"use_cached_eval_features\": False,\n",
    "    \"save_eval_checkpoints\": True,\n",
    "    \"save_steps\": 2000,\n",
    "    \"no_cache\": False,\n",
    "    \"save_model_every_epoch\": True,\n",
    "    \"tensorboard_dir\": None,\n",
    "\n",
    "    \"overwrite_output_dir\": False,\n",
    "    \"reprocess_input_data\": True,\n",
    "\n",
    "    \"n_gpu\": 1,\n",
    "    \"silent\": False,\n",
    "    \"use_multiprocessing\": False,\n",
    "\n",
    "    \"wandb_project\": None,\n",
    "    \"wandb_kwargs\": {},\n",
    "\n",
    "    \"use_early_stopping\": True,\n",
    "    \"early_stopping_patience\": 3,\n",
    "    \"early_stopping_delta\": 0,\n",
    "    \"early_stopping_metric\": \"eval_loss\",\n",
    "    \"early_stopping_metric_minimize\": True,\n",
    "\n",
    "    \"manual_seed\": None,\n",
    "    \"encoding\": None,\n",
    "    \"config\": {}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0528 08:05:44.215915 140570683492160 configuration_utils.py:285] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at /home/ino/.cache/torch/transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690\n",
      "I0528 08:05:44.216937 140570683492160 configuration_utils.py:321] Model config RobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\",\n",
      "    \"15\": \"LABEL_15\",\n",
      "    \"16\": \"LABEL_16\",\n",
      "    \"17\": \"LABEL_17\",\n",
      "    \"18\": \"LABEL_18\",\n",
      "    \"19\": \"LABEL_19\",\n",
      "    \"20\": \"LABEL_20\",\n",
      "    \"21\": \"LABEL_21\",\n",
      "    \"22\": \"LABEL_22\",\n",
      "    \"23\": \"LABEL_23\",\n",
      "    \"24\": \"LABEL_24\",\n",
      "    \"25\": \"LABEL_25\",\n",
      "    \"26\": \"LABEL_26\",\n",
      "    \"27\": \"LABEL_27\",\n",
      "    \"28\": \"LABEL_28\",\n",
      "    \"29\": \"LABEL_29\",\n",
      "    \"30\": \"LABEL_30\",\n",
      "    \"31\": \"LABEL_31\",\n",
      "    \"32\": \"LABEL_32\",\n",
      "    \"33\": \"LABEL_33\",\n",
      "    \"34\": \"LABEL_34\",\n",
      "    \"35\": \"LABEL_35\",\n",
      "    \"36\": \"LABEL_36\",\n",
      "    \"37\": \"LABEL_37\",\n",
      "    \"38\": \"LABEL_38\",\n",
      "    \"39\": \"LABEL_39\",\n",
      "    \"40\": \"LABEL_40\",\n",
      "    \"41\": \"LABEL_41\",\n",
      "    \"42\": \"LABEL_42\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_15\": 15,\n",
      "    \"LABEL_16\": 16,\n",
      "    \"LABEL_17\": 17,\n",
      "    \"LABEL_18\": 18,\n",
      "    \"LABEL_19\": 19,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_20\": 20,\n",
      "    \"LABEL_21\": 21,\n",
      "    \"LABEL_22\": 22,\n",
      "    \"LABEL_23\": 23,\n",
      "    \"LABEL_24\": 24,\n",
      "    \"LABEL_25\": 25,\n",
      "    \"LABEL_26\": 26,\n",
      "    \"LABEL_27\": 27,\n",
      "    \"LABEL_28\": 28,\n",
      "    \"LABEL_29\": 29,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_30\": 30,\n",
      "    \"LABEL_31\": 31,\n",
      "    \"LABEL_32\": 32,\n",
      "    \"LABEL_33\": 33,\n",
      "    \"LABEL_34\": 34,\n",
      "    \"LABEL_35\": 35,\n",
      "    \"LABEL_36\": 36,\n",
      "    \"LABEL_37\": 37,\n",
      "    \"LABEL_38\": 38,\n",
      "    \"LABEL_39\": 39,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_40\": 40,\n",
      "    \"LABEL_41\": 41,\n",
      "    \"LABEL_42\": 42,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0528 08:05:44.294339 140570683492160 modeling_utils.py:650] loading weights file https://cdn.huggingface.co/roberta-base-pytorch_model.bin from cache at /home/ino/.cache/torch/transformers/80b4a484eddeb259bec2f06a6f2f05d90934111628e0e1c09a33bd4a121358e1.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n",
      "I0528 08:05:48.327305 140570683492160 modeling_utils.py:741] Weights of RobertaForMultiLabelSequenceClassification not initialized from pretrained model: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "I0528 08:05:48.328436 140570683492160 modeling_utils.py:747] Weights from pretrained model not used in RobertaForMultiLabelSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
      "I0528 08:05:50.353892 140570683492160 tokenization_utils.py:1015] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /home/ino/.cache/torch/transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "I0528 08:05:50.354712 140570683492160 tokenization_utils.py:1015] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /home/ino/.cache/torch/transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n"
     ]
    }
   ],
   "source": [
    "model = MultiLabelClassificationModel('roberta', 'roberta-base', num_labels=43, args=train_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0528 08:06:00.336354 140570683492160 classification_model.py:801]  Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89f58fe61fba404f8f9dbbc5a4ee4d61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=32000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1c2cc5cff5f4a0b8076217067b58bc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=1.0, style=ProgressStyle(description_width='iâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3e2f682688b44d492b576ff34fc6186",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Current iteration', max=1000.0, style=ProgressStyle(descrâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss: 0.134398"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0528 08:11:50.538516 140570683492160 configuration_utils.py:144] Configuration saved in outputs/checkpoint-1000-epoch-1/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0528 08:11:51.021540 140570683492160 modeling_utils.py:483] Model weights saved in outputs/checkpoint-1000-epoch-1/pytorch_model.bin\n",
      "I0528 08:11:51.777126 140570683492160 configuration_utils.py:144] Configuration saved in outputs/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0528 08:11:52.144607 140570683492160 modeling_utils.py:483] Model weights saved in outputs/pytorch_model.bin\n",
      "I0528 08:11:52.224653 140570683492160 classification_model.py:279]  Training of roberta model complete. Saved to outputs/.\n"
     ]
    }
   ],
   "source": [
    "model.train_model(df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23e24ac063ab4c00b607e4f375275d0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=32000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5be4cd63d46b4889a1aa5bb956147b76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'LRAP': 0.33911590707358946, 'eval_loss': 0.12927393313497304}\n",
      "[[0.106563   0.09228969 0.02660343 ... 0.09141588 0.00963511 0.01519078]\n",
      " [0.10476324 0.08627755 0.02636511 ... 0.10016949 0.00949513 0.0167002 ]\n",
      " [0.10462174 0.10616038 0.02834731 ... 0.07819244 0.01117014 0.01637008]\n",
      " ...\n",
      " [0.05707459 0.0700381  0.03948026 ... 0.05524815 0.01141504 0.0683881 ]\n",
      " [0.07803417 0.12146964 0.04013249 ... 0.08036377 0.00937227 0.03468832]\n",
      " [0.1031523  0.10981105 0.02947175 ... 0.07654577 0.01117176 0.01665912]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "result, model_outputs, wrong_predictions = model.eval_model(df_new)\n",
    "print(result)\n",
    "print(model_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg map = 0.45852552083333087\n"
     ]
    }
   ],
   "source": [
    "avg_map = 0\n",
    "total_predict = []\n",
    "\n",
    "for eid, each_outputs in enumerate(model_outputs):\n",
    "    predict_class = []\n",
    "    correct = 0\n",
    "    sort_index = sorted(range(len(model_outputs[eid])), key=lambda k: model_outputs[eid][k], reverse=True)\n",
    "    for key, value in categories_mapping.items():\n",
    "        if value in sort_index[0:6]:\n",
    "            if key in df['categories'][eid]:\n",
    "                correct += 1\n",
    "            predict_class.append(key)\n",
    "    avg_map += (correct / len(df['categories'][eid]))\n",
    "    total_predict.append(predict_class)\n",
    "\n",
    "avg_map /= len(df['categories'])\n",
    "print(\"avg map = {}\".format(avg_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_a</th>\n",
       "      <th>text_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Drop your cash app, use hashtag #BailoutHumansNow</td>\n",
       "      <td>$tyratomaro #BailoutHumans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>After interviewing with a few incredible peopl...</td>\n",
       "      <td>CONGRATS!!!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I know GTC festival not happening next month b...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lordy, my daughter just said, â€œI wonder how th...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>THE UNEMPLOYMENT CLAIM SYSTEM SUCKS SO MUCH DICK</td>\n",
       "      <td>Watching everyone else get their weekly unempl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              text_a  \\\n",
       "0  Drop your cash app, use hashtag #BailoutHumansNow   \n",
       "1  After interviewing with a few incredible peopl...   \n",
       "2  I know GTC festival not happening next month b...   \n",
       "3  Lordy, my daughter just said, â€œI wonder how th...   \n",
       "4   THE UNEMPLOYMENT CLAIM SYSTEM SUCKS SO MUCH DICK   \n",
       "\n",
       "                                              text_b  \n",
       "0                         $tyratomaro #BailoutHumans  \n",
       "1                                      CONGRATS!!!!!  \n",
       "2                                                     \n",
       "3                                                     \n",
       "4  Watching everyone else get their weekly unempl...  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev = pd.read_json('./source/dev_unlabeled.json', lines=True)\n",
    "df_dev_result = df_dev.copy()[['text', 'reply']]\n",
    "df_dev_result.columns = ['text_a', 'text_b']\n",
    "df_dev_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0528 09:11:03.788838 140570683492160 classification_model.py:801]  Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ff73c65123d4fefab75861ebcb11b8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78c9514e03094f349c4c482e6ea5db0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=125.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "predictions, raw_outputs = model.predict(df_dev_result['text_a'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 43)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_predict = []\n",
    "for eid, row in enumerate(raw_outputs):\n",
    "    predict_class = []\n",
    "    correct = 0\n",
    "    sort_index = sorted(range(len(row)), key=lambda k: row[k], reverse=True)\n",
    "    for key, value in categories_mapping.items():\n",
    "        if value in sort_index[0:6]:\n",
    "            predict_class.append(key)\n",
    "    total_predict.append(predict_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev['categories'] = total_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "      <th>reply</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32000</td>\n",
       "      <td>Drop your cash app, use hashtag #BailoutHumansNow</td>\n",
       "      <td>$tyratomaro #BailoutHumans</td>\n",
       "      <td>[agree, applause, awww, hug, thank_you, yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32001</td>\n",
       "      <td>After interviewing with a few incredible peopl...</td>\n",
       "      <td>CONGRATS!!!!!</td>\n",
       "      <td>[agree, applause, hug, no, slow_clap, yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32002</td>\n",
       "      <td>I know GTC festival not happening next month b...</td>\n",
       "      <td></td>\n",
       "      <td>[agree, applause, no, seriously, shocked, yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32003</td>\n",
       "      <td>Lordy, my daughter just said, â€œI wonder how th...</td>\n",
       "      <td></td>\n",
       "      <td>[agree, applause, facepalm, seriously, sigh, smh]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32004</td>\n",
       "      <td>THE UNEMPLOYMENT CLAIM SYSTEM SUCKS SO MUCH DICK</td>\n",
       "      <td>Watching everyone else get their weekly unempl...</td>\n",
       "      <td>[agree, applause, facepalm, no, seriously, smh]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     idx                                               text  \\\n",
       "0  32000  Drop your cash app, use hashtag #BailoutHumansNow   \n",
       "1  32001  After interviewing with a few incredible peopl...   \n",
       "2  32002  I know GTC festival not happening next month b...   \n",
       "3  32003  Lordy, my daughter just said, â€œI wonder how th...   \n",
       "4  32004   THE UNEMPLOYMENT CLAIM SYSTEM SUCKS SO MUCH DICK   \n",
       "\n",
       "                                               reply  \\\n",
       "0                         $tyratomaro #BailoutHumans   \n",
       "1                                      CONGRATS!!!!!   \n",
       "2                                                      \n",
       "3                                                      \n",
       "4  Watching everyone else get their weekly unempl...   \n",
       "\n",
       "                                          categories  \n",
       "0       [agree, applause, awww, hug, thank_you, yes]  \n",
       "1         [agree, applause, hug, no, slow_clap, yes]  \n",
       "2     [agree, applause, no, seriously, shocked, yes]  \n",
       "3  [agree, applause, facepalm, seriously, sigh, smh]  \n",
       "4    [agree, applause, facepalm, no, seriously, smh]  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev.to_json('./results/dev.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/minerva-ml/open-solution-toxic-comments/blob/master/external_data/apostrophes.json\n",
    "apostrophes = {\n",
    "  \"arent\": \"are not\",\n",
    "  \"cant\": \"cannot\",\n",
    "  \"couldnt\": \"could not\",\n",
    "  \"didnt\": \"did not\",\n",
    "  \"doesnt\": \"does not\",\n",
    "  \"dont\": \"do not\",\n",
    "  \"hadnt\": \"had not\",\n",
    "  \"hasnt\": \"has not\",\n",
    "  \"havent\": \"have not\",\n",
    "  \"hed\": \"he would\",\n",
    "  \"hell\": \"he will\",\n",
    "  \"hes\": \"he is\",\n",
    "  \"id\": \"I had\",\n",
    "  \"ill\": \"I will\",\n",
    "  \"im\": \"I am\",\n",
    "  \"isnt\": \"is not\",\n",
    "  \"its\": \"it is\",\n",
    "  \"itll\": \"it will\",\n",
    "  \"ive\": \"I have\",\n",
    "  \"lets\": \"let us\",\n",
    "  \"mightnt\": \"might not\",\n",
    "  \"mustnt\": \"must not\",\n",
    "  \"shant\": \"shall not\",\n",
    "  \"shed\" : \"she would\",\n",
    "  \"shell\": \"she will\",\n",
    "  \"shes\": \"she is\",\n",
    "  \"shouldnt\": \"should not\",\n",
    "  \"thats\": \"that is\",\n",
    "  \"theres\": \"there is\",\n",
    "  \"theyd\": \"they would\",\n",
    "  \"theyll\": \"they will\",\n",
    "  \"theyre\": \"they are\",\n",
    "  \"theyve\": \"they have\",\n",
    "  \"wed\": \"we would\",\n",
    "  \"were\": \"we are\",\n",
    "  \"werent\": \"were not\",\n",
    "  \"weve\": \"we have\",\n",
    "  \"whatll\": \"what will\",\n",
    "  \"whatre\": \"what are\",\n",
    "  \"whats\": \"what is\",\n",
    "  \"whatve\": \"what have\",\n",
    "  \"wheres\": \"where is\",\n",
    "  \"whod\": \"who would\",\n",
    "  \"wholl\": \"who will\",\n",
    "  \"whore\": \"who are\",\n",
    "  \"whos\": \"who is\",\n",
    "  \"whove\": \"who have\",\n",
    "  \"wont\": \"will not\",\n",
    "  \"wouldnt\": \"would not\",\n",
    "  \"youd\": \"you would\",\n",
    "  \"youll\": \"you will\",\n",
    "  \"youre\": \"you are\",\n",
    "  \"youve\": \"you have\",\n",
    "  \"re\":  \"are\",\n",
    "  \"wasnt\": \"was not\",\n",
    "  \"well\":  \"will\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/minerva-ml/open-solution-toxic-comments/blob/master/external_data/compiled_bad_words.txt\n",
    "compiled_bad_list = pd.read_csv('https://raw.githubusercontent.com/minerva-ml/open-solution-toxic-comments/master/external_data/compiled_bad_words.txt', header=None)\n",
    "compiled_bad_list = list(compiled_bad_list[0].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://github.com/kaymal/twitter-emotions/blob/master/data-preprocessing.ipynb\n",
    "def preprocess_tweet(tweet):\n",
    "    # To lowercase (not good for VADER)\n",
    "    tweet = tweet.lower()\n",
    "    \n",
    "    # Remove fucking words\n",
    "    for bad_word in compiled_bad_list:\n",
    "        bad_candidate = ' ' + bad_word + ' '\n",
    "        tweet = tweet.replace(bad_candidate, ' ')\n",
    "        \n",
    "    # Replace emoji unicode to text\n",
    "#     tweet = emoji.demojize(tweet)\n",
    "#     tweet = tweet.replace('_', ' ')\n",
    "#     tweet = tweet.replace(':', ' ')\n",
    "    tweet = tweet.encode('ascii', 'ignore').decode('ascii')    \n",
    "    \n",
    "    # Replace apostrophes to original term\n",
    "    for key in apostrophes.keys():\n",
    "        tweet = tweet.replace(' ' + key + ' ', ' ' + apostrophes[key])\n",
    "    \n",
    "    # Remove punctuation\n",
    "    tweet = tweet.replace('.', ' ')\n",
    "    tweet = tweet.replace(',', ' ')\n",
    "    \n",
    "    # Remove HTML special entities (e.g. &amp;)\n",
    "    tweet = re.sub(r'\\&\\w*;', '', tweet)\n",
    "    \n",
    "    #Convert @username to \"user\"\n",
    "    tweet = re.sub('@[^\\s]+', 'user', tweet)\n",
    "    \n",
    "    # Remove whitespace (including new line characters)\n",
    "#     tweet = re.sub(r'\\s\\s+', ' ', tweet)\n",
    "    tweet = tweet.replace('\\t', '')\n",
    "    tweet = tweet.replace('\\n', '')\n",
    "    \n",
    "#     # Remove single space remaining at the front of the tweet.\n",
    "#     tweet = tweet.lstrip(' ')\n",
    "    \n",
    "#     # Remove characters beyond Basic Multilingual Plane (BMP) of Unicode:\n",
    "#     tweet = ''.join(c for c in tweet if c <= '\\uFFFF')\n",
    "    \n",
    "#     # Convert hyperlinks ->>>> For now just replace with http\n",
    "#     tweet = re.sub(r'https?:\\/\\/.*\\/\\w*', 'http', tweet)\n",
    "\n",
    "#     #Remove @user\n",
    "#     tweet = re.sub('@[^\\s]+','',tweet)\n",
    "    \n",
    "#     # Remove tickers such as USD ($)\n",
    "#     tweet = re.sub(r'\\$\\w*', '', tweet)\n",
    "    \n",
    "#     # Remove hashtags (not good for VADER)\n",
    "#     tweet = re.sub(r'#\\w*', '', tweet)\n",
    "    \n",
    "#     # Remove Punctuation and split 's, 't, 've with a space for filter\n",
    "#     tweet = re.sub(r'[' + punctuation.replace('@', '') + ']+', ' ', tweet)\n",
    "    \n",
    "#     # Remove words with 2 or fewer letters\n",
    "#     tweet = re.sub(r'\\b\\w{1,2}\\b', '', tweet)\n",
    "\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a toxic fav line is i just be chilling like no tf you do not\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df['text'] = df.text.apply(preprocess_tweet)\n",
    "df['reply'] = df.reply.apply(preprocess_tweet)\n",
    "print(df['text'][173])\n",
    "print(df['reply'][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_type = pd.read_json('./source/categories.json', lines=True)\n",
    "categories_mapping = {v[0]: k for k, v in categories_type.to_dict('list').items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilabel classification of BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertForMultiLabelSequenceClassification(BertPreTrainedModel):\n",
    "    \"\"\"BERT model for classification. This module is composed of the BERT model with a linear layer on top of the pooled output. \"\"\" \n",
    "    def __init__(self, config, num_labels=43):\n",
    "        super(BertForMultiLabelSequenceClassification, self).__init__(config)\n",
    "        self.num_labels = num_labels\n",
    "        self.bert = BertModel(config)\n",
    "        self.dropout = torch.nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = torch.nn.Linear(config.hidden_size, num_labels)\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None):\n",
    "        print(input_ids)\n",
    "        print(input_ids.shape)\n",
    "        print(token_type_ids)\n",
    "        print(token_type_ids.shape)\n",
    "        _, pooled_output = self.bert(input_ids, token_type_ids, attention_mask)\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        if labels is not None:\n",
    "            loss_fct = BCEWithLogitsLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1, self.num_labels))\n",
    "            return loss\n",
    "        else:\n",
    "            return logits\n",
    "        \n",
    "    def freeze_bert_encoder(self):\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def unfreeze_bert_encoder(self):\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilabel classification of RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobertaForMultiLabelSequenceClassification(BertPreTrainedModel):\n",
    "    \"\"\"\n",
    "    Roberta model adapted for multi-label sequence classification\n",
    "    \"\"\"\n",
    "\n",
    "    config_class = RobertaConfig\n",
    "    pretrained_model_archive_map = ROBERTA_PRETRAINED_MODEL_ARCHIVE_MAP\n",
    "    base_model_prefix = \"roberta\"\n",
    "\n",
    "    def __init__(self, config, pos_weight=None):\n",
    "        super(RobertaForMultiLabelSequenceClassification, self).__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.pos_weight = pos_weight\n",
    "\n",
    "        self.roberta = RobertaModel(config)\n",
    "        self.classifier = RobertaClassificationHead(config)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        labels=None,\n",
    "    ):\n",
    "        outputs = self.roberta(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "        )\n",
    "        sequence_output = outputs[0]\n",
    "        logits = self.classifier(sequence_output)\n",
    "\n",
    "        outputs = (logits,) + outputs[2:]\n",
    "        if labels is not None:\n",
    "            loss_fct = BCEWithLogitsLoss(pos_weight=self.pos_weight)\n",
    "            labels = labels.float()\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1, self.num_labels))\n",
    "            outputs = (loss,) + outputs\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/jiesutd/pytorch-pretrained-BERT/blob/master/examples/lm_finetuning/pregenerate_training_data.py\n",
    "def truncate_seq_pair(tokens_a, tokens_b, max_num_tokens):\n",
    "    \"\"\"Truncates a pair of sequences to a maximum sequence length. Lifted from Google's BERT repo.\"\"\"\n",
    "    while True:\n",
    "        total_length = len(tokens_a) + len(tokens_b)\n",
    "        if total_length <= max_num_tokens:\n",
    "            break\n",
    "\n",
    "        trunc_tokens = tokens_a if len(tokens_a) > len(tokens_b) else tokens_b\n",
    "        assert len(trunc_tokens) >= 1\n",
    "\n",
    "        # We want to sometimes truncate from the front and sometimes from the\n",
    "        # back to add more randomness and avoid biases.\n",
    "        if random() < 0.5:\n",
    "            del trunc_tokens[0]\n",
    "        else:\n",
    "            trunc_tokens.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocess():\n",
    "    def __init__(self, epochs=6, batch_size=64, max_seq_length=128, categories=None):\n",
    "        self.label = categories\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.max_seq_length = max_seq_length\n",
    "#         self.model = BertForMultiLabelSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=len(categories), output_hidden_states=False)\n",
    "#         self.tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "        self.model = RobertaForMultiLabelSequenceClassification.from_pretrained(\"roberta-base\", num_labels=len(categories), output_hidden_states=False)\n",
    "        self.tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "\n",
    "    \n",
    "    def tokenize(self, sentance):\n",
    "        return self.tokenizer.tokenize(sentance)\n",
    "    \n",
    "    def convert_features_to_tensors(self, corpus_text, corpus_reply, corpus_class):\n",
    "        df_tokenize = []\n",
    "        for sid, sentance in enumerate(corpus_text):\n",
    "            sentance_reply = corpus_reply[sid]\n",
    "            token_sentance = self.tokenize(sentance)\n",
    "            token_reply = self.tokenize(sentance_reply)\n",
    "            \n",
    "            # Since max length will > max_seq_length, need to truncate pairs\n",
    "            truncate_seq_pair(token_sentance, token_reply, self.max_seq_length - 3)\n",
    "            \n",
    "            first_sentance = ['[CLS]'] + token_sentance + ['[SEP]']\n",
    "            second_sentance = token_reply + ['[SEP]']\n",
    "            tokens = self.tokenizer.convert_tokens_to_ids(first_sentance + second_sentance)\n",
    "            len_first = len(first_sentance)\n",
    "            len_second = len(second_sentance)\n",
    "            tokens_tensor = torch.tensor(tokens)\n",
    "            segments_tensor = torch.tensor([0] * len_first + [1] * len_second, dtype=torch.long)\n",
    "            # Convert label to one hot encoding\n",
    "            label_onehot_tensor = torch.zeros([len(self.label)])\n",
    "            for each_class in corpus_class[sid]:\n",
    "                label_onehot_tensor[self.label[each_class]] = 1\n",
    "            df_tokenize.append([tokens_tensor, segments_tensor, label_onehot_tensor])\n",
    "        return df_tokenize\n",
    "    \n",
    "    def create_mini_batch(self, corpus):\n",
    "        tokens_tensors = [sentance[0] for sentance in corpus]\n",
    "        segments_tensors = [sentance[1] for sentance in corpus]\n",
    "        labels_tensors = torch.stack([sentance[2] for sentance in corpus])\n",
    "#         labels_tensors = labels_tensors.type(torch.LongTensor)\n",
    "        # zero padding\n",
    "        tokens_tensors = torch.nn.utils.rnn.pad_sequence(tokens_tensors, batch_first=True)\n",
    "        segments_tensors = torch.nn.utils.rnn.pad_sequence(segments_tensors, batch_first=True)\n",
    "        # attention masks to set non-zero padding position to one to let BERT focus on these tokens\n",
    "        masks_tensors = torch.zeros(tokens_tensors.shape, dtype=torch.long)\n",
    "        masks_tensors = masks_tensors.masked_fill(tokens_tensors != 0, 1)\n",
    "        return tokens_tensors, segments_tensors, masks_tensors, labels_tensors\n",
    "    \n",
    "    def train(self, training_data):\n",
    "        # let model training on GPU\n",
    "#         device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"device:\", device)\n",
    "    \n",
    "        # Load pretrained model\n",
    "#         model_state_dict = torch.load('./models/bert_adam_3_256')\n",
    "#         self.model = BertForMultiLabelSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=len(self.label), state_dict=model_state_dict)\n",
    "        self.model = self.model.to(device)\n",
    "        \n",
    "        # training mode\n",
    "        self.model.train()\n",
    "        # select adam as optimizer to update weights\n",
    "        optimizer = torch.optim.AdamW(self.model.parameters(), lr=3e-5)\n",
    "        \n",
    "        for epoch in tqdm(range(self.epochs), desc='Training epochs: '):\n",
    "            running_loss = 0\n",
    "            for data in tqdm(training_data, desc='Training progress: '):\n",
    "                tokens_tensors, segments_tensors, masks_tensors, labels = [t.to(device) for t in data]\n",
    "                # Initial gradients\n",
    "                optimizer.zero_grad()\n",
    "                # forward pass\n",
    "                loss = self.model(input_ids=tokens_tensors, \n",
    "                                token_type_ids=segments_tensors, \n",
    "                                attention_mask=masks_tensors, \n",
    "                                labels=labels)\n",
    "                # backward\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                # Record current batch loss\n",
    "                running_loss += loss.item()\n",
    "            print(\"Epoch: {}, loss: {}\".format(epoch + 1, running_loss))\n",
    "        torch.save(self.model.state_dict(), './models/roberta_adam_{}_{}_{}'.format(self.epochs, self.batch_size, self.max_seq_length))\n",
    "        # Calculate classification accuracy\n",
    "#         _, acc = self.get_predictions(model, training_data, True)\n",
    "        return self.model\n",
    "    \n",
    "    def baseline(self, corpus_text, corpus_reply, corpus_class):\n",
    "        df_tokenize = self.convert_features_to_tensors(corpus_text, corpus_reply, corpus_class)\n",
    "        train_loader = torch.utils.data.DataLoader(df_tokenize, batch_size=self.batch_size, collate_fn=self.create_mini_batch)\n",
    "        tuned_model = self.train(train_loader)\n",
    "        return tuned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0528 07:22:24.394951 139967809861440 configuration_utils.py:285] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at /home/ino/.cache/torch/transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690\n",
      "I0528 07:22:24.396391 139967809861440 configuration_utils.py:321] Model config RobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\",\n",
      "    \"15\": \"LABEL_15\",\n",
      "    \"16\": \"LABEL_16\",\n",
      "    \"17\": \"LABEL_17\",\n",
      "    \"18\": \"LABEL_18\",\n",
      "    \"19\": \"LABEL_19\",\n",
      "    \"20\": \"LABEL_20\",\n",
      "    \"21\": \"LABEL_21\",\n",
      "    \"22\": \"LABEL_22\",\n",
      "    \"23\": \"LABEL_23\",\n",
      "    \"24\": \"LABEL_24\",\n",
      "    \"25\": \"LABEL_25\",\n",
      "    \"26\": \"LABEL_26\",\n",
      "    \"27\": \"LABEL_27\",\n",
      "    \"28\": \"LABEL_28\",\n",
      "    \"29\": \"LABEL_29\",\n",
      "    \"30\": \"LABEL_30\",\n",
      "    \"31\": \"LABEL_31\",\n",
      "    \"32\": \"LABEL_32\",\n",
      "    \"33\": \"LABEL_33\",\n",
      "    \"34\": \"LABEL_34\",\n",
      "    \"35\": \"LABEL_35\",\n",
      "    \"36\": \"LABEL_36\",\n",
      "    \"37\": \"LABEL_37\",\n",
      "    \"38\": \"LABEL_38\",\n",
      "    \"39\": \"LABEL_39\",\n",
      "    \"40\": \"LABEL_40\",\n",
      "    \"41\": \"LABEL_41\",\n",
      "    \"42\": \"LABEL_42\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_15\": 15,\n",
      "    \"LABEL_16\": 16,\n",
      "    \"LABEL_17\": 17,\n",
      "    \"LABEL_18\": 18,\n",
      "    \"LABEL_19\": 19,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_20\": 20,\n",
      "    \"LABEL_21\": 21,\n",
      "    \"LABEL_22\": 22,\n",
      "    \"LABEL_23\": 23,\n",
      "    \"LABEL_24\": 24,\n",
      "    \"LABEL_25\": 25,\n",
      "    \"LABEL_26\": 26,\n",
      "    \"LABEL_27\": 27,\n",
      "    \"LABEL_28\": 28,\n",
      "    \"LABEL_29\": 29,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_30\": 30,\n",
      "    \"LABEL_31\": 31,\n",
      "    \"LABEL_32\": 32,\n",
      "    \"LABEL_33\": 33,\n",
      "    \"LABEL_34\": 34,\n",
      "    \"LABEL_35\": 35,\n",
      "    \"LABEL_36\": 36,\n",
      "    \"LABEL_37\": 37,\n",
      "    \"LABEL_38\": 38,\n",
      "    \"LABEL_39\": 39,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_40\": 40,\n",
      "    \"LABEL_41\": 41,\n",
      "    \"LABEL_42\": 42,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0528 07:22:24.723470 139967809861440 modeling_utils.py:617] loading weights file https://cdn.huggingface.co/roberta-base-pytorch_model.bin from cache at /home/ino/.cache/torch/transformers/80b4a484eddeb259bec2f06a6f2f05d90934111628e0e1c09a33bd4a121358e1.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n",
      "I0528 07:22:28.019290 139967809861440 modeling_utils.py:708] Weights of RobertaForMultiLabelSequenceClassification not initialized from pretrained model: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "I0528 07:22:28.020135 139967809861440 modeling_utils.py:714] Weights from pretrained model not used in RobertaForMultiLabelSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
      "I0528 07:22:29.862237 139967809861440 tokenization_utils.py:1015] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /home/ino/.cache/torch/transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "I0528 07:22:29.862975 139967809861440 tokenization_utils.py:1015] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /home/ino/.cache/torch/transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n"
     ]
    }
   ],
   "source": [
    "preprocess_module = Preprocess(epochs=1, batch_size=32, max_seq_length=max_seq_length, categories=categories_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c333b18d211c4be6ae28da89851bbcc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Training epochs: ', max=1.0, style=ProgressStyle(descriptâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "253f73f9f8474dc988cf11cd3bf5f3b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Training progress: ', max=1000.0, style=ProgressStyle(desâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-126-d4e16d971c2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtuned_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbaseline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reply'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'categories'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-123-b84c3095d92a>\u001b[0m in \u001b[0;36mbaseline\u001b[0;34m(self, corpus_text, corpus_reply, corpus_class)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mdf_tokenize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_features_to_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_reply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_tokenize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_mini_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mtuned_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuned_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-123-b84c3095d92a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, training_data)\u001b[0m\n\u001b[1;32m     77\u001b[0m                                 \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msegments_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                                 \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmasks_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                                 labels=labels)\n\u001b[0m\u001b[1;32m     80\u001b[0m                 \u001b[0;31m# backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-121-2acb3d2de5d1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels)\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         )\n\u001b[1;32m     35\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m         embedding_output = self.embeddings(\n\u001b[0;32m--> 729\u001b[0;31m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m         )\n\u001b[1;32m    731\u001b[0m         encoder_outputs = self.encoder(\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/transformers/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         return super().forward(\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         )\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds)\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0mposition_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0mtoken_type_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_type_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mposition_embeddings\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtoken_type_embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m         return F.embedding(\n\u001b[1;32m    113\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1722\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1723\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1724\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1726\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "tuned_model = preprocess_module.baseline(df['text'], df['reply'], df['categories'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count min, max, and average text length to select proper max_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max text length is: 264\n",
      "Min text length is: 1\n",
      "Average text length is: 28.5055625\n"
     ]
    }
   ],
   "source": [
    "text_cnt = 0\n",
    "max_cnt = 0\n",
    "min_cnt = 1e3\n",
    "text_bar = []\n",
    "for each_text in df['text']:\n",
    "    each_cnt = len(preprocess_module.tokenize(each_text))\n",
    "    text_cnt += each_cnt\n",
    "    text_bar.append(each_cnt % 10)\n",
    "    if each_cnt > max_cnt:\n",
    "        max_cnt = each_cnt\n",
    "    if each_cnt < min_cnt:\n",
    "        min_cnt = each_cnt\n",
    "print(\"Max text length is: {}\".format(max_cnt))\n",
    "print(\"Min text length is: {}\".format(min_cnt))\n",
    "print(\"Average text length is: {}\".format(text_cnt / len(df['text'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count max, min, and average reply length to select proper max_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max reply length is: 135\n",
      "Min reply length is: 0\n",
      "Average reply length is: 4.99925\n"
     ]
    }
   ],
   "source": [
    "reply_cnt = 0\n",
    "max_cnt = 0\n",
    "min_cnt = 1e3\n",
    "reply_bar = []\n",
    "for each_reply in df['reply']:\n",
    "    each_cnt = len(preprocess_module.tokenize(each_reply))\n",
    "    reply_cnt += each_cnt\n",
    "    reply_bar.append(each_cnt % 10)\n",
    "    if each_cnt > max_cnt:\n",
    "        max_cnt = each_cnt\n",
    "    if each_cnt < min_cnt:\n",
    "        min_cnt = each_cnt\n",
    "print(\"Max reply length is: {}\".format(max_cnt))\n",
    "print(\"Min reply length is: {}\".format(min_cnt))\n",
    "print(\"Average reply length is: {}\".format(reply_cnt / len(df['reply'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count max, min, and average text + reply length to select proper max_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max text + reply length is: 161\n",
      "Min text + reply length is: 0\n",
      "Average text + reply length is: 32.1114375\n"
     ]
    }
   ],
   "source": [
    "text_reply_cnt = 0\n",
    "max_cnt = 0\n",
    "min_cnt = 1e3\n",
    "text_reply_bar = []\n",
    "for eid, each_reply in enumerate(df['reply']):\n",
    "    each_text_cnt = len(preprocess_module.tokenize(df['text'][eid]))\n",
    "    each_reply_cnt = len(preprocess_module.tokenize(each_reply))\n",
    "    each_cnt = each_text_cnt + each_reply_cnt\n",
    "    text_reply_bar.append(each_cnt % 10)\n",
    "    text_reply_cnt += each_cnt\n",
    "    if each_cnt > max_cnt:\n",
    "        max_cnt = each_cnt\n",
    "    if each_cnt < min_cnt:\n",
    "        min_cnt = each_cnt\n",
    "print(\"Max text + reply length is: {}\".format(max_cnt))\n",
    "print(\"Min text + reply length is: {}\".format(min_cnt))\n",
    "print(\"Average text + reply length is: {}\".format(text_reply_cnt / len(df['reply'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize above results on 10 steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.bar(text_bar-0.2, y, width=0.2, color='b', align='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(tuned_model.state_dict(), 'test_bert')\n",
    "# # Load a trained model that you have fine-tuned\n",
    "# model_state_dict = torch.load(output_model_file)\n",
    "# model = BertForMultiLabelSequenceClassification.from_pretrained(args['bert_model'], num_labels = num_labels, state_dict=model_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0528 03:14:43.167084 139624844658496 configuration_utils.py:285] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/ino/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "I0528 03:14:43.168590 139624844658496 configuration_utils.py:321] Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\",\n",
      "    \"15\": \"LABEL_15\",\n",
      "    \"16\": \"LABEL_16\",\n",
      "    \"17\": \"LABEL_17\",\n",
      "    \"18\": \"LABEL_18\",\n",
      "    \"19\": \"LABEL_19\",\n",
      "    \"20\": \"LABEL_20\",\n",
      "    \"21\": \"LABEL_21\",\n",
      "    \"22\": \"LABEL_22\",\n",
      "    \"23\": \"LABEL_23\",\n",
      "    \"24\": \"LABEL_24\",\n",
      "    \"25\": \"LABEL_25\",\n",
      "    \"26\": \"LABEL_26\",\n",
      "    \"27\": \"LABEL_27\",\n",
      "    \"28\": \"LABEL_28\",\n",
      "    \"29\": \"LABEL_29\",\n",
      "    \"30\": \"LABEL_30\",\n",
      "    \"31\": \"LABEL_31\",\n",
      "    \"32\": \"LABEL_32\",\n",
      "    \"33\": \"LABEL_33\",\n",
      "    \"34\": \"LABEL_34\",\n",
      "    \"35\": \"LABEL_35\",\n",
      "    \"36\": \"LABEL_36\",\n",
      "    \"37\": \"LABEL_37\",\n",
      "    \"38\": \"LABEL_38\",\n",
      "    \"39\": \"LABEL_39\",\n",
      "    \"40\": \"LABEL_40\",\n",
      "    \"41\": \"LABEL_41\",\n",
      "    \"42\": \"LABEL_42\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_15\": 15,\n",
      "    \"LABEL_16\": 16,\n",
      "    \"LABEL_17\": 17,\n",
      "    \"LABEL_18\": 18,\n",
      "    \"LABEL_19\": 19,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_20\": 20,\n",
      "    \"LABEL_21\": 21,\n",
      "    \"LABEL_22\": 22,\n",
      "    \"LABEL_23\": 23,\n",
      "    \"LABEL_24\": 24,\n",
      "    \"LABEL_25\": 25,\n",
      "    \"LABEL_26\": 26,\n",
      "    \"LABEL_27\": 27,\n",
      "    \"LABEL_28\": 28,\n",
      "    \"LABEL_29\": 29,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_30\": 30,\n",
      "    \"LABEL_31\": 31,\n",
      "    \"LABEL_32\": 32,\n",
      "    \"LABEL_33\": 33,\n",
      "    \"LABEL_34\": 34,\n",
      "    \"LABEL_35\": 35,\n",
      "    \"LABEL_36\": 36,\n",
      "    \"LABEL_37\": 37,\n",
      "    \"LABEL_38\": 38,\n",
      "    \"LABEL_39\": 39,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_40\": 40,\n",
      "    \"LABEL_41\": 41,\n",
      "    \"LABEL_42\": 42,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "I0528 03:14:43.195816 139624844658496 modeling_utils.py:617] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /home/ino/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n"
     ]
    }
   ],
   "source": [
    "model_state_dict = torch.load('./models/bert_adam_3_256_128')\n",
    "model = BertForMultiLabelSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=43, state_dict=model_state_dict)\n",
    "# model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tokenize = []\n",
    "for sid, sentance in enumerate(df['text']):\n",
    "    sentance_reply = df['reply'][sid]\n",
    "    token_sentance = preprocess_module.tokenize(sentance)\n",
    "    token_reply = preprocess_module.tokenize(sentance_reply)\n",
    "    \n",
    "    # Since max length will > max_seq_length, need to truncate pairs\n",
    "    truncate_seq_pair(token_sentance, token_reply, max_seq_length - 3)\n",
    "    \n",
    "    first_sentance = ['[CLS]'] + token_sentance + ['[SEP]']\n",
    "    second_sentance = token_reply + ['[SEP]']\n",
    "    tokens = preprocess_module.tokenizer.convert_tokens_to_ids(first_sentance + second_sentance)\n",
    "    len_first = len(first_sentance)\n",
    "    len_second = len(second_sentance)\n",
    "    tokens_tensor = torch.tensor(tokens)\n",
    "    segments_tensor = torch.tensor([0] * len_first + [1] * len_second, dtype=torch.long)\n",
    "    # Convert label to one hot encoding\n",
    "    label_onehot_tensor = torch.zeros([len(preprocess_module.label)])\n",
    "    for each_class in df['categories'][sid]:\n",
    "        label_onehot_tensor[preprocess_module.label[each_class]] = 1\n",
    "    df_tokenize.append([tokens_tensor, segments_tensor, label_onehot_tensor])\n",
    "train_loader = torch.utils.data.DataLoader(df_tokenize, batch_size=preprocess_module.batch_size, collate_fn=preprocess_module.create_mini_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'agree': 0,\n",
       " 'applause': 1,\n",
       " 'awww': 2,\n",
       " 'dance': 3,\n",
       " 'deal_with_it': 4,\n",
       " 'do_not_want': 5,\n",
       " 'eww': 6,\n",
       " 'eye_roll': 7,\n",
       " 'facepalm': 8,\n",
       " 'fist_bump': 9,\n",
       " 'good_luck': 10,\n",
       " 'happy_dance': 11,\n",
       " 'hearts': 12,\n",
       " 'high_five': 13,\n",
       " 'hug': 14,\n",
       " 'idk': 15,\n",
       " 'kiss': 16,\n",
       " 'mic_drop': 17,\n",
       " 'no': 18,\n",
       " 'oh_snap': 19,\n",
       " 'ok': 20,\n",
       " 'omg': 21,\n",
       " 'oops': 22,\n",
       " 'please': 23,\n",
       " 'popcorn': 24,\n",
       " 'scared': 25,\n",
       " 'seriously': 26,\n",
       " 'shocked': 27,\n",
       " 'shrug': 28,\n",
       " 'sigh': 29,\n",
       " 'slow_clap': 30,\n",
       " 'smh': 31,\n",
       " 'sorry': 32,\n",
       " 'thank_you': 33,\n",
       " 'thumbs_down': 34,\n",
       " 'thumbs_up': 35,\n",
       " 'want': 36,\n",
       " 'win': 37,\n",
       " 'wink': 38,\n",
       " 'yawn': 39,\n",
       " 'yes': 40,\n",
       " 'yolo': 41,\n",
       " 'you_got_this': 42}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model, dataloader, compute_acc=False):\n",
    "    predictions = None\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    avg_map = 0\n",
    "    total_predict = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Traverse all batches\n",
    "        for data in tqdm(dataloader, desc='Prediction progress: '):\n",
    "            # Move tensors to GPU if we can\n",
    "            if next(model.parameters()).is_cuda:\n",
    "#                 data = [t.to(\"cpu\") for t in data if t is not None]\n",
    "                data = [t.to(\"cuda:0\") for t in data if t is not None]\n",
    "\n",
    "\n",
    "            # åˆ¥å¿˜è¨˜å‰ 3 å€‹ tensors åˆ†åˆ¥ç‚º tokens, segments ä»¥åŠ masks\n",
    "            # ä¸”å¼·çƒˆå»ºè­°åœ¨å°‡é€™äº› tensors ä¸Ÿå…¥ `model` æ™‚æŒ‡å®šå°æ‡‰çš„åƒæ•¸åç¨±\n",
    "            tokens_tensors, segments_tensors, masks_tensors = data[:3]\n",
    "            outputs = model(input_ids=tokens_tensors, \n",
    "                            token_type_ids=segments_tensors, \n",
    "                            attention_mask=masks_tensors)\n",
    "\n",
    "            logits = outputs\n",
    "            \n",
    "#             logits = logits.sigmoid()\n",
    "            \n",
    "            sorted_logits, sorted_index = torch.sort(logits.data, descending=True)\n",
    "            \n",
    "#             for eid, each_predict in enumerate(sorted_index.detach().numpy()):\n",
    "            for eid, each_predict in enumerate(sorted_index.cpu().detach().numpy()):\n",
    "                predict_class = []\n",
    "                correct = 0\n",
    "                for key, value in categories_mapping.items():\n",
    "                    if value in each_predict[0:6]:\n",
    "                        if key == df['categories'][eid][0] and compute_acc is True:\n",
    "                            correct += 1\n",
    "                        predict_class.append(key)\n",
    "                avg_map += (correct / len(df['categories'][eid]))\n",
    "                \n",
    "#                 print(\"answer = {}\".format(df['categories'][eid]))\n",
    "#                 print(\"predict = {}\".format(predict_class))\n",
    "#                 print(\"each map = {}\".format(correct / len(df['categories'][eid])))\n",
    "                total_predict.append(predict_class)\n",
    "\n",
    "    avg_map /= len(df['categories'])\n",
    "    print(\"avg map = {}\".format(avg_map))\n",
    "\n",
    "    if compute_acc:\n",
    "        return total_predict, avg_map\n",
    "    return total_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Prediction progress: ', max=250.0, style=ProgressStyle(deâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg map = 0.41369791666666733\n"
     ]
    }
   ],
   "source": [
    "_, acc = get_predictions(model, train_loader, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev = pd.read_json('./source/dev_unlabeled.json', lines=True)\n",
    "df_dev_result = df_dev.copy()\n",
    "df_dev['text'] = df.text.apply(preprocess_tweet)\n",
    "df_dev['reply'] = df.reply.apply(preprocess_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mini_batch_dev(corpus):\n",
    "    tokens_tensors = [sentance[0] for sentance in corpus]\n",
    "    segments_tensors = [sentance[1] for sentance in corpus]\n",
    "    # zero padding\n",
    "    tokens_tensors = torch.nn.utils.rnn.pad_sequence(tokens_tensors, batch_first=True)\n",
    "    segments_tensors = torch.nn.utils.rnn.pad_sequence(segments_tensors, batch_first=True)\n",
    "    # attention masks to set non-zero padding position to one to let BERT focus on these tokens\n",
    "    masks_tensors = torch.zeros(tokens_tensors.shape, dtype=torch.long)\n",
    "    masks_tensors = masks_tensors.masked_fill(tokens_tensors != 0, 1)\n",
    "    return tokens_tensors, segments_tensors, masks_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev_tokenize = []\n",
    "for sid, sentance in enumerate(df_dev['text']):\n",
    "    sentance_reply = df['reply'][sid]\n",
    "    token_sentance = preprocess_module.tokenize(sentance)\n",
    "    token_reply = preprocess_module.tokenize(sentance_reply)\n",
    "    \n",
    "    # Since max length will > max_seq_length, need to truncate pairs\n",
    "    truncate_seq_pair(token_sentance, token_reply, max_seq_length - 3)\n",
    "    \n",
    "    first_sentance = ['[CLS]'] + token_sentance + ['[SEP]']\n",
    "    second_sentance = token_reply + ['[SEP]']\n",
    "    tokens = preprocess_module.tokenizer.convert_tokens_to_ids(first_sentance + second_sentance)\n",
    "    len_first = len(first_sentance)\n",
    "    len_second = len(second_sentance)\n",
    "    tokens_tensor = torch.tensor(tokens)\n",
    "    segments_tensor = torch.tensor([0] * len_first + [1] * len_second, dtype=torch.long)\n",
    "\n",
    "    df_dev_tokenize.append([tokens_tensor, segments_tensor])\n",
    "dev_loader = torch.utils.data.DataLoader(df_dev_tokenize, batch_size=preprocess_module.batch_size, collate_fn=create_mini_batch_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions_dev(model, dataloader, compute_acc=False):\n",
    "    predictions = None\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    avg_map = 0\n",
    "    total_predict = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # éå·¡æ•´å€‹è³‡æ–™é›†\n",
    "        for data in tqdm(dataloader, desc='Prediction progress: '):\n",
    "            # å°‡æ‰€æœ‰ tensors ç§»åˆ° GPU ä¸Š\n",
    "            if next(model.parameters()).is_cuda:\n",
    "#                 data = [t.to(\"cpu\") for t in data if t is not None]\n",
    "                data = [t.to(\"cuda:0\") for t in data if t is not None]\n",
    "\n",
    "\n",
    "            # åˆ¥å¿˜è¨˜å‰ 3 å€‹ tensors åˆ†åˆ¥ç‚º tokens, segments ä»¥åŠ masks\n",
    "            # ä¸”å¼·çƒˆå»ºè­°åœ¨å°‡é€™äº› tensors ä¸Ÿå…¥ `model` æ™‚æŒ‡å®šå°æ‡‰çš„åƒæ•¸åç¨±\n",
    "            tokens_tensors, segments_tensors, masks_tensors = data[:3]\n",
    "            outputs = model(input_ids=tokens_tensors, \n",
    "                            token_type_ids=segments_tensors, \n",
    "                            attention_mask=masks_tensors)\n",
    "\n",
    "            logits = outputs\n",
    "            \n",
    "#             logits = logits.softmax()\n",
    "#             logits = logits.sigmoid()\n",
    "            \n",
    "            sorted_logits, sorted_index = torch.sort(logits.data, descending=True)\n",
    "            \n",
    "#             for eid, each_predict in enumerate(sorted_index.detach().numpy()):\n",
    "            for eid, each_predict in enumerate(sorted_index.cpu().detach().numpy()):\n",
    "                predict_class = []\n",
    "                for key, value in categories_mapping.items():\n",
    "                    if value in each_predict[0:6]:\n",
    "                        predict_class.append(key)\n",
    "                total_predict.append(predict_class)\n",
    "    return total_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Prediction progress: ', max=32.0, style=ProgressStyle(desâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dev_predictions = get_predictions_dev(model, dev_loader, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev_result['categories'] = dev_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "      <th>reply</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32000</td>\n",
       "      <td>Drop your cash app, use hashtag #BailoutHumansNow</td>\n",
       "      <td>$tyratomaro #BailoutHumans</td>\n",
       "      <td>[agree, applause, hug, no, seriously, yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32001</td>\n",
       "      <td>After interviewing with a few incredible peopl...</td>\n",
       "      <td>CONGRATS!!!!!</td>\n",
       "      <td>[agree, applause, facepalm, hug, no, yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32002</td>\n",
       "      <td>I know GTC festival not happening next month b...</td>\n",
       "      <td></td>\n",
       "      <td>[agree, applause, hug, seriously, smh, yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32003</td>\n",
       "      <td>Lordy, my daughter just said, â€œI wonder how th...</td>\n",
       "      <td></td>\n",
       "      <td>[agree, applause, facepalm, hug, no, yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32004</td>\n",
       "      <td>THE UNEMPLOYMENT CLAIM SYSTEM SUCKS SO MUCH DICK</td>\n",
       "      <td>Watching everyone else get their weekly unempl...</td>\n",
       "      <td>[agree, applause, facepalm, hug, no, yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>35995</td>\n",
       "      <td>WHY TF DO LOCALS LIKE USING GIFS SO MUCH THEYR...</td>\n",
       "      <td></td>\n",
       "      <td>[agree, applause, facepalm, hug, no, yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>35996</td>\n",
       "      <td>Choose a gif that best describes the Republica...</td>\n",
       "      <td></td>\n",
       "      <td>[agree, applause, hug, no, seriously, yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>35997</td>\n",
       "      <td>fuck soon</td>\n",
       "      <td>When soon</td>\n",
       "      <td>[agree, applause, hug, no, seriously, yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>35998</td>\n",
       "      <td>SOMEBODY GIVE ME A HUG PLEASE \\n\\nI would real...</td>\n",
       "      <td>I hope youâ€™re doing okay or will be okay!! Sen...</td>\n",
       "      <td>[agree, applause, facepalm, hug, no, yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>35999</td>\n",
       "      <td>Alright, I gotta give my daughter a bath. \\n\\n...</td>\n",
       "      <td>pick meeee! haha $astich1997 but on a serious ...</td>\n",
       "      <td>[agree, applause, facepalm, hug, no, yes]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        idx                                               text  \\\n",
       "0     32000  Drop your cash app, use hashtag #BailoutHumansNow   \n",
       "1     32001  After interviewing with a few incredible peopl...   \n",
       "2     32002  I know GTC festival not happening next month b...   \n",
       "3     32003  Lordy, my daughter just said, â€œI wonder how th...   \n",
       "4     32004   THE UNEMPLOYMENT CLAIM SYSTEM SUCKS SO MUCH DICK   \n",
       "...     ...                                                ...   \n",
       "3995  35995  WHY TF DO LOCALS LIKE USING GIFS SO MUCH THEYR...   \n",
       "3996  35996  Choose a gif that best describes the Republica...   \n",
       "3997  35997                                          fuck soon   \n",
       "3998  35998  SOMEBODY GIVE ME A HUG PLEASE \\n\\nI would real...   \n",
       "3999  35999  Alright, I gotta give my daughter a bath. \\n\\n...   \n",
       "\n",
       "                                                  reply  \\\n",
       "0                            $tyratomaro #BailoutHumans   \n",
       "1                                         CONGRATS!!!!!   \n",
       "2                                                         \n",
       "3                                                         \n",
       "4     Watching everyone else get their weekly unempl...   \n",
       "...                                                 ...   \n",
       "3995                                                      \n",
       "3996                                                      \n",
       "3997                                          When soon   \n",
       "3998  I hope youâ€™re doing okay or will be okay!! Sen...   \n",
       "3999  pick meeee! haha $astich1997 but on a serious ...   \n",
       "\n",
       "                                       categories  \n",
       "0      [agree, applause, hug, no, seriously, yes]  \n",
       "1       [agree, applause, facepalm, hug, no, yes]  \n",
       "2     [agree, applause, hug, seriously, smh, yes]  \n",
       "3       [agree, applause, facepalm, hug, no, yes]  \n",
       "4       [agree, applause, facepalm, hug, no, yes]  \n",
       "...                                           ...  \n",
       "3995    [agree, applause, facepalm, hug, no, yes]  \n",
       "3996   [agree, applause, hug, no, seriously, yes]  \n",
       "3997   [agree, applause, hug, no, seriously, yes]  \n",
       "3998    [agree, applause, facepalm, hug, no, yes]  \n",
       "3999    [agree, applause, facepalm, hug, no, yes]  \n",
       "\n",
       "[4000 rows x 4 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev_result.to_json('./results/dev.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tokens_tensors.shape   = torch.Size([128, 145]) \n",
      "tensor([[  101,  2057,  2064,  ...,     0,     0,     0],\n",
      "        [  101,  2097,  2017,  ...,     0,     0,     0],\n",
      "        [  101,  3652,  2039,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 16392,  2007,  ...,     0,     0,     0],\n",
      "        [  101,  1045,  2165,  ...,     0,     0,     0],\n",
      "        [  101,  1030,  5795,  ...,     0,     0,     0]])\n",
      "------------------------\n",
      "segments_tensors.shape = torch.Size([128, 145])\n",
      "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]])\n",
      "------------------------\n",
      "masks_tensors.shape    = torch.Size([128, 145])\n",
      "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])\n",
      "------------------------\n",
      "tensor([[0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Only for testing successful running\n",
    "tokens_tensors, segments_tensors, \\\n",
    "    masks_tensors, label_ids = next(iter(train_loader))\n",
    "print(f\"\"\"\n",
    "tokens_tensors.shape   = {tokens_tensors.shape} \n",
    "{tokens_tensors}\n",
    "------------------------\n",
    "segments_tensors.shape = {segments_tensors.shape}\n",
    "{segments_tensors}\n",
    "------------------------\n",
    "masks_tensors.shape    = {masks_tensors.shape}\n",
    "{masks_tensors}\n",
    "------------------------\n",
    "{label_ids}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To-Do or Want-To-Do\n",
    "\n",
    "- https://arxiv.org/pdf/1905.05583.pdf\n",
    "    - [ ] Try to count training and testing average length to modify max_seq_length\n",
    "    - [ ] Head 128 + tail 382 when larger than 512 tokens get best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.reddit.com/r/LanguageTechnology/comments/gnkeyl/covidtwitterbert_an_nlp_model_to_analyse_content/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Emotions Unnormalized')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualization of training classes\n",
    "categories_dict = defaultdict(lambda: 0)\n",
    "for i in range(len(df)):\n",
    "    for each_category in df['categories'][i]:\n",
    "        categories_dict[each_category] += 1\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.barh(list(categories_dict.keys()), categories_dict.values())\n",
    "plt.title('Emotions Unnormalized')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
