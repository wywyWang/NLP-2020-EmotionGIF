{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from random import random\n",
    "import emoji\n",
    "from tqdm import notebook\n",
    "def tqdm(x, **kargs):\n",
    "    return notebook.tqdm(x, leave=False, **kargs)\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter, defaultdict\n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from collections import Counter\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simpletransformers.classification import MultiLabelClassificationModel, ClassificationModel\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simpletransformers.language_modeling import LanguageModelingModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "tknzr = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "      <th>reply</th>\n",
       "      <th>categories</th>\n",
       "      <th>mp4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>we can all agree that any song by Niall Horan.</td>\n",
       "      <td>oui oui</td>\n",
       "      <td>[yes]</td>\n",
       "      <td>6dc39e96b11275f064fdaed88273b45e.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Will you be installing #ScottyFromMarketing's ...</td>\n",
       "      <td></td>\n",
       "      <td>[no]</td>\n",
       "      <td>cfff051f05d8d3b7136c7d58ea6ad55f.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Growing up my mum would call me a Nigga despit...</td>\n",
       "      <td>And he joins in??? Pour some hot grits on em</td>\n",
       "      <td>[smh]</td>\n",
       "      <td>bf39e7bd9ad24354ce3ba6822b0104af.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Rest your head on my chest when the world feel...</td>\n",
       "      <td>ðŸ˜‚ðŸ˜‚ðŸ˜‚ðŸ˜‚ðŸ˜‚</td>\n",
       "      <td>[wink]</td>\n",
       "      <td>173a707a04c277354a2f23cf01d6151e.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Imagine Will Hernandez and Wills both doing a ...</td>\n",
       "      <td></td>\n",
       "      <td>[yes]</td>\n",
       "      <td>aab6d6bfb0c1382269ddba9b71cc8b7a.mp4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx                                               text  \\\n",
       "0    0     we can all agree that any song by Niall Horan.   \n",
       "1    1  Will you be installing #ScottyFromMarketing's ...   \n",
       "2    2  Growing up my mum would call me a Nigga despit...   \n",
       "3    3  Rest your head on my chest when the world feel...   \n",
       "4    4  Imagine Will Hernandez and Wills both doing a ...   \n",
       "\n",
       "                                          reply categories  \\\n",
       "0                                       oui oui      [yes]   \n",
       "1                                                     [no]   \n",
       "2  And he joins in??? Pour some hot grits on em      [smh]   \n",
       "3                                         ðŸ˜‚ðŸ˜‚ðŸ˜‚ðŸ˜‚ðŸ˜‚     [wink]   \n",
       "4                                                    [yes]   \n",
       "\n",
       "                                    mp4  \n",
       "0  6dc39e96b11275f064fdaed88273b45e.mp4  \n",
       "1  cfff051f05d8d3b7136c7d58ea6ad55f.mp4  \n",
       "2  bf39e7bd9ad24354ce3ba6822b0104af.mp4  \n",
       "3  173a707a04c277354a2f23cf01d6151e.mp4  \n",
       "4  aab6d6bfb0c1382269ddba9b71cc8b7a.mp4  "
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json('/home/ino/Projects/Yao_tmp/Intro-PR/NLP/NLP-2020-EmotionGIF/source/train_gold.json', lines=True)\n",
    "df_new = df.copy()\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Try shuffle data\n",
    "# df_new = df.sample(frac=1).reset_index(drop=True)\n",
    "# df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_type = pd.read_json('/home/ino/Projects/Yao_tmp/Intro-PR/NLP/NLP-2020-EmotionGIF/source/categories.json', lines=True)\n",
    "categories_mapping = {v[0]: k for k, v in categories_type.to_dict('list').items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>reply</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Drop your cash app, use hashtag #BailoutHumansNow</td>\n",
       "      <td>$tyratomaro #BailoutHumans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>After interviewing with a few incredible peopl...</td>\n",
       "      <td>CONGRATS!!!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I know GTC festival not happening next month b...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lordy, my daughter just said, â€œI wonder how th...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>THE UNEMPLOYMENT CLAIM SYSTEM SUCKS SO MUCH DICK</td>\n",
       "      <td>Watching everyone else get their weekly unempl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Drop your cash app, use hashtag #BailoutHumansNow   \n",
       "1  After interviewing with a few incredible peopl...   \n",
       "2  I know GTC festival not happening next month b...   \n",
       "3  Lordy, my daughter just said, â€œI wonder how th...   \n",
       "4   THE UNEMPLOYMENT CLAIM SYSTEM SUCKS SO MUCH DICK   \n",
       "\n",
       "                                               reply  \n",
       "0                         $tyratomaro #BailoutHumans  \n",
       "1                                      CONGRATS!!!!!  \n",
       "2                                                     \n",
       "3                                                     \n",
       "4  Watching everyone else get their weekly unempl...  "
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev = pd.read_json('/home/ino/Projects/Yao_tmp/Intro-PR/NLP/NLP-2020-EmotionGIF/source/dev_unlabeled.json', lines=True)\n",
    "df_dev_result = df_dev.copy()[['text', 'reply']]\n",
    "df_dev_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>reply</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@Youngdeji_ I think if uzi and carti dropping ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>For the third year in a row weâ€™re discussing t...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dababy album sounds like it was made for nigga...</td>\n",
       "      <td>That's why you bought it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Majority of Indians donâ€™t watch any sport othe...</td>\n",
       "      <td>@ZairaWasimmm got a great story because of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>everybody is just now listening to @madisonbee...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  @Youngdeji_ I think if uzi and carti dropping ...   \n",
       "1  For the third year in a row weâ€™re discussing t...   \n",
       "2  dababy album sounds like it was made for nigga...   \n",
       "3  Majority of Indians donâ€™t watch any sport othe...   \n",
       "4  everybody is just now listening to @madisonbee...   \n",
       "\n",
       "                                               reply  \n",
       "0                                                     \n",
       "1                                                     \n",
       "2                          That's why you bought it.  \n",
       "3  @ZairaWasimmm got a great story because of the...  \n",
       "4                                                     "
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_json('/home/ino/Projects/Yao_tmp/Intro-PR/NLP/NLP-2020-EmotionGIF/source/test_unlabeled.json', lines=True)\n",
    "df_test_result = df_test.copy()[['text', 'reply']]\n",
    "df_test_result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    tokens = []\n",
    "    for each_text in text:\n",
    "        tokens.append(tknzr.tokenize(each_text.lower()))\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_terms(token_list):\n",
    "    vocabulary = Counter()\n",
    "    for tokens in token_list:\n",
    "        vocabulary.update(tokens)    \n",
    "    return vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idf(token_list):\n",
    "    idf = []\n",
    "    for token, freq in features_terms:\n",
    "        count = 0\n",
    "        for words in token_list:\n",
    "            if token in words:\n",
    "                count += 1\n",
    "        idf.append(count)\n",
    "    for i in range(len(idf)):\n",
    "        idf[i] = math.log(len(token_list)/idf[i])\n",
    "    return idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tweet(tweet):\n",
    "    tweet = tweet.lower()\n",
    "    for word, count in tf_high:\n",
    "        tweet = tweet.replace(' ' + word + ' ', ' ')\n",
    "    for word in tf_1:\n",
    "        tweet = tweet.replace(' ' + word + ' ', ' ')\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164.76767301559448"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before = time.time()\n",
    "text_list = df_new['text'].to_list()\n",
    "tokens = tokenize(text_list)\n",
    "features_terms = get_terms(tokens)\n",
    "tf_high = features_terms.most_common(25)\n",
    "tf_1 = [word for word, count in features_terms.most_common() if count==1]\n",
    "\n",
    "df_new['text'] = df_new.text.apply(preprocess_tweet)\n",
    "# # df_new['reply'] = df_new.reply.apply(preprocess_tweet)\n",
    "df_dev_result['text'] = df_dev_result.text.apply(preprocess_tweet)\n",
    "# df_dev_result['reply'] = df_dev_result.reply.apply(preprocess_tweet)\n",
    "# print(df_new['text'][1])\n",
    "# print(df_new['reply'][3])\n",
    "after = time.time()\n",
    "after - before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['text'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use multi-hot encoding and change column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "multi_hot = mlb.fit_transform(df_new['categories'].values)\n",
    "multi_hot_list = [list(_) for _ in multi_hot]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_new['labels'] = multi_hot_list\n",
    "df_new = df_new[['text', 'reply', 'labels']]\n",
    "df_new.columns = ['text_a', 'text_b', 'labels']\n",
    "df_dev_result.columns = ['text_a', 'text_b']\n",
    "df_test_result.columns = ['text_a', 'text_b']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training language model first, can imporve accuracy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Output data to train_file for training LM\n",
    "df_forLM = df_new.copy()\n",
    "# df_forLM['text'] = ['<s> '] + df_new['text_a'] + [' </s></s> '] + df_new['text_b'] + [' <s>']\n",
    "df_forLM['text'] = ['[CLS] '] + df_new['text_a'] + [' [SEP] '] + df_new['text_b'] + [' [SEP]']\n",
    "# df_forLM_dev = df_dev_result.copy()\n",
    "# df_forLM_dev['text'] = ['<s> '] + df_dev_result['text_a'] + [' </s></s> '] + df_dev_result['text_b'] + [' <s>']\n",
    "# df_forLM_test = df_test_result.copy()\n",
    "# df_forLM_test['text'] = ['<s> '] + df_test_result['text_a'] + [' [SEP] '] + df_test_result['text_b']\n",
    "# pd.concat([df_forLM['text'], df_forLM_dev['text'], df_forLM_test['text']])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_forLM['text'].to_csv(r'LM/training.txt', header=None, index=None, sep=' ')\n",
    "# pd.concat([df_forLM['text'], df_forLM_dev['text']]).to_csv(r'LM/training_dev.txt', header=None, index=None, sep=' ')\n",
    "# pd.concat([df_forLM['text'], df_forLM_dev['text'], df_forLM_test['text']]).to_csv(r'LM/training_dev_test.txt', header=None, index=None, sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0602 18:45:11.784299 139786362763072 filelock.py:274] Lock 139779598689672 acquired on cache/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b.lock\n",
      "I0602 18:45:11.785942 139786362763072 file_utils.py:436] https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json not found in cache or force_download set to True, downloading to /home/ino/Projects/Kai_tmp/cache/tmp82kwn72b\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5646928fcb6e473095da5162a7362d34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898823.0, style=ProgressStyle(descriptiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0602 18:45:13.866592 139786362763072 file_utils.py:440] storing https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json in cache at cache/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "I0602 18:45:13.866979 139786362763072 file_utils.py:443] creating metadata file for cache/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "I0602 18:45:13.867591 139786362763072 filelock.py:318] Lock 139779598689672 released on cache/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0602 18:45:14.817342 139786362763072 filelock.py:274] Lock 139782237559328 acquired on cache/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda.lock\n",
      "I0602 18:45:14.819007 139786362763072 file_utils.py:436] https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt not found in cache or force_download set to True, downloading to /home/ino/Projects/Kai_tmp/cache/tmp08_e1g1a\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c6f61e8959a47178cbd505e15e55b6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descriptiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0602 18:45:16.656232 139786362763072 file_utils.py:440] storing https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt in cache at cache/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "I0602 18:45:16.656765 139786362763072 file_utils.py:443] creating metadata file for cache/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "I0602 18:45:16.657276 139786362763072 filelock.py:318] Lock 139782237559328 released on cache/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda.lock\n",
      "I0602 18:45:16.657529 139786362763072 tokenization_utils.py:1015] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at cache/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "I0602 18:45:16.657771 139786362763072 tokenization_utils.py:1015] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at cache/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0602 18:45:17.615552 139786362763072 filelock.py:274] Lock 139779598680584 acquired on cache/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690.lock\n",
      "I0602 18:45:17.617280 139786362763072 file_utils.py:436] https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json not found in cache or force_download set to True, downloading to /home/ino/Projects/Kai_tmp/cache/tmp0z1wvtz9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f8b59c1650e45878804fc6d4a9b241d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=481.0, style=ProgressStyle(description_â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0602 18:45:18.547198 139786362763072 file_utils.py:440] storing https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json in cache at cache/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690\n",
      "I0602 18:45:18.547805 139786362763072 file_utils.py:443] creating metadata file for cache/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690\n",
      "I0602 18:45:18.548400 139786362763072 filelock.py:318] Lock 139779598680584 released on cache/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690.lock\n",
      "I0602 18:45:18.548912 139786362763072 configuration_utils.py:285] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at cache/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690\n",
      "I0602 18:45:18.549437 139786362763072 configuration_utils.py:321] Model config RobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0602 18:45:18.857625 139786362763072 filelock.py:274] Lock 139779591031384 acquired on cache/80b4a484eddeb259bec2f06a6f2f05d90934111628e0e1c09a33bd4a121358e1.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e.lock\n",
      "I0602 18:45:18.859058 139786362763072 file_utils.py:436] https://cdn.huggingface.co/roberta-base-pytorch_model.bin not found in cache or force_download set to True, downloading to /home/ino/Projects/Kai_tmp/cache/tmpm7yvlkwv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7be4070a818e4bb489a9f2a3c050aba2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=501200538.0, style=ProgressStyle(descriâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0602 18:45:24.019864 139786362763072 file_utils.py:440] storing https://cdn.huggingface.co/roberta-base-pytorch_model.bin in cache at cache/80b4a484eddeb259bec2f06a6f2f05d90934111628e0e1c09a33bd4a121358e1.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n",
      "I0602 18:45:24.020266 139786362763072 file_utils.py:443] creating metadata file for cache/80b4a484eddeb259bec2f06a6f2f05d90934111628e0e1c09a33bd4a121358e1.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n",
      "I0602 18:45:24.020787 139786362763072 filelock.py:318] Lock 139779591031384 released on cache/80b4a484eddeb259bec2f06a6f2f05d90934111628e0e1c09a33bd4a121358e1.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e.lock\n",
      "I0602 18:45:24.021033 139786362763072 modeling_utils.py:650] loading weights file https://cdn.huggingface.co/roberta-base-pytorch_model.bin from cache at cache/80b4a484eddeb259bec2f06a6f2f05d90934111628e0e1c09a33bd4a121358e1.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0602 18:45:27.818131 139786362763072 modeling_utils.py:741] Weights of RobertaForMaskedLM not initialized from pretrained model: ['lm_head.decoder.bias']\n"
     ]
    }
   ],
   "source": [
    "train_lm_args = {\n",
    "    \"output_dir\": \"LM/outputs_roberta_uncased_LM_training_pair/\",\n",
    "    \"cache_dir\": \"cache/\",\n",
    "    \"best_model_dir\": \"LM/outputs/best_model/\",\n",
    "\n",
    "    \"fp16\": False,\n",
    "    \"fp16_opt_level\": \"O1\",\n",
    "    \"max_seq_length\": 114,\n",
    "    \"train_batch_size\": 16,\n",
    "    \"eval_batch_size\": 16,\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"num_train_epochs\": 4,\n",
    "    \"weight_decay\": 0,\n",
    "    \"learning_rate\": 4e-5,\n",
    "    \"adam_epsilon\": 1e-8,\n",
    "    \"warmup_ratio\": 0.06,\n",
    "    \"warmup_steps\": 0,\n",
    "    \"max_grad_norm\": 1.0,\n",
    "    \"do_lower_case\": False,\n",
    "}\n",
    "model = LanguageModelingModel(\"roberta\", \"roberta-base\", args=train_lm_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0602 18:45:27.930772 139786362763072 language_modeling_utils.py:181]  Creating features from dataset file at cache/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c0ce14c0b954b7385aedb2e4a3a0ce5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=48939.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da2a0059dad244d4b571b61b49c8e414",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12025.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0602 18:45:32.725187 139786362763072 language_modeling_utils.py:229]  Saving features into cached file cache/roberta_cached_lm_111_training.txt\n",
      "I0602 18:45:32.757880 139786362763072 language_modeling_model.py:473]  Training started\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6067ab4874184db0b7b3c2cc50a2c0ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=4.0, style=ProgressStyle(description_width='iâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53299a06ef3e4e37b1962d107db46470",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Current iteration', max=752.0, style=ProgressStyle(descriâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss: 2.680486"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0602 18:48:26.711689 139786362763072 configuration_utils.py:144] Configuration saved in LM/outputs_roberta_uncased_LM_training_pair/checkpoint-752-epoch-1/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0602 18:48:26.977880 139786362763072 modeling_utils.py:483] Model weights saved in LM/outputs_roberta_uncased_LM_training_pair/checkpoint-752-epoch-1/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c5265a90cef4d148d77d9164f7c4300",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Current iteration', max=752.0, style=ProgressStyle(descriâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss: 1.963061"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0602 18:51:22.135511 139786362763072 configuration_utils.py:144] Configuration saved in LM/outputs_roberta_uncased_LM_training_pair/checkpoint-1504-epoch-2/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0602 18:51:22.380154 139786362763072 modeling_utils.py:483] Model weights saved in LM/outputs_roberta_uncased_LM_training_pair/checkpoint-1504-epoch-2/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3413dea76c1040e7929047be608c7448",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Current iteration', max=752.0, style=ProgressStyle(descriâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss: 1.818923"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0602 18:53:18.254215 139786362763072 configuration_utils.py:144] Configuration saved in LM/outputs_roberta_uncased_LM_training_pair/checkpoint-2000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Running loss: 1.766624"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0602 18:53:18.499403 139786362763072 modeling_utils.py:483] Model weights saved in LM/outputs_roberta_uncased_LM_training_pair/checkpoint-2000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss: 2.288359"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0602 18:54:18.476517 139786362763072 configuration_utils.py:144] Configuration saved in LM/outputs_roberta_uncased_LM_training_pair/checkpoint-2256-epoch-3/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0602 18:54:18.719528 139786362763072 modeling_utils.py:483] Model weights saved in LM/outputs_roberta_uncased_LM_training_pair/checkpoint-2256-epoch-3/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e100ecadcc74207ac1a48bfd49faebe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Current iteration', max=752.0, style=ProgressStyle(descriâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss: 1.568282"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0602 18:57:14.161850 139786362763072 configuration_utils.py:144] Configuration saved in LM/outputs_roberta_uncased_LM_training_pair/checkpoint-3008-epoch-4/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0602 18:57:14.408723 139786362763072 modeling_utils.py:483] Model weights saved in LM/outputs_roberta_uncased_LM_training_pair/checkpoint-3008-epoch-4/pytorch_model.bin\n",
      "I0602 18:57:15.160012 139786362763072 configuration_utils.py:144] Configuration saved in LM/outputs_roberta_uncased_LM_training_pair/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0602 18:57:15.409447 139786362763072 modeling_utils.py:483] Model weights saved in LM/outputs_roberta_uncased_LM_training_pair/pytorch_model.bin\n",
      "I0602 18:57:15.459530 139786362763072 language_modeling_model.py:402]  Training of roberta model complete. Saved to LM/outputs_roberta_uncased_LM_training_pair/.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "707.6288330554962"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before = time.time()\n",
    "model.train_model('LM/training.txt')\n",
    "after = time.time()\n",
    "after - before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_args = {\n",
    "    \"output_dir\": \"model_results_gpu/outputs_roberta_training/\",\n",
    "    \"cache_dir\": \"cache/\",\n",
    "    \"best_model_dir\": \"model_results_gpu/outputs/best_model/\",\n",
    "\n",
    "    \"fp16\": False,\n",
    "    \"fp16_opt_level\": \"O1\",\n",
    "    \"max_seq_length\": 114,\n",
    "    \"train_batch_size\": 16,\n",
    "    \"eval_batch_size\": 16,\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"num_train_epochs\": 4,\n",
    "    \"weight_decay\": 0,\n",
    "    \"learning_rate\": 4e-5,\n",
    "    \"adam_epsilon\": 1e-8,\n",
    "    \"warmup_ratio\": 0.06,\n",
    "    \"warmup_steps\": 0,\n",
    "    \"max_grad_norm\": 1.0,\n",
    "    \"do_lower_case\": False,\n",
    "\n",
    "    \"logging_steps\": 50,\n",
    "    \"evaluate_during_training\": False,\n",
    "    \"evaluate_during_training_steps\": 2000,\n",
    "    \"evaluate_during_training_verbose\": False,\n",
    "    \"use_cached_eval_features\": False,\n",
    "    \"save_eval_checkpoints\": False,\n",
    "    \"save_steps\": 2000,\n",
    "    \"no_cache\": True,\n",
    "    \"save_model_every_epoch\": True,\n",
    "    \"tensorboard_dir\": None,\n",
    "\n",
    "    \"overwrite_output_dir\": False,\n",
    "    \"reprocess_input_data\": True,\n",
    "\n",
    "    \"n_gpu\": 1,\n",
    "    \"silent\": False,\n",
    "    \"use_multiprocessing\": False,\n",
    "\n",
    "    \"wandb_project\": None,\n",
    "    \"wandb_kwargs\": {},\n",
    "\n",
    "    \"use_early_stopping\": True,\n",
    "    \"early_stopping_patience\": 3,\n",
    "    \"early_stopping_delta\": 0,\n",
    "    \"early_stopping_metric\": \"eval_loss\",\n",
    "    \"early_stopping_metric_minimize\": True,\n",
    "\n",
    "    \"manual_seed\": None,\n",
    "    \"encoding\": None,\n",
    "    \"config\": {}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0602 19:00:08.192695 139786362763072 configuration_utils.py:283] loading configuration file LM/outputs_roberta_uncased_LM_training_pair/config.json\n",
      "I0602 19:00:08.193446 139786362763072 configuration_utils.py:321] Model config RobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\",\n",
      "    \"15\": \"LABEL_15\",\n",
      "    \"16\": \"LABEL_16\",\n",
      "    \"17\": \"LABEL_17\",\n",
      "    \"18\": \"LABEL_18\",\n",
      "    \"19\": \"LABEL_19\",\n",
      "    \"20\": \"LABEL_20\",\n",
      "    \"21\": \"LABEL_21\",\n",
      "    \"22\": \"LABEL_22\",\n",
      "    \"23\": \"LABEL_23\",\n",
      "    \"24\": \"LABEL_24\",\n",
      "    \"25\": \"LABEL_25\",\n",
      "    \"26\": \"LABEL_26\",\n",
      "    \"27\": \"LABEL_27\",\n",
      "    \"28\": \"LABEL_28\",\n",
      "    \"29\": \"LABEL_29\",\n",
      "    \"30\": \"LABEL_30\",\n",
      "    \"31\": \"LABEL_31\",\n",
      "    \"32\": \"LABEL_32\",\n",
      "    \"33\": \"LABEL_33\",\n",
      "    \"34\": \"LABEL_34\",\n",
      "    \"35\": \"LABEL_35\",\n",
      "    \"36\": \"LABEL_36\",\n",
      "    \"37\": \"LABEL_37\",\n",
      "    \"38\": \"LABEL_38\",\n",
      "    \"39\": \"LABEL_39\",\n",
      "    \"40\": \"LABEL_40\",\n",
      "    \"41\": \"LABEL_41\",\n",
      "    \"42\": \"LABEL_42\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_15\": 15,\n",
      "    \"LABEL_16\": 16,\n",
      "    \"LABEL_17\": 17,\n",
      "    \"LABEL_18\": 18,\n",
      "    \"LABEL_19\": 19,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_20\": 20,\n",
      "    \"LABEL_21\": 21,\n",
      "    \"LABEL_22\": 22,\n",
      "    \"LABEL_23\": 23,\n",
      "    \"LABEL_24\": 24,\n",
      "    \"LABEL_25\": 25,\n",
      "    \"LABEL_26\": 26,\n",
      "    \"LABEL_27\": 27,\n",
      "    \"LABEL_28\": 28,\n",
      "    \"LABEL_29\": 29,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_30\": 30,\n",
      "    \"LABEL_31\": 31,\n",
      "    \"LABEL_32\": 32,\n",
      "    \"LABEL_33\": 33,\n",
      "    \"LABEL_34\": 34,\n",
      "    \"LABEL_35\": 35,\n",
      "    \"LABEL_36\": 36,\n",
      "    \"LABEL_37\": 37,\n",
      "    \"LABEL_38\": 38,\n",
      "    \"LABEL_39\": 39,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_40\": 40,\n",
      "    \"LABEL_41\": 41,\n",
      "    \"LABEL_42\": 42,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0602 19:00:08.193845 139786362763072 modeling_utils.py:648] loading weights file LM/outputs_roberta_uncased_LM_training_pair/pytorch_model.bin\n",
      "I0602 19:00:10.958323 139786362763072 modeling_utils.py:741] Weights of RobertaForMultiLabelSequenceClassification not initialized from pretrained model: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "I0602 19:00:10.958820 139786362763072 modeling_utils.py:747] Weights from pretrained model not used in RobertaForMultiLabelSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias']\n",
      "I0602 19:00:10.959804 139786362763072 tokenization_utils.py:929] Model name 'LM/outputs_roberta_uncased_LM_training_pair' not found in model shortcut name list (roberta-base, roberta-large, roberta-large-mnli, distilroberta-base, roberta-base-openai-detector, roberta-large-openai-detector). Assuming 'LM/outputs_roberta_uncased_LM_training_pair' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "I0602 19:00:10.960294 139786362763072 tokenization_utils.py:958] Didn't find file LM/outputs_roberta_uncased_LM_training_pair/added_tokens.json. We won't load it.\n",
      "I0602 19:00:10.960739 139786362763072 tokenization_utils.py:1013] loading file LM/outputs_roberta_uncased_LM_training_pair/vocab.json\n",
      "I0602 19:00:10.961024 139786362763072 tokenization_utils.py:1013] loading file LM/outputs_roberta_uncased_LM_training_pair/merges.txt\n",
      "I0602 19:00:10.961272 139786362763072 tokenization_utils.py:1013] loading file None\n",
      "I0602 19:00:10.961523 139786362763072 tokenization_utils.py:1013] loading file LM/outputs_roberta_uncased_LM_training_pair/special_tokens_map.json\n",
      "I0602 19:00:10.961830 139786362763072 tokenization_utils.py:1013] loading file LM/outputs_roberta_uncased_LM_training_pair/tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "# model = MultiLabelClassificationModel('roberta', 'roberta-base', num_labels=43, args=train_args)\n",
    "# Read from pretrained language model\n",
    "model = MultiLabelClassificationModel('roberta', 'LM/outputs_roberta_uncased_LM_training_pair', num_labels=43, args=train_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0602 19:00:12.768683 139786362763072 classification_model.py:801]  Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7956e182f6fb4cec90f95092a3a9d5a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=32000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "246d4c1b0ef04c07ac3c4edda6078c14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=4.0, style=ProgressStyle(description_width='iâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0602 19:00:18.147119 139786362763072 classification_model.py:367]    Starting fine-tuning.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a262bc418604f1e88bc1456871a7ead",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Current iteration', max=2000.0, style=ProgressStyle(descrâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss: 0.126159"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0602 19:05:51.608978 139786362763072 configuration_utils.py:144] Configuration saved in model_results_gpu/outputs_roberta_training/checkpoint-2000/config.json\n",
      "I0602 19:05:51.848461 139786362763072 modeling_utils.py:483] Model weights saved in model_results_gpu/outputs_roberta_training/checkpoint-2000/pytorch_model.bin\n",
      "I0602 19:05:52.375119 139786362763072 configuration_utils.py:144] Configuration saved in model_results_gpu/outputs_roberta_training/checkpoint-2000-epoch-1/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0602 19:05:52.617387 139786362763072 modeling_utils.py:483] Model weights saved in model_results_gpu/outputs_roberta_training/checkpoint-2000-epoch-1/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb5fbad2aa9d424b9bf2572c57a4af25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Current iteration', max=2000.0, style=ProgressStyle(descrâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss: 0.127880"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0602 19:11:27.338012 139786362763072 configuration_utils.py:144] Configuration saved in model_results_gpu/outputs_roberta_training/checkpoint-4000/config.json\n",
      "I0602 19:11:27.581629 139786362763072 modeling_utils.py:483] Model weights saved in model_results_gpu/outputs_roberta_training/checkpoint-4000/pytorch_model.bin\n",
      "I0602 19:11:28.320727 139786362763072 configuration_utils.py:144] Configuration saved in model_results_gpu/outputs_roberta_training/checkpoint-4000-epoch-2/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0602 19:11:28.565328 139786362763072 modeling_utils.py:483] Model weights saved in model_results_gpu/outputs_roberta_training/checkpoint-4000-epoch-2/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6462eee3a8d84b01a666145ea3783ce7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Current iteration', max=2000.0, style=ProgressStyle(descrâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss: 0.111884"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0602 19:17:03.752897 139786362763072 configuration_utils.py:144] Configuration saved in model_results_gpu/outputs_roberta_training/checkpoint-6000/config.json\n",
      "I0602 19:17:04.001096 139786362763072 modeling_utils.py:483] Model weights saved in model_results_gpu/outputs_roberta_training/checkpoint-6000/pytorch_model.bin\n",
      "I0602 19:17:04.557482 139786362763072 configuration_utils.py:144] Configuration saved in model_results_gpu/outputs_roberta_training/checkpoint-6000-epoch-3/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0602 19:17:04.813610 139786362763072 modeling_utils.py:483] Model weights saved in model_results_gpu/outputs_roberta_training/checkpoint-6000-epoch-3/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53c6687dcea44ee3887f7f55a952e021",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Current iteration', max=2000.0, style=ProgressStyle(descrâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss: 0.113842"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0602 19:22:39.984638 139786362763072 configuration_utils.py:144] Configuration saved in model_results_gpu/outputs_roberta_training/checkpoint-8000/config.json\n",
      "I0602 19:22:40.226206 139786362763072 modeling_utils.py:483] Model weights saved in model_results_gpu/outputs_roberta_training/checkpoint-8000/pytorch_model.bin\n",
      "I0602 19:22:40.756170 139786362763072 configuration_utils.py:144] Configuration saved in model_results_gpu/outputs_roberta_training/checkpoint-8000-epoch-4/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0602 19:22:40.997750 139786362763072 modeling_utils.py:483] Model weights saved in model_results_gpu/outputs_roberta_training/checkpoint-8000-epoch-4/pytorch_model.bin\n",
      "I0602 19:22:41.719073 139786362763072 configuration_utils.py:144] Configuration saved in model_results_gpu/outputs_roberta_training/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0602 19:22:41.961348 139786362763072 modeling_utils.py:483] Model weights saved in model_results_gpu/outputs_roberta_training/pytorch_model.bin\n",
      "I0602 19:22:42.006997 139786362763072 classification_model.py:279]  Training of roberta model complete. Saved to model_results_gpu/outputs_roberta_training/.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1349.372787475586"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before = time.time()\n",
    "model.train_model(df_new)\n",
    "after = time.time()\n",
    "after - before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model (unused can comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = MultiLabelClassificationModel('roberta', 'model_results_gpu/outputs_roberta_#64/checkpoint-6000-epoch-3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating model for LRAP and mAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe8631fb01b847afa73909d65a3c563a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=32000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69cb833384be4be2a343654fbfd459da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'LRAP': 0.5364130718472097, 'eval_loss': 0.09930125410854816}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "result, model_outputs, wrong_predictions = model.eval_model(df_new)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg map = 0.6800333333333327\n"
     ]
    }
   ],
   "source": [
    "avg_map = 0\n",
    "total_predict = []\n",
    "\n",
    "for eid, each_outputs in enumerate(model_outputs):\n",
    "    predict_class = []\n",
    "    correct = 0\n",
    "    sort_index = sorted(range(len(model_outputs[eid])), key=lambda k: model_outputs[eid][k], reverse=True)\n",
    "    for key, value in categories_mapping.items():\n",
    "        if value in sort_index[0:6]:\n",
    "            if key in df['categories'][eid]:\n",
    "                correct += 1\n",
    "            predict_class.append(key)\n",
    "    avg_map += (correct / len(df['categories'][eid]))\n",
    "    total_predict.append(predict_class)\n",
    "\n",
    "avg_map /= len(df['categories'])\n",
    "print(\"avg map = {}\".format(avg_map))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict results [pair sentance](https://simpletransformers.ai/docs/classification-data-formats/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text + [SEP] + reply\n",
    "to_predict = []\n",
    "for i in range(len(df_dev_result)):\n",
    "    # for roberta format\n",
    "    text_reply = '<s> ' + df_dev_result['text_a'][i] + ' </s></s> ' + df_dev_result['text_b'][i] + ' <s>'\n",
    "#     for bert format\n",
    "#     text_reply = '[CLS] ' + df_dev_result['text_a'][i] + ' [SEP] ' + df_dev_result['text_b'][i] + ' [SEP]'\n",
    "    to_predict.append(text_reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0602 19:25:43.147072 139786362763072 classification_model.py:801]  Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12876eb0414141899ed46aff96b157e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01f97890ee6647228824319e4c326167",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=250.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "predictions, raw_outputs = model.predict(to_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_predict = []\n",
    "for eid, row in enumerate(raw_outputs):\n",
    "    predict_class = []\n",
    "    correct = 0\n",
    "    sort_index = sorted(range(len(row)), key=lambda k: row[k], reverse=True)\n",
    "    for key, value in categories_mapping.items():\n",
    "        if value in sort_index[0:6]:\n",
    "            predict_class.append(key)\n",
    "    total_predict.append(predict_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev['categories'] = total_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "      <th>reply</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32000</td>\n",
       "      <td>Drop your cash app, use hashtag #BailoutHumansNow</td>\n",
       "      <td>$tyratomaro #BailoutHumans</td>\n",
       "      <td>[applause, dance, good_luck, please, thank_you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32001</td>\n",
       "      <td>After interviewing with a few incredible peopl...</td>\n",
       "      <td>CONGRATS!!!!!</td>\n",
       "      <td>[agree, applause, high_five, slow_clap, win, yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32002</td>\n",
       "      <td>I know GTC festival not happening next month b...</td>\n",
       "      <td></td>\n",
       "      <td>[agree, idk, no, omg, scared, shocked]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32003</td>\n",
       "      <td>Lordy, my daughter just said, â€œI wonder how th...</td>\n",
       "      <td></td>\n",
       "      <td>[eww, facepalm, oh_snap, omg, scared, shocked]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32004</td>\n",
       "      <td>THE UNEMPLOYMENT CLAIM SYSTEM SUCKS SO MUCH DICK</td>\n",
       "      <td>Watching everyone else get their weekly unempl...</td>\n",
       "      <td>[facepalm, oops, seriously, shrug, sigh, smh]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     idx                                               text  \\\n",
       "0  32000  Drop your cash app, use hashtag #BailoutHumansNow   \n",
       "1  32001  After interviewing with a few incredible peopl...   \n",
       "2  32002  I know GTC festival not happening next month b...   \n",
       "3  32003  Lordy, my daughter just said, â€œI wonder how th...   \n",
       "4  32004   THE UNEMPLOYMENT CLAIM SYSTEM SUCKS SO MUCH DICK   \n",
       "\n",
       "                                               reply  \\\n",
       "0                         $tyratomaro #BailoutHumans   \n",
       "1                                      CONGRATS!!!!!   \n",
       "2                                                      \n",
       "3                                                      \n",
       "4  Watching everyone else get their weekly unempl...   \n",
       "\n",
       "                                          categories  \n",
       "0  [applause, dance, good_luck, please, thank_you...  \n",
       "1  [agree, applause, high_five, slow_clap, win, yes]  \n",
       "2             [agree, idk, no, omg, scared, shocked]  \n",
       "3     [eww, facepalm, oh_snap, omg, scared, shocked]  \n",
       "4      [facepalm, oops, seriously, shrug, sigh, smh]  "
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev.to_json('./results/dev.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
