{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from random import random\n",
    "import emoji\n",
    "from tqdm import notebook\n",
    "def tqdm(x, **kargs):\n",
    "    return notebook.tqdm(x, leave=False, **kargs)\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter, defaultdict\n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0603 13:03:08.609767 140359886780224 file_utils.py:39] PyTorch version 1.5.0 available.\n"
     ]
    }
   ],
   "source": [
    "from simpletransformers.classification import MultiLabelClassificationModel, ClassificationModel\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simpletransformers.language_modeling import LanguageModelingModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "      <th>reply</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>we can all agree that any song by Niall Horan .</td>\n",
       "      <td>oui oui</td>\n",
       "      <td>[yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Will you be install  # ScottyFromMarketing  ' ...</td>\n",
       "      <td></td>\n",
       "      <td>[no]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Growing up my mum would call me a Nigga despit...</td>\n",
       "      <td>And he joins in ?  ?  ?  Pour some hot grits o...</td>\n",
       "      <td>[smh]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Rest your head on my chest when the world feel...</td>\n",
       "      <td>ðŸ˜‚ðŸ˜‚ðŸ˜‚ðŸ˜‚ðŸ˜‚</td>\n",
       "      <td>[wink]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Imagine Will Hernandez and Wills both doing a ...</td>\n",
       "      <td></td>\n",
       "      <td>[yes]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx                                               text  \\\n",
       "0    0   we can all agree that any song by Niall Horan .    \n",
       "1    1  Will you be install  # ScottyFromMarketing  ' ...   \n",
       "2    2  Growing up my mum would call me a Nigga despit...   \n",
       "3    3  Rest your head on my chest when the world feel...   \n",
       "4    4  Imagine Will Hernandez and Wills both doing a ...   \n",
       "\n",
       "                                               reply categories  \n",
       "0                                            oui oui      [yes]  \n",
       "1                                                          [no]  \n",
       "2  And he joins in ?  ?  ?  Pour some hot grits o...      [smh]  \n",
       "3                                              ðŸ˜‚ðŸ˜‚ðŸ˜‚ðŸ˜‚ðŸ˜‚     [wink]  \n",
       "4                                                         [yes]  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = pd.read_json('./source/train_gold.json', lines=True)\n",
    "df = pd.read_json('./preprocessed/preprocess_train.json', lines=True)\n",
    "df_new = df.copy()\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Try shuffle data\n",
    "# df_new = df.sample(frac=1).reset_index(drop=True)\n",
    "# df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_type = pd.read_json('./source/categories.json', lines=True)\n",
    "categories_mapping = {v[0]: k for k, v in categories_type.to_dict('list').items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>reply</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Drop your cash app ,  use hashtag  # BailoutHu...</td>\n",
       "      <td>$ tyratomaro  # BailoutHumans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>After interviewing with a few incredible peopl...</td>\n",
       "      <td>CONGRATS !  !  !  !  !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I know GTC festival not happening next month b...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lordy ,  my daughter just said ,    \"  I wonde...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>THE UNEMPLOYMENT CLAIM SYSTEM SUCKS SO MUCH DICK</td>\n",
       "      <td>Watching everyone else get their weekly unempl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Drop your cash app ,  use hashtag  # BailoutHu...   \n",
       "1  After interviewing with a few incredible peopl...   \n",
       "2  I know GTC festival not happening next month b...   \n",
       "3  Lordy ,  my daughter just said ,    \"  I wonde...   \n",
       "4   THE UNEMPLOYMENT CLAIM SYSTEM SUCKS SO MUCH DICK   \n",
       "\n",
       "                                               reply  \n",
       "0                      $ tyratomaro  # BailoutHumans  \n",
       "1                            CONGRATS !  !  !  !  !   \n",
       "2                                                     \n",
       "3                                                     \n",
       "4  Watching everyone else get their weekly unempl...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev_ori = pd.read_json('./source/dev_unlabeled.json', lines=True)\n",
    "df_dev = pd.read_json('./preprocessed/preprocess_dev.json', lines=True)\n",
    "df_dev_result = df_dev.copy()[['text', 'reply']]\n",
    "df_dev_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>reply</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@Youngdeji_ I think if uzi and carti dropping ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>For the third year in a row weâ€™re discussing t...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dababy album sounds like it was made for nigga...</td>\n",
       "      <td>That's why you bought it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Majority of Indians donâ€™t watch any sport othe...</td>\n",
       "      <td>@ZairaWasimmm got a great story because of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>everybody is just now listening to @madisonbee...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  @Youngdeji_ I think if uzi and carti dropping ...   \n",
       "1  For the third year in a row weâ€™re discussing t...   \n",
       "2  dababy album sounds like it was made for nigga...   \n",
       "3  Majority of Indians donâ€™t watch any sport othe...   \n",
       "4  everybody is just now listening to @madisonbee...   \n",
       "\n",
       "                                               reply  \n",
       "0                                                     \n",
       "1                                                     \n",
       "2                          That's why you bought it.  \n",
       "3  @ZairaWasimmm got a great story because of the...  \n",
       "4                                                     "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_json('./source/test_unlabeled.json', lines=True)\n",
    "df_test_result = df_test.copy()[['text', 'reply']]\n",
    "df_test_result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use multi-hot encoding and change column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "multi_hot = mlb.fit_transform(df_new['categories'].values)\n",
    "multi_hot_list = [list(_) for _ in multi_hot]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_new['labels'] = multi_hot_list\n",
    "df_new = df_new[['text', 'reply', 'labels']]\n",
    "df_new.columns = ['text_a', 'text_b', 'labels']\n",
    "df_dev_result.columns = ['text_a', 'text_b']\n",
    "df_test_result.columns = ['text_a', 'text_b']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training language model first, can imporve accuracy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Output data to train_file for training LM\n",
    "df_forLM = df_new.copy()\n",
    "# df_forLM['text'] = ['<s> '] + df_new['text_a'] + [' </s></s> '] + df_new['text_b'] + [' <s>']\n",
    "df_forLM['text'] = ['[CLS] '] + df_new['text_a'] + [' [SEP] '] + df_new['text_b'] + [' [SEP]']\n",
    "# df_forLM_dev = df_dev_result.copy()\n",
    "# df_forLM_dev['text'] = ['<s> '] + df_dev_result['text_a'] + [' </s></s> '] + df_dev_result['text_b'] + [' <s>']\n",
    "# df_forLM_test = df_test_result.copy()\n",
    "# df_forLM_test['text'] = ['<s> '] + df_test_result['text_a'] + [' [SEP] '] + df_test_result['text_b']\n",
    "# pd.concat([df_forLM['text'], df_forLM_dev['text'], df_forLM_test['text']])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_forLM['text'].to_csv(r'LM/training.txt', header=None, index=None, sep=' ')\n",
    "# pd.concat([df_forLM['text'], df_forLM_dev['text']]).to_csv(r'LM/training_dev.txt', header=None, index=None, sep=' ')\n",
    "# pd.concat([df_forLM['text'], df_forLM_dev['text'], df_forLM_test['text']]).to_csv(r'LM/training_dev_test.txt', header=None, index=None, sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0603 13:57:27.989449 140359886780224 tokenization_utils.py:1015] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "I0603 13:57:28.919435 140359886780224 configuration_utils.py:285] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at cache/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "I0603 13:57:28.920261 140359886780224 configuration_utils.py:321] Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "I0603 13:57:28.945221 140359886780224 modeling_utils.py:650] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at cache/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "I0603 13:57:31.197400 140359886780224 modeling_utils.py:741] Weights of BertForMaskedLM not initialized from pretrained model: ['cls.predictions.decoder.bias']\n",
      "I0603 13:57:31.197996 140359886780224 modeling_utils.py:747] Weights from pretrained model not used in BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n"
     ]
    }
   ],
   "source": [
    "train_lm_args = {\n",
    "    \"output_dir\": \"LM/outputs_bert_uncased_LM_training_preprocessed/\",\n",
    "    \"cache_dir\": \"cache/\",\n",
    "    \"best_model_dir\": \"LM/outputs/best_model/\",\n",
    "\n",
    "    \"fp16\": False,\n",
    "    \"fp16_opt_level\": \"O1\",\n",
    "    \"max_seq_length\": 113,\n",
    "    \"train_batch_size\": 16,\n",
    "    \"eval_batch_size\": 16,\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"num_train_epochs\": 4,\n",
    "    \"weight_decay\": 0,\n",
    "    \"learning_rate\": 4e-5,\n",
    "    \"adam_epsilon\": 1e-8,\n",
    "    \"warmup_ratio\": 0.06,\n",
    "    \"warmup_steps\": 0,\n",
    "    \"max_grad_norm\": 1.0,\n",
    "    \"do_lower_case\": False,\n",
    "}\n",
    "model = LanguageModelingModel(\"bert\", \"bert-base-uncased\", args=train_lm_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0603 13:57:31.295145 140359886780224 language_modeling_utils.py:181]  Creating features from dataset file at cache/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5471e248c22240f485ac8ab6ee06a452",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=48944.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24a57eed1d994e969fccbcdecd8f0a88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11016.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0603 13:57:34.919770 140359886780224 language_modeling_utils.py:229]  Saving features into cached file cache/bert_cached_lm_111_training.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0603 13:57:34.946201 140359886780224 language_modeling_model.py:473]  Training started\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f73399088cb404082fd37a63669ad79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=4.0, style=ProgressStyle(description_width='iâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4a13a9dad22481f870e38b2d3603af3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Current iteration', max=689.0, style=ProgressStyle(descriâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss: 2.317134"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0603 13:59:55.471956 140359886780224 configuration_utils.py:144] Configuration saved in LM/outputs_bert_uncased_LM_training_preprocessed/checkpoint-689-epoch-1/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0603 13:59:55.708569 140359886780224 modeling_utils.py:483] Model weights saved in LM/outputs_bert_uncased_LM_training_preprocessed/checkpoint-689-epoch-1/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e3611129bd04e69b3ba25a8d5ba054d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Current iteration', max=689.0, style=ProgressStyle(descriâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss: 2.516955"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0603 14:02:17.024956 140359886780224 configuration_utils.py:144] Configuration saved in LM/outputs_bert_uncased_LM_training_preprocessed/checkpoint-1378-epoch-2/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0603 14:02:17.248695 140359886780224 modeling_utils.py:483] Model weights saved in LM/outputs_bert_uncased_LM_training_preprocessed/checkpoint-1378-epoch-2/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e903f311a4ad4a62ab7570d56802b6cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Current iteration', max=689.0, style=ProgressStyle(descriâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss: 2.273551"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0603 14:04:25.192951 140359886780224 configuration_utils.py:144] Configuration saved in LM/outputs_bert_uncased_LM_training_preprocessed/checkpoint-2000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Running loss: 2.271214"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0603 14:04:25.416197 140359886780224 modeling_utils.py:483] Model weights saved in LM/outputs_bert_uncased_LM_training_preprocessed/checkpoint-2000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss: 2.730169"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0603 14:04:39.522027 140359886780224 configuration_utils.py:144] Configuration saved in LM/outputs_bert_uncased_LM_training_preprocessed/checkpoint-2067-epoch-3/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0603 14:04:39.744395 140359886780224 modeling_utils.py:483] Model weights saved in LM/outputs_bert_uncased_LM_training_preprocessed/checkpoint-2067-epoch-3/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31b1015950814822b1be14e8b502579e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Current iteration', max=689.0, style=ProgressStyle(descriâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss: 2.624485"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0603 14:07:01.557008 140359886780224 configuration_utils.py:144] Configuration saved in LM/outputs_bert_uncased_LM_training_preprocessed/checkpoint-2756-epoch-4/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0603 14:07:01.781935 140359886780224 modeling_utils.py:483] Model weights saved in LM/outputs_bert_uncased_LM_training_preprocessed/checkpoint-2756-epoch-4/pytorch_model.bin\n",
      "I0603 14:07:02.233439 140359886780224 configuration_utils.py:144] Configuration saved in LM/outputs_bert_uncased_LM_training_preprocessed/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0603 14:07:02.459305 140359886780224 modeling_utils.py:483] Model weights saved in LM/outputs_bert_uncased_LM_training_preprocessed/pytorch_model.bin\n",
      "I0603 14:07:02.472314 140359886780224 language_modeling_model.py:402]  Training of bert model complete. Saved to LM/outputs_bert_uncased_LM_training_preprocessed/.\n"
     ]
    }
   ],
   "source": [
    "model.train_model('LM/training.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_args = {\n",
    "    \"output_dir\": \"model_results_gpu/outputs_roberta_training_preprocessed/\",\n",
    "    \"cache_dir\": \"cache/\",\n",
    "    \"best_model_dir\": \"model_results_gpu/outputs/best_model/\",\n",
    "\n",
    "    \"fp16\": False,\n",
    "    \"fp16_opt_level\": \"O1\",\n",
    "    \"max_seq_length\": 113,\n",
    "    \"train_batch_size\": 16,\n",
    "    \"eval_batch_size\": 16,\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"num_train_epochs\": 4,\n",
    "    \"weight_decay\": 0,\n",
    "    \"learning_rate\": 4e-5,\n",
    "    \"adam_epsilon\": 1e-8,\n",
    "    \"warmup_ratio\": 0.06,\n",
    "    \"warmup_steps\": 0,\n",
    "    \"max_grad_norm\": 1.0,\n",
    "    \"do_lower_case\": False,\n",
    "\n",
    "    \"logging_steps\": 50,\n",
    "    \"evaluate_during_training\": False,\n",
    "    \"evaluate_during_training_steps\": 2000,\n",
    "    \"evaluate_during_training_verbose\": False,\n",
    "    \"use_cached_eval_features\": False,\n",
    "    \"save_eval_checkpoints\": False,\n",
    "    \"save_steps\": 2000,\n",
    "    \"no_cache\": True,\n",
    "    \"save_model_every_epoch\": True,\n",
    "    \"tensorboard_dir\": None,\n",
    "\n",
    "    \"overwrite_output_dir\": False,\n",
    "    \"reprocess_input_data\": True,\n",
    "\n",
    "    \"n_gpu\": 1,\n",
    "    \"silent\": False,\n",
    "    \"use_multiprocessing\": False,\n",
    "\n",
    "    \"wandb_project\": None,\n",
    "    \"wandb_kwargs\": {},\n",
    "\n",
    "    \"use_early_stopping\": True,\n",
    "    \"early_stopping_patience\": 3,\n",
    "    \"early_stopping_delta\": 0,\n",
    "    \"early_stopping_metric\": \"eval_loss\",\n",
    "    \"early_stopping_metric_minimize\": True,\n",
    "\n",
    "    \"manual_seed\": None,\n",
    "    \"encoding\": None,\n",
    "    \"config\": {}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0603 15:33:38.872920 140359886780224 configuration_utils.py:283] loading configuration file LM/outputs_roberta_LM_training_preprocessed/config.json\n",
      "I0603 15:33:38.873671 140359886780224 configuration_utils.py:321] Model config RobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\",\n",
      "    \"15\": \"LABEL_15\",\n",
      "    \"16\": \"LABEL_16\",\n",
      "    \"17\": \"LABEL_17\",\n",
      "    \"18\": \"LABEL_18\",\n",
      "    \"19\": \"LABEL_19\",\n",
      "    \"20\": \"LABEL_20\",\n",
      "    \"21\": \"LABEL_21\",\n",
      "    \"22\": \"LABEL_22\",\n",
      "    \"23\": \"LABEL_23\",\n",
      "    \"24\": \"LABEL_24\",\n",
      "    \"25\": \"LABEL_25\",\n",
      "    \"26\": \"LABEL_26\",\n",
      "    \"27\": \"LABEL_27\",\n",
      "    \"28\": \"LABEL_28\",\n",
      "    \"29\": \"LABEL_29\",\n",
      "    \"30\": \"LABEL_30\",\n",
      "    \"31\": \"LABEL_31\",\n",
      "    \"32\": \"LABEL_32\",\n",
      "    \"33\": \"LABEL_33\",\n",
      "    \"34\": \"LABEL_34\",\n",
      "    \"35\": \"LABEL_35\",\n",
      "    \"36\": \"LABEL_36\",\n",
      "    \"37\": \"LABEL_37\",\n",
      "    \"38\": \"LABEL_38\",\n",
      "    \"39\": \"LABEL_39\",\n",
      "    \"40\": \"LABEL_40\",\n",
      "    \"41\": \"LABEL_41\",\n",
      "    \"42\": \"LABEL_42\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_15\": 15,\n",
      "    \"LABEL_16\": 16,\n",
      "    \"LABEL_17\": 17,\n",
      "    \"LABEL_18\": 18,\n",
      "    \"LABEL_19\": 19,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_20\": 20,\n",
      "    \"LABEL_21\": 21,\n",
      "    \"LABEL_22\": 22,\n",
      "    \"LABEL_23\": 23,\n",
      "    \"LABEL_24\": 24,\n",
      "    \"LABEL_25\": 25,\n",
      "    \"LABEL_26\": 26,\n",
      "    \"LABEL_27\": 27,\n",
      "    \"LABEL_28\": 28,\n",
      "    \"LABEL_29\": 29,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_30\": 30,\n",
      "    \"LABEL_31\": 31,\n",
      "    \"LABEL_32\": 32,\n",
      "    \"LABEL_33\": 33,\n",
      "    \"LABEL_34\": 34,\n",
      "    \"LABEL_35\": 35,\n",
      "    \"LABEL_36\": 36,\n",
      "    \"LABEL_37\": 37,\n",
      "    \"LABEL_38\": 38,\n",
      "    \"LABEL_39\": 39,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_40\": 40,\n",
      "    \"LABEL_41\": 41,\n",
      "    \"LABEL_42\": 42,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0603 15:33:38.874068 140359886780224 modeling_utils.py:648] loading weights file LM/outputs_roberta_LM_training_preprocessed/pytorch_model.bin\n",
      "I0603 15:33:41.594870 140359886780224 modeling_utils.py:741] Weights of RobertaForMultiLabelSequenceClassification not initialized from pretrained model: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "I0603 15:33:41.595365 140359886780224 modeling_utils.py:747] Weights from pretrained model not used in RobertaForMultiLabelSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias']\n",
      "I0603 15:33:41.596317 140359886780224 tokenization_utils.py:929] Model name 'LM/outputs_roberta_LM_training_preprocessed' not found in model shortcut name list (roberta-base, roberta-large, roberta-large-mnli, distilroberta-base, roberta-base-openai-detector, roberta-large-openai-detector). Assuming 'LM/outputs_roberta_LM_training_preprocessed' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "I0603 15:33:41.596864 140359886780224 tokenization_utils.py:958] Didn't find file LM/outputs_roberta_LM_training_preprocessed/added_tokens.json. We won't load it.\n",
      "I0603 15:33:41.597169 140359886780224 tokenization_utils.py:1013] loading file LM/outputs_roberta_LM_training_preprocessed/vocab.json\n",
      "I0603 15:33:41.597484 140359886780224 tokenization_utils.py:1013] loading file LM/outputs_roberta_LM_training_preprocessed/merges.txt\n",
      "I0603 15:33:41.597736 140359886780224 tokenization_utils.py:1013] loading file None\n",
      "I0603 15:33:41.597990 140359886780224 tokenization_utils.py:1013] loading file LM/outputs_roberta_LM_training_preprocessed/special_tokens_map.json\n",
      "I0603 15:33:41.598295 140359886780224 tokenization_utils.py:1013] loading file LM/outputs_roberta_LM_training_preprocessed/tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "# model = MultiLabelClassificationModel('roberta', 'roberta-base', num_labels=43, args=train_args)\n",
    "# Read from pretrained language model\n",
    "model = MultiLabelClassificationModel('roberta', 'LM/outputs_roberta_LM_training_preprocessed', num_labels=43, args=train_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0603 15:33:44.631558 140359886780224 classification_model.py:801]  Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3254993347a4bf2861b38c8c5da5953",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=32000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ebf8e9ba82d4d9cb8f5c1c4139d27d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=4.0, style=ProgressStyle(description_width='iâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0603 15:33:51.105255 140359886780224 classification_model.py:367]    Starting fine-tuning.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f84183eda9645139371efeb233f89ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Current iteration', max=2000.0, style=ProgressStyle(descrâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss: 0.092893"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0603 15:38:57.064907 140359886780224 configuration_utils.py:144] Configuration saved in model_results_gpu/outputs_roberta_training_preprocessed/checkpoint-1000-epoch-1/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0603 15:38:57.352392 140359886780224 modeling_utils.py:483] Model weights saved in model_results_gpu/outputs_roberta_training_preprocessed/checkpoint-1000-epoch-1/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3178f0e4fa144220bc1cf8043bf0987b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Current iteration', max=2000.0, style=ProgressStyle(descrâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss: 0.144542"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0603 15:44:05.242049 140359886780224 configuration_utils.py:144] Configuration saved in model_results_gpu/outputs_roberta_training_preprocessed/checkpoint-2000/config.json\n",
      "I0603 15:44:05.536704 140359886780224 modeling_utils.py:483] Model weights saved in model_results_gpu/outputs_roberta_training_preprocessed/checkpoint-2000/pytorch_model.bin\n",
      "I0603 15:44:06.263444 140359886780224 configuration_utils.py:144] Configuration saved in model_results_gpu/outputs_roberta_training_preprocessed/checkpoint-2000-epoch-2/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0603 15:44:06.557447 140359886780224 modeling_utils.py:483] Model weights saved in model_results_gpu/outputs_roberta_training_preprocessed/checkpoint-2000-epoch-2/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a39fca7c842420a9d4e45e6be4b6aa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Current iteration', max=2000.0, style=ProgressStyle(descrâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss: 0.093893"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0603 15:49:14.642549 140359886780224 configuration_utils.py:144] Configuration saved in model_results_gpu/outputs_roberta_training_preprocessed/checkpoint-3000-epoch-3/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0603 15:49:14.935518 140359886780224 modeling_utils.py:483] Model weights saved in model_results_gpu/outputs_roberta_training_preprocessed/checkpoint-3000-epoch-3/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e772079271ac4853a23e01b2d50f8b6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Current iteration', max=2000.0, style=ProgressStyle(descrâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss: 0.129605"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0603 15:54:23.209842 140359886780224 configuration_utils.py:144] Configuration saved in model_results_gpu/outputs_roberta_training_preprocessed/checkpoint-4000/config.json\n",
      "I0603 15:54:23.495933 140359886780224 modeling_utils.py:483] Model weights saved in model_results_gpu/outputs_roberta_training_preprocessed/checkpoint-4000/pytorch_model.bin\n",
      "I0603 15:54:24.117335 140359886780224 configuration_utils.py:144] Configuration saved in model_results_gpu/outputs_roberta_training_preprocessed/checkpoint-4000-epoch-4/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0603 15:54:24.403540 140359886780224 modeling_utils.py:483] Model weights saved in model_results_gpu/outputs_roberta_training_preprocessed/checkpoint-4000-epoch-4/pytorch_model.bin\n",
      "I0603 15:54:25.023161 140359886780224 configuration_utils.py:144] Configuration saved in model_results_gpu/outputs_roberta_training_preprocessed/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0603 15:54:25.316444 140359886780224 modeling_utils.py:483] Model weights saved in model_results_gpu/outputs_roberta_training_preprocessed/pytorch_model.bin\n",
      "I0603 15:54:25.451917 140359886780224 classification_model.py:279]  Training of roberta model complete. Saved to model_results_gpu/outputs_roberta_training_preprocessed/.\n"
     ]
    }
   ],
   "source": [
    "model.train_model(df_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model (unused can comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0531 07:08:04.448168 140289921820480 configuration_utils.py:283] loading configuration file model_results_gpu/outputs_roberta_#64/checkpoint-6000-epoch-3/config.json\n",
      "I0531 07:08:04.452016 140289921820480 configuration_utils.py:321] Model config RobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMultiLabelSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\",\n",
      "    \"15\": \"LABEL_15\",\n",
      "    \"16\": \"LABEL_16\",\n",
      "    \"17\": \"LABEL_17\",\n",
      "    \"18\": \"LABEL_18\",\n",
      "    \"19\": \"LABEL_19\",\n",
      "    \"20\": \"LABEL_20\",\n",
      "    \"21\": \"LABEL_21\",\n",
      "    \"22\": \"LABEL_22\",\n",
      "    \"23\": \"LABEL_23\",\n",
      "    \"24\": \"LABEL_24\",\n",
      "    \"25\": \"LABEL_25\",\n",
      "    \"26\": \"LABEL_26\",\n",
      "    \"27\": \"LABEL_27\",\n",
      "    \"28\": \"LABEL_28\",\n",
      "    \"29\": \"LABEL_29\",\n",
      "    \"30\": \"LABEL_30\",\n",
      "    \"31\": \"LABEL_31\",\n",
      "    \"32\": \"LABEL_32\",\n",
      "    \"33\": \"LABEL_33\",\n",
      "    \"34\": \"LABEL_34\",\n",
      "    \"35\": \"LABEL_35\",\n",
      "    \"36\": \"LABEL_36\",\n",
      "    \"37\": \"LABEL_37\",\n",
      "    \"38\": \"LABEL_38\",\n",
      "    \"39\": \"LABEL_39\",\n",
      "    \"40\": \"LABEL_40\",\n",
      "    \"41\": \"LABEL_41\",\n",
      "    \"42\": \"LABEL_42\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_15\": 15,\n",
      "    \"LABEL_16\": 16,\n",
      "    \"LABEL_17\": 17,\n",
      "    \"LABEL_18\": 18,\n",
      "    \"LABEL_19\": 19,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_20\": 20,\n",
      "    \"LABEL_21\": 21,\n",
      "    \"LABEL_22\": 22,\n",
      "    \"LABEL_23\": 23,\n",
      "    \"LABEL_24\": 24,\n",
      "    \"LABEL_25\": 25,\n",
      "    \"LABEL_26\": 26,\n",
      "    \"LABEL_27\": 27,\n",
      "    \"LABEL_28\": 28,\n",
      "    \"LABEL_29\": 29,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_30\": 30,\n",
      "    \"LABEL_31\": 31,\n",
      "    \"LABEL_32\": 32,\n",
      "    \"LABEL_33\": 33,\n",
      "    \"LABEL_34\": 34,\n",
      "    \"LABEL_35\": 35,\n",
      "    \"LABEL_36\": 36,\n",
      "    \"LABEL_37\": 37,\n",
      "    \"LABEL_38\": 38,\n",
      "    \"LABEL_39\": 39,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_40\": 40,\n",
      "    \"LABEL_41\": 41,\n",
      "    \"LABEL_42\": 42,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0531 07:08:04.454348 140289921820480 modeling_utils.py:648] loading weights file model_results_gpu/outputs_roberta_#64/checkpoint-6000-epoch-3/pytorch_model.bin\n",
      "I0531 07:08:09.960238 140289921820480 tokenization_utils.py:929] Model name 'model_results_gpu/outputs_roberta_#64/checkpoint-6000-epoch-3' not found in model shortcut name list (roberta-base, roberta-large, roberta-large-mnli, distilroberta-base, roberta-base-openai-detector, roberta-large-openai-detector). Assuming 'model_results_gpu/outputs_roberta_#64/checkpoint-6000-epoch-3' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "I0531 07:08:09.961287 140289921820480 tokenization_utils.py:958] Didn't find file model_results_gpu/outputs_roberta_#64/checkpoint-6000-epoch-3/added_tokens.json. We won't load it.\n",
      "I0531 07:08:09.961711 140289921820480 tokenization_utils.py:1013] loading file model_results_gpu/outputs_roberta_#64/checkpoint-6000-epoch-3/vocab.json\n",
      "I0531 07:08:09.961947 140289921820480 tokenization_utils.py:1013] loading file model_results_gpu/outputs_roberta_#64/checkpoint-6000-epoch-3/merges.txt\n",
      "I0531 07:08:09.962193 140289921820480 tokenization_utils.py:1013] loading file None\n",
      "I0531 07:08:09.962444 140289921820480 tokenization_utils.py:1013] loading file model_results_gpu/outputs_roberta_#64/checkpoint-6000-epoch-3/special_tokens_map.json\n",
      "I0531 07:08:09.962717 140289921820480 tokenization_utils.py:1013] loading file model_results_gpu/outputs_roberta_#64/checkpoint-6000-epoch-3/tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "# model = MultiLabelClassificationModel('roberta', 'model_results_gpu/outputs_roberta_#64/checkpoint-6000-epoch-3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating model for LRAP and mAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "575d05c0b78a48888ab540e76dc47f43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=32000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0c82da1eb0d405ba2096499ad10ffa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'LRAP': 0.5373189964402629, 'eval_loss': 0.10006559572741389}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "result, model_outputs, wrong_predictions = model.eval_model(df_new)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg map = 0.6769109374999988\n"
     ]
    }
   ],
   "source": [
    "avg_map = 0\n",
    "total_predict = []\n",
    "\n",
    "predict_ok_yes = 0\n",
    "unpredict_class = defaultdict(lambda: 0)\n",
    "record_unpredict_class = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "\n",
    "for eid, each_outputs in enumerate(model_outputs):\n",
    "    predict_class = []\n",
    "    correct = 0\n",
    "    sort_index = sorted(range(len(model_outputs[eid])), key=lambda k: model_outputs[eid][k], reverse=True)\n",
    "    for key, value in categories_mapping.items():\n",
    "        if value in sort_index[0:6]:\n",
    "            if key in df['categories'][eid]:\n",
    "                correct += 1\n",
    "            predict_class.append(key)\n",
    "    # Check what not predicted correct\n",
    "    check = predict_class.copy()\n",
    "    unmatch = df['categories'][eid].copy()\n",
    "    for each_class in df['categories'][eid]:\n",
    "        if each_class not in predict_class:\n",
    "            unpredict_class[each_class] += 1\n",
    "        else:\n",
    "            unmatch.remove(each_class)\n",
    "            check.remove(each_class)\n",
    "    for each_class in unmatch:\n",
    "        for each_check in check:\n",
    "            record_unpredict_class[each_class][each_check] += 1\n",
    "    if 'ok' in predict_class and 'yes' in predict_class:\n",
    "        predict_ok_yes += 1\n",
    "    \n",
    "    avg_map += (correct / len(df['categories'][eid]))\n",
    "    total_predict.append(predict_class)\n",
    "\n",
    "avg_map /= len(df['categories'])\n",
    "print(\"avg map = {}\".format(avg_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2594"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_ok_yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "807\n",
      "2916\n"
     ]
    }
   ],
   "source": [
    "both_ok_agree = 0\n",
    "only_ok = 0\n",
    "only_agree = 0\n",
    "for i in range(len(df)):\n",
    "    if 'ok' in df['categories'][i] and 'agree' in df['categories'][i]:\n",
    "        both_ok_agree += 1\n",
    "    elif 'ok' in df['categories'][i] and 'agree' not in df['categories'][i]:\n",
    "        only_ok += 1\n",
    "    elif 'ok' not in df['categories'][i] and 'agree' in df['categories'][i]:\n",
    "        only_agree += 1\n",
    "print(both_ok_agree)\n",
    "print(only_ok)\n",
    "print(only_agree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>.<locals>.<lambda>()>,\n",
       "            {'eww': 66,\n",
       "             'idk': 96,\n",
       "             'oh_snap': 90,\n",
       "             'omg': 203,\n",
       "             'scared': 85,\n",
       "             'shocked': 264,\n",
       "             'agree': 370,\n",
       "             'applause': 388,\n",
       "             'no': 177,\n",
       "             'seriously': 276,\n",
       "             'slow_clap': 185,\n",
       "             'yes': 357,\n",
       "             'awww': 141,\n",
       "             'dance': 159,\n",
       "             'happy_dance': 135,\n",
       "             'please': 65,\n",
       "             'wink': 40,\n",
       "             'facepalm': 197,\n",
       "             'sigh': 176,\n",
       "             'smh': 200,\n",
       "             'popcorn': 55,\n",
       "             'thank_you': 86,\n",
       "             'hearts': 48,\n",
       "             'hug': 82,\n",
       "             'you_got_this': 59,\n",
       "             'oops': 62,\n",
       "             'high_five': 21,\n",
       "             'good_luck': 73,\n",
       "             'win': 16,\n",
       "             'shrug': 34,\n",
       "             'thumbs_up': 28,\n",
       "             'eye_roll': 63,\n",
       "             'do_not_want': 8,\n",
       "             'want': 6,\n",
       "             'kiss': 3,\n",
       "             'yawn': 15,\n",
       "             'sorry': 4})"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sorted(categories_dict.items(), key=lambda d: d[1], reverse=True)\n",
    "record_unpredict_class['ok']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ok', 762),\n",
       " ('shrug', 634),\n",
       " ('eww', 610),\n",
       " ('oops', 579),\n",
       " ('omg', 561),\n",
       " ('scared', 545),\n",
       " ('eye_roll', 542),\n",
       " ('oh_snap', 493),\n",
       " ('no', 490),\n",
       " ('idk', 479),\n",
       " ('wink', 466),\n",
       " ('high_five', 460),\n",
       " ('shocked', 441),\n",
       " ('deal_with_it', 429),\n",
       " ('yawn', 426),\n",
       " ('sigh', 411),\n",
       " ('thumbs_up', 390),\n",
       " ('awww', 367),\n",
       " ('win', 356),\n",
       " ('agree', 348),\n",
       " ('popcorn', 340),\n",
       " ('yes', 304),\n",
       " ('smh', 302),\n",
       " ('thank_you', 300),\n",
       " ('fist_bump', 292),\n",
       " ('sorry', 287),\n",
       " ('applause', 282),\n",
       " ('seriously', 265),\n",
       " ('facepalm', 264),\n",
       " ('do_not_want', 241),\n",
       " ('want', 231),\n",
       " ('please', 225),\n",
       " ('thumbs_down', 220),\n",
       " ('dance', 217),\n",
       " ('slow_clap', 214),\n",
       " ('happy_dance', 208),\n",
       " ('yolo', 197),\n",
       " ('good_luck', 179),\n",
       " ('mic_drop', 170),\n",
       " ('kiss', 166),\n",
       " ('you_got_this', 151),\n",
       " ('hearts', 124),\n",
       " ('hug', 100)]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(unpredict_class.items(), key=lambda d: d[1], reverse=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict results [pair sentance](https://simpletransformers.ai/docs/classification-data-formats/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text + [SEP] + reply\n",
    "to_predict = []\n",
    "for i in range(len(df_dev_result)):\n",
    "    # for roberta format\n",
    "    text_reply = '<s> ' + df_dev_result['text_a'][i] + ' </s></s> ' + df_dev_result['text_b'][i] + ' <s>'\n",
    "#     for bert format\n",
    "#     text_reply = '[CLS] ' + df_dev_result['text_a'][i] + ' [SEP] ' + df_dev_result['text_b'][i] + ' [SEP]'\n",
    "    to_predict.append(text_reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0603 16:07:48.571024 140359886780224 classification_model.py:801]  Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0549aa5f14bb44f08e5ac09a222be99a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c70cd923fd114229bd11c848df548d69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=250.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "predictions, raw_outputs = model.predict(to_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_predict = []\n",
    "for eid, row in enumerate(raw_outputs):\n",
    "    predict_class = []\n",
    "    correct = 0\n",
    "    sort_index = sorted(range(len(row)), key=lambda k: row[k], reverse=True)\n",
    "    for key, value in categories_mapping.items():\n",
    "        if value in sort_index[0:6]:\n",
    "            predict_class.append(key)\n",
    "    total_predict.append(predict_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev_ori['categories'] = total_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "      <th>reply</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32000</td>\n",
       "      <td>Drop your cash app, use hashtag #BailoutHumansNow</td>\n",
       "      <td>$tyratomaro #BailoutHumans</td>\n",
       "      <td>[applause, dance, good_luck, happy_dance, plea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32001</td>\n",
       "      <td>After interviewing with a few incredible peopl...</td>\n",
       "      <td>CONGRATS!!!!!</td>\n",
       "      <td>[agree, applause, high_five, slow_clap, thumbs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32002</td>\n",
       "      <td>I know GTC festival not happening next month b...</td>\n",
       "      <td></td>\n",
       "      <td>[facepalm, no, scared, seriously, sigh, smh]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32003</td>\n",
       "      <td>Lordy, my daughter just said, â€œI wonder how th...</td>\n",
       "      <td></td>\n",
       "      <td>[applause, eww, facepalm, oh_snap, omg, shocked]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32004</td>\n",
       "      <td>THE UNEMPLOYMENT CLAIM SYSTEM SUCKS SO MUCH DICK</td>\n",
       "      <td>Watching everyone else get their weekly unempl...</td>\n",
       "      <td>[eye_roll, facepalm, seriously, shrug, sigh, smh]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     idx                                               text  \\\n",
       "0  32000  Drop your cash app, use hashtag #BailoutHumansNow   \n",
       "1  32001  After interviewing with a few incredible peopl...   \n",
       "2  32002  I know GTC festival not happening next month b...   \n",
       "3  32003  Lordy, my daughter just said, â€œI wonder how th...   \n",
       "4  32004   THE UNEMPLOYMENT CLAIM SYSTEM SUCKS SO MUCH DICK   \n",
       "\n",
       "                                               reply  \\\n",
       "0                         $tyratomaro #BailoutHumans   \n",
       "1                                      CONGRATS!!!!!   \n",
       "2                                                      \n",
       "3                                                      \n",
       "4  Watching everyone else get their weekly unempl...   \n",
       "\n",
       "                                          categories  \n",
       "0  [applause, dance, good_luck, happy_dance, plea...  \n",
       "1  [agree, applause, high_five, slow_clap, thumbs...  \n",
       "2       [facepalm, no, scared, seriously, sigh, smh]  \n",
       "3   [applause, eww, facepalm, oh_snap, omg, shocked]  \n",
       "4  [eye_roll, facepalm, seriously, shrug, sigh, smh]  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev_ori.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev_ori.to_json('./results/dev.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Power n weighted sum to blend models (Try average first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 16:48:35.482314 139779627980608 configuration_utils.py:283] loading configuration file model_results_gpu/outputs_roberta_training_#87/config.json\n",
      "I0601 16:48:35.483019 139779627980608 configuration_utils.py:321] Model config RobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMultiLabelSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\",\n",
      "    \"15\": \"LABEL_15\",\n",
      "    \"16\": \"LABEL_16\",\n",
      "    \"17\": \"LABEL_17\",\n",
      "    \"18\": \"LABEL_18\",\n",
      "    \"19\": \"LABEL_19\",\n",
      "    \"20\": \"LABEL_20\",\n",
      "    \"21\": \"LABEL_21\",\n",
      "    \"22\": \"LABEL_22\",\n",
      "    \"23\": \"LABEL_23\",\n",
      "    \"24\": \"LABEL_24\",\n",
      "    \"25\": \"LABEL_25\",\n",
      "    \"26\": \"LABEL_26\",\n",
      "    \"27\": \"LABEL_27\",\n",
      "    \"28\": \"LABEL_28\",\n",
      "    \"29\": \"LABEL_29\",\n",
      "    \"30\": \"LABEL_30\",\n",
      "    \"31\": \"LABEL_31\",\n",
      "    \"32\": \"LABEL_32\",\n",
      "    \"33\": \"LABEL_33\",\n",
      "    \"34\": \"LABEL_34\",\n",
      "    \"35\": \"LABEL_35\",\n",
      "    \"36\": \"LABEL_36\",\n",
      "    \"37\": \"LABEL_37\",\n",
      "    \"38\": \"LABEL_38\",\n",
      "    \"39\": \"LABEL_39\",\n",
      "    \"40\": \"LABEL_40\",\n",
      "    \"41\": \"LABEL_41\",\n",
      "    \"42\": \"LABEL_42\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_15\": 15,\n",
      "    \"LABEL_16\": 16,\n",
      "    \"LABEL_17\": 17,\n",
      "    \"LABEL_18\": 18,\n",
      "    \"LABEL_19\": 19,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_20\": 20,\n",
      "    \"LABEL_21\": 21,\n",
      "    \"LABEL_22\": 22,\n",
      "    \"LABEL_23\": 23,\n",
      "    \"LABEL_24\": 24,\n",
      "    \"LABEL_25\": 25,\n",
      "    \"LABEL_26\": 26,\n",
      "    \"LABEL_27\": 27,\n",
      "    \"LABEL_28\": 28,\n",
      "    \"LABEL_29\": 29,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_30\": 30,\n",
      "    \"LABEL_31\": 31,\n",
      "    \"LABEL_32\": 32,\n",
      "    \"LABEL_33\": 33,\n",
      "    \"LABEL_34\": 34,\n",
      "    \"LABEL_35\": 35,\n",
      "    \"LABEL_36\": 36,\n",
      "    \"LABEL_37\": 37,\n",
      "    \"LABEL_38\": 38,\n",
      "    \"LABEL_39\": 39,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_40\": 40,\n",
      "    \"LABEL_41\": 41,\n",
      "    \"LABEL_42\": 42,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0601 16:48:35.483775 139779627980608 modeling_utils.py:648] loading weights file model_results_gpu/outputs_roberta_training_#87/pytorch_model.bin\n",
      "I0601 16:48:41.226637 139779627980608 tokenization_utils.py:929] Model name 'model_results_gpu/outputs_roberta_training_#87/' not found in model shortcut name list (roberta-base, roberta-large, roberta-large-mnli, distilroberta-base, roberta-base-openai-detector, roberta-large-openai-detector). Assuming 'model_results_gpu/outputs_roberta_training_#87/' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "I0601 16:48:41.227607 139779627980608 tokenization_utils.py:958] Didn't find file model_results_gpu/outputs_roberta_training_#87/added_tokens.json. We won't load it.\n",
      "I0601 16:48:41.227987 139779627980608 tokenization_utils.py:1013] loading file model_results_gpu/outputs_roberta_training_#87/vocab.json\n",
      "I0601 16:48:41.228246 139779627980608 tokenization_utils.py:1013] loading file model_results_gpu/outputs_roberta_training_#87/merges.txt\n",
      "I0601 16:48:41.228676 139779627980608 tokenization_utils.py:1013] loading file None\n",
      "I0601 16:48:41.228970 139779627980608 tokenization_utils.py:1013] loading file model_results_gpu/outputs_roberta_training_#87/special_tokens_map.json\n",
      "I0601 16:48:41.229220 139779627980608 tokenization_utils.py:1013] loading file model_results_gpu/outputs_roberta_training_#87/tokenizer_config.json\n",
      "I0601 16:48:41.481712 139779627980608 configuration_utils.py:283] loading configuration file model_results_gpu/outputs_bert_uncased_training_#92/config.json\n",
      "I0601 16:48:41.482555 139779627980608 configuration_utils.py:321] Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMultiLabelSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\",\n",
      "    \"15\": \"LABEL_15\",\n",
      "    \"16\": \"LABEL_16\",\n",
      "    \"17\": \"LABEL_17\",\n",
      "    \"18\": \"LABEL_18\",\n",
      "    \"19\": \"LABEL_19\",\n",
      "    \"20\": \"LABEL_20\",\n",
      "    \"21\": \"LABEL_21\",\n",
      "    \"22\": \"LABEL_22\",\n",
      "    \"23\": \"LABEL_23\",\n",
      "    \"24\": \"LABEL_24\",\n",
      "    \"25\": \"LABEL_25\",\n",
      "    \"26\": \"LABEL_26\",\n",
      "    \"27\": \"LABEL_27\",\n",
      "    \"28\": \"LABEL_28\",\n",
      "    \"29\": \"LABEL_29\",\n",
      "    \"30\": \"LABEL_30\",\n",
      "    \"31\": \"LABEL_31\",\n",
      "    \"32\": \"LABEL_32\",\n",
      "    \"33\": \"LABEL_33\",\n",
      "    \"34\": \"LABEL_34\",\n",
      "    \"35\": \"LABEL_35\",\n",
      "    \"36\": \"LABEL_36\",\n",
      "    \"37\": \"LABEL_37\",\n",
      "    \"38\": \"LABEL_38\",\n",
      "    \"39\": \"LABEL_39\",\n",
      "    \"40\": \"LABEL_40\",\n",
      "    \"41\": \"LABEL_41\",\n",
      "    \"42\": \"LABEL_42\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_15\": 15,\n",
      "    \"LABEL_16\": 16,\n",
      "    \"LABEL_17\": 17,\n",
      "    \"LABEL_18\": 18,\n",
      "    \"LABEL_19\": 19,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_20\": 20,\n",
      "    \"LABEL_21\": 21,\n",
      "    \"LABEL_22\": 22,\n",
      "    \"LABEL_23\": 23,\n",
      "    \"LABEL_24\": 24,\n",
      "    \"LABEL_25\": 25,\n",
      "    \"LABEL_26\": 26,\n",
      "    \"LABEL_27\": 27,\n",
      "    \"LABEL_28\": 28,\n",
      "    \"LABEL_29\": 29,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_30\": 30,\n",
      "    \"LABEL_31\": 31,\n",
      "    \"LABEL_32\": 32,\n",
      "    \"LABEL_33\": 33,\n",
      "    \"LABEL_34\": 34,\n",
      "    \"LABEL_35\": 35,\n",
      "    \"LABEL_36\": 36,\n",
      "    \"LABEL_37\": 37,\n",
      "    \"LABEL_38\": 38,\n",
      "    \"LABEL_39\": 39,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_40\": 40,\n",
      "    \"LABEL_41\": 41,\n",
      "    \"LABEL_42\": 42,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "I0601 16:48:41.482997 139779627980608 modeling_utils.py:648] loading weights file model_results_gpu/outputs_bert_uncased_training_#92/pytorch_model.bin\n",
      "I0601 16:48:43.258243 139779627980608 tokenization_utils.py:929] Model name 'model_results_gpu/outputs_bert_uncased_training_#92/' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'model_results_gpu/outputs_bert_uncased_training_#92/' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "I0601 16:48:43.258922 139779627980608 tokenization_utils.py:958] Didn't find file model_results_gpu/outputs_bert_uncased_training_#92/added_tokens.json. We won't load it.\n",
      "I0601 16:48:43.259260 139779627980608 tokenization_utils.py:1013] loading file model_results_gpu/outputs_bert_uncased_training_#92/vocab.txt\n",
      "I0601 16:48:43.259537 139779627980608 tokenization_utils.py:1013] loading file None\n",
      "I0601 16:48:43.259783 139779627980608 tokenization_utils.py:1013] loading file model_results_gpu/outputs_bert_uncased_training_#92/special_tokens_map.json\n",
      "I0601 16:48:43.260066 139779627980608 tokenization_utils.py:1013] loading file model_results_gpu/outputs_bert_uncased_training_#92/tokenizer_config.json\n",
      "I0601 16:48:43.278987 139779627980608 configuration_utils.py:283] loading configuration file model_results_gpu/outputs_bert_cased_training_#93/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 16:48:43.279752 139779627980608 configuration_utils.py:321] Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMultiLabelSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\",\n",
      "    \"15\": \"LABEL_15\",\n",
      "    \"16\": \"LABEL_16\",\n",
      "    \"17\": \"LABEL_17\",\n",
      "    \"18\": \"LABEL_18\",\n",
      "    \"19\": \"LABEL_19\",\n",
      "    \"20\": \"LABEL_20\",\n",
      "    \"21\": \"LABEL_21\",\n",
      "    \"22\": \"LABEL_22\",\n",
      "    \"23\": \"LABEL_23\",\n",
      "    \"24\": \"LABEL_24\",\n",
      "    \"25\": \"LABEL_25\",\n",
      "    \"26\": \"LABEL_26\",\n",
      "    \"27\": \"LABEL_27\",\n",
      "    \"28\": \"LABEL_28\",\n",
      "    \"29\": \"LABEL_29\",\n",
      "    \"30\": \"LABEL_30\",\n",
      "    \"31\": \"LABEL_31\",\n",
      "    \"32\": \"LABEL_32\",\n",
      "    \"33\": \"LABEL_33\",\n",
      "    \"34\": \"LABEL_34\",\n",
      "    \"35\": \"LABEL_35\",\n",
      "    \"36\": \"LABEL_36\",\n",
      "    \"37\": \"LABEL_37\",\n",
      "    \"38\": \"LABEL_38\",\n",
      "    \"39\": \"LABEL_39\",\n",
      "    \"40\": \"LABEL_40\",\n",
      "    \"41\": \"LABEL_41\",\n",
      "    \"42\": \"LABEL_42\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_15\": 15,\n",
      "    \"LABEL_16\": 16,\n",
      "    \"LABEL_17\": 17,\n",
      "    \"LABEL_18\": 18,\n",
      "    \"LABEL_19\": 19,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_20\": 20,\n",
      "    \"LABEL_21\": 21,\n",
      "    \"LABEL_22\": 22,\n",
      "    \"LABEL_23\": 23,\n",
      "    \"LABEL_24\": 24,\n",
      "    \"LABEL_25\": 25,\n",
      "    \"LABEL_26\": 26,\n",
      "    \"LABEL_27\": 27,\n",
      "    \"LABEL_28\": 28,\n",
      "    \"LABEL_29\": 29,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_30\": 30,\n",
      "    \"LABEL_31\": 31,\n",
      "    \"LABEL_32\": 32,\n",
      "    \"LABEL_33\": 33,\n",
      "    \"LABEL_34\": 34,\n",
      "    \"LABEL_35\": 35,\n",
      "    \"LABEL_36\": 36,\n",
      "    \"LABEL_37\": 37,\n",
      "    \"LABEL_38\": 38,\n",
      "    \"LABEL_39\": 39,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_40\": 40,\n",
      "    \"LABEL_41\": 41,\n",
      "    \"LABEL_42\": 42,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "I0601 16:48:43.280257 139779627980608 modeling_utils.py:648] loading weights file model_results_gpu/outputs_bert_cased_training_#93/pytorch_model.bin\n",
      "I0601 16:48:45.161744 139779627980608 tokenization_utils.py:929] Model name 'model_results_gpu/outputs_bert_cased_training_#93/' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'model_results_gpu/outputs_bert_cased_training_#93/' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "I0601 16:48:45.162338 139779627980608 tokenization_utils.py:958] Didn't find file model_results_gpu/outputs_bert_cased_training_#93/added_tokens.json. We won't load it.\n",
      "I0601 16:48:45.162821 139779627980608 tokenization_utils.py:1013] loading file model_results_gpu/outputs_bert_cased_training_#93/vocab.txt\n",
      "I0601 16:48:45.163140 139779627980608 tokenization_utils.py:1013] loading file None\n",
      "I0601 16:48:45.163411 139779627980608 tokenization_utils.py:1013] loading file model_results_gpu/outputs_bert_cased_training_#93/special_tokens_map.json\n",
      "I0601 16:48:45.163674 139779627980608 tokenization_utils.py:1013] loading file model_results_gpu/outputs_bert_cased_training_#93/tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "model_roberta_base = MultiLabelClassificationModel('roberta', 'model_results_gpu/outputs_roberta_training_#87/')\n",
    "# model_xlmroberta_base = MultiLabelClassificationModel('xlmroberta', 'model_results_gpu/outputs_xlmroberta_#66/')\n",
    "model_bert_base_uncased = MultiLabelClassificationModel('bert', 'model_results_gpu/outputs_bert_uncased_training_#92/')\n",
    "model_bert_base_cased = MultiLabelClassificationModel('bert', 'model_results_gpu/outputs_bert_cased_training_#93/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 16:50:13.922566 139779627980608 classification_model.py:801]  Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fba401b930ba402d9cb28f9d32403c4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a0e301e43954710b1c05758f5984532",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=250.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 16:50:27.369440 139779627980608 classification_model.py:801]  Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d830bf731344966a89aed39a0e0c921",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04bc543f647a4885bda4055e9d65939f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=250.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0601 16:50:41.028582 139779627980608 classification_model.py:801]  Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92d4f02e6307415b9e9d52bdc64982b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7e0e82c7f29481a9be7cf0a21031a6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=250.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_roberta_base, raw_outputs_roberta_base = model_roberta_base.predict(to_predict)\n",
    "# predictions_xlmroberta_base, raw_outputs_xlmroberta_base = model_xlmroberta_base.predict(to_predict)\n",
    "predictions_bert_base_uncased, raw_outputs_bert_base_uncased = model_bert_base_uncased.predict(to_predict)\n",
    "predictions_bert_base_cased, raw_outputs_bert_base_cased = model_bert_base_cased.predict(to_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02645903 0.10327499 0.03311556 0.05657279 0.00648181 0.00293745\n",
      " 0.00533747 0.00601103 0.00631634 0.01446454 0.17714569 0.04154743\n",
      " 0.02221017 0.02777012 0.02029944 0.00463329 0.00927887 0.0037198\n",
      " 0.00842672 0.00784296 0.01934045 0.01441806 0.00511787 0.30099168\n",
      " 0.00598345 0.00995661 0.00670238 0.0104104  0.00400015 0.0101754\n",
      " 0.03269726 0.00562772 0.00344808 0.04705882 0.00422613 0.01852409\n",
      " 0.01474785 0.01721057 0.01229597 0.00395585 0.03457728 0.00400766\n",
      " 0.04768348]\n",
      "[0.02078844 0.10037786 0.03057312 0.10406715 0.00828542 0.00479606\n",
      " 0.00503582 0.00828322 0.00806296 0.01815269 0.12900525 0.07502341\n",
      " 0.02855058 0.02924531 0.01486535 0.00473417 0.0154389  0.00295408\n",
      " 0.00696931 0.0041835  0.01842031 0.01044888 0.00485222 0.24313185\n",
      " 0.01325911 0.00796377 0.00695796 0.0052148  0.00579062 0.00924185\n",
      " 0.02309374 0.00738855 0.00792435 0.05473048 0.00321092 0.02384039\n",
      " 0.0144172  0.02597312 0.02158143 0.00610717 0.04183538 0.00582641\n",
      " 0.0492948 ]\n",
      "[0.03709638 0.13854958 0.02369575 0.06301356 0.00885939 0.00537783\n",
      " 0.00500702 0.00621208 0.00537111 0.01722972 0.1287047  0.04562667\n",
      " 0.02179942 0.03872908 0.0091007  0.00418526 0.0064012  0.00591154\n",
      " 0.01500725 0.00471556 0.02323533 0.01050497 0.00615968 0.27571782\n",
      " 0.01246532 0.00604873 0.00628134 0.00769578 0.00278776 0.00690875\n",
      " 0.03159102 0.00432815 0.00445005 0.04520502 0.00359517 0.01871939\n",
      " 0.01411582 0.02782822 0.01841228 0.0073025  0.04675308 0.00430733\n",
      " 0.03419598]\n"
     ]
    }
   ],
   "source": [
    "print(raw_outputs_roberta_base[0])\n",
    "# print(raw_outputs_xlmroberta_base[0])\n",
    "print(raw_outputs_bert_base_uncased[0])\n",
    "print(raw_outputs_bert_base_cased[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = 3.5\n",
    "total_predict = []\n",
    "for eid, row_roberta_base in enumerate(raw_outputs_roberta_base):\n",
    "    row = (row_roberta_base ** P) * 3.0 + \\\n",
    "            (raw_outputs_bert_base_uncased[eid] ** P) * 0.8 + (raw_outputs_bert_base_cased[eid] ** P) * 0.8 \n",
    "    predict_class = []\n",
    "    correct = 0\n",
    "    sort_index = sorted(range(len(row)), key=lambda k: row[k], reverse=True)\n",
    "    for key, value in categories_mapping.items():\n",
    "        if value in sort_index[0:6]:\n",
    "            predict_class.append(key)\n",
    "    total_predict.append(predict_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev_ori['categories'] = total_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "      <th>reply</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32000</td>\n",
       "      <td>Drop your cash app, use hashtag #BailoutHumansNow</td>\n",
       "      <td>$tyratomaro #BailoutHumans</td>\n",
       "      <td>[applause, dance, good_luck, happy_dance, plea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32001</td>\n",
       "      <td>After interviewing with a few incredible peopl...</td>\n",
       "      <td>CONGRATS!!!!!</td>\n",
       "      <td>[agree, applause, slow_clap, thumbs_up, win, yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32002</td>\n",
       "      <td>I know GTC festival not happening next month b...</td>\n",
       "      <td></td>\n",
       "      <td>[idk, no, scared, seriously, shrug, sigh]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32003</td>\n",
       "      <td>Lordy, my daughter just said, â€œI wonder how th...</td>\n",
       "      <td></td>\n",
       "      <td>[applause, facepalm, oh_snap, omg, scared, sho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32004</td>\n",
       "      <td>THE UNEMPLOYMENT CLAIM SYSTEM SUCKS SO MUCH DICK</td>\n",
       "      <td>Watching everyone else get their weekly unempl...</td>\n",
       "      <td>[applause, dance, omg, popcorn, shocked, yes]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     idx                                               text  \\\n",
       "0  32000  Drop your cash app, use hashtag #BailoutHumansNow   \n",
       "1  32001  After interviewing with a few incredible peopl...   \n",
       "2  32002  I know GTC festival not happening next month b...   \n",
       "3  32003  Lordy, my daughter just said, â€œI wonder how th...   \n",
       "4  32004   THE UNEMPLOYMENT CLAIM SYSTEM SUCKS SO MUCH DICK   \n",
       "\n",
       "                                               reply  \\\n",
       "0                         $tyratomaro #BailoutHumans   \n",
       "1                                      CONGRATS!!!!!   \n",
       "2                                                      \n",
       "3                                                      \n",
       "4  Watching everyone else get their weekly unempl...   \n",
       "\n",
       "                                          categories  \n",
       "0  [applause, dance, good_luck, happy_dance, plea...  \n",
       "1  [agree, applause, slow_clap, thumbs_up, win, yes]  \n",
       "2          [idk, no, scared, seriously, shrug, sigh]  \n",
       "3  [applause, facepalm, oh_snap, omg, scared, sho...  \n",
       "4      [applause, dance, omg, popcorn, shocked, yes]  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev_ori.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev_ori.to_json('./results/dev.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Below are Stastistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer, RobertaTokenizer, BertForSequenceClassification\n",
    "from transformers.modeling_bert import BertPreTrainedModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count min, max, and average text length to select proper max_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0528 11:37:52.815811 140258912331584 tokenization_utils.py:1015] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /home/ino/.cache/torch/transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "I0528 11:37:52.817564 140258912331584 tokenization_utils.py:1015] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /home/ino/.cache/torch/transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max text length is: 587\n",
      "Min text length is: 1\n",
      "Average text length is: 30.57615625\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "text_cnt = 0\n",
    "max_cnt = 0\n",
    "min_cnt = 1e3\n",
    "text_bar = []\n",
    "for each_text in df['text']:\n",
    "    each_cnt = len(tokenizer.tokenize(each_text))\n",
    "    text_cnt += each_cnt\n",
    "    text_bar.append(each_cnt // 10)\n",
    "    if each_cnt > max_cnt:\n",
    "        max_cnt = each_cnt\n",
    "    if each_cnt < min_cnt:\n",
    "        min_cnt = each_cnt\n",
    "text_level = Counter(sorted(text_bar))\n",
    "print(\"Max text length is: {}\".format(max_cnt))\n",
    "print(\"Min text length is: {}\".format(min_cnt))\n",
    "print(\"Average text length is: {}\".format(text_cnt / len(df['text'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count max, min, and average reply length to select proper max_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max reply length is: 292\n",
      "Min reply length is: 0\n",
      "Average reply length is: 5.54871875\n"
     ]
    }
   ],
   "source": [
    "reply_cnt = 0\n",
    "max_cnt = 0\n",
    "min_cnt = 1e3\n",
    "reply_bar = []\n",
    "for each_reply in df['reply']:\n",
    "    each_cnt = len(tokenizer.tokenize(each_reply))\n",
    "    reply_cnt += each_cnt\n",
    "    reply_bar.append(each_cnt // 10)\n",
    "    if each_cnt > max_cnt:\n",
    "        max_cnt = each_cnt\n",
    "    if each_cnt < min_cnt:\n",
    "        min_cnt = each_cnt\n",
    "reply_level = Counter(sorted(reply_bar))\n",
    "print(\"Max reply length is: {}\".format(max_cnt))\n",
    "print(\"Min reply length is: {}\".format(min_cnt))\n",
    "print(\"Average reply length is: {}\".format(reply_cnt / len(df['reply'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count max, min, and average text + reply length to select proper max_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max text + reply length is: 587\n",
      "Min text + reply length is: 1\n",
      "Average text + reply length is: 36.124875\n"
     ]
    }
   ],
   "source": [
    "text_reply_cnt = 0\n",
    "max_cnt = 0\n",
    "min_cnt = 1e3\n",
    "text_reply_bar = []\n",
    "for eid, each_reply in enumerate(df['reply']):\n",
    "    each_text_cnt = len(tokenizer.tokenize(df['text'][eid]))\n",
    "    each_reply_cnt = len(tokenizer.tokenize(each_reply))\n",
    "    each_cnt = each_text_cnt + each_reply_cnt\n",
    "    text_reply_bar.append(each_cnt // 10)\n",
    "    text_reply_cnt += each_cnt\n",
    "    if each_cnt > max_cnt:\n",
    "        max_cnt = each_cnt\n",
    "    if each_cnt < min_cnt:\n",
    "        min_cnt = each_cnt\n",
    "text_reply_level = Counter(sorted(text_reply_bar))\n",
    "print(\"Max text + reply length is: {}\".format(max_cnt))\n",
    "print(\"Min text + reply length is: {}\".format(min_cnt))\n",
    "print(\"Average text + reply length is: {}\".format(text_reply_cnt / len(df['reply'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def autolabel(rects):\n",
    "    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('{}'.format(height),\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "text_indices = np.arange(len(text_level))\n",
    "reply_indices = np.arange(len(reply_level))\n",
    "text_reply_indices = np.arange(len(text_reply_level))\n",
    "# Plot results\n",
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "width = 0.2\n",
    "results_text = plt.bar(text_indices - 0.3, list(text_level.values()), width, label='text')\n",
    "results_reply = plt.bar(reply_indices + 0.3, list(reply_level.values()), width, label='reply')\n",
    "results_text_reply = plt.bar(text_reply_indices, list(text_reply_level.values()), width, label='text_reply')\n",
    "\n",
    "plt.xticks(range(len(text_reply_level)), list(text_reply_level.keys()))\n",
    "ax.set_ylabel('Counts')\n",
    "ax.set_title('Distribution of training text with // 10')\n",
    "# ax.set_xticks(x)\n",
    "# ax.set_xticklabels(text_reply_indices)\n",
    "ax.legend()\n",
    "\n",
    "# autolabel(results_text)\n",
    "# autolabel(results_reply)\n",
    "# autolabel(results_text_reply)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx           0\n",
      "text          0\n",
      "reply         0\n",
      "categories    0\n",
      "mp4           0\n",
      "dtype: int64\n",
      "idx      0\n",
      "text     0\n",
      "reply    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# There isn't null value in training data\n",
    "print(df.isnull().sum())\n",
    "print(df_dev.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['we can all agree that any song by Niall Horan.',\n",
       "       \"Will you be installing #ScottyFromMarketing's new tracking app. \\n\\nPlease answer in the form of a gif.\",\n",
       "       'Growing up my mum would call me a Nigga despite her not being black. I would tell her to stop but she would only call me more racist slurs and hit me. I recently started dating a white boy and sheâ€™s being making more slurs and he joins in. What should i do? -anon',\n",
       "       ..., 'Your @3rd is your future ex',\n",
       "       'If tell you a duck can pull a truck, hook that mf up',\n",
       "       'The only receipts in life are our memories weather you instill them in family or yourself make them count because they are non returnable. Love yall stay grinding.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To-Do or Want-To-Do\n",
    "\n",
    "- https://arxiv.org/pdf/1905.05583.pdf\n",
    "    - [X] Try to count training and testing average length to modify max_seq_length\n",
    "    - [ ] Head 128 + tail 382 when larger than 512 tokens get best results.\n",
    "- [ ] [Exploratory Data Analysis](https://www.analyticsvidhya.com/blog/2020/04/beginners-guide-exploratory-data-analysis-text-data/?fbclid=IwAR07KpVViBMrZx5aboOMe2CPr4_QizPNoyW_Fdl6L1ZNN0_lhhGyl1KZxRg)\n",
    "- [ ] [Blend models  10th](https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification/discussion/101630)\n",
    "- [X] [Blend models 2nd](https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification/discussion/100661)\n",
    "- [ ] [Data cleaning](https://www.kaggle.com/christofhenkel/how-to-preprocessing-for-glove-part1-eda)\n",
    "- [ ] [Stopword removal](http://www.lrec-conf.org/proceedings/lrec2014/pdf/292_Paper.pdf)\n",
    "- [ ] [Preprocess EDA](https://www.kaggle.com/christofhenkel/how-to-preprocessing-for-glove-part1-eda)\n",
    "- [X] Shuffle data (no good)\n",
    "- [ ] [Data cleaning](https://www.kaggle.com/theoviel/improve-your-score-with-text-preprocessing-v2)\n",
    "- [ ] [EDA preprocessing DO FIRST!!](https://www.kaggle.com/nz0722/simple-eda-text-preprocessing-jigsaw)\n",
    "    - [ ] Check Roberta tokenizer proportion and data include proportion\n",
    "    - [ ] Draw text cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.reddit.com/r/LanguageTechnology/comments/gnkeyl/covidtwitterbert_an_nlp_model_to_analyse_content/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Visualization of training classes\n",
    "total_classes = 0\n",
    "categories_dict = defaultdict(lambda: 0)\n",
    "for i in range(len(df)):\n",
    "    for each_category in df['categories'][i]:\n",
    "        categories_dict[each_category] += 1\n",
    "        total_classes += 1\n",
    "for key in categories_dict:\n",
    "    categories_dict[key] = categories_dict[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Emotions Unnormalized')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.barh(list(categories_dict.keys()), categories_dict.values())\n",
    "plt.title('Emotions Unnormalized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'yes': 15.978668628172121,\n",
       "             'no': 20.128146453089244,\n",
       "             'smh': 23.54279638490165,\n",
       "             'wink': 79.42682926829268,\n",
       "             'shocked': 26.09213615023474,\n",
       "             'omg': 28.764667956157318,\n",
       "             'scared': 54.6875753920386,\n",
       "             'oops': 55.57475490196079,\n",
       "             'hug': 13.252855819697437,\n",
       "             'facepalm': 22.070964517741128,\n",
       "             'you_got_this': 54.822249093107615,\n",
       "             'agree': 14.455306327418814,\n",
       "             'eww': 49.73076923076923,\n",
       "             'dance': 49.61951754385965,\n",
       "             'sigh': 25.111425339366516,\n",
       "             'hearts': 135.17994100294985,\n",
       "             'popcorn': 78.1852487135506,\n",
       "             'applause': 12.412260313771064,\n",
       "             'seriously': 21.944831013916502,\n",
       "             'thumbs_down': 208.8409090909091,\n",
       "             'yawn': 99.1409978308026,\n",
       "             'idk': 41.54838709677419,\n",
       "             'shrug': 51.88087056128293,\n",
       "             'eye_roll': 36.80917280917281,\n",
       "             'slow_clap': 33.374534623976174,\n",
       "             'oh_snap': 50.067477876106196,\n",
       "             'mic_drop': 270.55882352941177,\n",
       "             'happy_dance': 55.99382716049383,\n",
       "             'high_five': 85.28971962616822,\n",
       "             'deal_with_it': 106.6107226107226,\n",
       "             'please': 73.94318181818181,\n",
       "             'awww': 46.2517911975435,\n",
       "             'thank_you': 52.68023255813954,\n",
       "             'good_luck': 64.02112676056338,\n",
       "             'ok': 51.57972665148064,\n",
       "             'thumbs_up': 65.71242774566474,\n",
       "             'kiss': 238.19689119170985,\n",
       "             'yolo': 233.34010152284264,\n",
       "             'win': 96.39451476793249,\n",
       "             'fist_bump': 157.09931506849315,\n",
       "             'do_not_want': 140.17737003058105,\n",
       "             'want': 162.12720848056537,\n",
       "             'sorry': 136.39583333333334})"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/57021620/how-to-calculate-unbalanced-weights-for-bcewithlogitsloss-in-pytorch\n",
    "categories_dict_pos = categories_dict.copy()\n",
    "for key in categories_dict_pos:\n",
    "    categories_dict_pos[key] = (total_classes - categories_dict_pos[key]) / categories_dict_pos[key]\n",
    "categories_dict_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14.455306327418814,\n",
       " 12.412260313771064,\n",
       " 46.2517911975435,\n",
       " 49.61951754385965,\n",
       " 106.6107226107226,\n",
       " 140.17737003058105,\n",
       " 49.73076923076923,\n",
       " 36.80917280917281,\n",
       " 22.070964517741128,\n",
       " 157.09931506849315,\n",
       " 64.02112676056338,\n",
       " 55.99382716049383,\n",
       " 135.17994100294985,\n",
       " 85.28971962616822,\n",
       " 13.252855819697437,\n",
       " 41.54838709677419,\n",
       " 238.19689119170985,\n",
       " 270.55882352941177,\n",
       " 20.128146453089244,\n",
       " 50.067477876106196,\n",
       " 51.57972665148064,\n",
       " 28.764667956157318,\n",
       " 55.57475490196079,\n",
       " 73.94318181818181,\n",
       " 78.1852487135506,\n",
       " 54.6875753920386,\n",
       " 21.944831013916502,\n",
       " 26.09213615023474,\n",
       " 51.88087056128293,\n",
       " 25.111425339366516,\n",
       " 33.374534623976174,\n",
       " 23.54279638490165,\n",
       " 136.39583333333334,\n",
       " 52.68023255813954,\n",
       " 208.8409090909091,\n",
       " 65.71242774566474,\n",
       " 162.12720848056537,\n",
       " 96.39451476793249,\n",
       " 79.42682926829268,\n",
       " 99.1409978308026,\n",
       " 15.978668628172121,\n",
       " 233.34010152284264,\n",
       " 54.822249093107615]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weight = sorted(categories_dict_pos.items(), key=lambda pair: categories_mapping[pair[0]])\n",
    "class_weight = [_[1] for _ in class_weight]\n",
    "class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'agree': 0,\n",
       " 'applause': 1,\n",
       " 'awww': 2,\n",
       " 'dance': 3,\n",
       " 'deal_with_it': 4,\n",
       " 'do_not_want': 5,\n",
       " 'eww': 6,\n",
       " 'eye_roll': 7,\n",
       " 'facepalm': 8,\n",
       " 'fist_bump': 9,\n",
       " 'good_luck': 10,\n",
       " 'happy_dance': 11,\n",
       " 'hearts': 12,\n",
       " 'high_five': 13,\n",
       " 'hug': 14,\n",
       " 'idk': 15,\n",
       " 'kiss': 16,\n",
       " 'mic_drop': 17,\n",
       " 'no': 18,\n",
       " 'oh_snap': 19,\n",
       " 'ok': 20,\n",
       " 'omg': 21,\n",
       " 'oops': 22,\n",
       " 'please': 23,\n",
       " 'popcorn': 24,\n",
       " 'scared': 25,\n",
       " 'seriously': 26,\n",
       " 'shocked': 27,\n",
       " 'shrug': 28,\n",
       " 'sigh': 29,\n",
       " 'slow_clap': 30,\n",
       " 'smh': 31,\n",
       " 'sorry': 32,\n",
       " 'thank_you': 33,\n",
       " 'thumbs_down': 34,\n",
       " 'thumbs_up': 35,\n",
       " 'want': 36,\n",
       " 'win': 37,\n",
       " 'wink': 38,\n",
       " 'yawn': 39,\n",
       " 'yes': 40,\n",
       " 'yolo': 41,\n",
       " 'you_got_this': 42}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories_mapping"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
