{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from random import random\n",
    "import emoji\n",
    "from tqdm import notebook\n",
    "def tqdm(x, **kargs):\n",
    "    return notebook.tqdm(x, leave=False, **kargs)\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter, defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0622 05:56:37.220417 140500398008128 file_utils.py:39] PyTorch version 1.5.0 available.\n",
      "/home/ino/anaconda3/envs/TrackNet/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ino/anaconda3/envs/TrackNet/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ino/anaconda3/envs/TrackNet/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ino/anaconda3/envs/TrackNet/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ino/anaconda3/envs/TrackNet/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ino/anaconda3/envs/TrackNet/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer, RobertaModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of text in training data: 32000\n",
      "Number of text in categories: 43\n",
      "Number of text in developing data: 4000\n",
      "Number of text in testing data: 4000\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_json('./source/train_gold.json', lines=True)\n",
    "categories_type = pd.read_json('./source/categories.json', lines=True)\n",
    "df_dev = pd.read_json('./source/dev_unlabeled.json', lines=True)\n",
    "df_test = pd.read_json('./source/test_unlabeled.json', lines=True)\n",
    "print(\"Number of text in training data: {}\".format(df_train.shape[0]))\n",
    "print(\"Number of text in categories: {}\".format(categories_type.shape[1]))\n",
    "print(\"Number of text in developing data: {}\".format(df_dev.shape[0]))\n",
    "print(\"Number of text in testing data: {}\".format(df_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0622 05:56:49.801682 140500398008128 tokenization_utils.py:1015] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /home/ino/.cache/torch/transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "I0622 05:56:49.803424 140500398008128 tokenization_utils.py:1015] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /home/ino/.cache/torch/transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "I0622 05:56:50.841392 140500398008128 configuration_utils.py:285] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at /home/ino/.cache/torch/transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690\n",
      "I0622 05:56:50.844237 140500398008128 configuration_utils.py:321] Model config RobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0622 05:56:51.160835 140500398008128 modeling_utils.py:650] loading weights file https://cdn.huggingface.co/roberta-base-pytorch_model.bin from cache at /home/ino/.cache/torch/transformers/80b4a484eddeb259bec2f06a6f2f05d90934111628e0e1c09a33bd4a121358e1.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "model = RobertaModel.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./roberta_vocab/vocab.json', './roberta_vocab/merges.txt')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output tokenizer vocab\n",
    "tokenizer.save_vocabulary('./roberta_vocab/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "roberta_vocab = pd.read_json('roberta_vocab/vocab.json', typ='series')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>',\n",
       " '<pad>',\n",
       " '</s>',\n",
       " '<unk>',\n",
       " '.',\n",
       " 'Ä the',\n",
       " ',',\n",
       " 'Ä to',\n",
       " 'Ä and',\n",
       " 'Ä of',\n",
       " 'Ä a',\n",
       " 'Ä in',\n",
       " '-',\n",
       " 'Ä for',\n",
       " 'Ä that',\n",
       " 'Ä on',\n",
       " 'Ä is',\n",
       " 'Ã¢Ä¢',\n",
       " \"'s\",\n",
       " 'Ä with',\n",
       " 'Ä The',\n",
       " 'Ä was',\n",
       " 'Ä \"',\n",
       " 'Ä at',\n",
       " 'Ä it',\n",
       " 'Ä as',\n",
       " 'Ä said',\n",
       " 'Ä»',\n",
       " 'Ä be',\n",
       " 's',\n",
       " 'Ä by',\n",
       " 'Ä from',\n",
       " 'Ä are',\n",
       " 'Ä have',\n",
       " 'Ä has',\n",
       " ':',\n",
       " 'Ä (',\n",
       " 'Ä he',\n",
       " 'Ä I',\n",
       " 'Ä his',\n",
       " 'Ä will',\n",
       " 'Ä an',\n",
       " 'Ä this',\n",
       " ')',\n",
       " 'Ä Ã¢Ä¢',\n",
       " 'Ä not',\n",
       " 'Ä¿',\n",
       " 'Ä you',\n",
       " 'Ä¾',\n",
       " 'Ä their',\n",
       " 'Ä or',\n",
       " 'Ä they',\n",
       " 'Ä we',\n",
       " 'Ä but',\n",
       " 'Ä who',\n",
       " 'Ä more',\n",
       " 'Ä had',\n",
       " 'Ä been',\n",
       " 'Ä were',\n",
       " 'Ä about',\n",
       " ',\"',\n",
       " 'Ä which',\n",
       " 'Ä up',\n",
       " 'Ä its',\n",
       " 'Ä can',\n",
       " 'Ä one',\n",
       " 'Ä out',\n",
       " 'Ä also',\n",
       " 'Ä $',\n",
       " 'Ä her',\n",
       " 'Ä all',\n",
       " 'Ä after',\n",
       " '.\"',\n",
       " '/',\n",
       " 'Ä would',\n",
       " \"'t\",\n",
       " 'Ä year',\n",
       " 'Ä when',\n",
       " 'Ä first',\n",
       " 'Ä she',\n",
       " 'Ä two',\n",
       " 'Ä over',\n",
       " 'Ä people',\n",
       " 'Ä A',\n",
       " 'Ä our',\n",
       " 'Ä It',\n",
       " 'Ä time',\n",
       " 'Ä than',\n",
       " 'Ä into',\n",
       " 'Ä there',\n",
       " 't',\n",
       " 'Ä He',\n",
       " 'Ä new',\n",
       " 'Ä Ã¢Ä¢Ä¶',\n",
       " 'Ä last',\n",
       " 'Ä just',\n",
       " 'Ä In',\n",
       " 'Ä other',\n",
       " 'Ä so',\n",
       " 'Ä what',\n",
       " 'I',\n",
       " 'Ä like',\n",
       " 'a',\n",
       " 'Ä some',\n",
       " 'S',\n",
       " 'ÃƒÂ«',\n",
       " 'Ä them',\n",
       " 'Ä years',\n",
       " \"'\",\n",
       " 'Ä do',\n",
       " 'Ä your',\n",
       " 'Ä -',\n",
       " 'Ä 1',\n",
       " '\"',\n",
       " 'Ä if',\n",
       " 'Ä could',\n",
       " '?',\n",
       " 'Ä no',\n",
       " 'i',\n",
       " 'm',\n",
       " 'Ä get',\n",
       " 'Ä U',\n",
       " 'Ä now',\n",
       " 'Ä him',\n",
       " 'Ä back',\n",
       " 'Ä But',\n",
       " 'Ä Ã¢Ä¢Äµ',\n",
       " 'Ä my',\n",
       " \"Ä '\",\n",
       " 'Ä only',\n",
       " 'Ä three',\n",
       " ';',\n",
       " 'Ä 2',\n",
       " 'The',\n",
       " '1',\n",
       " 'Ä percent',\n",
       " 'Ä against',\n",
       " 'Ä before',\n",
       " 'Ä company',\n",
       " 'o',\n",
       " 'Ä Trump',\n",
       " 'Ä how',\n",
       " 'Ä because',\n",
       " 'Ä any',\n",
       " 'Ä most',\n",
       " 'Ä being',\n",
       " 'Ä make',\n",
       " 'Ä where',\n",
       " 'Ä during',\n",
       " 'Ä through',\n",
       " 'Ä while',\n",
       " '000',\n",
       " 'Ä This',\n",
       " 'Ä million',\n",
       " 'ing',\n",
       " 'Ä 3',\n",
       " 'Ä made',\n",
       " 'Ä well',\n",
       " 'Ä 10',\n",
       " 'Ä down',\n",
       " 'Ä off',\n",
       " 'Ä says',\n",
       " 'Ä me',\n",
       " 'Ä B',\n",
       " 'Ä going',\n",
       " 'Ä team',\n",
       " 'Ä We',\n",
       " 'Ä those',\n",
       " 'Ä government',\n",
       " 'Ä way',\n",
       " 'We',\n",
       " 'Ä many',\n",
       " 'Ä then',\n",
       " 'Ä work',\n",
       " 'Ä told',\n",
       " 'com',\n",
       " '2',\n",
       " 'Ä game',\n",
       " 'Ä And',\n",
       " 'in',\n",
       " 'year',\n",
       " 'Ä p',\n",
       " 'Ä very',\n",
       " 'Ä day',\n",
       " 'Ä home',\n",
       " 'Ä take',\n",
       " 'Ä week',\n",
       " 'Ä since',\n",
       " 'Ä New',\n",
       " 'Ä may',\n",
       " 'Ä even',\n",
       " 'Ä season',\n",
       " 'Ä see',\n",
       " 'Ä 2017',\n",
       " 'Ä state',\n",
       " 'Ä 5',\n",
       " 'ed',\n",
       " 'Ä should',\n",
       " 'Ä around',\n",
       " 'Ä 2018',\n",
       " 'Ä second',\n",
       " 'Ä us',\n",
       " 'Ä still',\n",
       " 'Ä much',\n",
       " 'Ä 4',\n",
       " 'Ä good',\n",
       " 'Ä think',\n",
       " '%',\n",
       " 'Ä S',\n",
       " 'Ä these',\n",
       " 'Ä market',\n",
       " 'Ä D',\n",
       " 'th',\n",
       " 'Ä go',\n",
       " \"'re\",\n",
       " 'Ä such',\n",
       " 'Ä know',\n",
       " 'Ä including',\n",
       " 'Ä don',\n",
       " 'y',\n",
       " 'Ä next',\n",
       " 'Ä P',\n",
       " 'Ä did',\n",
       " 'Ä under',\n",
       " 'Ä say',\n",
       " 'en',\n",
       " 'Ä L',\n",
       " 'Ä between',\n",
       " 'Ä per',\n",
       " 'Ä K',\n",
       " 'Ä C',\n",
       " 'Ä 6',\n",
       " 'Ä world',\n",
       " 'Ä part',\n",
       " 'Ä N',\n",
       " 'Ä right',\n",
       " 'Ä want',\n",
       " 'Ä four',\n",
       " '),',\n",
       " 'Ä high',\n",
       " 'Ä need',\n",
       " 're',\n",
       " 'e',\n",
       " 'It',\n",
       " 'Ä help',\n",
       " '5',\n",
       " '3',\n",
       " 'Ä country',\n",
       " 'Ä R',\n",
       " 'Ä police',\n",
       " 'A',\n",
       " 'Ä long',\n",
       " 'Ä They',\n",
       " 'Ä end',\n",
       " 'er',\n",
       " 'Ä T',\n",
       " 'Ä M',\n",
       " 'u',\n",
       " 'Ä both',\n",
       " 'Ä here',\n",
       " 'an',\n",
       " 'on',\n",
       " 'Ä 7',\n",
       " 'Ä de',\n",
       " 'Ä She',\n",
       " 'Ä business',\n",
       " 'Ä report',\n",
       " 'j',\n",
       " 'ers',\n",
       " 'Ä really',\n",
       " 'Ä President',\n",
       " 'ar',\n",
       " 'Ä G',\n",
       " 'Ä Friday',\n",
       " 'Ä F',\n",
       " 'Ä best',\n",
       " 'Ä same',\n",
       " 'Ä another',\n",
       " 'Ä set',\n",
       " 'old',\n",
       " 'Ä That',\n",
       " 'as',\n",
       " 'n',\n",
       " 'Ä come',\n",
       " 'Ä family',\n",
       " 'Ä public',\n",
       " 'Ä For',\n",
       " 'Ä As',\n",
       " '0',\n",
       " 'Ä H',\n",
       " 'Ä 8',\n",
       " 'Ä 20',\n",
       " 'Ä five',\n",
       " 'es',\n",
       " 'Ä Tuesday',\n",
       " 'Ä n',\n",
       " 'Ä Thursday',\n",
       " 'Ä quarter',\n",
       " 'h',\n",
       " 'Ä top',\n",
       " 'Ä got',\n",
       " 'Ä life',\n",
       " 'Ä Monday',\n",
       " 'Ä found',\n",
       " 'Ä use',\n",
       " 'Ä W',\n",
       " '4',\n",
       " 'Ä Wednesday',\n",
       " 'Ä own',\n",
       " 'Ä according',\n",
       " 'Ä play',\n",
       " 'Ä show',\n",
       " 'Ä St',\n",
       " 'Ä man',\n",
       " 'Ä left',\n",
       " 'Ä United',\n",
       " 'Ä 12',\n",
       " 'Ä place',\n",
       " 'Ä If',\n",
       " 'Ä lot',\n",
       " 'Ä former',\n",
       " 'Ä 0',\n",
       " ').',\n",
       " 'Ä support',\n",
       " 'ie',\n",
       " 'Ä billion',\n",
       " 'Ä t',\n",
       " 'Ä shares',\n",
       " '!',\n",
       " 'z',\n",
       " 'k',\n",
       " 'Ä State',\n",
       " 'Ä points',\n",
       " 'Ä group',\n",
       " 'Ä school',\n",
       " 'Ä information',\n",
       " 'Ä 2016',\n",
       " 'al',\n",
       " 'r',\n",
       " 'Ä win',\n",
       " 'Ä news',\n",
       " 'Ä used',\n",
       " 'Ä put',\n",
       " 'Ä city',\n",
       " 'Ä J',\n",
       " 'Ä There',\n",
       " 'Ä number',\n",
       " 'C',\n",
       " \"'ve\",\n",
       " 'Ä each',\n",
       " 'Ä too',\n",
       " 'Ä won',\n",
       " 'ly',\n",
       " 'Ä month',\n",
       " 'is',\n",
       " 'Ä added',\n",
       " 'Ä look',\n",
       " 'Ä better',\n",
       " 'Ä every',\n",
       " 'Ä &',\n",
       " 'Ä days',\n",
       " 'Ä 9',\n",
       " 'Ä took',\n",
       " 'Ä night',\n",
       " 'Ä e',\n",
       " 'Ä 11',\n",
       " 'os',\n",
       " 'Ä few',\n",
       " 'or',\n",
       " 'Ä North',\n",
       " 'Ä You',\n",
       " 'Ä third',\n",
       " 'Ä great',\n",
       " 'Ä called',\n",
       " 'Ä On',\n",
       " 'Ä past',\n",
       " 'Ä came',\n",
       " 'Ä months',\n",
       " 'Ä Saturday',\n",
       " 'Ä 15',\n",
       " 'Ä big',\n",
       " 'Ä E',\n",
       " 'Ä US',\n",
       " 'Ä things',\n",
       " 'Ä O',\n",
       " 'Ä d',\n",
       " 'Ä start',\n",
       " 'B',\n",
       " 'Ä stock',\n",
       " 'Ä 30',\n",
       " 'Ä women',\n",
       " 'Ä South',\n",
       " 'Ä May',\n",
       " 'Ä never',\n",
       " 'Ä president',\n",
       " 'Ä Sunday',\n",
       " 'Ä without',\n",
       " 'man',\n",
       " '8',\n",
       " 'Ä didn',\n",
       " 'Ä local',\n",
       " '6',\n",
       " 'Ä something',\n",
       " 'Ä case',\n",
       " 'Ä All',\n",
       " 'it',\n",
       " '7',\n",
       " 'Ä So',\n",
       " 'Ä children',\n",
       " 'Ä away',\n",
       " 'Ä little',\n",
       " 'Ä six',\n",
       " 'Ä City',\n",
       " 'Ä County',\n",
       " 'Ä data',\n",
       " 'at',\n",
       " 'Ä already',\n",
       " 'd',\n",
       " 'Ä money',\n",
       " 'Ä early',\n",
       " 'Ä across',\n",
       " 'Ä expected',\n",
       " 'Ä run',\n",
       " 'Ä later',\n",
       " 'am',\n",
       " 'Ä price',\n",
       " 'Ä games',\n",
       " 'Ä Mr',\n",
       " 'b',\n",
       " 'Ä might',\n",
       " 'Ä different',\n",
       " 'Ä reported',\n",
       " 'Ä deal',\n",
       " 'Ä media',\n",
       " 'Ä growth',\n",
       " 'Ä community',\n",
       " 'Ä China',\n",
       " \"'m\",\n",
       " 'c',\n",
       " 'Ä went',\n",
       " 'Ä No',\n",
       " 'Ä able',\n",
       " 'Ä making',\n",
       " 'Ä area',\n",
       " 'Ä far',\n",
       " 'Ä statement',\n",
       " 'Ä House',\n",
       " 'Ä working',\n",
       " 'M',\n",
       " 'Ä k',\n",
       " 'Ä seen',\n",
       " 'Ä companies',\n",
       " 'Ä today',\n",
       " 'Ä members',\n",
       " 'Ä until',\n",
       " 'Ä full',\n",
       " 'Ä again',\n",
       " 'Ä half',\n",
       " 'Ä share',\n",
       " 'le',\n",
       " 'Ä always',\n",
       " 'Ä court',\n",
       " 'l',\n",
       " 'and',\n",
       " 'Ä change',\n",
       " 'Ä find',\n",
       " '9',\n",
       " 'Ä system',\n",
       " 'Ä V',\n",
       " 'Ä York',\n",
       " 'Ä American',\n",
       " 'Ä head',\n",
       " 'Ä players',\n",
       " 'Ä does',\n",
       " 'Ä health',\n",
       " 'Ä m',\n",
       " 'Ä power',\n",
       " 'Ä point',\n",
       " 'Ä hit',\n",
       " 'Ä .',\n",
       " 'Ä --',\n",
       " 'Ä free',\n",
       " '.,',\n",
       " 'Ä lead',\n",
       " 'Ä several',\n",
       " 'Ä recent',\n",
       " 'Ä call',\n",
       " 'N',\n",
       " 'Ä law',\n",
       " 'Ä keep',\n",
       " 'Ä open',\n",
       " 'Ä News',\n",
       " 'Ä give',\n",
       " 'ia',\n",
       " 'Ä March',\n",
       " 'D',\n",
       " 'Ä National',\n",
       " 'Ä At',\n",
       " 'Ä times',\n",
       " 'Ä future',\n",
       " 'R',\n",
       " 'Ä 14',\n",
       " 'Ä June',\n",
       " 'Ä officials',\n",
       " 'Ä 18',\n",
       " 'Ä important',\n",
       " 'f',\n",
       " 'Ä final',\n",
       " 'Ä 13',\n",
       " 'Ä One',\n",
       " 'P',\n",
       " 'Ä following',\n",
       " 'Ä car',\n",
       " 'Ä least',\n",
       " 'Ä water',\n",
       " 'Ä event',\n",
       " 'Ä line',\n",
       " 'Ä move',\n",
       " 'Ä services',\n",
       " 'Ä having',\n",
       " 'Ä When',\n",
       " 'Ä students',\n",
       " 'Ä Police',\n",
       " 'el',\n",
       " 'Ä am',\n",
       " 'Ä Z',\n",
       " 'Ä side',\n",
       " 'Ä story',\n",
       " 'Ä due',\n",
       " 'Ä meeting',\n",
       " 'K',\n",
       " 'Ä must',\n",
       " 'Ä States',\n",
       " 'Ä likely',\n",
       " 'G',\n",
       " 'Ä continue',\n",
       " 'Ä ago',\n",
       " 'Ä party',\n",
       " 'Ä major',\n",
       " 'Ä industry',\n",
       " 'Ä less',\n",
       " '30',\n",
       " 'Ä un',\n",
       " 'Ä hard',\n",
       " 'Ä service',\n",
       " 'Ä 16',\n",
       " 'Ä looking',\n",
       " 'Ä held',\n",
       " 've',\n",
       " 'Ä whether',\n",
       " 'Ä July',\n",
       " 'Ä taken',\n",
       " 'Ä along',\n",
       " 'Ä asked',\n",
       " 'Ä started',\n",
       " 'Ä become',\n",
       " 'Ä forward',\n",
       " 'Ä research',\n",
       " 'Ä office',\n",
       " 'Ä political',\n",
       " 'to',\n",
       " 'Ä together',\n",
       " 'Ä getting',\n",
       " 'Ä plan',\n",
       " 'Ä 25',\n",
       " 'T',\n",
       " 'Ä among',\n",
       " 'Ä coming',\n",
       " 'Ä decision',\n",
       " 'Ä video',\n",
       " 'Ä 2015',\n",
       " 'g',\n",
       " 'Ä After',\n",
       " 'Ä security',\n",
       " 'L',\n",
       " 'Ä care',\n",
       " 'Ä given',\n",
       " 'Ä available',\n",
       " 'Ã¢Ä¢Ä¶',\n",
       " 'Ä s',\n",
       " 'Ä West',\n",
       " \"'ll\",\n",
       " 'Ä pay',\n",
       " 'Ä near',\n",
       " 'Ä saying',\n",
       " 'Ä announced',\n",
       " 'Ä program',\n",
       " 'Ä April',\n",
       " 'Ä real',\n",
       " 'Ä University',\n",
       " 'Ä With',\n",
       " 'AP',\n",
       " 'Ä social',\n",
       " 'Ä close',\n",
       " 'et',\n",
       " 'Ä current',\n",
       " 'Ä why',\n",
       " 'F',\n",
       " 'Ä To',\n",
       " 'Ä Twitter',\n",
       " 'Ä though',\n",
       " 'Ä 17',\n",
       " 'Ä taking',\n",
       " 'Ä Inc',\n",
       " 'Ä men',\n",
       " 'w',\n",
       " 'Ä comes',\n",
       " 'ley',\n",
       " 'Ä doing',\n",
       " 'Ä process',\n",
       " 'Ä John',\n",
       " 'ch',\n",
       " '00',\n",
       " 'Ä financial',\n",
       " 'Ä low',\n",
       " 'Ä enough',\n",
       " 'Ä While',\n",
       " 'Ä further',\n",
       " 'Ä post',\n",
       " 'Ä feel',\n",
       " 'st',\n",
       " 'Ä person',\n",
       " 'Ä Facebook',\n",
       " 'Ä World',\n",
       " 'Ä within',\n",
       " 'ad',\n",
       " 'Ä done',\n",
       " 'the',\n",
       " 'Ä late',\n",
       " 'Ä tax',\n",
       " 'Ä doesn',\n",
       " 'Ä thing',\n",
       " 'Ä national',\n",
       " 'Ä job',\n",
       " 'Ä using',\n",
       " 'Ä However',\n",
       " 'ic',\n",
       " 'Ä campaign',\n",
       " 'Ä record',\n",
       " 'Ä behind',\n",
       " '://',\n",
       " 'Ä Department',\n",
       " 'p',\n",
       " 'Ä others',\n",
       " 'Ä January',\n",
       " 'Ä order',\n",
       " 'Ä [',\n",
       " 'Ä sales',\n",
       " 'Ä yet',\n",
       " 'Ã„',\n",
       " 'Ä small',\n",
       " 'Ä series',\n",
       " 'Ä face',\n",
       " 'Ä What',\n",
       " 'Ä 50',\n",
       " 'Ä ever',\n",
       " 'Ä earlier',\n",
       " 'Ä love',\n",
       " 'up',\n",
       " 'Ä rights',\n",
       " 'Ä An',\n",
       " 'ist',\n",
       " 'Ä morning',\n",
       " 'Ä Washington',\n",
       " 'Ä young',\n",
       " 'Ä latest',\n",
       " 'Ä India',\n",
       " 'Ä trying',\n",
       " 'Ä fire',\n",
       " 'Ä led',\n",
       " 'Ä strong',\n",
       " 'Ä return',\n",
       " 'Ä level',\n",
       " 'O',\n",
       " 'Ä average',\n",
       " 'Ä period',\n",
       " 'Ä experience',\n",
       " 'ak',\n",
       " 'Ä possible',\n",
       " 'Ä believe',\n",
       " 'Ä include',\n",
       " 'Ä oil',\n",
       " 'Ä recently',\n",
       " 'Ä once',\n",
       " 'Ä known',\n",
       " 'Ä lost',\n",
       " 'Ä sure',\n",
       " 'us',\n",
       " 'Ä weeks',\n",
       " 'Ä food',\n",
       " 'Ä reports',\n",
       " 'Ä rating',\n",
       " 'Ä Minister',\n",
       " 'Ä woman',\n",
       " 'Ä provide',\n",
       " 'Ä project',\n",
       " 'Ä issue',\n",
       " 'Ä live',\n",
       " '10',\n",
       " 'Ä clear',\n",
       " 'he',\n",
       " 'Ä cost',\n",
       " 'Ä played',\n",
       " 'Ä released',\n",
       " 'Ä coach',\n",
       " 'v',\n",
       " 'Ä 24',\n",
       " 'Ä seven',\n",
       " 'Ä plans',\n",
       " 'Ä development',\n",
       " 'ur',\n",
       " 'Äº',\n",
       " 'Ä increase',\n",
       " 'This',\n",
       " 'Ä policy',\n",
       " 'Ä cent',\n",
       " 'Ä based',\n",
       " 'E',\n",
       " 'il',\n",
       " 'Ä December',\n",
       " 'Ä global',\n",
       " 'Ä trade',\n",
       " 'Ä hours',\n",
       " 'Ä higher',\n",
       " 'Ä goal',\n",
       " 'H',\n",
       " 'Ä Al',\n",
       " 'Ä 100',\n",
       " 'Ä minutes',\n",
       " 'Ä election',\n",
       " 'Ä America',\n",
       " 'Ä rate',\n",
       " 'Ä Ch',\n",
       " 'Ä 21',\n",
       " '...',\n",
       " 'Ä White',\n",
       " 'Ä director',\n",
       " 'Ä position',\n",
       " 'Ä shot',\n",
       " 'Ä large',\n",
       " 'Ä c',\n",
       " 'Ä b',\n",
       " ']',\n",
       " 'Ä issues',\n",
       " 'Ä death',\n",
       " 'Ä building',\n",
       " 'Ä total',\n",
       " 'Ä often',\n",
       " 'Ä v',\n",
       " 'Ä countries',\n",
       " 'Ä history',\n",
       " 'Ä outside',\n",
       " 'Ä federal',\n",
       " 'Ä 19',\n",
       " 'Ä fact',\n",
       " 'Ä High',\n",
       " 'Ä career',\n",
       " 'im',\n",
       " 'Ä international',\n",
       " 'Ä November',\n",
       " 'Ä front',\n",
       " 'Ä kind',\n",
       " 'Ä key',\n",
       " 'ra',\n",
       " 'Ä San',\n",
       " 'Ä short',\n",
       " 'Ä name',\n",
       " 'Ä According',\n",
       " 'Ä course',\n",
       " 'Ä re',\n",
       " 'Ä wanted',\n",
       " 'W',\n",
       " 'Ä September',\n",
       " 'Ä interest',\n",
       " 'Ä role',\n",
       " 'Ä results',\n",
       " 'Ä economic',\n",
       " 'Ä 2014',\n",
       " 'Ä chance',\n",
       " 'Ä October',\n",
       " 'Ä special',\n",
       " 'Ä official',\n",
       " 'Ä needs',\n",
       " 'um',\n",
       " 'Ä l',\n",
       " 'Ä products',\n",
       " 'Ä non',\n",
       " 'Ä @',\n",
       " 'Ä Bank',\n",
       " 'Ä ahead',\n",
       " 'Ä house',\n",
       " 'U',\n",
       " 'Ä board',\n",
       " 'Ä old',\n",
       " 'Ä saw',\n",
       " 'Ä lower',\n",
       " 'Ä European',\n",
       " 'Ä control',\n",
       " 'Ä Russia',\n",
       " 'Ä eight',\n",
       " 'Ä release',\n",
       " 'Ä potential',\n",
       " 'Ä thought',\n",
       " 'Ä investigation',\n",
       " 'Ä online',\n",
       " 'based',\n",
       " 'Ä technology',\n",
       " 'Ä Donald',\n",
       " 'id',\n",
       " 'Ä body',\n",
       " 'Ä risk',\n",
       " 'ian',\n",
       " 'Ä capital',\n",
       " 'Ä staff',\n",
       " 'Ä action',\n",
       " 'Ä League',\n",
       " 'Ä playing',\n",
       " 'Ä makes',\n",
       " 'Ä almost',\n",
       " 'Ä performance',\n",
       " 'Ä 22',\n",
       " 'Ä g',\n",
       " 'Ä film',\n",
       " 'Ä nearly',\n",
       " 'Ä Center',\n",
       " 'Ä visit',\n",
       " 'Ä Group',\n",
       " 'Ä bank',\n",
       " 'Ä bit',\n",
       " 'Ä received',\n",
       " 'Ä August',\n",
       " 'Ä military',\n",
       " 'Ä His',\n",
       " 'ine',\n",
       " 'Ä chief',\n",
       " 'Ä School',\n",
       " 'Ä bring',\n",
       " 'Ä Court',\n",
       " 'Ä (@',\n",
       " 'Ä means',\n",
       " 'Ä Sh',\n",
       " 'Ä fans',\n",
       " 'Ä se',\n",
       " 'Ä 40',\n",
       " '20',\n",
       " '\".',\n",
       " 'V',\n",
       " 'Ä cut',\n",
       " 'Ä killed',\n",
       " 'Ä #',\n",
       " 'Ä prices',\n",
       " 'Ä gave',\n",
       " 'Ä Street',\n",
       " 'ir',\n",
       " 'Ä Y',\n",
       " 'Ä currently',\n",
       " 'Ä f',\n",
       " 'ay',\n",
       " 'ne',\n",
       " 'te',\n",
       " 'Ä try',\n",
       " 'Ä Park',\n",
       " 'Ä¥',\n",
       " 'J',\n",
       " 'Ä question',\n",
       " 'Ä hand',\n",
       " 'Ä economy',\n",
       " 'Ä investors',\n",
       " 'able',\n",
       " 'Ä player',\n",
       " 'Ä By',\n",
       " 'Ä David',\n",
       " 'Ä loss',\n",
       " 'ab',\n",
       " 'Ä below',\n",
       " 'Ä wrote',\n",
       " 'co',\n",
       " 'ate',\n",
       " 'Ä running',\n",
       " 'un',\n",
       " 'Ä began',\n",
       " 'Ä single',\n",
       " 'Ä field',\n",
       " 'Ä 23',\n",
       " 'Ä leader',\n",
       " 'Ä w',\n",
       " 'Ä California',\n",
       " 'Ä fourth',\n",
       " 'Ä actually',\n",
       " 'Ä list',\n",
       " 'll',\n",
       " 'Ä couple',\n",
       " 'Ä study',\n",
       " 'Ä teams',\n",
       " 'He',\n",
       " 'ah',\n",
       " 'Ä Canada',\n",
       " 'Ä la',\n",
       " 'Ä result',\n",
       " 'Ä access',\n",
       " 'Ä vote',\n",
       " 'Ä More',\n",
       " 'Ä February',\n",
       " 'Ä revenue',\n",
       " 'Ä offer',\n",
       " 'Ä let',\n",
       " 'ier',\n",
       " 'Ä buy',\n",
       " 'Ä attack',\n",
       " 'Ä black',\n",
       " 'Ä r',\n",
       " 'Ä areas',\n",
       " 'Ä stop',\n",
       " 'Ä impact',\n",
       " 'Ä match',\n",
       " 'Ä investment',\n",
       " 'Ä customers',\n",
       " 'Ä leaders',\n",
       " 'ies',\n",
       " 'Ä member',\n",
       " 'Ä child',\n",
       " 'Ä road',\n",
       " 'ul',\n",
       " 'Ä value',\n",
       " 'Ä shows',\n",
       " 'Ä Dr',\n",
       " 'Ä De',\n",
       " 'ant',\n",
       " 'Ä London',\n",
       " 'Ä room',\n",
       " 'Ä music',\n",
       " 'Ä production',\n",
       " 'Ä anything',\n",
       " 'Ä firm',\n",
       " 'Ä biggest',\n",
       " 'Ä air',\n",
       " 'Ä problem',\n",
       " 'Ä general',\n",
       " 'Ä wasn',\n",
       " 'Ä i',\n",
       " 'Ä private',\n",
       " 'Ä especially',\n",
       " 'Ä administration',\n",
       " 'Ä additional',\n",
       " 'Ä Co',\n",
       " 'Ä opportunity',\n",
       " 'Ä hold',\n",
       " '&',\n",
       " 'Ä matter',\n",
       " 'Ä senior',\n",
       " 'Ä club',\n",
       " 'Ä someone',\n",
       " 'Ä Ãƒ',\n",
       " 'Ä East',\n",
       " 'Ä 2019',\n",
       " \".'\",\n",
       " 'Ä needed',\n",
       " 'Ä James',\n",
       " 'time',\n",
       " 'Ä however',\n",
       " 'Ä everything',\n",
       " 'Ä everyone',\n",
       " 'Ä died',\n",
       " 'Ä involved',\n",
       " 'Ä friends',\n",
       " 'Ä isn',\n",
       " 'Ä worth',\n",
       " 'ik',\n",
       " 'Ä Cup',\n",
       " 'Ä showed',\n",
       " 'There',\n",
       " 'Ä 28',\n",
       " 'Ä meet',\n",
       " 'Ä 26',\n",
       " 'Ä 27',\n",
       " 'Y',\n",
       " 'Ä region',\n",
       " 'Ä Press',\n",
       " 'Ä Now',\n",
       " 'Ä son',\n",
       " 'Ä space',\n",
       " 'Ä leading',\n",
       " 'Ä states',\n",
       " 'Ä weekend',\n",
       " 'Ä Ã‚Â£',\n",
       " 'Ä mother',\n",
       " 'Ä previous',\n",
       " 'Ä UK',\n",
       " 'Ä Michael',\n",
       " 'Ä leave',\n",
       " 'est',\n",
       " 'em',\n",
       " 'Ä z',\n",
       " 'Ä Some',\n",
       " 'ors',\n",
       " 'out',\n",
       " '15',\n",
       " 'Ä war',\n",
       " 'Ä website',\n",
       " 'Ä star',\n",
       " ...]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(roberta_vocab.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab(corpus):\n",
    "    vocabulary = Counter()\n",
    "    for sentance in corpus:\n",
    "        for word in sentance.split():\n",
    "            vocabulary.update([word])\n",
    "    return vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_coverage(vocabs, roberta_vocab):\n",
    "    known_words = {}\n",
    "    unknown_words = {}\n",
    "    known_count = 0\n",
    "    unknown_count = 0\n",
    "    for word in tqdm(vocabs.keys(), desc='Checking: '):\n",
    "        if word in list(roberta_vocab.keys()):\n",
    "            known_words[word] = roberta_vocab[word]\n",
    "            known_count += vocabs[word]\n",
    "        elif 'Ä ' + word in list(roberta_vocab.keys()):\n",
    "            # If we have deep look in roberta tokenizer, many words combine with 'Ä ' since roberta is byte pair encoding\n",
    "            known_words[word] = roberta_vocab['Ä ' + word]\n",
    "            known_count += vocabs[word]            \n",
    "        else:\n",
    "            unknown_words[word] = vocabs[word]\n",
    "            unknown_count += vocabs[word]\n",
    "    print(\"Found embeddings for {:.3%} ({} / {}) of vocab\".format(len(known_words) / len(vocabs), len(known_words), len(vocabs)))\n",
    "    print(\"Found embeddings for {:.3%} ({} / {}) of all text\".format(known_count / (known_count + unknown_count), known_count, (known_count + unknown_count)))\n",
    "    return unknown_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train text unique vocab count is: 68961\n",
      "train reply unique vocab count is: 25542\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=68961.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 22.820% (15737 / 68961) of vocab\n",
      "Found embeddings for 77.681% (508783 / 654963) of all text\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=25542.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 30.307% (7741 / 25542) of vocab\n",
      "Found embeddings for 73.164% (79306 / 108395) of all text\n"
     ]
    }
   ],
   "source": [
    "train_text_vocab = get_vocab(df_train['text'].values)\n",
    "train_reply_vocab = get_vocab(df_train['reply'].values)\n",
    "print(\"train text unique vocab count is: {}\".format(len(train_text_vocab)))\n",
    "print(\"train reply unique vocab count is: {}\".format(len(train_reply_vocab)))\n",
    "unknown_text = check_coverage(train_text_vocab, roberta_vocab)\n",
    "print()\n",
    "unknown_reply = check_coverage(train_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev text unique vocab count is: 17684\n",
      "dev reply unique vocab count is: 5360\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=17684.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 39.064% (6908 / 17684) of vocab\n",
      "Found embeddings for 77.472% (64280 / 82972) of all text\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=5360.0, style=ProgressStyle(description_â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 45.243% (2425 / 5360) of vocab\n",
      "Found embeddings for 72.608% (10046 / 13836) of all text\n"
     ]
    }
   ],
   "source": [
    "dev_text_vocab = get_vocab(df_dev['text'].values)\n",
    "dev_reply_vocab = get_vocab(df_dev['reply'].values)\n",
    "print(\"dev text unique vocab count is: {}\".format(len(dev_text_vocab)))\n",
    "print(\"dev reply unique vocab count is: {}\".format(len(dev_reply_vocab)))\n",
    "unknown_text = check_coverage(dev_text_vocab, roberta_vocab)\n",
    "print()\n",
    "unknown_reply = check_coverage(dev_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test text unique vocab count is: 17338\n",
      "test reply unique vocab count is: 5187\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=17338.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 39.826% (6905 / 17338) of vocab\n",
      "Found embeddings for 78.101% (63967 / 81903) of all text\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=5187.0, style=ProgressStyle(description_â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 45.171% (2343 / 5187) of vocab\n",
      "Found embeddings for 72.828% (9641 / 13238) of all text\n"
     ]
    }
   ],
   "source": [
    "test_text_vocab = get_vocab(df_test['text'].values)\n",
    "test_reply_vocab = get_vocab(df_test['reply'].values)\n",
    "print(\"test text unique vocab count is: {}\".format(len(test_text_vocab)))\n",
    "print(\"test reply unique vocab count is: {}\".format(len(test_reply_vocab)))\n",
    "unknown_text = check_coverage(test_text_vocab, roberta_vocab)\n",
    "print()\n",
    "unknown_reply = check_coverage(test_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try to convert to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab_lower(corpus):\n",
    "    vocabulary = Counter()\n",
    "    for sentance in corpus:\n",
    "        for word in sentance.lower().split():\n",
    "            vocabulary.update([word])\n",
    "    return vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train text unique vocab count is: 60613\n",
      "train reply unique vocab count is: 22586\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=60613.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 19.479% (11807 / 60613) of vocab\n",
      "Found embeddings for 77.394% (506905 / 654963) of all text\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=22586.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 27.344% (6176 / 22586) of vocab\n",
      "Found embeddings for 73.495% (79665 / 108395) of all text\n"
     ]
    }
   ],
   "source": [
    "train_text_vocab = get_vocab_lower(df_train['text'].values)\n",
    "train_reply_vocab = get_vocab_lower(df_train['reply'].values)\n",
    "print(\"train text unique vocab count is: {}\".format(len(train_text_vocab)))\n",
    "print(\"train reply unique vocab count is: {}\".format(len(train_reply_vocab)))\n",
    "unknown_text_lower = check_coverage(train_text_vocab, roberta_vocab)\n",
    "print()\n",
    "unknown_reply_lower = check_coverage(train_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev text unique vocab count is: 15888\n",
      "dev reply unique vocab count is: 4818\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=15888.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 35.203% (5593 / 15888) of vocab\n",
      "Found embeddings for 77.151% (64014 / 82972) of all text\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=4818.0, style=ProgressStyle(description_â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 42.777% (2061 / 4818) of vocab\n",
      "Found embeddings for 73.143% (10120 / 13836) of all text\n"
     ]
    }
   ],
   "source": [
    "dev_text_vocab = get_vocab_lower(df_dev['text'].values)\n",
    "dev_reply_vocab = get_vocab_lower(df_dev['reply'].values)\n",
    "print(\"dev text unique vocab count is: {}\".format(len(dev_text_vocab)))\n",
    "print(\"dev reply unique vocab count is: {}\".format(len(dev_reply_vocab)))\n",
    "unknown_text = check_coverage(dev_text_vocab, roberta_vocab)\n",
    "print()\n",
    "unknown_reply = check_coverage(dev_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test text unique vocab count is: 15473\n",
      "test reply unique vocab count is: 4674\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=15473.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 36.418% (5635 / 15473) of vocab\n",
      "Found embeddings for 77.830% (63745 / 81903) of all text\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=4674.0, style=ProgressStyle(description_â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 42.576% (1990 / 4674) of vocab\n",
      "Found embeddings for 73.236% (9695 / 13238) of all text\n"
     ]
    }
   ],
   "source": [
    "test_text_vocab = get_vocab_lower(df_test['text'].values)\n",
    "test_reply_vocab = get_vocab_lower(df_test['reply'].values)\n",
    "print(\"test text unique vocab count is: {}\".format(len(test_text_vocab)))\n",
    "print(\"test reply unique vocab count is: {}\".format(len(test_reply_vocab)))\n",
    "unknown_text = check_coverage(test_text_vocab, roberta_vocab)\n",
    "print()\n",
    "unknown_reply = check_coverage(test_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show some unknown tokens!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'@youngdeji_': 1,\n",
       " 'uzi': 2,\n",
       " 'carti': 4,\n",
       " 'monday': 3,\n",
       " 'woah': 1,\n",
       " 'weâ€™re': 27,\n",
       " 'safety.': 1,\n",
       " 'dababy': 4,\n",
       " 'niggas': 10,\n",
       " 'dennyâ€™s': 1,\n",
       " 'indians': 3,\n",
       " 'donâ€™t': 126,\n",
       " 'cricket.': 1,\n",
       " 'wouldâ€™ve': 3,\n",
       " 'out.': 21,\n",
       " 'zaira': 1,\n",
       " 'wasim': 1,\n",
       " 'hardwork': 1,\n",
       " 'screen.': 1,\n",
       " 'sick.': 4,\n",
       " '@madisonbeer': 1,\n",
       " 'iâ€™ve': 57,\n",
       " 'â€œas': 2,\n",
       " 'pleaseâ€': 1,\n",
       " 'wtf': 8,\n",
       " '@lupeloops': 1,\n",
       " 'ğŸ˜“': 3,\n",
       " \"haven't\": 7,\n",
       " 'ops,': 1,\n",
       " \"ain't\": 6,\n",
       " 'disappointments....': 1,\n",
       " 'work.': 6,\n",
       " 'cried.': 1,\n",
       " 'settings,': 1,\n",
       " 'home,': 3,\n",
       " 'it.': 94,\n",
       " 'nightmare.': 3,\n",
       " 'spamming': 4,\n",
       " 'mad.': 4,\n",
       " 'couldnâ€™t': 10,\n",
       " 'back.': 14,\n",
       " 'replying': 5,\n",
       " 'â€œwho': 4,\n",
       " 'are?!â€': 3,\n",
       " 'up.': 25,\n",
       " 'ğŸ˜°': 4,\n",
       " 'understands.': 1,\n",
       " 'prophet.': 1,\n",
       " 'doing?': 4,\n",
       " 'iâ€™m': 263,\n",
       " 'overreacting,': 1,\n",
       " 'obsessing,': 1,\n",
       " 'worrying,': 1,\n",
       " 'disassociating.': 1,\n",
       " 'here!': 2,\n",
       " 'covid-19': 34,\n",
       " 'vaccine?': 11,\n",
       " 'myrtle': 1,\n",
       " 'am.': 3,\n",
       " 'spiraling.': 1,\n",
       " 'grudges.': 1,\n",
       " 'so,': 7,\n",
       " 'mind,': 2,\n",
       " \"who's\": 9,\n",
       " 'me?': 11,\n",
       " 'oldrich': 6,\n",
       " 'people,': 13,\n",
       " 'judgement,': 6,\n",
       " 'kindness,': 8,\n",
       " '(now': 6,\n",
       " 'â€œteammatesâ€)!': 6,\n",
       " 'canâ€™t': 55,\n",
       " 'hyperventilate': 1,\n",
       " 'bag.': 2,\n",
       " 'â˜¹ï¸': 2,\n",
       " 'could.': 1,\n",
       " 'able,': 1,\n",
       " 'yeah?': 1,\n",
       " 'you.': 35,\n",
       " 'ğŸ’›': 2,\n",
       " '\\U0001f97a': 14,\n",
       " 'hands,': 1,\n",
       " \"they're\": 12,\n",
       " \"you're\": 45,\n",
       " 'trumpâ€™s': 10,\n",
       " 'health?': 1,\n",
       " \"i'm\": 186,\n",
       " 'lunch.': 1,\n",
       " \"who'd\": 1,\n",
       " 'join?': 1,\n",
       " 'guaging': 1,\n",
       " 'interest.': 2,\n",
       " 'trump,': 5,\n",
       " 'script,': 1,\n",
       " \"country's\": 1,\n",
       " '\"since': 1,\n",
       " 'ii.\"': 1,\n",
       " '\"most': 1,\n",
       " 'all\":': 1,\n",
       " \"americans'\": 1,\n",
       " 'courage.': 2,\n",
       " \"who've\": 2,\n",
       " 'pain.': 6,\n",
       " 'yesterday.': 2,\n",
       " 'idk': 13,\n",
       " 'me.': 58,\n",
       " 'better.': 14,\n",
       " 'wna': 2,\n",
       " 'fucj': 1,\n",
       " 'bcs': 1,\n",
       " 'trash.': 2,\n",
       " 'yourself.': 2,\n",
       " 'natin': 1,\n",
       " 'germany:': 1,\n",
       " '\"what': 3,\n",
       " 'stupidity?\"': 1,\n",
       " '\"mexico': 1,\n",
       " 'canada!\"': 1,\n",
       " 'what?!': 1,\n",
       " '#whyruep12': 1,\n",
       " 'simpsons': 2,\n",
       " \"#scottyfrommarketing's\": 23,\n",
       " 'app.': 26,\n",
       " 'gif.': 26,\n",
       " 'hollyweird': 1,\n",
       " 'pedophile': 1,\n",
       " 'iâ€™ll': 47,\n",
       " 'grandiloquent': 1,\n",
       " 'hypocrites': 1,\n",
       " 'joe': 24,\n",
       " 'biden,': 1,\n",
       " 'â€œi': 7,\n",
       " 'jumpinâ€™': 1,\n",
       " 'lapâ€': 1,\n",
       " 'biden': 26,\n",
       " 'now,': 20,\n",
       " 'petulance,': 1,\n",
       " 'gridlock,': 1,\n",
       " 'vendettas': 1,\n",
       " 'itâ€™s': 117,\n",
       " 'â€˜bates': 1,\n",
       " 'motelâ€™??': 1,\n",
       " 'spoilers!!': 1,\n",
       " '3.': 7,\n",
       " 'yâ€™all,': 1,\n",
       " 'normanâ€™s': 1,\n",
       " 'nerves.': 1,\n",
       " 'heâ€™s': 27,\n",
       " 'ğŸ¤·ğŸ»\\u200dâ™€ï¸ğŸ¤·ğŸ»\\u200dâ™€ï¸': 1,\n",
       " \"i've\": 31,\n",
       " 'night.': 9,\n",
       " 'bombarded': 2,\n",
       " 'hurtful': 3,\n",
       " 'words.': 2,\n",
       " 'sapped': 2,\n",
       " 'dry.': 2,\n",
       " '#salt': 2,\n",
       " 'skateboard': 1,\n",
       " 'iâ€™d': 12,\n",
       " 'ass.': 4,\n",
       " 'ğŸ™Œ': 2,\n",
       " 'york': 8,\n",
       " \"post's\": 1,\n",
       " \"halladay's\": 1,\n",
       " 'today.': 41,\n",
       " '\"some': 2,\n",
       " 'wonâ€™t': 9,\n",
       " 'halladay': 1,\n",
       " 'amphetamines': 1,\n",
       " 'morphine\"': 1,\n",
       " '$$?': 2,\n",
       " '$200': 3,\n",
       " 'hours.': 14,\n",
       " '@loyalgiveaways': 2,\n",
       " 'somn': 1,\n",
       " 'dick,': 3,\n",
       " 'ainâ€™t': 13,\n",
       " \"don't\": 97,\n",
       " 'going,': 3,\n",
       " 'lot.': 3,\n",
       " \"it's\": 125,\n",
       " 'america.': 7,\n",
       " 'ğŸ™‹\\u200dâ™‚ï¸ğŸ™‹\\u200dâ™‚ï¸ğŸ™‹\\u200dâ™‚ï¸': 2,\n",
       " 'in:': 8,\n",
       " 'china': 27,\n",
       " 'coronavirus': 41,\n",
       " 'needğŸŒ¹solo': 1,\n",
       " 'ğŸŒ¹sanağŸŒ¹projectsğŸŒ¹': 1,\n",
       " 'rapists?': 1,\n",
       " 'em?': 1,\n",
       " 'morning!': 1,\n",
       " 'today!': 7,\n",
       " 'specifically?': 1,\n",
       " '#svtraintobusan': 1,\n",
       " 'smh': 6,\n",
       " 'ğŸ˜­': 16,\n",
       " '2020!': 2,\n",
       " 'lockdowns': 3,\n",
       " 'quarantining.': 1,\n",
       " 'conflated.': 1,\n",
       " 'risk.': 1,\n",
       " '@dxvilishangxl': 1,\n",
       " 'veniece': 1,\n",
       " 'drive-in': 1,\n",
       " 'punks': 1,\n",
       " 'smuggle': 1,\n",
       " 'days!': 1,\n",
       " 'america': 65,\n",
       " 'up?': 10,\n",
       " 'no?': 11,\n",
       " 'negotiations,': 3,\n",
       " \"government's\": 3,\n",
       " 'eu.': 3,\n",
       " 'december': 6,\n",
       " 'year.': 10,\n",
       " 'no.': 12,\n",
       " '1/2': 4,\n",
       " 'app,': 24,\n",
       " '#bailouthumansnow': 25,\n",
       " '@shelleymcelyea1': 1,\n",
       " 'birthday,': 3,\n",
       " 'â¤ï¸ğŸ’‹ğŸğŸ‰ğŸ°ğŸˆ': 1,\n",
       " '#giveaway': 3,\n",
       " '$25': 4,\n",
       " '24hours..': 1,\n",
       " 'like/rt/tag': 1,\n",
       " '(must': 1,\n",
       " 'me)': 1,\n",
       " 'following?': 1,\n",
       " 'grow!': 1,\n",
       " 'ğŸ”¥ğŸš€': 1,\n",
       " \"how's\": 4,\n",
       " 'flutter?': 1,\n",
       " 'gifs': 17,\n",
       " '\\U0001f91fğŸ¼': 1,\n",
       " '#flutter': 1,\n",
       " 'also,': 21,\n",
       " \"win's\": 1,\n",
       " '\"how': 2,\n",
       " 'drop\"': 1,\n",
       " 'govt': 10,\n",
       " \"'stay\": 1,\n",
       " \"lives'\": 2,\n",
       " '15,000': 1,\n",
       " 'checks,': 4,\n",
       " 'worst-hit': 1,\n",
       " 'nyc': 4,\n",
       " 'italy.': 1,\n",
       " 'something?': 2,\n",
       " '@seanhannity': 18,\n",
       " 'minutes.': 4,\n",
       " 'in!': 4,\n",
       " 'power?': 4,\n",
       " 'â€˜promoter': 1,\n",
       " 'unconvincing': 1,\n",
       " 'consoler': 1,\n",
       " 'chief.': 1,\n",
       " 'hugger,': 1,\n",
       " '~s': 1,\n",
       " 'news:': 2,\n",
       " 'years,': 2,\n",
       " '@tes.': 1,\n",
       " 'director.': 1,\n",
       " 'journalism.': 1,\n",
       " '1/': 1,\n",
       " 'didnâ€™t': 32,\n",
       " 'sister.': 3,\n",
       " '20â€™s': 2,\n",
       " '-famu': 3,\n",
       " 'cnbc': 1,\n",
       " 'aawaz': 1,\n",
       " 'package.': 3,\n",
       " '30th': 3,\n",
       " 'days.': 4,\n",
       " 'birthday.': 8,\n",
       " 'eke,': 1,\n",
       " 'uti,': 1,\n",
       " 'hardworking': 1,\n",
       " 'bobrisky,': 1,\n",
       " 'enkayy': 1,\n",
       " 'spartans.': 1,\n",
       " 'â¤ï¸': 21,\n",
       " '#zenmagazine': 1,\n",
       " '@liberianboii': 1,\n",
       " 'twenties.': 1,\n",
       " 'married.': 2,\n",
       " 'people.': 18,\n",
       " 'follow.': 6,\n",
       " 'you,': 22,\n",
       " 'there.': 8,\n",
       " 'day?': 4,\n",
       " 'shet': 1,\n",
       " 'ğŸ˜®ğŸ˜…': 1,\n",
       " 'ago,': 4,\n",
       " 'tinder': 2,\n",
       " 'services.': 1,\n",
       " 'premium,': 1,\n",
       " 'profile,': 1,\n",
       " 'theirs.': 1,\n",
       " 'celebratory': 1,\n",
       " 'thereâ€™s': 21,\n",
       " 'ğŸ˜': 5,\n",
       " 'monday!': 2,\n",
       " 'ğŸ‘»ğŸ‘»ğŸ‘»': 2,\n",
       " 'disrespects': 1,\n",
       " 'religion.': 1,\n",
       " 'tbh...at': 1,\n",
       " 'sinning': 1,\n",
       " 'seala': 1,\n",
       " '@filmgob': 1,\n",
       " '@jodyscorner1': 1,\n",
       " 'nonsense.': 1,\n",
       " 'filmgob': 1,\n",
       " 'jody': 1,\n",
       " 'there?': 1,\n",
       " 'interesting.': 4,\n",
       " '$1,200': 12,\n",
       " \"trump's\": 16,\n",
       " 'obama': 16,\n",
       " \"he's\": 23,\n",
       " 'questionsâ€¦': 12,\n",
       " '(not': 4,\n",
       " \"isn't\": 17,\n",
       " 'ill,': 3,\n",
       " 'holiday,': 2,\n",
       " 'fridge)': 2,\n",
       " 'cabinet,': 3,\n",
       " 'parliament:': 2,\n",
       " 'pandemic': 16,\n",
       " 'brexit-induced': 2,\n",
       " 'crisis:': 3,\n",
       " 'through.': 2,\n",
       " '\"\\U0001f97a\"': 1,\n",
       " 'emojis': 2,\n",
       " 'up,': 13,\n",
       " 'down.': 9,\n",
       " 'overthinking': 1,\n",
       " 'away.': 5,\n",
       " 'guys..?': 1,\n",
       " 's/o': 1,\n",
       " 'yâ€™all': 39,\n",
       " '13k+': 1,\n",
       " '#covid_19': 7,\n",
       " 'india,': 1,\n",
       " 'recovered.': 1,\n",
       " '400+.': 1,\n",
       " 'situation,': 1,\n",
       " '@mohfw_india': 1,\n",
       " '@drharshvardhan': 1,\n",
       " '@pmoindia': 1,\n",
       " 'consider:': 1,\n",
       " 'decelerate': 1,\n",
       " 'panic,': 1,\n",
       " 'prone,': 1,\n",
       " 'neglected?': 1,\n",
       " 'am,': 1,\n",
       " 'dreading,': 1,\n",
       " 'vibes': 5,\n",
       " 'nudes': 5,\n",
       " 'u.s': 2,\n",
       " 'it???': 1,\n",
       " 'intro.': 1,\n",
       " 'two.': 1,\n",
       " '50+': 1,\n",
       " 'secs': 1,\n",
       " 'â€”': 8,\n",
       " 'nope.': 3,\n",
       " '@kellyinvegas': 1,\n",
       " '@vegasmurray': 1,\n",
       " 'signed,': 1,\n",
       " 'rhode': 1,\n",
       " 'jacob': 1,\n",
       " 'toppin': 1,\n",
       " 'kentucky,': 1,\n",
       " 'page.': 2,\n",
       " 'ğŸ˜­â¤ï¸': 1,\n",
       " 'housekeeping': 1,\n",
       " 'yet.': 5,\n",
       " 'theyâ€™re': 12,\n",
       " 'in.': 4,\n",
       " 'decorate': 1,\n",
       " 'doesnâ€™t': 25,\n",
       " 'ridiculous.': 1,\n",
       " 'ğŸ‘€': 8,\n",
       " '.@joebiden': 1,\n",
       " 'ğŸ¤”': 21,\n",
       " 'chinese': 11,\n",
       " '#covid19pandemic': 4,\n",
       " 'americans': 29,\n",
       " 'jobs.': 4,\n",
       " 'responsible.': 4,\n",
       " 'account.': 6,\n",
       " 'hourrrssss': 1,\n",
       " '@shmsaaldh': 1,\n",
       " 'sweatshirt': 1,\n",
       " 'time.': 20,\n",
       " 'havenâ€™t': 14,\n",
       " 'hammock': 1,\n",
       " 'isolation,': 1,\n",
       " 'tests?': 1,\n",
       " 'fun:': 1,\n",
       " 'shehnaaz': 2,\n",
       " 'gill': 1,\n",
       " 'question,': 3,\n",
       " 'be.': 6,\n",
       " 'one.': 9,\n",
       " '#shehnaazgill': 1,\n",
       " '@ishehnaaz_gill': 1,\n",
       " '@kaushaljoshi15': 1,\n",
       " 'depression.': 2,\n",
       " 'worse.': 9,\n",
       " 'hi.': 15,\n",
       " 'isnâ€™t': 13,\n",
       " 'nose....': 1,\n",
       " 'pointless.': 1,\n",
       " 'please.': 3,\n",
       " \"doesn't\": 24,\n",
       " 'exist;': 1,\n",
       " 'trump:': 15,\n",
       " '\"i': 17,\n",
       " 'campaigning.\"': 8,\n",
       " 'whoâ€™s': 11,\n",
       " 'goin': 1,\n",
       " 'thorpe': 1,\n",
       " 'park/alton': 1,\n",
       " 'yâ€™all!!!': 1,\n",
       " 'twitch!!!': 1,\n",
       " '\\U0001f973\\U0001f929': 1,\n",
       " 'me!': 10,\n",
       " 'yâ€™all!': 1,\n",
       " 'donos': 1,\n",
       " 'ğŸ’—': 1,\n",
       " 'who-the-hell-even-knows-anymore': 18,\n",
       " 'quarantine:': 19,\n",
       " 'gif,': 21,\n",
       " 'read/hear': 18,\n",
       " '\"we\\'re': 18,\n",
       " 'together\".': 18,\n",
       " 'ğŸ‘‹ğŸ»': 1,\n",
       " 'relaxation?': 1,\n",
       " 'hunch': 1,\n",
       " 'page,': 1,\n",
       " 'pencil,': 1,\n",
       " 'choice.': 3,\n",
       " 'done,': 10,\n",
       " 'therapy.': 9,\n",
       " '@the_badger_jm': 1,\n",
       " 'fsq!!': 1,\n",
       " 'players.': 2,\n",
       " 'not.': 11,\n",
       " 'memory?': 1,\n",
       " 'werenâ€™t': 4,\n",
       " 'great,': 2,\n",
       " 'were?': 1,\n",
       " 'childhood:': 1,\n",
       " 'ğŸ˜‹': 4,\n",
       " '65th': 2,\n",
       " 'sonâ€™s': 5,\n",
       " 'yup': 2,\n",
       " 'gif?': 2,\n",
       " '$50,000': 2,\n",
       " 'run?': 2,\n",
       " '#btc': 3,\n",
       " 'biden?': 5,\n",
       " 'ggs': 1,\n",
       " '@cetralol': 1,\n",
       " 'maad': 1,\n",
       " '1-0': 2,\n",
       " 'prl!': 1,\n",
       " '9pm': 1,\n",
       " 'defiance.': 1,\n",
       " 'passion/happiness': 1,\n",
       " 'life....or': 1,\n",
       " 'condescending!!': 1,\n",
       " 'everyone.': 5,\n",
       " 'awful.': 4,\n",
       " 'covid19.': 4,\n",
       " 'straight.': 5,\n",
       " 'her.': 8,\n",
       " 'forever.': 4,\n",
       " 'unwell': 2,\n",
       " '@schittscreek': 1,\n",
       " 'disneyâ€™s': 1,\n",
       " 'along...': 1,\n",
       " '@stageit': 2,\n",
       " 'week?': 3,\n",
       " '\"we\"': 2,\n",
       " 'we.': 2,\n",
       " \"can't\": 51,\n",
       " 'alone...that': 2,\n",
       " 'sad.': 3,\n",
       " '4/20': 2,\n",
       " 'audacity': 1,\n",
       " 'skype': 1,\n",
       " '9am.': 1,\n",
       " '11am?': 1,\n",
       " 'letâ€™s': 15,\n",
       " 'fantasized': 1,\n",
       " 'smothering': 1,\n",
       " 'pillow.': 2,\n",
       " 'scale?': 1,\n",
       " 'virginia,': 14,\n",
       " '2nd': 18,\n",
       " 'amendment.': 11,\n",
       " 'siege!': 11,\n",
       " 'while.': 6,\n",
       " 'hella': 4,\n",
       " 'now.': 21,\n",
       " 'verkis': 1,\n",
       " 'yâ€™all?': 1,\n",
       " 'assğŸ˜©': 1,\n",
       " 'glasses,': 1,\n",
       " 'foggy': 1,\n",
       " 'specs!!!': 1,\n",
       " '#covid19': 16,\n",
       " 'to,': 1,\n",
       " 'to.': 4,\n",
       " '.@who': 1,\n",
       " 'pandemic,': 3,\n",
       " 'advice,': 1,\n",
       " 'training,': 1,\n",
       " 'livesâ€”including': 1,\n",
       " 'americansâ€™.': 1,\n",
       " 'dangerousâ€”trump': 1,\n",
       " 'know:': 3,\n",
       " 'impeached.': 1,\n",
       " 'nigga': 6,\n",
       " 'aboogie': 1,\n",
       " 'prime,': 2,\n",
       " 'hurt.': 2,\n",
       " \"that's\": 30,\n",
       " 'redskins': 1,\n",
       " 'morning.': 12,\n",
       " 'uh.': 1,\n",
       " '#oustduterenow': 3,\n",
       " '#oustdutertenow': 1,\n",
       " 'philippines': 1,\n",
       " '@coliathgaming': 1,\n",
       " '@baker_tv_': 1,\n",
       " '@vicdgordon': 1,\n",
       " '@streamgamma': 1,\n",
       " '@kedabosch': 1,\n",
       " '@day1negaming': 1,\n",
       " '@jxckwsw': 1,\n",
       " '@ncshredder_': 1,\n",
       " '@samurai_ree': 1,\n",
       " '@stardrix1': 1,\n",
       " '@gso_joey': 1,\n",
       " '@tsillysweat': 1,\n",
       " '@chloedonald_': 1,\n",
       " '@xlexry': 1,\n",
       " '@multynwolf': 1,\n",
       " '@saycredangel': 1,\n",
       " '@fuscyoface': 1,\n",
       " '@storkyyy1': 1,\n",
       " 'kamo': 1,\n",
       " 'mphela': 1,\n",
       " '\"she': 1,\n",
       " 'shit\"': 2,\n",
       " 'ğŸ˜•': 1,\n",
       " 'intensions.': 1,\n",
       " 'actions.': 1,\n",
       " 'steyer': 1,\n",
       " 'lives.': 5,\n",
       " 'california.': 3,\n",
       " 'newsom': 2,\n",
       " 'force,': 1,\n",
       " 'injustices': 1,\n",
       " 'crisis.': 4,\n",
       " 'reasonable,': 1,\n",
       " 'know.': 9,\n",
       " 'ğŸ’¨ğŸ’¨': 1,\n",
       " 'yall': 15,\n",
       " 'caucasians': 1,\n",
       " '4th': 7,\n",
       " 'july?!!!!!': 1,\n",
       " 'convo': 4,\n",
       " 'meteoric': 1,\n",
       " 'again.': 21,\n",
       " 'soon.': 4,\n",
       " 'nathaniel': 14,\n",
       " 'cnn': 16,\n",
       " 'here.': 20,\n",
       " 'you?': 21,\n",
       " '7th': 8,\n",
       " 'dms?': 7,\n",
       " 'did.': 3,\n",
       " 'orders.': 2,\n",
       " 'oklahoma': 1,\n",
       " '53%': 1,\n",
       " '60%': 3,\n",
       " 'arkansas,': 1,\n",
       " '74%': 1,\n",
       " 'nebraska,': 1,\n",
       " '82%': 1,\n",
       " 'iowa.': 1,\n",
       " 'dakota': 3,\n",
       " '205%': 1,\n",
       " 'spike.': 1,\n",
       " '#stayhomestaysafesavelives': 1,\n",
       " 'body.': 4,\n",
       " \"what's\": 13,\n",
       " 'first.': 4,\n",
       " '#smallvictory': 1,\n",
       " 'decorating': 1,\n",
       " '#animalcrossing': 1,\n",
       " 'november': 5,\n",
       " 'preview:': 2,\n",
       " 'mitch': 2,\n",
       " 'mcconnell': 2,\n",
       " 'lindsey': 4,\n",
       " 'graham': 7,\n",
       " 'susan': 2,\n",
       " 'collins': 4,\n",
       " 'martha': 2,\n",
       " 'mcsally': 2,\n",
       " 'cory': 2,\n",
       " 'gardner': 2,\n",
       " 'kelly': 4,\n",
       " 'loeffler': 3,\n",
       " 'thom': 2,\n",
       " 'tillis': 2,\n",
       " 'yeah,': 6,\n",
       " 'night,': 2,\n",
       " 'dreamt': 1,\n",
       " 'journalists,': 2,\n",
       " 'uddhav': 1,\n",
       " 'pm.': 2,\n",
       " 'mine,': 1,\n",
       " 'no,': 7,\n",
       " '#soproudofmyself': 1,\n",
       " 'hooping': 1,\n",
       " '$50': 8,\n",
       " 'retweets': 6,\n",
       " '@k_9girl': 1,\n",
       " 'myself.': 11,\n",
       " 'krispies': 2,\n",
       " 'this?': 4,\n",
       " 'wasted.': 1,\n",
       " 'repaint': 1,\n",
       " 'home.': 6,\n",
       " 'ğŸ˜Š': 18,\n",
       " 'man-half': 1,\n",
       " 'assholes': 2,\n",
       " 'exercise,': 1,\n",
       " 'shit,': 2,\n",
       " 'smoke,': 1,\n",
       " 'alcohol.': 2,\n",
       " 'helluva': 1,\n",
       " 'covid.': 3,\n",
       " 'lebron': 8,\n",
       " 'mj.': 7,\n",
       " 'thatâ€™s': 34,\n",
       " 'scott': 2,\n",
       " 'moir.': 1,\n",
       " 'nowâœŒğŸ»': 1,\n",
       " 'brooks': 3,\n",
       " 'sidharth': 2,\n",
       " 'please?': 3,\n",
       " 'please.ğŸ˜­': 1,\n",
       " 'belive': 1,\n",
       " 'loosing': 2,\n",
       " '\"nah': 1,\n",
       " 'ğŸ˜­ğŸ˜­': 9,\n",
       " 'jens': 1,\n",
       " '#ff': 25,\n",
       " '@theowaldspecht': 1,\n",
       " '@nichtpartei': 1,\n",
       " '@moschaefer66': 1,\n",
       " '@erdtrabantmaria': 1,\n",
       " '@humanbeinx': 1,\n",
       " '#ty': 1,\n",
       " 'gifs,': 2,\n",
       " 'it?': 24,\n",
       " 'idgaf': 2,\n",
       " 'â˜ºï¸': 5,\n",
       " 'ğŸ˜ª': 5,\n",
       " \"i'd\": 14,\n",
       " 'whiskey,': 1,\n",
       " 'marry.': 2,\n",
       " 'â™¥ï¸': 1,\n",
       " '91,636': 1,\n",
       " 'manuscript.': 1,\n",
       " '#amwriting': 8,\n",
       " '#writingcommunity': 21,\n",
       " '#writing': 4,\n",
       " 'derrick': 3,\n",
       " 'brown,': 2,\n",
       " 'be?': 8,\n",
       " '#giantschat': 2,\n",
       " 'djt': 2,\n",
       " 'respirators': 2,\n",
       " 'ventilators,': 2,\n",
       " 'tired,': 3,\n",
       " 'harried': 2,\n",
       " 'masks...do': 2,\n",
       " 'compassion?': 2,\n",
       " '@realdonaldtrump': 24,\n",
       " 'magats': 3,\n",
       " 'libs?': 3,\n",
       " 'slaves?': 3,\n",
       " \"there's\": 18,\n",
       " 'rashford': 7,\n",
       " 'neymar': 6,\n",
       " 'best.': 7,\n",
       " 'marcus': 6,\n",
       " 'catchup': 2,\n",
       " 'covid': 23,\n",
       " 'ğŸ™‚': 2,\n",
       " \"let's\": 28,\n",
       " 'game.': 1,\n",
       " '1-10.': 1,\n",
       " 'ğŸ˜ğŸ˜': 1,\n",
       " '@jazzrazdfs': 1,\n",
       " 'nikeâ€™s': 1,\n",
       " 'â€œsee': 3,\n",
       " 'everyoneâ€': 1,\n",
       " 'realy': 1,\n",
       " 'hasnâ€™t': 6,\n",
       " '1:': 8,\n",
       " 'zack': 5,\n",
       " 'ryder': 2,\n",
       " 'aew.': 2,\n",
       " '2:': 13,\n",
       " 'cody': 2,\n",
       " 'rhodes': 2,\n",
       " 'him.': 5,\n",
       " '3:': 4,\n",
       " 'â€œthe': 4,\n",
       " 'codyâ€': 2,\n",
       " '4:': 3,\n",
       " 'jericho': 2,\n",
       " 'â€œaew:': 2,\n",
       " 'deckâ€': 2,\n",
       " '5:': 3,\n",
       " 'ğŸ“ˆğŸ“ˆğŸ“ˆ': 2,\n",
       " 'dryer': 1,\n",
       " 'out,': 4,\n",
       " 'advice?': 1,\n",
       " 'load?': 1,\n",
       " 'brand?': 1,\n",
       " 'googled': 1,\n",
       " 'menopause': 1,\n",
       " '51.': 1,\n",
       " '*starts': 1,\n",
       " 'countdown*': 1,\n",
       " 'jeff': 2,\n",
       " 'okudah': 1,\n",
       " 'ğŸ‘‡ğŸ‘‡ğŸ‘‡': 1,\n",
       " '3rd': 9,\n",
       " 'darkies': 1,\n",
       " 'nominate,': 1,\n",
       " 'koppaberg': 1,\n",
       " 'life.': 11,\n",
       " 'screwing': 1,\n",
       " 'later.': 2,\n",
       " 'anyone.': 3,\n",
       " '\"whatever': 1,\n",
       " 'off,': 4,\n",
       " 'same.\"': 1,\n",
       " 'emily': 1,\n",
       " 'bronte': 1,\n",
       " 'misbah': 2,\n",
       " 'haunts': 2,\n",
       " 'day.': 25,\n",
       " 'bitches': 8,\n",
       " 'honeymoon': 1,\n",
       " 'that,': 4,\n",
       " 'tweeted,': 2,\n",
       " 'â€œcrazy': 1,\n",
       " 'â€œnancy': 17,\n",
       " 'pelosi,': 26,\n",
       " 'person.': 19,\n",
       " 'leader.': 19,\n",
       " 'politicians,': 17,\n",
       " 'yourself.â€': 17,\n",
       " 'seanhannity': 1,\n",
       " 'left,': 19,\n",
       " 'puppet.....â€': 1,\n",
       " 'thoughts?': 3,\n",
       " 'season,': 3,\n",
       " 'june': 6,\n",
       " \"friday's\": 1,\n",
       " 'meeting.': 1,\n",
       " 'amuck': 1,\n",
       " 'christian': 1,\n",
       " 'muslim': 6,\n",
       " 'abroad.': 1,\n",
       " 'bjp': 1,\n",
       " 'government,': 2,\n",
       " 'rss,': 1,\n",
       " 'hindutva.': 1,\n",
       " 'muslims': 1,\n",
       " 'hindus': 1,\n",
       " 'art.14.': 1,\n",
       " '\"gif': 2,\n",
       " 'giver\"': 2,\n",
       " 'thing!': 2,\n",
       " \"we're\": 14,\n",
       " 'q&a': 1,\n",
       " 'video,': 1,\n",
       " 'post!': 1,\n",
       " 'better?': 2,\n",
       " 'goes!!': 1,\n",
       " 'bombay': 1,\n",
       " 'cupboard': 1,\n",
       " 'enough,': 2,\n",
       " \"won't\": 12,\n",
       " 'shows.': 1,\n",
       " 'anthony': 3,\n",
       " 'bourdain': 1,\n",
       " '(r.i.p)': 1,\n",
       " 'lately!': 1,\n",
       " 'tht': 1,\n",
       " 'y2k': 1,\n",
       " 'thing!!!!!!': 1,\n",
       " 'tacky': 1,\n",
       " 'exclusively!': 1,\n",
       " 'everything.': 7,\n",
       " 'cut.': 1,\n",
       " 'fabrics.': 1,\n",
       " 'fit.': 2,\n",
       " 'colors.': 2,\n",
       " 'brands.': 1,\n",
       " 'vibes.': 2,\n",
       " 'hideous.': 1,\n",
       " 'relive': 1,\n",
       " 'capacity...': 1,\n",
       " 'ğŸ‘‡': 2,\n",
       " 'exhilarating': 1,\n",
       " '9am': 1,\n",
       " 'peopleâ€™s': 2,\n",
       " 'suggestions.': 2,\n",
       " 'well.': 6,\n",
       " 'switches,': 3,\n",
       " '$100': 6,\n",
       " 'winner.': 2,\n",
       " 'home....': 2,\n",
       " 'hell?!': 2,\n",
       " 'sorta': 1,\n",
       " 'blossom': 1,\n",
       " 'recipes.': 1,\n",
       " '@pieceofarke': 1,\n",
       " 'coz': 1,\n",
       " 'ğŸ’•ğŸ’•': 1,\n",
       " '5.45': 1,\n",
       " '@abpnews': 1,\n",
       " '\"hey,': 2,\n",
       " 'dead\"': 2,\n",
       " 'skan': 2,\n",
       " 't;oo': 1,\n",
       " 'bwant': 1,\n",
       " 'huh?': 3,\n",
       " 'moisturize': 1,\n",
       " 'nah?': 2,\n",
       " 'hand!': 1,\n",
       " 'ğŸ™‹ğŸ¿\\u200dâ™€ï¸': 1,\n",
       " '#dontskipyourskincareroutine': 1,\n",
       " 'robert': 2,\n",
       " 'f.': 1,\n",
       " 'kennedy': 1,\n",
       " 'jr.': 4,\n",
       " 'dr.': 75,\n",
       " 'fauciâ€™s': 1,\n",
       " 'fraud.': 6,\n",
       " 'yesterday,': 3,\n",
       " '4,591': 1,\n",
       " 'coronavirus.': 5,\n",
       " 'horrific.': 1,\n",
       " 'community.': 4,\n",
       " 'lost,': 3,\n",
       " 'boris': 2,\n",
       " 'royally.': 1,\n",
       " 'disrespected': 1,\n",
       " '$600': 1,\n",
       " 'openings,': 2,\n",
       " 'nightclubs/dayclubs': 1,\n",
       " 'year...ğŸ’ƒğŸ•º': 1,\n",
       " '#vegas': 1,\n",
       " '#lasvegas': 1,\n",
       " '@vitalvegas': 1,\n",
       " '@lasvegaslocally': 1,\n",
       " '@luckyslasvegas': 1,\n",
       " '*gestures': 1,\n",
       " 'everything*': 1,\n",
       " 'ğŸ˜…': 4,\n",
       " 'mean.....': 1,\n",
       " 'agent.': 2,\n",
       " '#imreadyimreadyimready': 2,\n",
       " '#dontpanic': 2,\n",
       " 'philippians': 1,\n",
       " '4:13': 1,\n",
       " 'clap': 3,\n",
       " 'though.': 1,\n",
       " 'dependable': 24,\n",
       " 'oz.': 25,\n",
       " 'go!': 29,\n",
       " 'biden/obama': 10,\n",
       " 'h1n1': 10,\n",
       " 'swine': 10,\n",
       " 'flu.': 11,\n",
       " 'numbers.': 11,\n",
       " '17,000': 10,\n",
       " 'incompetence!': 10,\n",
       " 'obamacare': 10,\n",
       " 'nothing!': 11,\n",
       " \"ğŸ—£ï¸it's\": 1,\n",
       " 'forgive?': 1,\n",
       " 'forget?': 1,\n",
       " 'tuambiane': 1,\n",
       " 'ukweli..': 1,\n",
       " 'nyashinskis': 1,\n",
       " 'weeeak..': 1,\n",
       " 'flow,l': 1,\n",
       " 'boring..': 1,\n",
       " 'it..': 3,\n",
       " 'instagram': 8,\n",
       " 'hafollow': 1,\n",
       " 'mtu': 1,\n",
       " 'face...': 1,\n",
       " 'schedules.': 1,\n",
       " 'counts.': 1,\n",
       " 'goals.': 1,\n",
       " 'imposter': 2,\n",
       " 'syndrome.': 1,\n",
       " 'all.': 10,\n",
       " 'streamers.': 1,\n",
       " 'want,': 3,\n",
       " 'want.': 3,\n",
       " 'calculating.': 1,\n",
       " 'atiny': 1,\n",
       " '#iahperdchat': 1,\n",
       " 'lisa': 2,\n",
       " 'herself,': 1,\n",
       " 'q1:': 1,\n",
       " '1-5,': 1,\n",
       " 'control.': 1,\n",
       " 'youâ€™d': 3,\n",
       " 'like.': 2,\n",
       " '#physed': 2,\n",
       " '#healthed': 1,\n",
       " 'absurdities': 1,\n",
       " 'â€˜doctorsâ€™': 1,\n",
       " 'company.': 2,\n",
       " 'health.': 3,\n",
       " '30.': 4,\n",
       " 'contracts,': 1,\n",
       " 'cash-flow': 1,\n",
       " 'etc.': 5,\n",
       " 'plan,': 1,\n",
       " 'course,': 1,\n",
       " 'experts.': 1,\n",
       " 'safe.': 7,\n",
       " 'snarky': 1,\n",
       " 'jesus.': 2,\n",
       " 'cuddling': 1,\n",
       " 'oxytocin.': 1,\n",
       " 'compete,': 1,\n",
       " 'completeâœ¨': 1,\n",
       " 'raiders': 4,\n",
       " 'justin': 3,\n",
       " 'jefferson': 3,\n",
       " 'ruggs': 3,\n",
       " 'jeudy': 4,\n",
       " '(lamb': 3,\n",
       " 'board)': 3,\n",
       " 'form?': 3,\n",
       " '#raidernation': 3,\n",
       " 'tired.': 4,\n",
       " 'bicyclists': 1,\n",
       " 'predators.': 1,\n",
       " 'marriage.': 1,\n",
       " 'fearce': 1,\n",
       " 'loyalty.': 1,\n",
       " 'true.': 4,\n",
       " 'guy!': 1,\n",
       " '@bookiecrumbles': 1,\n",
       " '@andiabcs': 1,\n",
       " '@bookscents': 1,\n",
       " '@bookmarklit': 1,\n",
       " '@gonewiththeword': 1,\n",
       " 'lockdown,': 3,\n",
       " \"aren't\": 6,\n",
       " 'socialising': 1,\n",
       " 'holidays.': 1,\n",
       " \"we'll\": 14,\n",
       " 'ğŸ™„': 9,\n",
       " 'rangoli': 1,\n",
       " 'chandel': 1,\n",
       " 'kangna': 1,\n",
       " 'ranaut': 1,\n",
       " '#twitter': 1,\n",
       " 'â¤ï¸how': 1,\n",
       " 'today?': 9,\n",
       " 'routine?': 1,\n",
       " 'mind?': 1,\n",
       " 'crazy?': 1,\n",
       " 'fridge?ğŸ˜³lol': 1,\n",
       " 'comment/gif': 1,\n",
       " '#lockdown': 3,\n",
       " ...}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unknown_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean weird punctuations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No significantly improve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_weird(text):\n",
    "    specials = [\"â€™\", \"â€˜\", \"Â´\", \"`\"]\n",
    "    text = text.replace(\"â€™\", \"'\")\n",
    "    text = text.replace(\"â€˜\", \"'\")\n",
    "    text = text.replace(\"Â´\", \"'\")\n",
    "    text = text.replace(\"`\", \"'\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['text'] = df_train.text.apply(clean_weird)\n",
    "df_train['reply'] = df_train.reply.apply(clean_weird)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev['text'] = df_dev.text.apply(clean_weird)\n",
    "df_dev['reply'] = df_dev.reply.apply(clean_weird)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['text'] = df_test.text.apply(clean_weird)\n",
    "df_test['reply'] = df_test.reply.apply(clean_weird)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train text unique vocab count is: 68710\n",
      "train reply unique vocab count is: 25436\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=68710.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 22.908% (15740 / 68710) of vocab\n",
      "Found embeddings for 77.684% (508799 / 654963) of all text\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=25436.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 30.441% (7743 / 25436) of vocab\n",
      "Found embeddings for 73.166% (79308 / 108395) of all text\n"
     ]
    }
   ],
   "source": [
    "train_text_vocab = get_vocab(df_train['text'].values)\n",
    "train_reply_vocab = get_vocab(df_train['reply'].values)\n",
    "print(\"train text unique vocab count is: {}\".format(len(train_text_vocab)))\n",
    "print(\"train reply unique vocab count is: {}\".format(len(train_reply_vocab)))\n",
    "unknown_text = check_coverage(train_text_vocab, roberta_vocab)\n",
    "print()\n",
    "unknown_reply = check_coverage(train_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev text unique vocab count is: 17597\n",
      "dev reply unique vocab count is: 5322\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=17597.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 39.257% (6908 / 17597) of vocab\n",
      "Found embeddings for 77.473% (64281 / 82972) of all text\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=5322.0, style=ProgressStyle(description_â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 45.584% (2426 / 5322) of vocab\n",
      "Found embeddings for 72.615% (10047 / 13836) of all text\n"
     ]
    }
   ],
   "source": [
    "dev_text_vocab = get_vocab(df_dev['text'].values)\n",
    "dev_reply_vocab = get_vocab(df_dev['reply'].values)\n",
    "print(\"dev text unique vocab count is: {}\".format(len(dev_text_vocab)))\n",
    "print(\"dev reply unique vocab count is: {}\".format(len(dev_reply_vocab)))\n",
    "unknown_text = check_coverage(dev_text_vocab, roberta_vocab)\n",
    "print()\n",
    "unknown_reply = check_coverage(dev_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test text unique vocab count is: 17246\n",
      "test reply unique vocab count is: 5152\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=17246.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 40.044% (6906 / 17246) of vocab\n",
      "Found embeddings for 78.102% (63968 / 81903) of all text\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=5152.0, style=ProgressStyle(description_â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 45.477% (2343 / 5152) of vocab\n",
      "Found embeddings for 72.828% (9641 / 13238) of all text\n"
     ]
    }
   ],
   "source": [
    "test_text_vocab = get_vocab(df_test['text'].values)\n",
    "test_reply_vocab = get_vocab(df_test['reply'].values)\n",
    "print(\"test text unique vocab count is: {}\".format(len(test_text_vocab)))\n",
    "print(\"test reply unique vocab count is: {}\".format(len(test_reply_vocab)))\n",
    "unknown_text = check_coverage(test_text_vocab, roberta_vocab)\n",
    "print()\n",
    "unknown_reply = check_coverage(test_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform apostrophes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "apostrophes = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\" }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_apostrophes(text):\n",
    "    # Replace apostrophes to original term\n",
    "    for key in apostrophes.keys():\n",
    "        text = text.replace(key, apostrophes[key])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train['text'] = df_train.text.apply(change_apostrophes)\n",
    "df_train['reply'] = df_train.reply.apply(change_apostrophes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev['text'] = df_dev.text.apply(change_apostrophes)\n",
    "df_dev['reply'] = df_dev.reply.apply(change_apostrophes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['text'] = df_test.text.apply(change_apostrophes)\n",
    "df_test['reply'] = df_test.reply.apply(change_apostrophes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train text unique vocab count is: 68558\n",
      "train reply unique vocab count is: 25352\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=68558.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 22.959% (15740 / 68558) of vocab\n",
      "Found embeddings for 80.319% (537529 / 669242) of all text\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=25352.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 30.546% (7744 / 25352) of vocab\n",
      "Found embeddings for 75.973% (84170 / 110789) of all text\n"
     ]
    }
   ],
   "source": [
    "train_text_vocab = get_vocab(df_train['text'].values)\n",
    "train_reply_vocab = get_vocab(df_train['reply'].values)\n",
    "print(\"train text unique vocab count is: {}\".format(len(train_text_vocab)))\n",
    "print(\"train reply unique vocab count is: {}\".format(len(train_reply_vocab)))\n",
    "unknown_text = check_coverage(train_text_vocab, roberta_vocab)\n",
    "print()\n",
    "unknown_reply = check_coverage(train_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev text unique vocab count is: 17524\n",
      "dev reply unique vocab count is: 5273\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=17524.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 39.432% (6910 / 17524) of vocab\n",
      "Found embeddings for 80.157% (67975 / 84802) of all text\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=5273.0, style=ProgressStyle(description_â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 46.008% (2426 / 5273) of vocab\n",
      "Found embeddings for 75.556% (10692 / 14151) of all text\n"
     ]
    }
   ],
   "source": [
    "dev_text_vocab = get_vocab(df_dev['text'].values)\n",
    "dev_reply_vocab = get_vocab(df_dev['reply'].values)\n",
    "print(\"dev text unique vocab count is: {}\".format(len(dev_text_vocab)))\n",
    "print(\"dev reply unique vocab count is: {}\".format(len(dev_reply_vocab)))\n",
    "unknown_text = check_coverage(dev_text_vocab, roberta_vocab)\n",
    "print()\n",
    "unknown_reply = check_coverage(dev_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test text unique vocab count is: 17171\n",
      "test reply unique vocab count is: 5108\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=17171.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 40.225% (6907 / 17171) of vocab\n",
      "Found embeddings for 80.592% (67376 / 83601) of all text\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=5108.0, style=ProgressStyle(description_â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 45.869% (2343 / 5108) of vocab\n",
      "Found embeddings for 75.643% (10236 / 13532) of all text\n"
     ]
    }
   ],
   "source": [
    "test_text_vocab = get_vocab(df_test['text'].values)\n",
    "test_reply_vocab = get_vocab(df_test['reply'].values)\n",
    "print(\"test text unique vocab count is: {}\".format(len(test_text_vocab)))\n",
    "print(\"test reply unique vocab count is: {}\".format(len(test_reply_vocab)))\n",
    "unknown_text = check_coverage(test_text_vocab, roberta_vocab)\n",
    "print()\n",
    "unknown_reply = check_coverage(test_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'@Youngdeji_': 1,\n",
       " 'uzi': 2,\n",
       " 'carti': 3,\n",
       " 'woah': 1,\n",
       " 'safety.': 1,\n",
       " 'dababy': 3,\n",
       " 'niggas': 6,\n",
       " \"Denny's\": 1,\n",
       " 'cricket.': 1,\n",
       " 'out.': 21,\n",
       " 'Zaira': 1,\n",
       " 'Wasim': 1,\n",
       " 'hardwork': 1,\n",
       " 'screen.': 1,\n",
       " 'sick.': 4,\n",
       " '@madisonbeer': 1,\n",
       " 'â€œas': 2,\n",
       " 'pleaseâ€': 1,\n",
       " 'wtf': 5,\n",
       " '@LupeLoops': 1,\n",
       " 'ğŸ˜“': 3,\n",
       " 'ops,': 1,\n",
       " 'disappointments....': 1,\n",
       " 'work.': 6,\n",
       " 'cried.': 1,\n",
       " 'settings,': 1,\n",
       " 'home,': 3,\n",
       " 'it.': 93,\n",
       " 'nightmare.': 3,\n",
       " 'spamming': 4,\n",
       " 'mad.': 4,\n",
       " 'back.': 13,\n",
       " 'replying': 5,\n",
       " 'â€œWho': 3,\n",
       " 'are?!â€': 3,\n",
       " 'PHYSICALLY': 3,\n",
       " 'up.': 25,\n",
       " 'ğŸ˜°': 4,\n",
       " 'understands.': 1,\n",
       " 'prophet.': 1,\n",
       " 'Doing?': 1,\n",
       " 'overreacting,': 1,\n",
       " 'obsessing,': 1,\n",
       " 'worrying,': 1,\n",
       " 'disassociating.': 1,\n",
       " 'here!': 2,\n",
       " 'Covid-19': 15,\n",
       " 'Vaccine?': 11,\n",
       " 'myrtle': 1,\n",
       " 'am.': 3,\n",
       " 'spiraling.': 1,\n",
       " 'STRATEGICALLY': 1,\n",
       " 'DYNAMICALLY': 1,\n",
       " 'grudges.': 1,\n",
       " 'So,': 5,\n",
       " 'mind,': 2,\n",
       " 'me?': 9,\n",
       " 'OldRich': 6,\n",
       " 'people,': 12,\n",
       " 'judgement,': 6,\n",
       " 'kindness,': 8,\n",
       " 'HUNGRY': 6,\n",
       " '(now': 6,\n",
       " 'â€œteammatesâ€)!': 6,\n",
       " 'hyperventilate': 1,\n",
       " 'bag.': 1,\n",
       " 'â˜¹ï¸': 2,\n",
       " 'could.': 1,\n",
       " 'able,': 1,\n",
       " 'yeah?': 1,\n",
       " 'you.': 33,\n",
       " 'ğŸ’›': 2,\n",
       " '\\U0001f97a': 14,\n",
       " 'hands,': 1,\n",
       " \"You're\": 9,\n",
       " \"Trump's\": 25,\n",
       " 'health?': 1,\n",
       " 'lunch.': 1,\n",
       " \"who'd\": 3,\n",
       " 'join?': 1,\n",
       " 'guaging': 1,\n",
       " 'interest.': 2,\n",
       " 'Trump,': 3,\n",
       " 'script,': 1,\n",
       " \"country's\": 3,\n",
       " '\"since': 1,\n",
       " 'II.\"': 1,\n",
       " '\"most': 1,\n",
       " 'all\":': 1,\n",
       " \"Americans'\": 1,\n",
       " 'courage.': 1,\n",
       " 'pain.': 6,\n",
       " 'yesterday.': 2,\n",
       " 'idk': 5,\n",
       " 'me.': 56,\n",
       " 'better.': 14,\n",
       " 'wna': 2,\n",
       " 'fucj': 1,\n",
       " 'bcs': 1,\n",
       " 'trash.': 2,\n",
       " 'yourself.': 2,\n",
       " 'natin': 1,\n",
       " 'Germany:': 1,\n",
       " '\"What': 2,\n",
       " 'stupidity?\"': 1,\n",
       " '\"Mexico': 1,\n",
       " 'Canada!\"': 1,\n",
       " 'what?!': 1,\n",
       " '#WHYRUep12': 1,\n",
       " 'simpsons': 1,\n",
       " \"#ScottyFromMarketing's\": 23,\n",
       " 'app.': 25,\n",
       " 'gif.': 25,\n",
       " 'Hollyweird': 1,\n",
       " 'pedophile': 1,\n",
       " 'grandiloquent': 1,\n",
       " 'hypocrites': 1,\n",
       " 'Biden,': 1,\n",
       " 'â€œI': 7,\n",
       " \"jumpin'\": 1,\n",
       " 'lapâ€': 1,\n",
       " 'now,': 17,\n",
       " 'petulance,': 1,\n",
       " 'gridlock,': 1,\n",
       " 'vendettas': 1,\n",
       " \"'Bates\": 1,\n",
       " \"Motel'??\": 1,\n",
       " 'spoilers!!': 1,\n",
       " '3.': 7,\n",
       " 'all,': 8,\n",
       " \"Norman's\": 1,\n",
       " 'nerves.': 1,\n",
       " \"He's\": 16,\n",
       " 'ğŸ¤·ğŸ»\\u200dâ™€ï¸ğŸ¤·ğŸ»\\u200dâ™€ï¸': 1,\n",
       " 'night.': 9,\n",
       " 'bombarded': 2,\n",
       " 'hurtful': 3,\n",
       " 'words.': 2,\n",
       " 'sapped': 2,\n",
       " 'dry.': 2,\n",
       " '#salt': 2,\n",
       " 'skateboard': 1,\n",
       " 'ass.': 3,\n",
       " 'ğŸ™Œ': 2,\n",
       " \"Post's\": 1,\n",
       " \"Halladay's\": 1,\n",
       " 'today.': 41,\n",
       " '\"Some': 2,\n",
       " 'Halladay': 1,\n",
       " 'amphetamines': 1,\n",
       " 'morphine\"': 1,\n",
       " '$$?': 2,\n",
       " '$200': 3,\n",
       " 'hours.': 14,\n",
       " '@LoyalGiveaways': 2,\n",
       " 'somn': 1,\n",
       " 'dick,': 3,\n",
       " 'going,': 3,\n",
       " 'lot.': 3,\n",
       " 'America.': 7,\n",
       " 'ğŸ™‹\\u200dâ™‚ï¸ğŸ™‹\\u200dâ™‚ï¸ğŸ™‹\\u200dâ™‚ï¸': 2,\n",
       " 'IN:': 7,\n",
       " 'coronavirus': 27,\n",
       " 'NEEDğŸŒ¹SOLO': 1,\n",
       " 'ğŸŒ¹SANAğŸŒ¹PROJECTSğŸŒ¹': 1,\n",
       " 'rapists?': 1,\n",
       " 'em?': 1,\n",
       " 'morning!': 1,\n",
       " 'today!': 5,\n",
       " 'specifically?': 1,\n",
       " '#SVTrainToBusan': 1,\n",
       " 'smh': 6,\n",
       " 'ğŸ˜­': 16,\n",
       " '2020!': 2,\n",
       " 'lockdowns': 3,\n",
       " 'quarantining.': 1,\n",
       " 'conflated.': 1,\n",
       " 'risk.': 1,\n",
       " '@DxvilishAngxl': 1,\n",
       " 'Veniece': 1,\n",
       " 'Drive-In': 1,\n",
       " 'punks': 1,\n",
       " 'smuggle': 1,\n",
       " 'THOSE': 1,\n",
       " 'days!': 1,\n",
       " 'up?': 10,\n",
       " 'no?': 10,\n",
       " 'negotiations,': 3,\n",
       " \"Government's\": 3,\n",
       " 'EU.': 3,\n",
       " 'year.': 10,\n",
       " 'no.': 6,\n",
       " '1/2': 4,\n",
       " 'app,': 24,\n",
       " '#BailoutHumansNow': 24,\n",
       " '@ShelleyMcElyea1': 1,\n",
       " 'birthday,': 3,\n",
       " 'â¤ï¸ğŸ’‹ğŸğŸ‰ğŸ°ğŸˆ': 1,\n",
       " '#Giveaway': 2,\n",
       " '$25': 4,\n",
       " '24hours..': 1,\n",
       " 'Like/RT/Tag': 1,\n",
       " '(must': 1,\n",
       " 'me)': 1,\n",
       " 'following?': 1,\n",
       " 'grow!': 1,\n",
       " 'ğŸ”¥ğŸš€': 1,\n",
       " \"How's\": 6,\n",
       " 'Flutter?': 1,\n",
       " 'gifs': 12,\n",
       " '\\U0001f91fğŸ¼': 1,\n",
       " '#Flutter': 1,\n",
       " 'Also,': 21,\n",
       " \"Win's\": 1,\n",
       " '\"How': 2,\n",
       " 'drop\"': 1,\n",
       " 'Govt': 5,\n",
       " \"'stay\": 1,\n",
       " \"lives'\": 1,\n",
       " '15,000': 1,\n",
       " 'checks,': 4,\n",
       " 'worst-hit': 1,\n",
       " 'Italy.': 1,\n",
       " 'something?': 2,\n",
       " '@seanhannity': 18,\n",
       " 'minutes.': 2,\n",
       " 'in!': 4,\n",
       " 'power?': 4,\n",
       " \"'promoter\": 1,\n",
       " 'unconvincing': 1,\n",
       " 'consoler': 1,\n",
       " 'Chief.': 1,\n",
       " 'Hugger,': 1,\n",
       " '~S': 1,\n",
       " 'news:': 1,\n",
       " 'years,': 2,\n",
       " '@Tes.': 1,\n",
       " 'director.': 1,\n",
       " 'journalism.': 1,\n",
       " '1/': 1,\n",
       " 'sister.': 3,\n",
       " \"20's\": 2,\n",
       " '-famu': 3,\n",
       " 'AAWAZ': 1,\n",
       " 'Stimulus': 2,\n",
       " 'Package.': 1,\n",
       " '30th': 3,\n",
       " 'days.': 4,\n",
       " 'birthday.': 8,\n",
       " 'Eke,': 1,\n",
       " 'Uti,': 1,\n",
       " 'hardworking': 1,\n",
       " 'BobRisky,': 1,\n",
       " 'Enkayy': 1,\n",
       " 'Mercenaries': 1,\n",
       " 'Spartans.': 1,\n",
       " 'â¤ï¸': 21,\n",
       " '#ZenMagazine': 1,\n",
       " '@liberianboii': 1,\n",
       " 'Twenties.': 1,\n",
       " 'married.': 2,\n",
       " 'people.': 18,\n",
       " 'follow.': 6,\n",
       " 'you,': 18,\n",
       " 'there.': 8,\n",
       " 'Horny': 4,\n",
       " 'Day?': 1,\n",
       " \"It's\": 90,\n",
       " 'Shet': 1,\n",
       " 'ğŸ˜®ğŸ˜…': 1,\n",
       " 'ago,': 4,\n",
       " 'services.': 1,\n",
       " 'premium,': 1,\n",
       " 'profile,': 1,\n",
       " 'theirs.': 1,\n",
       " 'celebratory': 1,\n",
       " 'ğŸ˜': 5,\n",
       " 'COMING': 3,\n",
       " 'MONDAY!': 2,\n",
       " 'ğŸ‘»ğŸ‘»ğŸ‘»': 2,\n",
       " 'disrespects': 1,\n",
       " 'religion.': 1,\n",
       " 'tbh...at': 1,\n",
       " 'sinning': 1,\n",
       " 'Seala': 1,\n",
       " '@FilmGob': 1,\n",
       " '@jodyscorner1': 1,\n",
       " 'nonsense.': 1,\n",
       " 'filmgob': 1,\n",
       " 'jody': 1,\n",
       " 'there?': 1,\n",
       " 'interesting.': 4,\n",
       " '$1,200': 12,\n",
       " 'questionsâ€¦': 12,\n",
       " '(not': 4,\n",
       " 'ill,': 3,\n",
       " 'holiday,': 2,\n",
       " 'fridge)': 2,\n",
       " 'Cabinet,': 2,\n",
       " 'Parliament:': 2,\n",
       " 'pandemic': 16,\n",
       " 'Brexit-induced': 2,\n",
       " 'crisis:': 3,\n",
       " 'through.': 2,\n",
       " '\"\\U0001f97a\"': 1,\n",
       " 'emojis': 2,\n",
       " 'up,': 13,\n",
       " 'down.': 9,\n",
       " 'overthinking': 1,\n",
       " 'away.': 5,\n",
       " 'guys..?': 1,\n",
       " 's/o': 1,\n",
       " \"Y'all\": 16,\n",
       " '13k+': 1,\n",
       " '#Covid_19': 6,\n",
       " 'India,': 1,\n",
       " 'recovered.': 1,\n",
       " '400+.': 1,\n",
       " 'situation,': 1,\n",
       " '@MoHFW_INDIA': 1,\n",
       " '@drharshvardhan': 1,\n",
       " '@PMOIndia': 1,\n",
       " 'consider:': 1,\n",
       " 'decelerate': 1,\n",
       " 'panic,': 1,\n",
       " 'prone,': 1,\n",
       " 'neglected?': 1,\n",
       " 'am,': 1,\n",
       " 'dreading,': 1,\n",
       " 'vibes': 4,\n",
       " 'nudes': 3,\n",
       " 'U.S': 2,\n",
       " 'it???': 1,\n",
       " 'intro.': 1,\n",
       " 'two.': 1,\n",
       " '50+': 1,\n",
       " 'secs': 1,\n",
       " 'â€”': 8,\n",
       " 'nope.': 2,\n",
       " '@kellyinvegas': 1,\n",
       " '@vegasmurray': 1,\n",
       " 'Signed,': 1,\n",
       " 'Toppin': 1,\n",
       " 'Kentucky,': 1,\n",
       " 'page.': 2,\n",
       " 'ğŸ˜­â¤ï¸': 1,\n",
       " 'housekeeping': 1,\n",
       " 'yet.': 5,\n",
       " \"They're\": 4,\n",
       " 'in.': 4,\n",
       " 'decorate': 1,\n",
       " 'ridiculous.': 1,\n",
       " 'ğŸ‘€': 8,\n",
       " '.@JoeBiden': 1,\n",
       " 'ğŸ¤”': 21,\n",
       " '#COVID19Pandemic': 4,\n",
       " 'jobs.': 4,\n",
       " 'responsible.': 4,\n",
       " 'account.': 6,\n",
       " 'HOURRRSSSS': 1,\n",
       " '@shmsaaldh': 1,\n",
       " 'sweatshirt': 1,\n",
       " 'time.': 20,\n",
       " \"Can't\": 27,\n",
       " 'hammock': 1,\n",
       " 'isolation,': 1,\n",
       " 'tests?': 1,\n",
       " 'fun:': 1,\n",
       " 'Shehnaaz': 2,\n",
       " 'question,': 3,\n",
       " 'be.': 6,\n",
       " 'ONE.': 1,\n",
       " '#ShehnaazGill': 1,\n",
       " '@ishehnaaz_gill': 1,\n",
       " '@KaushalJoshi15': 1,\n",
       " 'depression.': 2,\n",
       " 'worse.': 9,\n",
       " 'Hi.': 15,\n",
       " 'nose....': 1,\n",
       " 'pointless.': 1,\n",
       " 'please.': 3,\n",
       " 'exist;': 1,\n",
       " 'Trump:': 15,\n",
       " '\"I': 19,\n",
       " 'campaigning.\"': 8,\n",
       " 'goin': 1,\n",
       " 'Thorpe': 1,\n",
       " 'Park/Alton': 1,\n",
       " \"Y'ALL!!!\": 1,\n",
       " 'FOLLOWERS': 3,\n",
       " 'TWITCH!!!': 1,\n",
       " '\\U0001f973\\U0001f929': 1,\n",
       " 'me!': 10,\n",
       " 'all!': 5,\n",
       " 'donos': 1,\n",
       " 'ğŸ’—': 1,\n",
       " 'who-the-hell-even-knows-anymore': 18,\n",
       " 'quarantine:': 19,\n",
       " 'GIF,': 19,\n",
       " 'read/hear': 18,\n",
       " '\"we': 19,\n",
       " 'together\".': 18,\n",
       " 'ğŸ‘‹ğŸ»': 1,\n",
       " 'relaxation?': 1,\n",
       " 'hunch': 1,\n",
       " 'page,': 1,\n",
       " 'pencil,': 1,\n",
       " 'choice.': 3,\n",
       " 'done,': 10,\n",
       " 'therapy.': 9,\n",
       " '@The_Badger_jm': 1,\n",
       " 'FSQ!!': 1,\n",
       " 'Retired': 1,\n",
       " 'players.': 2,\n",
       " 'not.': 14,\n",
       " 'memory?': 1,\n",
       " 'great,': 2,\n",
       " 'were?': 1,\n",
       " 'Childhood:': 1,\n",
       " 'ğŸ˜‹': 4,\n",
       " '65th': 2,\n",
       " \"son's\": 5,\n",
       " 'Yup': 2,\n",
       " 'GIF?': 2,\n",
       " '$50,000': 2,\n",
       " 'run?': 2,\n",
       " '#BTC': 3,\n",
       " 'Biden?': 5,\n",
       " 'GGs': 1,\n",
       " '@CetraLol': 1,\n",
       " 'mAAd': 1,\n",
       " '1-0': 2,\n",
       " 'PRL!': 1,\n",
       " '9PM': 1,\n",
       " 'Defiance.': 1,\n",
       " 'passion/happiness': 1,\n",
       " 'life....or': 1,\n",
       " 'condescending!!': 1,\n",
       " 'everyone.': 4,\n",
       " 'awful.': 4,\n",
       " 'Covid19.': 3,\n",
       " 'straight.': 5,\n",
       " 'her.': 8,\n",
       " 'forever.': 4,\n",
       " 'unwell': 2,\n",
       " '@SchittsCreek': 1,\n",
       " \"Disney's\": 1,\n",
       " 'along...': 1,\n",
       " '@stageit': 2,\n",
       " 'week?': 3,\n",
       " '\"we\"': 2,\n",
       " 'we.': 2,\n",
       " 'alone...that': 2,\n",
       " 'sad.': 3,\n",
       " '4/20': 2,\n",
       " 'AUDACITY': 1,\n",
       " '9am.': 1,\n",
       " '11am?': 1,\n",
       " \"Let's\": 31,\n",
       " 'fantasized': 1,\n",
       " 'smothering': 1,\n",
       " 'pillow.': 2,\n",
       " 'scale?': 1,\n",
       " 'LIBERATE': 13,\n",
       " 'VIRGINIA,': 11,\n",
       " '2nd': 18,\n",
       " 'Amendment.': 11,\n",
       " 'siege!': 11,\n",
       " 'while.': 6,\n",
       " 'hella': 4,\n",
       " 'now.': 21,\n",
       " 'Verkis': 1,\n",
       " 'all?': 3,\n",
       " 'assğŸ˜©': 1,\n",
       " 'glasses,': 1,\n",
       " 'foggy': 1,\n",
       " 'specs!!!': 1,\n",
       " '#COVID19': 16,\n",
       " 'to,': 1,\n",
       " 'to.': 4,\n",
       " '.@WHO': 1,\n",
       " 'pandemic,': 3,\n",
       " 'advice,': 1,\n",
       " 'training,': 1,\n",
       " 'livesâ€”including': 1,\n",
       " \"Americans'.\": 1,\n",
       " 'dangerousâ€”Trump': 1,\n",
       " 'know:': 3,\n",
       " 'impeached.': 1,\n",
       " 'nigga': 6,\n",
       " 'aboogie': 1,\n",
       " 'prime,': 2,\n",
       " 'hurt.': 2,\n",
       " 'morning.': 10,\n",
       " 'Uh.': 1,\n",
       " '#OUSTDUTERENOW': 3,\n",
       " '#OUSTDUTERTENOW': 1,\n",
       " 'philippines': 1,\n",
       " '@COLIATHGAMING': 1,\n",
       " '@Baker_TV_': 1,\n",
       " '@vicdgordon': 1,\n",
       " '@StreamGamma': 1,\n",
       " '@kedabosch': 1,\n",
       " '@Day1neGaming': 1,\n",
       " '@JxckWSW': 1,\n",
       " '@Ncshredder_': 1,\n",
       " '@Samurai_Ree': 1,\n",
       " '@Stardrix1': 1,\n",
       " '@GSO_Joey': 1,\n",
       " '@TSillysweat': 1,\n",
       " '@ChloeDonald_': 1,\n",
       " '@xLexry': 1,\n",
       " '@MultynWolf': 1,\n",
       " '@SaycredAngel': 1,\n",
       " '@fuscyoface': 1,\n",
       " '@Storkyyy1': 1,\n",
       " 'Kamo': 1,\n",
       " 'Mphela': 1,\n",
       " '\"she': 1,\n",
       " 'shit\"': 2,\n",
       " 'ğŸ˜•': 1,\n",
       " 'intensions.': 1,\n",
       " 'actions.': 1,\n",
       " 'Steyer': 1,\n",
       " 'lives.': 5,\n",
       " 'California.': 3,\n",
       " 'Newsom': 2,\n",
       " 'force,': 1,\n",
       " 'injustices': 1,\n",
       " 'crisis.': 4,\n",
       " 'reasonable,': 1,\n",
       " 'know.': 9,\n",
       " 'ğŸ’¨ğŸ’¨': 1,\n",
       " 'YALL': 3,\n",
       " 'READY': 1,\n",
       " 'CAUCASIANS': 1,\n",
       " 'CANCEL': 1,\n",
       " '4TH': 3,\n",
       " 'JULY?!!!!!': 1,\n",
       " 'convo': 4,\n",
       " 'meteoric': 1,\n",
       " 'again.': 19,\n",
       " 'soon.': 4,\n",
       " 'here.': 20,\n",
       " 'you?': 19,\n",
       " '7th': 8,\n",
       " 'DMs?': 7,\n",
       " 'did.': 3,\n",
       " 'orders.': 2,\n",
       " '53%': 1,\n",
       " '60%': 3,\n",
       " 'Arkansas,': 1,\n",
       " '74%': 1,\n",
       " 'Nebraska,': 1,\n",
       " '82%': 1,\n",
       " 'Iowa.': 1,\n",
       " '205%': 1,\n",
       " 'spike.': 1,\n",
       " '#StayHomeStaySafeSaveLives': 1,\n",
       " 'body.': 4,\n",
       " 'yall': 11,\n",
       " \"What's\": 15,\n",
       " 'first.': 4,\n",
       " '#smallvictory': 1,\n",
       " 'decorating': 1,\n",
       " '#AnimalCrossing': 1,\n",
       " 'NOVEMBER': 2,\n",
       " 'preview:': 2,\n",
       " 'McSally': 2,\n",
       " 'Loeffler': 3,\n",
       " 'Tillis': 2,\n",
       " 'Yeah,': 3,\n",
       " 'night,': 2,\n",
       " 'dreamt': 1,\n",
       " 'journalists,': 1,\n",
       " 'Uddhav': 1,\n",
       " 'PM.': 2,\n",
       " 'mine,': 1,\n",
       " 'no,': 3,\n",
       " '#soproudofmyself': 1,\n",
       " 'Niggas': 1,\n",
       " 'hooping': 1,\n",
       " '$50': 8,\n",
       " 'retweets': 6,\n",
       " 'Minutes.': 2,\n",
       " '@K_9Girl': 1,\n",
       " 'Myself.': 2,\n",
       " 'Cocoa': 1,\n",
       " 'Krispies': 2,\n",
       " 'this?': 4,\n",
       " 'wasted.': 1,\n",
       " 'repaint': 1,\n",
       " 'home.': 5,\n",
       " 'ğŸ˜Š': 18,\n",
       " 'man-half': 1,\n",
       " 'assholes': 2,\n",
       " 'exercise,': 1,\n",
       " 'shit,': 2,\n",
       " 'smoke,': 1,\n",
       " 'alcohol.': 2,\n",
       " 'helluva': 1,\n",
       " 'Covid.': 1,\n",
       " 'Lebron': 7,\n",
       " 'MJ.': 7,\n",
       " \"That's\": 33,\n",
       " 'Moir.': 1,\n",
       " 'nowâœŒğŸ»': 1,\n",
       " 'Sidharth': 1,\n",
       " 'please?': 3,\n",
       " 'please.ğŸ˜­': 1,\n",
       " 'belive': 1,\n",
       " 'loosing': 2,\n",
       " '\"nah': 1,\n",
       " 'ğŸ˜­ğŸ˜­': 9,\n",
       " 'Jens': 1,\n",
       " 'TWELVE': 1,\n",
       " '#FF': 22,\n",
       " 'Gratitude': 1,\n",
       " '@theowaldspecht': 1,\n",
       " '@Nichtpartei': 1,\n",
       " '@MoSchaefer66': 1,\n",
       " '@ErdtrabantMaria': 1,\n",
       " '@humanbeinx': 1,\n",
       " '#TY': 1,\n",
       " 'gifs,': 2,\n",
       " 'it?': 24,\n",
       " 'idgaf': 1,\n",
       " 'â˜ºï¸': 5,\n",
       " 'ğŸ˜ª': 5,\n",
       " 'whiskey,': 1,\n",
       " 'marry.': 2,\n",
       " 'â™¥ï¸': 1,\n",
       " '91,636': 1,\n",
       " 'manuscript.': 1,\n",
       " '#amwriting': 6,\n",
       " '#writingcommunity': 4,\n",
       " '#writing': 2,\n",
       " 'Brown,': 2,\n",
       " 'be?': 8,\n",
       " '#giantschat': 2,\n",
       " 'DJT': 2,\n",
       " 'respirators': 2,\n",
       " 'ventilators,': 2,\n",
       " 'tired,': 3,\n",
       " 'harried': 2,\n",
       " 'masks...do': 2,\n",
       " 'compassion?': 2,\n",
       " '@realDonaldTrump': 24,\n",
       " 'MAGAts': 3,\n",
       " 'libs?': 3,\n",
       " 'slaves?': 3,\n",
       " 'Genuinely': 7,\n",
       " 'Rashford': 7,\n",
       " 'Neymar': 6,\n",
       " 'best.': 7,\n",
       " 'Heading': 2,\n",
       " 'catchup': 2,\n",
       " 'covid': 8,\n",
       " 'ğŸ™‚': 2,\n",
       " 'game.': 1,\n",
       " 'Emoji': 1,\n",
       " '1-10.': 1,\n",
       " 'ğŸ˜ğŸ˜': 1,\n",
       " '@JazzrazDFS': 1,\n",
       " 'Clips': 1,\n",
       " \"Nike's\": 1,\n",
       " 'Blonde': 2,\n",
       " 'â€œsee': 1,\n",
       " 'everyoneâ€': 1,\n",
       " 'realy': 1,\n",
       " '1:': 8,\n",
       " 'AEW.': 2,\n",
       " '2:': 13,\n",
       " 'him.': 5,\n",
       " '3:': 4,\n",
       " 'â€œThe': 3,\n",
       " 'Codyâ€': 2,\n",
       " '4:': 3,\n",
       " 'â€œAEW:': 2,\n",
       " 'Deckâ€': 2,\n",
       " '5:': 3,\n",
       " 'ğŸ“ˆğŸ“ˆğŸ“ˆ': 2,\n",
       " 'dryer': 1,\n",
       " 'out,': 4,\n",
       " 'advice?': 1,\n",
       " 'load?': 1,\n",
       " 'brand?': 1,\n",
       " 'googled': 1,\n",
       " 'menopause': 1,\n",
       " '51.': 1,\n",
       " '*starts': 1,\n",
       " 'countdown*': 1,\n",
       " 'Okudah': 1,\n",
       " 'ğŸ‘‡ğŸ‘‡ğŸ‘‡': 1,\n",
       " '3rd': 9,\n",
       " 'Frequently': 8,\n",
       " 'darkies': 1,\n",
       " 'nominate,': 1,\n",
       " 'koppaberg': 1,\n",
       " 'life.': 11,\n",
       " 'screwing': 1,\n",
       " 'later.': 2,\n",
       " 'ANYONE.': 1,\n",
       " '\"Whatever': 1,\n",
       " 'off,': 4,\n",
       " 'same.\"': 1,\n",
       " 'Bronte': 1,\n",
       " 'Misbah': 2,\n",
       " 'haunts': 2,\n",
       " 'day.': 23,\n",
       " 'BITCHES': 1,\n",
       " \"IT'S\": 3,\n",
       " 'HEAVY': 1,\n",
       " 'BABY': 3,\n",
       " 'HONEYMOON': 1,\n",
       " 'THAT,': 1,\n",
       " 'WEDDING': 1,\n",
       " 'tweeted,': 1,\n",
       " 'â€œCrazy': 1,\n",
       " 'â€œNancy': 17,\n",
       " 'Pelosi,': 26,\n",
       " 'person.': 19,\n",
       " 'leader.': 19,\n",
       " 'politicians,': 17,\n",
       " 'yourself.â€': 17,\n",
       " 'seanhannity': 1,\n",
       " 'Left,': 19,\n",
       " 'puppet.....â€': 1,\n",
       " 'Thoughts?': 3,\n",
       " 'season,': 3,\n",
       " \"Friday's\": 1,\n",
       " 'meeting.': 1,\n",
       " 'amuck': 1,\n",
       " 'abroad.': 1,\n",
       " 'Government,': 1,\n",
       " 'RSS,': 1,\n",
       " 'Hindutva.': 1,\n",
       " 'Art.14.': 1,\n",
       " '\"gif': 2,\n",
       " 'giver\"': 2,\n",
       " 'thing!': 2,\n",
       " 'Q&A': 1,\n",
       " 'video,': 1,\n",
       " 'post!': 1,\n",
       " 'Adopt': 2,\n",
       " 'Me?': 1,\n",
       " 'better?': 2,\n",
       " 'goes!!': 1,\n",
       " 'cupboard': 1,\n",
       " 'Oddly': 1,\n",
       " 'enough,': 2,\n",
       " 'shows.': 1,\n",
       " 'Bourdain': 1,\n",
       " '(R.I.P)': 1,\n",
       " 'lately!': 1,\n",
       " 'HATE': 4,\n",
       " 'tht': 1,\n",
       " 'y2k': 1,\n",
       " 'thing!!!!!!': 1,\n",
       " 'UGLY': 1,\n",
       " 'TACKY': 1,\n",
       " 'exclusively!': 1,\n",
       " 'everything.': 7,\n",
       " 'cut.': 1,\n",
       " 'fabrics.': 1,\n",
       " 'fit.': 2,\n",
       " 'colors.': 2,\n",
       " 'brands.': 1,\n",
       " 'vibes.': 2,\n",
       " 'HIDEOUS.': 1,\n",
       " 'relive': 1,\n",
       " 'capacity...': 1,\n",
       " 'ğŸ‘‡': 2,\n",
       " 'exhilarating': 1,\n",
       " 'Giveaway': 1,\n",
       " '9AM': 1,\n",
       " \"people's\": 3,\n",
       " 'suggestions.': 2,\n",
       " 'well.': 6,\n",
       " 'switches,': 3,\n",
       " '$100': 6,\n",
       " 'winner.': 2,\n",
       " 'home....': 2,\n",
       " 'hell?!': 2,\n",
       " 'Idk': 8,\n",
       " 'sorta': 1,\n",
       " 'blossom': 1,\n",
       " 'recipes.': 1,\n",
       " '@PieceOfArke': 1,\n",
       " 'coz': 1,\n",
       " 'ğŸ’•ğŸ’•': 1,\n",
       " '5.45': 1,\n",
       " '@ABPNews': 1,\n",
       " \"Doesn't\": 2,\n",
       " '\"hey,': 2,\n",
       " 'dead\"': 2,\n",
       " 'skan': 2,\n",
       " 't;oo': 1,\n",
       " 'bwant': 1,\n",
       " 'huh?': 3,\n",
       " 'moisturize': 1,\n",
       " 'nah?': 2,\n",
       " 'hand!': 1,\n",
       " 'ğŸ™‹ğŸ¿\\u200dâ™€ï¸': 1,\n",
       " '#DontSkipYourSkincareRoutine': 1,\n",
       " 'F.': 1,\n",
       " 'Jr.': 4,\n",
       " 'Dr.': 75,\n",
       " \"Fauci's\": 2,\n",
       " 'government,': 1,\n",
       " 'fraud.': 4,\n",
       " 'Yesterday,': 3,\n",
       " '4,591': 1,\n",
       " 'coronavirus.': 4,\n",
       " 'horrific.': 1,\n",
       " 'community.': 4,\n",
       " 'lost,': 3,\n",
       " 'royally.': 1,\n",
       " 'disrespected': 1,\n",
       " '$600': 1,\n",
       " 'openings,': 2,\n",
       " 'nightclubs/dayclubs': 1,\n",
       " 'year...ğŸ’ƒğŸ•º': 1,\n",
       " '#vegas': 1,\n",
       " '#lasvegas': 1,\n",
       " '@VitalVegas': 1,\n",
       " '@LasVegasLocally': 1,\n",
       " '@LuckysLasVegas': 1,\n",
       " '*gestures': 1,\n",
       " 'everything*': 1,\n",
       " 'ğŸ˜…': 4,\n",
       " 'mean.....': 1,\n",
       " '#WritingCommunity': 17,\n",
       " 'agent.': 2,\n",
       " \"Who's\": 10,\n",
       " '#imreadyimreadyimready': 2,\n",
       " '#dontpanic': 2,\n",
       " 'Philippians': 1,\n",
       " '4:13': 1,\n",
       " 'clap': 3,\n",
       " 'though.': 1,\n",
       " 'dependable': 24,\n",
       " 'Oz.': 25,\n",
       " 'Go!': 27,\n",
       " 'Biden/Obama': 10,\n",
       " 'H1N1': 10,\n",
       " 'Swine': 10,\n",
       " 'Flu.': 10,\n",
       " 'Polling': 10,\n",
       " 'numbers.': 10,\n",
       " '17,000': 10,\n",
       " 'incompetence!': 10,\n",
       " 'nothing!': 10,\n",
       " 'ğŸ—£ï¸it': 1,\n",
       " 'forgive?': 1,\n",
       " 'forget?': 1,\n",
       " 'Tuambiane': 1,\n",
       " 'ukweli..': 1,\n",
       " 'Nyashinskis': 1,\n",
       " 'weeeak..': 1,\n",
       " 'flow,l': 1,\n",
       " 'boring..': 1,\n",
       " 'it..': 3,\n",
       " 'hafollow': 1,\n",
       " 'mtu': 1,\n",
       " 'face...': 1,\n",
       " 'schedules.': 1,\n",
       " 'counts.': 1,\n",
       " 'goals.': 1,\n",
       " 'imposter': 2,\n",
       " 'syndrome.': 1,\n",
       " 'all.': 14,\n",
       " 'streamers.': 1,\n",
       " 'want,': 3,\n",
       " 'want.': 3,\n",
       " 'calculating.': 1,\n",
       " 'ANYBODY': 2,\n",
       " 'CARES': 1,\n",
       " 'AWAY': 3,\n",
       " 'atiny': 1,\n",
       " '#iahperdchat': 1,\n",
       " 'herself,': 1,\n",
       " 'Q1:': 1,\n",
       " 'doing?': 3,\n",
       " '1-5,': 1,\n",
       " 'control.': 1,\n",
       " 'like.': 2,\n",
       " '#physed': 2,\n",
       " '#healthed': 1,\n",
       " 'absurdities': 1,\n",
       " \"'doctors'\": 1,\n",
       " 'company.': 2,\n",
       " 'health.': 3,\n",
       " 'Completely': 1,\n",
       " '30.': 4,\n",
       " 'Contracts,': 1,\n",
       " 'cash-flow': 1,\n",
       " 'etc.': 5,\n",
       " 'Sensible': 1,\n",
       " 'plan,': 1,\n",
       " 'course,': 1,\n",
       " 'experts.': 1,\n",
       " 'safe.': 7,\n",
       " 'snarky': 1,\n",
       " 'Jesus.': 2,\n",
       " 'Cuddling': 1,\n",
       " 'oxytocin.': 1,\n",
       " 'compete,': 1,\n",
       " 'completeâœ¨': 1,\n",
       " 'Ruggs': 3,\n",
       " 'Jeudy': 4,\n",
       " '(Lamb': 3,\n",
       " 'board)': 3,\n",
       " 'form?': 3,\n",
       " '#RaiderNation': 3,\n",
       " 'Tired.': 1,\n",
       " 'Bicyclists': 1,\n",
       " 'predators.': 1,\n",
       " 'marriage.': 1,\n",
       " 'fearce': 1,\n",
       " 'loyalty.': 1,\n",
       " 'true.': 4,\n",
       " 'guy!': 1,\n",
       " '@BookieCrumbles': 1,\n",
       " '@andiABCs': 1,\n",
       " '@BookScents': 1,\n",
       " '@bookmarklit': 1,\n",
       " '@gonewiththeword': 1,\n",
       " 'lockdown,': 2,\n",
       " 'socialising': 1,\n",
       " 'holidays.': 1,\n",
       " \"We'll\": 4,\n",
       " 'ğŸ™„': 9,\n",
       " 'Rangoli': 1,\n",
       " 'Chandel': 1,\n",
       " 'Kangna': 1,\n",
       " 'Ranaut': 1,\n",
       " '#Twitter': 1,\n",
       " 'â¤ï¸how': 1,\n",
       " 'today?': 9,\n",
       " 'routine?': 1,\n",
       " 'Bored': 1,\n",
       " 'mind?': 1,\n",
       " 'crazy?': 1,\n",
       " 'fridge?ğŸ˜³lol': 1,\n",
       " 'comment/gif': 1,\n",
       " '#lockdown': 2,\n",
       " 'farğŸ™Œ': 1,\n",
       " 'pollğŸ‘‡ğŸ¼how': 1,\n",
       " 'pattern?': 1,\n",
       " 'tryna': 3,\n",
       " 'lowkey': 5,\n",
       " 'florida': 1,\n",
       " 'Halsey': 1,\n",
       " 'ğŸ˜‚': 22,\n",
       " 'VoteSafe': 4,\n",
       " 'Act.': 4,\n",
       " 'includes:': 4,\n",
       " 'â†’$2.5': 8,\n",
       " 'vote-by-mail': 4,\n",
       " 'â†’No-excuse': 4,\n",
       " 'mail-in': 5,\n",
       " 'â†’At': 4,\n",
       " 'right.': 6,\n",
       " 'Hoath.': 1,\n",
       " \"LET'S\": 1,\n",
       " 'ğŸŒğŸŒˆâ˜€ï¸ğŸŒ³â¤ï¸': 1,\n",
       " 'way,': 3,\n",
       " '#Mastectomy': 1,\n",
       " 'mastectomy': 1,\n",
       " 'drains.': 1,\n",
       " '#breastcancer': 1,\n",
       " '2.': 11,\n",
       " 'plan!': 1,\n",
       " 'v12.41': 1,\n",
       " 'staging,': 1,\n",
       " 'normie': 1,\n",
       " 'otaku': 1,\n",
       " 'between....': 1,\n",
       " '*hugs*': 1,\n",
       " 'â€œc,â€': 2,\n",
       " 'wednesday,': 2,\n",
       " 'energy.': 2,\n",
       " 'puppet.': 16,\n",
       " 'job!': 16,\n",
       " 'snob': 1,\n",
       " '#TheRiver1Magic': 1,\n",
       " 'Hahaha': 1,\n",
       " 'rewatching': 1,\n",
       " 'man,': 4,\n",
       " 'octagon.': 1,\n",
       " 'champ.': 1,\n",
       " \"Jhene's\": 1,\n",
       " '@_bryantnotkobe': 1,\n",
       " 'ğŸ¤£ğŸ¤£ğŸ¤£': 4,\n",
       " 'bitchğŸ’”ğŸ’”': 1,\n",
       " 'out.ğŸ˜”': 1,\n",
       " 'ğŸ’”': 4,\n",
       " 'racist/homophobic/misogynistic.': 1,\n",
       " 'â€œkeeping': 1,\n",
       " ...}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unknown_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check punctuations that roberta unknown "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "punct = \"/-'?!.,#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~\" + '\"\"â€œâ€â€™' + 'âˆÎ¸Ã·Î±â€¢Ã âˆ’Î²âˆ…Â³Ï€â€˜â‚¹Â´Â°Â£â‚¬\\Ã—â„¢âˆšÂ²â€”â€“&'\n",
    "def unknown_punctuation(roberta_vocab):\n",
    "    unknown = ''\n",
    "    for char in punct:\n",
    "        if char not in list(roberta_vocab.keys()):\n",
    "            unknown += char\n",
    "            unknown += ' '\n",
    "    return unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Roberta unknown: \n",
      "â€œ â€ â€™ âˆ Î¸ Î± â€¢ âˆ’ Î² âˆ… Ï€ â€˜ â‚¹ â‚¬ â„¢ âˆš â€” â€“ \n"
     ]
    }
   ],
   "source": [
    "print(\"Roberta unknown: \")\n",
    "print(unknown_punctuation(roberta_vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping unknown to known punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_punc(text):\n",
    "    punct_mapping = {\"â€˜\": \"'\", \"â‚¹\": \"e\", \"Â´\": \"'\", \"Â°\": \"\", \"â‚¬\": \"e\", \"â„¢\": \"tm\", \"âˆš\": \" sqrt \", \"Ã—\": \"x\", \"Â²\": \"2\", \"â€”\": \"-\", \"â€“\": \"-\", \"â€™\": \"'\", \"_\": \"-\", \"`\": \"'\", 'â€œ': '\"', 'â€': '\"', 'â€œ': '\"', \"Â£\": \"e\", 'âˆ': 'infinity', 'Î¸': 'theta', 'Ã·': '/', 'Î±': 'alpha', 'â€¢': '.', 'Ã ': 'a', 'âˆ’': '-', 'Î²': 'beta', 'âˆ…': '', 'Â³': '3', 'Ï€': 'pi', }\n",
    "    for p in punct_mapping:\n",
    "        text = text.replace(p, punct_mapping[p])\n",
    "    for p in punct:\n",
    "        text = text.replace(p, ' {} '.format(p))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['map_punc_text'] = df_train.text.apply(change_punc)\n",
    "df_train['map_punc_reply'] = df_train.reply.apply(change_punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev['map_punc_text'] = df_dev.text.apply(change_punc)\n",
    "df_dev['map_punc_reply'] = df_dev.reply.apply(change_punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['map_punc_text'] = df_test.text.apply(change_punc)\n",
    "df_test['map_punc_reply'] = df_test.reply.apply(change_punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train text unique vocab count is: 46129\n",
      "train reply unique vocab count is: 18569\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=46129.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 38.009% (17533 / 46129) of vocab\n",
      "Found embeddings for 92.560% (743996 / 803801) of all text\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=18569.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 47.709% (8859 / 18569) of vocab\n",
      "Found embeddings for 89.777% (124148 / 138285) of all text\n"
     ]
    }
   ],
   "source": [
    "train_text_vocab = get_vocab(df_train['map_punc_text'].values)\n",
    "train_reply_vocab = get_vocab(df_train['map_punc_reply'].values)\n",
    "print(\"train text unique vocab count is: {}\".format(len(train_text_vocab)))\n",
    "print(\"train reply unique vocab count is: {}\".format(len(train_reply_vocab)))\n",
    "print()\n",
    "\n",
    "unknown_text = check_coverage(train_text_vocab, roberta_vocab)\n",
    "print()\n",
    "unknown_reply = check_coverage(train_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev text unique vocab count is: 13357\n",
      "dev reply unique vocab count is: 4473\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=13357.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 59.886% (7999 / 13357) of vocab\n",
      "Found embeddings for 92.546% (94356 / 101956) of all text\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=4473.0, style=ProgressStyle(description_â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 63.604% (2845 / 4473) of vocab\n",
      "Found embeddings for 89.144% (15635 / 17539) of all text\n"
     ]
    }
   ],
   "source": [
    "dev_text_vocab = get_vocab(df_dev['map_punc_text'].values)\n",
    "dev_reply_vocab = get_vocab(df_dev['map_punc_reply'].values)\n",
    "print(\"dev text unique vocab count is: {}\".format(len(dev_text_vocab)))\n",
    "print(\"dev reply unique vocab count is: {}\".format(len(dev_reply_vocab)))\n",
    "unknown_text = check_coverage(dev_text_vocab, roberta_vocab)\n",
    "print()\n",
    "unknown_reply = check_coverage(dev_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test text unique vocab count is: 13174\n",
      "test reply unique vocab count is: 4263\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=13174.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 60.710% (7998 / 13174) of vocab\n",
      "Found embeddings for 92.731% (92696 / 99962) of all text\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=4263.0, style=ProgressStyle(description_â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 65.142% (2777 / 4263) of vocab\n",
      "Found embeddings for 89.830% (15236 / 16961) of all text\n"
     ]
    }
   ],
   "source": [
    "test_text_vocab = get_vocab(df_test['map_punc_text'].values)\n",
    "test_reply_vocab = get_vocab(df_test['map_punc_reply'].values)\n",
    "print(\"test text unique vocab count is: {}\".format(len(test_text_vocab)))\n",
    "print(\"test reply unique vocab count is: {}\".format(len(test_reply_vocab)))\n",
    "unknown_text = check_coverage(test_text_vocab, roberta_vocab)\n",
    "print()\n",
    "unknown_reply = check_coverage(test_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('coronavirus', 43),\n",
       " ('COVID', 38),\n",
       " ('Covid', 32),\n",
       " ('COVID19', 31),\n",
       " ('pandemic', 27),\n",
       " ('BailoutHumansNow', 24),\n",
       " ('dependable', 24),\n",
       " ('ğŸ˜‚', 24),\n",
       " ('ScottyFromMarketing', 23),\n",
       " ('â¤ï¸', 23),\n",
       " ('ğŸ¤”', 23),\n",
       " ('\\U0001f97a', 19),\n",
       " ('ğŸ˜­', 19),\n",
       " ('seanhannity', 19),\n",
       " ('2nd', 19),\n",
       " ('WritingCommunity', 19),\n",
       " ('ğŸ˜Š', 18),\n",
       " ('gifs', 17),\n",
       " ('AGAIN', 17),\n",
       " ('ğŸ˜”', 16),\n",
       " ('OPENING', 16),\n",
       " ('distancing', 15),\n",
       " ('LIBERATE', 14),\n",
       " ('lmao', 14),\n",
       " ('yall', 13),\n",
       " ('corona', 13),\n",
       " ('6pm', 13),\n",
       " ('ğŸ™ƒ', 13),\n",
       " ('Vaccine', 12),\n",
       " ('questionsâ€¦', 12),\n",
       " ('covid', 12),\n",
       " ('VIRGINIA', 11),\n",
       " ('DMs', 11),\n",
       " ('\\U0001f974', 11),\n",
       " ('Ventilators', 11),\n",
       " ('ğŸ˜³', 11),\n",
       " ('1st', 11),\n",
       " ('ventilators', 10),\n",
       " ('H1N1', 10),\n",
       " ('Swine', 10),\n",
       " ('Polling', 10),\n",
       " ('cuz', 10),\n",
       " ('ğŸ˜‚ğŸ˜‚ğŸ˜‚', 10),\n",
       " ('reopening', 10),\n",
       " ('BREAKING', 10),\n",
       " ('5k', 10),\n",
       " ('ğŸ‘€', 9),\n",
       " ('ğŸ˜­ğŸ˜­', 9),\n",
       " ('3rd', 9),\n",
       " ('Idk', 9),\n",
       " ('ğŸ™„', 9),\n",
       " ('ppl', 9),\n",
       " ('pls', 9),\n",
       " ('idk', 8),\n",
       " ('11am', 8),\n",
       " ('nigga', 8),\n",
       " ('7th', 8),\n",
       " ('Frequently', 8),\n",
       " ('â†’', 8),\n",
       " ('ğŸ’•', 8),\n",
       " ('Coronavirus', 8),\n",
       " ('Gif', 8),\n",
       " ('âœ…', 8),\n",
       " ('ğŸ¤', 8),\n",
       " ('FollowFriday', 8),\n",
       " ('OldRich', 7),\n",
       " ('Lebron', 7),\n",
       " ('Genuinely', 7),\n",
       " ('Rashford', 7),\n",
       " ('RETWEET', 7),\n",
       " ('TESTING', 7),\n",
       " ('QUARANTINE', 7),\n",
       " ('\\U0001f970', 7),\n",
       " ('ğŸ”‘', 7),\n",
       " ('niggas', 6),\n",
       " ('HUNGRY', 6),\n",
       " ('smh', 6),\n",
       " ('vibes', 6),\n",
       " ('Covid19', 6),\n",
       " ('retweets', 6),\n",
       " ('ğŸ˜ª', 6),\n",
       " ('amwriting', 6),\n",
       " ('Neymar', 6),\n",
       " ('lowkey', 6),\n",
       " ('Cassper', 6),\n",
       " ('Bailout', 6),\n",
       " ('Shout', 6),\n",
       " ('ğŸ¤£', 6),\n",
       " ('Quarantine', 6),\n",
       " ('ventilator', 6),\n",
       " ('cuddle', 6),\n",
       " ('CoronaVirus', 6),\n",
       " ('POTUS', 6),\n",
       " ('CoronavirusLiar', 6),\n",
       " ('ğŸ‘ğŸ¼', 6),\n",
       " ('wtf', 5),\n",
       " ('replying', 5),\n",
       " ('Govt', 5),\n",
       " ('ğŸ˜', 5),\n",
       " ('tbh', 5),\n",
       " ('â˜ºï¸', 5),\n",
       " ('BABY', 5),\n",
       " ('Fauci', 5),\n",
       " ('winğŸ’°', 5),\n",
       " ('mutuals', 5),\n",
       " ('ğŸ™', 5),\n",
       " ('ğŸ‡ºğŸ‡¸', 5),\n",
       " ('bitches', 5),\n",
       " ('10k', 5),\n",
       " ('tiktok', 5),\n",
       " ('DrOz', 5),\n",
       " ('RAT', 5),\n",
       " ('Retweet', 5),\n",
       " ('furloughed', 5),\n",
       " ('writerslift', 5),\n",
       " ('govt', 5),\n",
       " ('LikewiseApp', 5),\n",
       " ('Yay', 5),\n",
       " ('Lockdown', 5),\n",
       " ('âœ¨', 5),\n",
       " ('juliemac1000', 5),\n",
       " ('OKAY', 5),\n",
       " ('Wuhan', 5),\n",
       " ('ğŸ˜”ğŸ˜”', 5),\n",
       " ('WOW', 5),\n",
       " ('Couldn', 5),\n",
       " ('spamming', 4),\n",
       " ('ğŸ˜°', 4),\n",
       " ('Horny', 4),\n",
       " ('COVID19Pandemic', 4),\n",
       " ('ğŸ˜‹', 4),\n",
       " ('Yup', 4),\n",
       " ('hella', 4),\n",
       " ('convo', 4),\n",
       " ('writingcommunity', 4),\n",
       " ('libs', 4),\n",
       " ('AEW', 4),\n",
       " ('HATE', 4),\n",
       " ('ğŸ˜…', 4),\n",
       " ('Ruggs', 4),\n",
       " ('Jeudy', 4),\n",
       " ('VoteSafe', 4),\n",
       " ('â†’No', 4),\n",
       " ('â†’At', 4),\n",
       " ('ğŸ¤£ğŸ¤£ğŸ¤£', 4),\n",
       " ('ğŸ’”', 4),\n",
       " ('Pls', 4),\n",
       " ('4th', 4),\n",
       " ('SpeakerPelosi', 4),\n",
       " ('Ozark', 4),\n",
       " ('PPP', 4),\n",
       " ('ğŸ’€', 4),\n",
       " ('positivity', 4),\n",
       " ('ğŸ˜ˆ', 4),\n",
       " ('streamer', 4),\n",
       " ('â˜€ï¸', 4),\n",
       " ('\\U0001f973', 4),\n",
       " ('ğŸ˜‰', 4),\n",
       " ('FCE', 4),\n",
       " ('friday', 4),\n",
       " ('BOY', 4),\n",
       " ('ğŸ˜¢', 4),\n",
       " ('ğŸ˜˜', 4),\n",
       " ('CashApp', 4),\n",
       " ('Rona', 4),\n",
       " ('StayAtHome', 4),\n",
       " ('ğŸ˜Œ', 4),\n",
       " ('OANN', 4),\n",
       " ('Welp', 4),\n",
       " ('virologist', 4),\n",
       " ('EVERYONE', 4),\n",
       " ('imma', 4),\n",
       " ('WENT', 4),\n",
       " ('BATHROOM', 4),\n",
       " ('HAD', 4),\n",
       " ('SWUM', 4),\n",
       " ('TOILET', 4),\n",
       " ('THOUGHT', 4),\n",
       " ('URBAN', 4),\n",
       " ('LEGEND', 4),\n",
       " ('MOVE', 4),\n",
       " ('covid19', 4),\n",
       " ('Apologies', 4),\n",
       " ('Lemme', 4),\n",
       " ('Fortnite', 4),\n",
       " ('whack', 4),\n",
       " ('ğŸ˜©', 4),\n",
       " ('gimme', 4),\n",
       " ('12k', 4),\n",
       " ('ğŸ˜’', 4),\n",
       " ('ğŸ‰', 4),\n",
       " ('SHIT', 4),\n",
       " ('ğŸ˜­ğŸ˜­ğŸ˜­', 4),\n",
       " ('ğŸ˜', 4),\n",
       " ('ğŸ’°', 4),\n",
       " ('geng', 4),\n",
       " ('carti', 3),\n",
       " ('dababy', 3),\n",
       " ('ğŸ˜“', 3),\n",
       " ('PHYSICALLY', 3),\n",
       " ('hurtful', 3),\n",
       " ('lockdowns', 3),\n",
       " ('quarantining', 3),\n",
       " ('Giveaway', 3),\n",
       " ('famu', 3),\n",
       " ('30th', 3),\n",
       " ('COMING', 3),\n",
       " ('nudes', 3),\n",
       " ('JoeBiden', 3),\n",
       " ('FOLLOWERS', 3),\n",
       " ('OUSTDUTERENOW', 3),\n",
       " ('Newsom', 3),\n",
       " ('YALL', 3),\n",
       " ('4TH', 3),\n",
       " ('Loeffler', 3),\n",
       " ('MAGAts', 3),\n",
       " ('Blonde', 3),\n",
       " ('clap', 3),\n",
       " ('streamers', 3),\n",
       " ('AWAY', 3),\n",
       " ('RaiderNation', 3),\n",
       " ('Tired', 3),\n",
       " ('tryna', 3),\n",
       " ('ğŸ˜‚ğŸ˜‚', 3),\n",
       " ('ğŸ˜', 3),\n",
       " ('Schitt', 3),\n",
       " ('satanic', 3),\n",
       " ('botoxed', 3),\n",
       " ('slimy', 3),\n",
       " ('wad', 3),\n",
       " ('hag', 3),\n",
       " ('allğŸ˜', 3),\n",
       " ('\\U0001f92a', 3),\n",
       " ('ALX', 3),\n",
       " ('rut', 3),\n",
       " ('diy', 3),\n",
       " ('LOCALS', 3),\n",
       " ('USING', 3),\n",
       " ('GIFS', 3),\n",
       " ('THEYRE', 3),\n",
       " ('CRINGE', 3),\n",
       " ('WTF', 3),\n",
       " ('FYI', 3),\n",
       " ('STILL', 3),\n",
       " ('ğŸ˜‘', 3),\n",
       " ('overrated', 3),\n",
       " ('Pulte', 3),\n",
       " ('Struggling', 3),\n",
       " ('NationalHornyDay', 3),\n",
       " ('GONE', 3),\n",
       " ('nuggets', 3),\n",
       " ('clapping', 3),\n",
       " ('CHINA', 3),\n",
       " ('\\U0001f92f', 3),\n",
       " ('LMAO', 3),\n",
       " ('ğŸ¤·\\u200dâ™€ï¸', 3),\n",
       " ('PSA', 3),\n",
       " ('2k', 3),\n",
       " ('Peanut', 3),\n",
       " ('ğŸ’š', 3),\n",
       " ('ğŸ’–', 3),\n",
       " ('pissy', 3),\n",
       " ('Ugh', 3),\n",
       " ('alerting', 3),\n",
       " ('talkin', 3),\n",
       " ('dey', 3),\n",
       " ('omg', 3),\n",
       " ('presser', 3),\n",
       " ('Gives', 3),\n",
       " ('Approval', 3),\n",
       " ('Sleepy', 3),\n",
       " ('Candidates', 3),\n",
       " ('SenThomTillis', 3),\n",
       " ('Titties', 3),\n",
       " ('AMEN', 3),\n",
       " ('Mauricio', 3),\n",
       " ('Pochettino', 3),\n",
       " ('Whitmer', 3),\n",
       " ('ramadan', 3),\n",
       " ('Gonna', 3),\n",
       " ('1M', 3),\n",
       " ('Zooming', 3),\n",
       " ('Shoutout', 3),\n",
       " ('Maternal', 3),\n",
       " ('enabler', 3),\n",
       " ('boycotted', 3),\n",
       " ('Husband', 3),\n",
       " ('THINK', 3),\n",
       " ('DONT', 3),\n",
       " ('whoop', 3),\n",
       " ('NIGGAS', 3),\n",
       " ('pickle', 3),\n",
       " ('Mnuchin', 3),\n",
       " ('Paycheck', 3),\n",
       " ('\\U0001f97a\\U0001f97a', 3),\n",
       " ('tweeps', 3),\n",
       " ('HAPPY', 3),\n",
       " ('Nyovest', 3),\n",
       " ('EVERYTHING', 3),\n",
       " ('YT', 3),\n",
       " ('\\U0001f92e', 3),\n",
       " ('goodnight', 3),\n",
       " ('kiddos', 3),\n",
       " ('HORSE', 3),\n",
       " ('tik', 3),\n",
       " ('tok', 3),\n",
       " ('ğŸ˜', 3),\n",
       " ('atleast', 3),\n",
       " ('amediting', 3),\n",
       " ('LETS', 3),\n",
       " ('GIFs', 3),\n",
       " ('ğŸ’€ğŸ’€ğŸ’€', 3),\n",
       " ('maddow', 3),\n",
       " ('2m', 3),\n",
       " ('StayHomeSaveLives', 3),\n",
       " ('HISTORY', 3),\n",
       " ('Shouldn', 3),\n",
       " ('100k', 3),\n",
       " ('Fucking', 3),\n",
       " ('meds', 3),\n",
       " ('LDSB', 3),\n",
       " ('NationalHighFiveDay', 3),\n",
       " ('ğŸš¨', 3),\n",
       " ('Staying', 3),\n",
       " ('FORCE', 3),\n",
       " ('30pm', 3),\n",
       " ('â­', 3),\n",
       " ('SMILE', 3),\n",
       " ('uzi', 2),\n",
       " ('overreacting', 2),\n",
       " ('obsessing', 2),\n",
       " ('â˜¹ï¸', 2),\n",
       " ('ğŸ’›', 2),\n",
       " ('wna', 2),\n",
       " ('hypocrites', 2),\n",
       " ('bombarded', 2),\n",
       " ('sapped', 2),\n",
       " ('ğŸ™Œ', 2),\n",
       " ('Halladay', 2),\n",
       " ('LoyalGiveaways', 2),\n",
       " ('ğŸ™‹\\u200dâ™‚ï¸ğŸ™‹\\u200dâ™‚ï¸ğŸ™‹\\u200dâ™‚ï¸', 2),\n",
       " ('Flutter', 2),\n",
       " ('Stimulus', 2),\n",
       " ('MONDAY', 2),\n",
       " ('ğŸ‘»ğŸ‘»ğŸ‘»', 2),\n",
       " ('emojis', 2),\n",
       " ('INDIA', 2),\n",
       " ('nope', 2),\n",
       " ('Shehnaaz', 2),\n",
       " ('jm', 2),\n",
       " ('65th', 2),\n",
       " ('unwell', 2),\n",
       " ('stageit', 2),\n",
       " ('impeached', 2),\n",
       " ('ğŸ˜•', 2),\n",
       " ('decorating', 2),\n",
       " ('NOVEMBER', 2),\n",
       " ('McSally', 2),\n",
       " ('Tillis', 2),\n",
       " ('Myself', 2),\n",
       " ('Krispies', 2),\n",
       " ('assholes', 2),\n",
       " ('loosing', 2),\n",
       " ('â™¥ï¸', 2),\n",
       " ('giantschat', 2),\n",
       " ('DJT', 2),\n",
       " ('respirators', 2),\n",
       " ('harried', 2),\n",
       " ('Heading', 2),\n",
       " ('catchup', 2),\n",
       " ('ğŸ™‚', 2),\n",
       " ('ğŸ“ˆğŸ“ˆğŸ“ˆ', 2),\n",
       " ('ANYONE', 2),\n",
       " ('Misbah', 2),\n",
       " ('haunts', 2),\n",
       " ('giver', 2),\n",
       " ('Adopt', 2),\n",
       " ('ğŸ‘‡', 2),\n",
       " ('skan', 2),\n",
       " ('imreadyimreadyimready', 2),\n",
       " ('dontpanic', 2),\n",
       " ('imposter', 2),\n",
       " ('ANYBODY', 2),\n",
       " ('physed', 2),\n",
       " ('wednesday', 2),\n",
       " ('mama', 2),\n",
       " ('wholesome', 2),\n",
       " ('WriterLift', 2),\n",
       " ('mandylawson7', 2),\n",
       " ('LilyBOW2', 2),\n",
       " ('DnD', 2),\n",
       " ('distanced', 2),\n",
       " ('Adderall', 2),\n",
       " ('GIVE', 2),\n",
       " ('GUYS', 2),\n",
       " ('tipsy', 2),\n",
       " ('oatmeal', 2),\n",
       " ('joe', 2),\n",
       " ('Wtf', 2),\n",
       " ('stroller', 2),\n",
       " ('cranky', 2),\n",
       " ('grandad', 2),\n",
       " ('carer', 2),\n",
       " ('selfisolating', 2),\n",
       " ('Whos', 2),\n",
       " ('LOSE', 2),\n",
       " ('SenSchumer', 2),\n",
       " ('hoes', 2),\n",
       " ('realdonaldTrump', 2),\n",
       " ('KUWTK', 2),\n",
       " ('WORKING', 2),\n",
       " ('impactful', 2),\n",
       " ('â¤ï¸â¤ï¸â¤ï¸â¤ï¸', 2),\n",
       " ('FAVORITE', 2),\n",
       " ('FRIDAY', 2),\n",
       " ('FUNNY', 2),\n",
       " ('comatose', 2),\n",
       " ('outta', 2),\n",
       " ('BTS', 2),\n",
       " ('Interchange', 2),\n",
       " ('HARD', 2),\n",
       " ('ğŸ‡ºğŸ‡¸â¤ï¸ğŸ™ğŸ‘', 2),\n",
       " ('tradeoff', 2),\n",
       " ('Bitches', 2),\n",
       " ('LockdownHouseParty', 2),\n",
       " ('shahs', 2),\n",
       " ('unfollowing', 2),\n",
       " ('lemme', 2),\n",
       " ('16th', 2),\n",
       " ('\\U0001f9d0', 2),\n",
       " ('disgustingly', 2),\n",
       " ('fucks', 2),\n",
       " ('TogetherAtHome', 2),\n",
       " ('repos', 2),\n",
       " ('dawg', 2),\n",
       " ('Ima', 2),\n",
       " ('e9', 2),\n",
       " ('brandy', 2),\n",
       " ('NUFC', 2),\n",
       " ('faouzia', 2),\n",
       " ('faouxia', 2),\n",
       " ('ğŸ™ˆ', 2),\n",
       " ('Octopus', 2),\n",
       " ('ğŸ¤—', 2),\n",
       " ('Bettman', 2),\n",
       " ('BarackObama', 2),\n",
       " ('onlyfans', 2),\n",
       " ('DBCarterAuthor', 2),\n",
       " ('BellaRayne10', 2),\n",
       " ('FaerieRealms', 2),\n",
       " ('cutest', 2),\n",
       " ('illiterates', 2),\n",
       " ('TooHotToHandle', 2),\n",
       " ('opals', 2),\n",
       " ('bums', 2),\n",
       " ('FOLLOW', 2),\n",
       " ('RID', 2),\n",
       " ('BALLOT', 2),\n",
       " ('HARVESTING', 2),\n",
       " ('RAMPANT', 2),\n",
       " ('FRAUD', 2),\n",
       " ('VOTER', 2),\n",
       " ('HONEST', 2),\n",
       " ('COUNT', 2),\n",
       " ('humbled', 2),\n",
       " ('ğŸ¤¦ğŸ»\\u200dâ™€ï¸', 2),\n",
       " ('influencers', 2),\n",
       " ('fuckery', 2),\n",
       " ('LockdownHousePartyğŸ”¥', 2),\n",
       " ('ALMOST', 2),\n",
       " ('shouldnt', 2),\n",
       " ('webkinz', 2),\n",
       " ('8th', 2),\n",
       " ('ğŸ˜¬ğŸ˜¬ğŸ˜¬im', 2),\n",
       " ('ğŸ˜¬ğŸ˜¬ğŸ˜¬If', 2),\n",
       " ('dresser', 2),\n",
       " ('fckn', 2),\n",
       " ('stinks', 2),\n",
       " ('jt', 2),\n",
       " ('bday', 2),\n",
       " ('ğŸ˜±', 2),\n",
       " ('Poets', 2),\n",
       " ('Bloggers', 2),\n",
       " ('MULK', 2),\n",
       " ('cornbread', 2),\n",
       " ('Hakeem', 2),\n",
       " ('bottlenecks', 2),\n",
       " ('MARINES', 2),\n",
       " ('sunday', 2),\n",
       " ('paypal', 2),\n",
       " ('OSU', 2),\n",
       " ('sims', 2),\n",
       " ('Wetin', 2),\n",
       " ('BailoutHumans', 2),\n",
       " ('Trending', 2),\n",
       " ('BAIL', 2),\n",
       " ('HUMANS', 2),\n",
       " ('hyenas', 2),\n",
       " ('euphoric', 2),\n",
       " ('Describe', 2),\n",
       " ('prosecco', 2),\n",
       " ('FACT', 2),\n",
       " ('INFORM', 2),\n",
       " ('Accidentally', 2),\n",
       " ('HOPE', 2),\n",
       " ('thfc', 2),\n",
       " ('e12', 2),\n",
       " ('5M', 2),\n",
       " ('severance', 2),\n",
       " ('TelegraphSport', 2),\n",
       " ('â€¼ï¸', 2),\n",
       " ('\\U0001f928', 2),\n",
       " ('daisy', 2),\n",
       " ('dukes', 2),\n",
       " ('Xanax', 2),\n",
       " ('slink', 2),\n",
       " ('sappy', 2),\n",
       " ('Luh', 2),\n",
       " ('muslim', 2),\n",
       " ('OnlyFans', 2),\n",
       " ('â¤ï¸ğŸ˜˜', 2),\n",
       " ('ğŸ˜«', 2),\n",
       " ('MOST', 2),\n",
       " ('Ingraham', 2),\n",
       " ('KEEP', 2),\n",
       " ('jus', 2),\n",
       " ('alboy88', 2),\n",
       " ('followfriday', 2),\n",
       " ('hospitalizes', 2),\n",
       " ('hospitalizations', 2),\n",
       " ('doin', 2),\n",
       " ('Newz', 2),\n",
       " ('quarantined', 2),\n",
       " ('musicals', 2),\n",
       " ('gangsta', 2),\n",
       " ('ğŸ’ªğŸ¼', 2),\n",
       " ('moots', 2),\n",
       " ('whoops', 2),\n",
       " ('â¤ï¸â¤ï¸â¤ï¸', 2),\n",
       " ('WANNA', 2),\n",
       " ('TAKE', 2),\n",
       " ('APPRECIATE', 2),\n",
       " ('necking', 2),\n",
       " ('donuts', 2),\n",
       " ('Hydroxychloroquine', 2),\n",
       " ('bruh', 2),\n",
       " ('YAYYYY', 2),\n",
       " ('\\U0001f92b', 2),\n",
       " ('johnpodesta', 2),\n",
       " ('hoodie', 2),\n",
       " ('Gorsky', 2),\n",
       " ('TheHiveVR', 2),\n",
       " ('Navahk', 2),\n",
       " ('museumpaige', 2),\n",
       " ('AltspaceVR', 2),\n",
       " ('TheKillettosVR', 2),\n",
       " ('Onward', 2),\n",
       " ('VRML', 2),\n",
       " ('Spoken', 2),\n",
       " ('pornstar', 2),\n",
       " ('Nasty', 2),\n",
       " ('ğŸ˜ ', 2),\n",
       " ('Cryin', 2),\n",
       " ('ENDLESS', 2),\n",
       " ('VACATION', 2),\n",
       " ('prepping', 2),\n",
       " ('869', 2),\n",
       " ('peeling', 2),\n",
       " ('psychopaths', 2),\n",
       " ('gong', 2),\n",
       " ('TikTok', 2),\n",
       " ('kum', 2),\n",
       " ('Zlatan', 2),\n",
       " ('papa', 2),\n",
       " ('MORNING', 2),\n",
       " ('Boneless', 2),\n",
       " ('Goodnight', 2),\n",
       " ('VN', 2),\n",
       " ('ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½',\n",
       "  2),\n",
       " ('Deluded', 2),\n",
       " ('mhm', 2),\n",
       " ('ğŸ˜¯', 2),\n",
       " ('djs', 2),\n",
       " ('26th', 2),\n",
       " ('HOLY', 2),\n",
       " ('FINALLY', 2),\n",
       " ('ğŸ˜­ğŸ¤£', 2),\n",
       " ('ğŸ™ŒğŸ»', 2),\n",
       " ('madison', 2),\n",
       " ('fuckers', 2),\n",
       " ('Replaced', 2),\n",
       " ('walkaway', 2),\n",
       " ('MAGAt', 2),\n",
       " ('McKinney', 2),\n",
       " ('â¬‡ï¸â¬‡ï¸', 2),\n",
       " ('Kroenke', 2),\n",
       " ('SamiMokbel81', 2),\n",
       " ('hows', 2),\n",
       " ('DOESN', 2),\n",
       " ('ArianaGrande', 2),\n",
       " ('squirters', 2),\n",
       " ('airwaves', 2),\n",
       " ('loosening', 2),\n",
       " ('mullet', 2),\n",
       " ('Reopening', 2),\n",
       " ('ğŸ‡ºğŸ‡¸ğŸ‡ºğŸ‡¸ğŸ‡ºğŸ‡¸', 2),\n",
       " ('Refilling', 2),\n",
       " ('Rydiee', 2),\n",
       " ('sneaker', 2),\n",
       " ('wannabe', 2),\n",
       " ('bobandtom', 2),\n",
       " ('Cute', 2),\n",
       " ('ğŸ˜ƒ', 2),\n",
       " ('ADOS', 2),\n",
       " ('youre', 2),\n",
       " ('Morehouse', 2),\n",
       " ('Fingers', 2),\n",
       " ('celery', 2),\n",
       " ('spoons', 2),\n",
       " ('Jojo', 2),\n",
       " ('thx', 2),\n",
       " ('writerslife', 2),\n",
       " ('toyota', 2),\n",
       " ('hoil', 2),\n",
       " ('ğŸ¤§', 2),\n",
       " ('ophthalmologist', 2),\n",
       " ('NationalHighFiveDayâ€¦', 2),\n",
       " ('slippin', 2),\n",
       " ('gratefully', 2),\n",
       " ('april', 2),\n",
       " ('weirder', 2),\n",
       " ('showered', 2),\n",
       " ('coochie', 2),\n",
       " ('faves', 2),\n",
       " ('TrumpVirus', 2),\n",
       " ('Outlander', 2),\n",
       " ('ğŸ’œ', 2),\n",
       " ('pampered', 2),\n",
       " ('brat', 2),\n",
       " ('unmask', 2),\n",
       " ('Millville', 2),\n",
       " ('6k', 2),\n",
       " ('ğŸ’¥Under', 2),\n",
       " ('ğŸ’¥Over', 2),\n",
       " ('writerscommunity', 2),\n",
       " ('ğŸ˜¡', 2),\n",
       " ('Dennehy', 2),\n",
       " ('Gasol', 2),\n",
       " ('WellI', 2),\n",
       " ('homestead', 2),\n",
       " ('yalls', 2),\n",
       " ('CryptoGainz1', 2),\n",
       " ('Tbh', 2),\n",
       " ('POINT', 2),\n",
       " ('lookin', 2),\n",
       " ('asap', 2),\n",
       " ('ğŸ˜³ğŸ˜³ğŸ˜³', 2),\n",
       " ('motherfuckers', 2),\n",
       " ('Emtee', 2),\n",
       " ('haters', 2),\n",
       " ('\\U0001f97aâ¤ï¸', 2),\n",
       " ('cancelling', 2),\n",
       " ('Gretchen', 2),\n",
       " ('smoothie', 2),\n",
       " ('cosplay', 2),\n",
       " ('Romanians', 2),\n",
       " ('8pm', 2),\n",
       " ('ğŸ˜·', 2),\n",
       " ('moans', 2),\n",
       " ('soo', 2),\n",
       " ('werewolf', 2),\n",
       " ('ğŸŒ™', 2),\n",
       " ('Sigh', 2),\n",
       " ('ASK', 2),\n",
       " ('intubated', 2),\n",
       " ('Bruh', 2),\n",
       " ('ğŸ’¯', 2),\n",
       " ('decimated', 2),\n",
       " ('coven', 2),\n",
       " ('sheltering', 2),\n",
       " ('fellas', 2),\n",
       " ('Gotta', 2),\n",
       " ('Onlyfans', 2),\n",
       " ('skittles', 2),\n",
       " ('Tempting', 2),\n",
       " ('SPY', 2),\n",
       " ('ğŸ˜„', 2),\n",
       " ('tolerable', 2),\n",
       " ('overlords', 2),\n",
       " ('portly', 2),\n",
       " ('raccoons', 2),\n",
       " ('masturbating', 2),\n",
       " ('Told', 2),\n",
       " ('ğŸ¤¢', 2),\n",
       " ('MAGA', 2),\n",
       " ('Nsfas', 2),\n",
       " ('R3000', 2),\n",
       " ('ğŸ¤ğŸ½', 2),\n",
       " ('BoycottOnlineLearningUJ', 2),\n",
       " ('DAMN', 2),\n",
       " ('snobs', 2),\n",
       " ('Amwriting', 2),\n",
       " ('pero', 2),\n",
       " ('QuarantineLife', 2),\n",
       " ('sanitizer', 2),\n",
       " ('ğŸ‘‰ğŸ‘ˆ', 2),\n",
       " ('yadda', 2),\n",
       " ('Dominguez', 2),\n",
       " ('BUYING', 2),\n",
       " ('NUDES', 2),\n",
       " ('MIRROR', 2),\n",
       " ('PUSSY', 2),\n",
       " ('mf', 2),\n",
       " ('Afghanis', 2),\n",
       " ('dO', 2),\n",
       " ('FF7', 2),\n",
       " ('STAY', 2),\n",
       " ('SB19', 2),\n",
       " ('âœ‹', 2),\n",
       " ('Woke', 2),\n",
       " ('tarts', 2),\n",
       " ('Basu', 2),\n",
       " ('Yechury', 2),\n",
       " ('cavefish', 2),\n",
       " ('FridayMotivation', 2),\n",
       " ('VSAT', 2),\n",
       " ('Unplugged', 2),\n",
       " ('FamiliesFirst', 2),\n",
       " ('whew', 2),\n",
       " ('uncontrollably', 2),\n",
       " ('eyeroll', 2),\n",
       " ('booty', 2),\n",
       " ('VPG', 2),\n",
       " ('x1', 2),\n",
       " ('ğŸ”¥', 2),\n",
       " ('banger', 2),\n",
       " ('WhatsMiner', 2),\n",
       " ('Whatsminer', 2),\n",
       " ('MBT', 2),\n",
       " ('CryptoFinally', 2),\n",
       " ('\\U0001fa90âœ¨', 2),\n",
       " ('Solidarity', 2),\n",
       " ('darkskin', 2),\n",
       " ('elizabeth', 2),\n",
       " ('warren', 2),\n",
       " ('rachel', 2),\n",
       " ('distasteful', 2),\n",
       " ('biden', 2),\n",
       " ('runningmate', 2),\n",
       " ('Stacey', 2),\n",
       " ('shortlist', 2),\n",
       " ('rlly', 2),\n",
       " ('ğŸ˜©ğŸ˜©', 2),\n",
       " ('Maxie', 2),\n",
       " ('Paxie', 2),\n",
       " ('idc', 2),\n",
       " ('winded', 2),\n",
       " ('BEEN', 2),\n",
       " ('ICYMI', 2),\n",
       " ('MLCC', 2),\n",
       " ('AllInThisTogether', 2),\n",
       " ('everytime', 2),\n",
       " ('MADE', 2),\n",
       " ('omelette', 2),\n",
       " ('isnt', 2),\n",
       " ('ğŸ›', 2),\n",
       " ('FridayThoughts', 2),\n",
       " ('pubic', 2),\n",
       " ('ğŸ˜µ', 2),\n",
       " ('YO', 2),\n",
       " ('wank', 2),\n",
       " ('lmaoooo', 2),\n",
       " ('ğŸ’ğŸ˜', 2),\n",
       " ('ğŸ™ğŸ˜˜ğŸ˜Š', 2),\n",
       " ('hyped', 2),\n",
       " ('100K', 2),\n",
       " ('WWESuperCard', 2),\n",
       " ('Propaganda', 2),\n",
       " ('Feenix', 2),\n",
       " ('OWL', 2),\n",
       " ('disneysingalong', 2),\n",
       " ('momos', 2),\n",
       " ('Taurus', 2),\n",
       " ('NFG', 2),\n",
       " ('Wearing', 2),\n",
       " ('facetime', 2),\n",
       " ('ğŸ¤·\\u200dâ™‚ï¸', 2),\n",
       " ('reminiscing', 2),\n",
       " ('ğŸ’', 2),\n",
       " ('Youngdeji', 1),\n",
       " ('woah', 1),\n",
       " ('Denny', 1),\n",
       " ('Zaira', 1),\n",
       " ('Wasim', 1),\n",
       " ('hardwork', 1),\n",
       " ('madisonbeer', 1),\n",
       " ('LupeLoops', 1),\n",
       " ('disappointments', 1),\n",
       " ('disassociating', 1),\n",
       " ('myrtle', 1),\n",
       " ('spiraling', 1),\n",
       " ('STRATEGICALLY', 1),\n",
       " ('DYNAMICALLY', 1),\n",
       " ('grudges', 1),\n",
       " ('hyperventilate', 1),\n",
       " ('guaging', 1),\n",
       " ('fucj', 1),\n",
       " ('bcs', 1),\n",
       " ('natin', 1),\n",
       " ('WHYRUep12', 1),\n",
       " ('simpsons', 1),\n",
       " ('Hollyweird', 1),\n",
       " ('pedophile', 1),\n",
       " ('grandiloquent', 1),\n",
       " ('jumpin', 1),\n",
       " ('petulance', 1),\n",
       " ('gridlock', 1),\n",
       " ('vendettas', 1),\n",
       " ('Motel', 1),\n",
       " ('ğŸ¤·ğŸ»\\u200dâ™€ï¸ğŸ¤·ğŸ»\\u200dâ™€ï¸', 1),\n",
       " ('skateboard', 1),\n",
       " ('amphetamines', 1),\n",
       " ('somn', 1),\n",
       " ('NEEDğŸŒ¹SOLO', 1),\n",
       " ('ğŸŒ¹SANAğŸŒ¹PROJECTSğŸŒ¹', 1),\n",
       " ('SVTrainToBusan', 1),\n",
       " ('conflated', 1),\n",
       " ('DxvilishAngxl', 1),\n",
       " ('Veniece', 1),\n",
       " ('punks', 1),\n",
       " ('smuggle', 1),\n",
       " ('THOSE', 1),\n",
       " ('ShelleyMcElyea1', 1),\n",
       " ('â¤ï¸ğŸ’‹ğŸğŸ‰ğŸ°ğŸˆ', 1),\n",
       " ('24hours', 1),\n",
       " ('ğŸ”¥ğŸš€', 1),\n",
       " ('\\U0001f91fğŸ¼', 1),\n",
       " ('unconvincing', 1),\n",
       " ('consoler', 1),\n",
       " ('Hugger', 1),\n",
       " ('AAWAZ', 1),\n",
       " ('Eke', 1),\n",
       " ('Uti', 1),\n",
       " ('hardworking', 1),\n",
       " ('BobRisky', 1),\n",
       " ('Enkayy', 1),\n",
       " ('Mercenaries', 1),\n",
       " ('ZenMagazine', 1),\n",
       " ('liberianboii', 1),\n",
       " ('Twenties', 1),\n",
       " ('Shet', 1),\n",
       " ('ğŸ˜®ğŸ˜…', 1),\n",
       " ('celebratory', 1),\n",
       " ('disrespects', 1),\n",
       " ('sinning', 1),\n",
       " ('Seala', 1),\n",
       " ('FilmGob', 1),\n",
       " ('jodyscorner1', 1),\n",
       " ('filmgob', 1),\n",
       " ('jody', 1),\n",
       " ('overthinking', 1),\n",
       " ('13k', 1),\n",
       " ('MoHFW', 1),\n",
       " ('drharshvardhan', 1),\n",
       " ('PMOIndia', 1),\n",
       " ('decelerate', 1),\n",
       " ('dreading', 1),\n",
       " ('secs', 1),\n",
       " ('kellyinvegas', 1),\n",
       " ('vegasmurray', 1),\n",
       " ('Toppin', 1),\n",
       " ('ğŸ˜­â¤ï¸', 1),\n",
       " ('housekeeping', 1),\n",
       " ('decorate', 1),\n",
       " ('HOURRRSSSS', 1),\n",
       " ('shmsaaldh', 1),\n",
       " ('sweatshirt', 1),\n",
       " ('hammock', 1),\n",
       " ('ShehnaazGill', 1),\n",
       " ('ishehnaaz', 1),\n",
       " ('gill', 1),\n",
       " ('KaushalJoshi15', 1),\n",
       " ('goin', 1),\n",
       " ('Thorpe', 1),\n",
       " ('Alton', 1),\n",
       " ('TWITCH', 1),\n",
       " ('\\U0001f973\\U0001f929', 1),\n",
       " ('donos', 1),\n",
       " ('ğŸ’—', 1),\n",
       " ('ğŸ‘‹ğŸ»', 1),\n",
       " ('hunch', 1),\n",
       " ('Badger', 1),\n",
       " ('FSQ', 1),\n",
       " ('Retired', 1),\n",
       " ('GGs', 1),\n",
       " ('CetraLol', 1),\n",
       " ('mAAd', 1),\n",
       " ('PRL', 1),\n",
       " ('9PM', 1),\n",
       " ('Defiance', 1),\n",
       " ('condescending', 1),\n",
       " ('SchittsCreek', 1),\n",
       " ('AUDACITY', 1),\n",
       " ('9am', 1),\n",
       " ('fantasized', 1),\n",
       " ('smothering', 1),\n",
       " ('Verkis', 1),\n",
       " ('assğŸ˜©', 1),\n",
       " ('foggy', 1),\n",
       " ('aboogie', 1),\n",
       " ('OUSTDUTERTENOW', 1),\n",
       " ('philippines', 1),\n",
       " ('COLIATHGAMING', 1),\n",
       " ('vicdgordon', 1),\n",
       " ('StreamGamma', 1),\n",
       " ('kedabosch', 1),\n",
       " ('Day1neGaming', 1),\n",
       " ('JxckWSW', 1),\n",
       " ('Ncshredder', 1),\n",
       " ('Stardrix1', 1),\n",
       " ('GSO', 1),\n",
       " ('TSillysweat', 1),\n",
       " ('ChloeDonald', 1),\n",
       " ('xLexry', 1),\n",
       " ('MultynWolf', 1),\n",
       " ('SaycredAngel', 1),\n",
       " ('fuscyoface', 1),\n",
       " ('Storkyyy1', 1),\n",
       " ('Kamo', 1),\n",
       " ('Mphela', 1),\n",
       " ('intensions', 1),\n",
       " ('Steyer', 1),\n",
       " ('injustices', 1),\n",
       " ('ğŸ’¨ğŸ’¨', 1),\n",
       " ('READY', 1),\n",
       " ('CAUCASIANS', 1),\n",
       " ('CANCEL', 1),\n",
       " ('JULY', 1),\n",
       " ('meteoric', 1),\n",
       " ('StayHomeStaySafeSaveLives', 1),\n",
       " ('smallvictory', 1),\n",
       " ('AnimalCrossing', 1),\n",
       " ('dreamt', 1),\n",
       " ('Uddhav', 1),\n",
       " ('soproudofmyself', 1),\n",
       " ('Niggas', 1),\n",
       " ('hooping', 1),\n",
       " ('9Girl', 1),\n",
       " ('Cocoa', 1),\n",
       " ('repaint', 1),\n",
       " ('helluva', 1),\n",
       " ('Moir', 1),\n",
       " ('nowâœŒğŸ»', 1),\n",
       " ('Sidharth', 1),\n",
       " ('belive', 1),\n",
       " ('Jens', 1),\n",
       " ('TWELVE', 1),\n",
       " ('Gratitude', 1),\n",
       " ('theowaldspecht', 1),\n",
       " ('Nichtpartei', 1),\n",
       " ('MoSchaefer66', 1),\n",
       " ('ErdtrabantMaria', 1),\n",
       " ('humanbeinx', 1),\n",
       " ('idgaf', 1),\n",
       " ('636', 1),\n",
       " ('Emoji', 1),\n",
       " ('ğŸ˜ğŸ˜', 1),\n",
       " ('JazzrazDFS', 1),\n",
       " ('Clips', 1),\n",
       " ('realy', 1),\n",
       " ('dryer', 1),\n",
       " ('googled', 1),\n",
       " ('menopause', 1),\n",
       " ('Okudah', 1),\n",
       " ('ğŸ‘‡ğŸ‘‡ğŸ‘‡', 1),\n",
       " ('darkies', 1),\n",
       " ('koppaberg', 1),\n",
       " ('screwing', 1),\n",
       " ('Bronte', 1),\n",
       " ('BITCHES', 1),\n",
       " ('HEAVY', 1),\n",
       " ('HONEYMOON', 1),\n",
       " ('WEDDING', 1),\n",
       " ('amuck', 1),\n",
       " ('Hindutva', 1),\n",
       " ('cupboard', 1),\n",
       " ('Oddly', 1),\n",
       " ('Bourdain', 1),\n",
       " ('tht', 1),\n",
       " ('y2k', 1),\n",
       " ('UGLY', 1),\n",
       " ('TACKY', 1),\n",
       " ('HIDEOUS', 1),\n",
       " ('relive', 1),\n",
       " ('exhilarating', 1),\n",
       " ('9AM', 1),\n",
       " ('sorta', 1),\n",
       " ('blossom', 1),\n",
       " ('PieceOfArke', 1),\n",
       " ('coz', 1),\n",
       " ...]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(unknown_text.items(), key=lambda d: d[1], reverse=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform more words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "more_apostrophes = {'cannot': \"can not\", 'gonna': \"go to\", 'wanna': \"want to\", 'coronavirus': \"COVID\", 'wanted': \"want\", 'weeks': \"week\", 'feeling': \"feel\", 'says': \"say\", 'yourself': \"your self\", 'saying': \"say\", 'says': \"say\", 'GIF': \"gif\", 'waiting': \"wait\", 'Covid': \"COVID\", 'hugs': \"hug\", 'gave': \"give\", 'COVID19': \"COVID\", 'installing': \"install\", 'wants': \"want\", 'knows': \"know\", 'describes': \"describe\", 'following': \"follow\", 'asked': \"ask\", 'amazing': \"amaze\", 'finally': \"final\", 'minutes': \"minute\", 'died': \"die\", 'tired': \"tire\", 'quickly': \"quick\", 'gotta': \"go to\", 'deaths': \"death\", 'means': \"mean\", 'took': \"take\", 'feels': \"feel\", 'fans': \"fan\", 'numbers': \"number\", 'lives': \"live\", 'safely': \"safe\", 'tried': \"try\", 'businesses': \"business\", '2nd': \"second\", 'decided': \"decide\", '3rd': \"third\", 'hates': \"hate\", 'dont': \"do not\", 'lonely': \"lone\", 'totally': \"total\", 'excited': \"excite\", 'BREAKING': \"break\", 'gifs': \"gif\", 'goes': \"go\", 'thoughts': \"thought\", 'campaigning': \"campaign\", 'immediately': \"immediate\", 'teammates': \"team mate\", 'knew': \"know\", 'politicians': \"politician\", 'distancing': \"distance\", 'reopening': \"reopen\", 'pls': \"please\", 'AGAIN': \"again\", 'tears': \"tear\", 'supposed': \"suppose\", 'loved': \"love\", 'ppl': \"people\", 'drinking': \"drink\", 'Guidelines': \"guide line\", 'losing': \"lose\", 'Conference': \"conference\", 'officially': \"official\", 'OPENING': \"open\", 'buying': \"buy\", 'Gif': \"gif\", 'looks': \"look\", 'bought': \"buy\", 'likes': \"like\", 'truely': \"true\", 'happened': \"happen\", 'putting': \"put\", 'families': \"family\", 'moved': \"move\", 'Raise': \"raise\", 'helped': \"help\", 'vibes': \"vibe\", 'voting': \"vote\", 'showed': \"show\", 'Instagram': \"instagram\", 'spent': \"spend\", 'watched': \"watch\", 'kinda': \"kind of\", 'Governor': \"governor\", 'Coronavirus': \"COVID\", 'lmao': \"laugh\", 'seems': \"seem\", 'staying': \"stay\", 'listening': \"listen\", 'accounts': \"account\"}\n",
    "def change_punc(text):\n",
    "    for key in more_apostrophes.keys():\n",
    "        text = text.replace(key, more_apostrophes[key])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['map_more_punc_text'] = df_train.map_punc_text.apply(change_punc)\n",
    "df_train['map_more_punc_reply'] = df_train.map_punc_reply.apply(change_punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev['map_more_punc_text'] = df_dev.map_punc_text.apply(change_punc)\n",
    "df_dev['map_more_punc_reply'] = df_dev.map_punc_reply.apply(change_punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['map_more_punc_text'] = df_test.map_punc_text.apply(change_punc)\n",
    "df_test['map_more_punc_reply'] = df_test.map_punc_reply.apply(change_punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train text unique vocab count is: 46010\n",
      "train reply unique vocab count is: 18481\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=46010.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 37.846% (17413 / 46010) of vocab\n",
      "Found embeddings for 92.670% (747104 / 806199) of all text\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=18481.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 47.443% (8768 / 18481) of vocab\n",
      "Found embeddings for 89.807% (124583 / 138723) of all text\n"
     ]
    }
   ],
   "source": [
    "train_text_vocab = get_vocab(df_train['map_more_punc_text'].values)\n",
    "train_reply_vocab = get_vocab(df_train['map_more_punc_reply'].values)\n",
    "print(\"train text unique vocab count is: {}\".format(len(train_text_vocab)))\n",
    "print(\"train reply unique vocab count is: {}\".format(len(train_reply_vocab)))\n",
    "print()\n",
    "\n",
    "unknown_text = check_coverage(train_text_vocab, roberta_vocab)\n",
    "print()\n",
    "unknown_reply = check_coverage(train_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev text unique vocab count is: 13257\n",
      "dev reply unique vocab count is: 4415\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=13257.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 59.644% (7907 / 13257) of vocab\n",
      "Found embeddings for 92.660% (94744 / 102249) of all text\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=4415.0, style=ProgressStyle(description_â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 63.284% (2794 / 4415) of vocab\n",
      "Found embeddings for 89.189% (15699 / 17602) of all text\n"
     ]
    }
   ],
   "source": [
    "dev_text_vocab = get_vocab(df_dev['map_more_punc_text'].values)\n",
    "dev_reply_vocab = get_vocab(df_dev['map_more_punc_reply'].values)\n",
    "print(\"dev text unique vocab count is: {}\".format(len(dev_text_vocab)))\n",
    "print(\"dev reply unique vocab count is: {}\".format(len(dev_reply_vocab)))\n",
    "unknown_text = check_coverage(dev_text_vocab, roberta_vocab)\n",
    "print()\n",
    "unknown_reply = check_coverage(dev_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test text unique vocab count is: 13076\n",
      "test reply unique vocab count is: 4209\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=13076.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 60.477% (7908 / 13076) of vocab\n",
      "Found embeddings for 92.838% (93088 / 100269) of all text\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=4209.0, style=ProgressStyle(description_â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 64.837% (2729 / 4209) of vocab\n",
      "Found embeddings for 89.866% (15288 / 17012) of all text\n"
     ]
    }
   ],
   "source": [
    "test_text_vocab = get_vocab(df_test['map_more_punc_text'].values)\n",
    "test_reply_vocab = get_vocab(df_test['map_more_punc_reply'].values)\n",
    "print(\"test text unique vocab count is: {}\".format(len(test_text_vocab)))\n",
    "print(\"test reply unique vocab count is: {}\".format(len(test_reply_vocab)))\n",
    "unknown_text = check_coverage(test_text_vocab, roberta_vocab)\n",
    "print()\n",
    "unknown_reply = check_coverage(test_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('COVID', 158),\n",
       " ('pandemic', 27),\n",
       " ('BailoutHumansNow', 24),\n",
       " ('dependable', 24),\n",
       " ('ğŸ˜‚', 24),\n",
       " ('ScottyFromMarketing', 23),\n",
       " ('â¤ï¸', 23),\n",
       " ('ğŸ¤”', 23),\n",
       " ('amaze', 21),\n",
       " ('\\U0001f97a', 19),\n",
       " ('ğŸ˜­', 19),\n",
       " ('seanhannity', 19),\n",
       " ('WritingCommunity', 19),\n",
       " ('ğŸ˜Š', 18),\n",
       " ('excite', 17),\n",
       " ('ğŸ˜”', 16),\n",
       " ('LIBERATE', 14),\n",
       " ('yall', 13),\n",
       " ('corona', 13),\n",
       " ('6pm', 13),\n",
       " ('ğŸ™ƒ', 13),\n",
       " ('Vaccine', 12),\n",
       " ('questionsâ€¦', 12),\n",
       " ('covid', 12),\n",
       " ('VIRGINIA', 11),\n",
       " ('DMs', 11),\n",
       " ('\\U0001f974', 11),\n",
       " ('Ventilators', 11),\n",
       " ('ğŸ˜³', 11),\n",
       " ('1st', 11),\n",
       " ('ventilators', 10),\n",
       " ('H1N1', 10),\n",
       " ('Swine', 10),\n",
       " ('Polling', 10),\n",
       " ('cuz', 10),\n",
       " ('ğŸ˜‚ğŸ˜‚ğŸ˜‚', 10),\n",
       " ('5k', 10),\n",
       " ('ğŸ‘€', 9),\n",
       " ('ğŸ˜­ğŸ˜­', 9),\n",
       " ('Idk', 9),\n",
       " ('ğŸ™„', 9),\n",
       " ('idk', 8),\n",
       " ('11am', 8),\n",
       " ('nigga', 8),\n",
       " ('7th', 8),\n",
       " ('Frequently', 8),\n",
       " ('instagram', 8),\n",
       " ('â†’', 8),\n",
       " ('ğŸ’•', 8),\n",
       " ('âœ…', 8),\n",
       " ('ğŸ¤', 8),\n",
       " ('FollowFriday', 8),\n",
       " ('OldRich', 7),\n",
       " ('Lebron', 7),\n",
       " ('Genuinely', 7),\n",
       " ('Rashford', 7),\n",
       " ('RETWEET', 7),\n",
       " ('TESTING', 7),\n",
       " ('QUARANTINE', 7),\n",
       " ('\\U0001f970', 7),\n",
       " ('ğŸ”‘', 7),\n",
       " ('niggas', 6),\n",
       " ('HUNGRY', 6),\n",
       " ('smh', 6),\n",
       " ('retweets', 6),\n",
       " ('ğŸ˜ª', 6),\n",
       " ('amwriting', 6),\n",
       " ('Neymar', 6),\n",
       " ('lowkey', 6),\n",
       " ('Cassper', 6),\n",
       " ('Bailout', 6),\n",
       " ('Shout', 6),\n",
       " ('ğŸ¤£', 6),\n",
       " ('Quarantine', 6),\n",
       " ('ventilator', 6),\n",
       " ('cuddle', 6),\n",
       " ('CoronaVirus', 6),\n",
       " ('POTUS', 6),\n",
       " ('COVIDLiar', 6),\n",
       " ('ğŸ‘ğŸ¼', 6),\n",
       " ('wtf', 5),\n",
       " ('replying', 5),\n",
       " ('Govt', 5),\n",
       " ('ğŸ˜', 5),\n",
       " ('tbh', 5),\n",
       " ('â˜ºï¸', 5),\n",
       " ('BABY', 5),\n",
       " ('Fauci', 5),\n",
       " ('winğŸ’°', 5),\n",
       " ('apeopley', 5),\n",
       " ('mutuals', 5),\n",
       " ('ğŸ™', 5),\n",
       " ('ğŸ‡ºğŸ‡¸', 5),\n",
       " ('bitches', 5),\n",
       " ('10k', 5),\n",
       " ('tiktok', 5),\n",
       " ('DrOz', 5),\n",
       " ('RAT', 5),\n",
       " ('Retweet', 5),\n",
       " ('furloughed', 5),\n",
       " ('writerslift', 5),\n",
       " ('govt', 5),\n",
       " ('LikewiseApp', 5),\n",
       " ('Yay', 5),\n",
       " ('Lockdown', 5),\n",
       " ('âœ¨', 5),\n",
       " ('juliemac1000', 5),\n",
       " ('OKAY', 5),\n",
       " ('Wuhan', 5),\n",
       " ('apeopleause', 5),\n",
       " ('ğŸ˜”ğŸ˜”', 5),\n",
       " ('WOW', 5),\n",
       " ('Couldn', 5),\n",
       " ('spamming', 4),\n",
       " ('ğŸ˜°', 4),\n",
       " ('Horny', 4),\n",
       " ('COVIDPandemic', 4),\n",
       " ('ğŸ˜‹', 4),\n",
       " ('Yup', 4),\n",
       " ('hella', 4),\n",
       " ('convo', 4),\n",
       " ('writingcommunity', 4),\n",
       " ('libs', 4),\n",
       " ('AEW', 4),\n",
       " ('HATE', 4),\n",
       " ('ğŸ˜…', 4),\n",
       " ('Ruggs', 4),\n",
       " ('Jeudy', 4),\n",
       " ('VoteSafe', 4),\n",
       " ('â†’No', 4),\n",
       " ('â†’At', 4),\n",
       " ('ğŸ¤£ğŸ¤£ğŸ¤£', 4),\n",
       " ('ğŸ’”', 4),\n",
       " ('Pls', 4),\n",
       " ('4th', 4),\n",
       " ('SpeakerPelosi', 4),\n",
       " ('Ozark', 4),\n",
       " ('PPP', 4),\n",
       " ('ğŸ’€', 4),\n",
       " ('positivity', 4),\n",
       " ('ğŸ˜ˆ', 4),\n",
       " ('streamer', 4),\n",
       " ('â˜€ï¸', 4),\n",
       " ('\\U0001f973', 4),\n",
       " ('ğŸ˜‰', 4),\n",
       " ('FCE', 4),\n",
       " ('friday', 4),\n",
       " ('BOY', 4),\n",
       " ('ğŸ˜¢', 4),\n",
       " ('ğŸ˜˜', 4),\n",
       " ('CashApp', 4),\n",
       " ('Rona', 4),\n",
       " ('supeopley', 4),\n",
       " ('StayAtHome', 4),\n",
       " ('ğŸ˜Œ', 4),\n",
       " ('OANN', 4),\n",
       " ('Welp', 4),\n",
       " ('virologist', 4),\n",
       " ('EVERYONE', 4),\n",
       " ('imma', 4),\n",
       " ('WENT', 4),\n",
       " ('BATHROOM', 4),\n",
       " ('HAD', 4),\n",
       " ('SWUM', 4),\n",
       " ('TOILET', 4),\n",
       " ('THOUGHT', 4),\n",
       " ('URBAN', 4),\n",
       " ('LEGEND', 4),\n",
       " ('MOVE', 4),\n",
       " ('covid19', 4),\n",
       " ('Apologies', 4),\n",
       " ('Lemme', 4),\n",
       " ('Fortnite', 4),\n",
       " ('whack', 4),\n",
       " ('ğŸ˜©', 4),\n",
       " ('gimme', 4),\n",
       " ('Apeoplee', 4),\n",
       " ('12k', 4),\n",
       " ('ğŸ˜’', 4),\n",
       " ('ğŸ‰', 4),\n",
       " ('SHIT', 4),\n",
       " ('ğŸ˜­ğŸ˜­ğŸ˜­', 4),\n",
       " ('ğŸ˜', 4),\n",
       " ('ğŸ’°', 4),\n",
       " ('geng', 4),\n",
       " ('carti', 3),\n",
       " ('dababy', 3),\n",
       " ('ğŸ˜“', 3),\n",
       " ('PHYSICALLY', 3),\n",
       " ('hurtful', 3),\n",
       " ('lockdowns', 3),\n",
       " ('quarantining', 3),\n",
       " ('Giveaway', 3),\n",
       " ('famu', 3),\n",
       " ('30th', 3),\n",
       " ('COMING', 3),\n",
       " ('nudes', 3),\n",
       " ('JoeBiden', 3),\n",
       " ('FOLLOWERS', 3),\n",
       " ('OUSTDUTERENOW', 3),\n",
       " ('Newsom', 3),\n",
       " ('YALL', 3),\n",
       " ('4TH', 3),\n",
       " ('Loeffler', 3),\n",
       " ('MAGAts', 3),\n",
       " ('Blonde', 3),\n",
       " ('clap', 3),\n",
       " ('streamers', 3),\n",
       " ('AWAY', 3),\n",
       " ('RaiderNation', 3),\n",
       " ('Tired', 3),\n",
       " ('tryna', 3),\n",
       " ('ğŸ˜‚ğŸ˜‚', 3),\n",
       " ('unfollow', 3),\n",
       " ('ğŸ˜', 3),\n",
       " ('Schitt', 3),\n",
       " ('satanic', 3),\n",
       " ('botoxed', 3),\n",
       " ('slimy', 3),\n",
       " ('wad', 3),\n",
       " ('hag', 3),\n",
       " ('allğŸ˜', 3),\n",
       " ('\\U0001f92a', 3),\n",
       " ('ALX', 3),\n",
       " ('rut', 3),\n",
       " ('apeopleications', 3),\n",
       " ('diy', 3),\n",
       " ('LOCALS', 3),\n",
       " ('USING', 3),\n",
       " ('gifS', 3),\n",
       " ('THEYRE', 3),\n",
       " ('CRINGE', 3),\n",
       " ('WTF', 3),\n",
       " ('FYI', 3),\n",
       " ('STILL', 3),\n",
       " ('ğŸ˜‘', 3),\n",
       " ('overrated', 3),\n",
       " ('Pulte', 3),\n",
       " ('Struggling', 3),\n",
       " ('NationalHornyDay', 3),\n",
       " ('nipeoplees', 3),\n",
       " ('GONE', 3),\n",
       " ('nuggets', 3),\n",
       " ('clapping', 3),\n",
       " ('CHINA', 3),\n",
       " ('\\U0001f92f', 3),\n",
       " ('LMAO', 3),\n",
       " ('ğŸ¤·\\u200dâ™€ï¸', 3),\n",
       " ('PSA', 3),\n",
       " ('2k', 3),\n",
       " ('Peanut', 3),\n",
       " ('ğŸ’š', 3),\n",
       " ('ğŸ’–', 3),\n",
       " ('pissy', 3),\n",
       " ('Ugh', 3),\n",
       " ('alerting', 3),\n",
       " ('talkin', 3),\n",
       " ('dey', 3),\n",
       " ('omg', 3),\n",
       " ('presser', 3),\n",
       " ('Gives', 3),\n",
       " ('Approval', 3),\n",
       " ('Sleepy', 3),\n",
       " ('Candidates', 3),\n",
       " ('SenThomTillis', 3),\n",
       " ('Titties', 3),\n",
       " ('AMEN', 3),\n",
       " ('Mauricio', 3),\n",
       " ('Pochettino', 3),\n",
       " ('Whitmer', 3),\n",
       " ('ramadan', 3),\n",
       " ('Gonna', 3),\n",
       " ('1M', 3),\n",
       " ('Zooming', 3),\n",
       " ('Shoutout', 3),\n",
       " ('Maternal', 3),\n",
       " ('enabler', 3),\n",
       " ('boycotted', 3),\n",
       " ('Husband', 3),\n",
       " ('THINK', 3),\n",
       " ('DONT', 3),\n",
       " ('whoop', 3),\n",
       " ('NIGGAS', 3),\n",
       " ('pickle', 3),\n",
       " ('Mnuchin', 3),\n",
       " ('Paycheck', 3),\n",
       " ('\\U0001f97a\\U0001f97a', 3),\n",
       " ('tweeps', 3),\n",
       " ('HAPPY', 3),\n",
       " ('Nyovest', 3),\n",
       " ('EVERYTHING', 3),\n",
       " ('YT', 3),\n",
       " ('\\U0001f92e', 3),\n",
       " ('goodnight', 3),\n",
       " ('kiddos', 3),\n",
       " ('HORSE', 3),\n",
       " ('tik', 3),\n",
       " ('tok', 3),\n",
       " ('ğŸ˜', 3),\n",
       " ('atleast', 3),\n",
       " ('amediting', 3),\n",
       " ('LETS', 3),\n",
       " ('ğŸ’€ğŸ’€ğŸ’€', 3),\n",
       " ('maddow', 3),\n",
       " ('2m', 3),\n",
       " ('StayHomeSaveLives', 3),\n",
       " ('HISTORY', 3),\n",
       " ('Shouldn', 3),\n",
       " ('100k', 3),\n",
       " ('Fucking', 3),\n",
       " ('meds', 3),\n",
       " ('LDSB', 3),\n",
       " ('NationalHighFiveDay', 3),\n",
       " ('ğŸš¨', 3),\n",
       " ('Staying', 3),\n",
       " ('FORCE', 3),\n",
       " ('30pm', 3),\n",
       " ('â­', 3),\n",
       " ('SMILE', 3),\n",
       " ('uzi', 2),\n",
       " ('overreacting', 2),\n",
       " ('obsessing', 2),\n",
       " ('â˜¹ï¸', 2),\n",
       " ('ğŸ’›', 2),\n",
       " ('wna', 2),\n",
       " ('hypocrites', 2),\n",
       " ('bombarded', 2),\n",
       " ('sapped', 2),\n",
       " ('ğŸ™Œ', 2),\n",
       " ('Halladay', 2),\n",
       " ('LoyalGiveaways', 2),\n",
       " ('ğŸ™‹\\u200dâ™‚ï¸ğŸ™‹\\u200dâ™‚ï¸ğŸ™‹\\u200dâ™‚ï¸', 2),\n",
       " ('Flutter', 2),\n",
       " ('Stimulus', 2),\n",
       " ('pineapeoplee', 2),\n",
       " ('MONDAY', 2),\n",
       " ('ğŸ‘»ğŸ‘»ğŸ‘»', 2),\n",
       " ('emojis', 2),\n",
       " ('INDIA', 2),\n",
       " ('nope', 2),\n",
       " ('Shehnaaz', 2),\n",
       " ('jm', 2),\n",
       " ('65th', 2),\n",
       " ('unwell', 2),\n",
       " ('stageit', 2),\n",
       " ('impeached', 2),\n",
       " ('ğŸ˜•', 2),\n",
       " ('decorating', 2),\n",
       " ('NOVEMBER', 2),\n",
       " ('McSally', 2),\n",
       " ('Tillis', 2),\n",
       " ('Myself', 2),\n",
       " ('Krispies', 2),\n",
       " ('assholes', 2),\n",
       " ('loosing', 2),\n",
       " ('â™¥ï¸', 2),\n",
       " ('giantschat', 2),\n",
       " ('DJT', 2),\n",
       " ('respirators', 2),\n",
       " ('harried', 2),\n",
       " ('Heading', 2),\n",
       " ('catchup', 2),\n",
       " ('ğŸ™‚', 2),\n",
       " ('ğŸ“ˆğŸ“ˆğŸ“ˆ', 2),\n",
       " ('ANYONE', 2),\n",
       " ('Misbah', 2),\n",
       " ('haunts', 2),\n",
       " ('giver', 2),\n",
       " ('Adopt', 2),\n",
       " ('ğŸ‘‡', 2),\n",
       " ('skan', 2),\n",
       " ('imreadyimreadyimready', 2),\n",
       " ('notpanic', 2),\n",
       " ('imposter', 2),\n",
       " ('ANYBODY', 2),\n",
       " ('physed', 2),\n",
       " ('wednesday', 2),\n",
       " ('mama', 2),\n",
       " ('wholesome', 2),\n",
       " ('WriterLift', 2),\n",
       " ('mandylawson7', 2),\n",
       " ('LilyBOW2', 2),\n",
       " ('DnD', 2),\n",
       " ('distanced', 2),\n",
       " ('Adderall', 2),\n",
       " ('GIVE', 2),\n",
       " ('GUYS', 2),\n",
       " ('tipsy', 2),\n",
       " ('oatmeal', 2),\n",
       " ('joe', 2),\n",
       " ('Wtf', 2),\n",
       " ('stroller', 2),\n",
       " ('cranky', 2),\n",
       " ('grandad', 2),\n",
       " ('carer', 2),\n",
       " ('selfisolating', 2),\n",
       " ('Whos', 2),\n",
       " ('LOSE', 2),\n",
       " ('SenSchumer', 2),\n",
       " ('hoes', 2),\n",
       " ('realdonaldTrump', 2),\n",
       " ('KUWTK', 2),\n",
       " ('WORKING', 2),\n",
       " ('impactful', 2),\n",
       " ('â¤ï¸â¤ï¸â¤ï¸â¤ï¸', 2),\n",
       " ('FAVORITE', 2),\n",
       " ('FRIDAY', 2),\n",
       " ('FUNNY', 2),\n",
       " ('comatose', 2),\n",
       " ('outta', 2),\n",
       " ('BTS', 2),\n",
       " ('Interchange', 2),\n",
       " ('HARD', 2),\n",
       " ('ğŸ‡ºğŸ‡¸â¤ï¸ğŸ™ğŸ‘', 2),\n",
       " ('tradeoff', 2),\n",
       " ('Bitches', 2),\n",
       " ('LockdownHouseParty', 2),\n",
       " ('shahs', 2),\n",
       " ('lemme', 2),\n",
       " ('16th', 2),\n",
       " ('\\U0001f9d0', 2),\n",
       " ('disgustingly', 2),\n",
       " ('fucks', 2),\n",
       " ('TogetherAtHome', 2),\n",
       " ('repos', 2),\n",
       " ('dawg', 2),\n",
       " ('Ima', 2),\n",
       " ('e9', 2),\n",
       " ('brandy', 2),\n",
       " ('NUFC', 2),\n",
       " ('faouzia', 2),\n",
       " ('faouxia', 2),\n",
       " ('ğŸ™ˆ', 2),\n",
       " ('Octopus', 2),\n",
       " ('ğŸ¤—', 2),\n",
       " ('Bettman', 2),\n",
       " ('BarackObama', 2),\n",
       " ('onlyfan', 2),\n",
       " ('DBCarterAuthor', 2),\n",
       " ('BellaRayne10', 2),\n",
       " ('FaerieRealms', 2),\n",
       " ('cutest', 2),\n",
       " ('illiterates', 2),\n",
       " ('TooHotToHandle', 2),\n",
       " ('opals', 2),\n",
       " ('bums', 2),\n",
       " ('FOLLOW', 2),\n",
       " ('RID', 2),\n",
       " ('BALLOT', 2),\n",
       " ('HARVESTING', 2),\n",
       " ('RAMPANT', 2),\n",
       " ('FRAUD', 2),\n",
       " ('VOTER', 2),\n",
       " ('HONEST', 2),\n",
       " ('COUNT', 2),\n",
       " ('humbled', 2),\n",
       " ('ğŸ¤¦ğŸ»\\u200dâ™€ï¸', 2),\n",
       " ('influencers', 2),\n",
       " ('fuckery', 2),\n",
       " ('LockdownHousePartyğŸ”¥', 2),\n",
       " ('ALMOST', 2),\n",
       " ('refollow', 2),\n",
       " ('shouldnt', 2),\n",
       " ('webkinz', 2),\n",
       " ('8th', 2),\n",
       " ('ğŸ˜¬ğŸ˜¬ğŸ˜¬im', 2),\n",
       " ('ğŸ˜¬ğŸ˜¬ğŸ˜¬If', 2),\n",
       " ('dresser', 2),\n",
       " ('fckn', 2),\n",
       " ('stinks', 2),\n",
       " ('jt', 2),\n",
       " ('bday', 2),\n",
       " ('ğŸ˜±', 2),\n",
       " ('Poets', 2),\n",
       " ('Bloggers', 2),\n",
       " ('MULK', 2),\n",
       " ('cornbread', 2),\n",
       " ('Hakeem', 2),\n",
       " ('bottlenecks', 2),\n",
       " ('MARINES', 2),\n",
       " ('sunday', 2),\n",
       " ('paypal', 2),\n",
       " ('OSU', 2),\n",
       " ('sims', 2),\n",
       " ('Wetin', 2),\n",
       " ('BailoutHumans', 2),\n",
       " ('Trending', 2),\n",
       " ('BAIL', 2),\n",
       " ('HUMANS', 2),\n",
       " ('hyenas', 2),\n",
       " ('euphoric', 2),\n",
       " ('Describe', 2),\n",
       " ('prosecco', 2),\n",
       " ('FACT', 2),\n",
       " ('INFORM', 2),\n",
       " ('Accidentally', 2),\n",
       " ('HOPE', 2),\n",
       " ('thfc', 2),\n",
       " ('e12', 2),\n",
       " ('5M', 2),\n",
       " ('severance', 2),\n",
       " ('TelegraphSport', 2),\n",
       " ('â€¼ï¸', 2),\n",
       " ('\\U0001f928', 2),\n",
       " ('daisy', 2),\n",
       " ('dukes', 2),\n",
       " ('Xanax', 2),\n",
       " ('slink', 2),\n",
       " ('sappy', 2),\n",
       " ('Luh', 2),\n",
       " ('muslim', 2),\n",
       " ('OnlyFans', 2),\n",
       " ('â¤ï¸ğŸ˜˜', 2),\n",
       " ('ğŸ˜«', 2),\n",
       " ('MOST', 2),\n",
       " ('Ingraham', 2),\n",
       " ('KEEP', 2),\n",
       " ('jus', 2),\n",
       " ('alboy88', 2),\n",
       " ('followfriday', 2),\n",
       " ('hospitalizes', 2),\n",
       " ('hospitalizations', 2),\n",
       " ('doin', 2),\n",
       " ('Newz', 2),\n",
       " ('quarantined', 2),\n",
       " ('musicals', 2),\n",
       " ('gangsta', 2),\n",
       " ('belove', 2),\n",
       " ('ğŸ’ªğŸ¼', 2),\n",
       " ('moots', 2),\n",
       " ('whoops', 2),\n",
       " ('â¤ï¸â¤ï¸â¤ï¸', 2),\n",
       " ('WANNA', 2),\n",
       " ('TAKE', 2),\n",
       " ('APPRECIATE', 2),\n",
       " ('necking', 2),\n",
       " ('donuts', 2),\n",
       " ('Hydroxychloroquine', 2),\n",
       " ('bruh', 2),\n",
       " ('YAYYYY', 2),\n",
       " ('\\U0001f92b', 2),\n",
       " ('johnpodesta', 2),\n",
       " ('hoodie', 2),\n",
       " ('Gorsky', 2),\n",
       " ('supeopleies', 2),\n",
       " ('TheHiveVR', 2),\n",
       " ('Navahk', 2),\n",
       " ('museumpaige', 2),\n",
       " ('AltspaceVR', 2),\n",
       " ('TheKillettosVR', 2),\n",
       " ('Onward', 2),\n",
       " ('VRML', 2),\n",
       " ('Spoken', 2),\n",
       " ('pornstar', 2),\n",
       " ('Nasty', 2),\n",
       " ('ğŸ˜ ', 2),\n",
       " ('Cryin', 2),\n",
       " ('ENDLESS', 2),\n",
       " ('VACATION', 2),\n",
       " ('prepping', 2),\n",
       " ('869', 2),\n",
       " ('peeling', 2),\n",
       " ('psychopaths', 2),\n",
       " ('gong', 2),\n",
       " ('TikTok', 2),\n",
       " ('kum', 2),\n",
       " ('Zlatan', 2),\n",
       " ('papa', 2),\n",
       " ('MORNING', 2),\n",
       " ('Boneless', 2),\n",
       " ('Goodnight', 2),\n",
       " ('VN', 2),\n",
       " ('ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½ğŸ‘ğŸ½',\n",
       "  2),\n",
       " ('Deluded', 2),\n",
       " ('mhm', 2),\n",
       " ('ğŸ˜¯', 2),\n",
       " ('djs', 2),\n",
       " ('26th', 2),\n",
       " ('HOLY', 2),\n",
       " ('FINALLY', 2),\n",
       " ('ğŸ˜­ğŸ¤£', 2),\n",
       " ('ğŸ™ŒğŸ»', 2),\n",
       " ('madison', 2),\n",
       " ('fuckers', 2),\n",
       " ('Replaced', 2),\n",
       " ('walkaway', 2),\n",
       " ('MAGAt', 2),\n",
       " ('McKinney', 2),\n",
       " ('â¬‡ï¸â¬‡ï¸', 2),\n",
       " ('Kroenke', 2),\n",
       " ('SamiMokbel81', 2),\n",
       " ('hows', 2),\n",
       " ('DOESN', 2),\n",
       " ('ArianaGrande', 2),\n",
       " ('squirters', 2),\n",
       " ('airwaves', 2),\n",
       " ('loosening', 2),\n",
       " ('mullet', 2),\n",
       " ('Reopening', 2),\n",
       " ('ğŸ‡ºğŸ‡¸ğŸ‡ºğŸ‡¸ğŸ‡ºğŸ‡¸', 2),\n",
       " ('Refilling', 2),\n",
       " ('Rydiee', 2),\n",
       " ('sneaker', 2),\n",
       " ('tobe', 2),\n",
       " ('bobandtom', 2),\n",
       " ('Cute', 2),\n",
       " ('ğŸ˜ƒ', 2),\n",
       " ('ADOS', 2),\n",
       " ('youre', 2),\n",
       " ('Morehouse', 2),\n",
       " ('Fingers', 2),\n",
       " ('celery', 2),\n",
       " ('spoons', 2),\n",
       " ('Jojo', 2),\n",
       " ('thx', 2),\n",
       " ('writerslife', 2),\n",
       " ('toyota', 2),\n",
       " ('hoil', 2),\n",
       " ('ğŸ¤§', 2),\n",
       " ('ophthalmologist', 2),\n",
       " ('NationalHighFiveDayâ€¦', 2),\n",
       " ('slippin', 2),\n",
       " ('gratefully', 2),\n",
       " ('april', 2),\n",
       " ('weirder', 2),\n",
       " ('showered', 2),\n",
       " ('coochie', 2),\n",
       " ('faves', 2),\n",
       " ('TrumpVirus', 2),\n",
       " ('Outlander', 2),\n",
       " ('ğŸ’œ', 2),\n",
       " ('pampered', 2),\n",
       " ('brat', 2),\n",
       " ('unmask', 2),\n",
       " ('Millville', 2),\n",
       " ('6k', 2),\n",
       " ('ğŸ’¥Under', 2),\n",
       " ('ğŸ’¥Over', 2),\n",
       " ('writerscommunity', 2),\n",
       " ('ğŸ˜¡', 2),\n",
       " ('Dennehy', 2),\n",
       " ('Gasol', 2),\n",
       " ('WellI', 2),\n",
       " ('homestead', 2),\n",
       " ('yalls', 2),\n",
       " ('CryptoGainz1', 2),\n",
       " ('Tbh', 2),\n",
       " ('POINT', 2),\n",
       " ('lookin', 2),\n",
       " ('asap', 2),\n",
       " ('ğŸ˜³ğŸ˜³ğŸ˜³', 2),\n",
       " ('motherfuckers', 2),\n",
       " ('Emtee', 2),\n",
       " ('haters', 2),\n",
       " ('\\U0001f97aâ¤ï¸', 2),\n",
       " ('cancelling', 2),\n",
       " ('Gretchen', 2),\n",
       " ('smoothie', 2),\n",
       " ('cosplay', 2),\n",
       " ('Romanians', 2),\n",
       " ('8pm', 2),\n",
       " ('ğŸ˜·', 2),\n",
       " ('moans', 2),\n",
       " ('soo', 2),\n",
       " ('werewolf', 2),\n",
       " ('ğŸŒ™', 2),\n",
       " ('Sigh', 2),\n",
       " ('ASK', 2),\n",
       " ('intubated', 2),\n",
       " ('Bruh', 2),\n",
       " ('ğŸ’¯', 2),\n",
       " ('decimated', 2),\n",
       " ('coven', 2),\n",
       " ('sheltering', 2),\n",
       " ('fellas', 2),\n",
       " ('Gotta', 2),\n",
       " ('Onlyfan', 2),\n",
       " ('skittles', 2),\n",
       " ('Tempting', 2),\n",
       " ('SPY', 2),\n",
       " ('ğŸ˜„', 2),\n",
       " ('tolerable', 2),\n",
       " ('overlords', 2),\n",
       " ('portly', 2),\n",
       " ('raccoons', 2),\n",
       " ('masturbating', 2),\n",
       " ('Told', 2),\n",
       " ('ğŸ¤¢', 2),\n",
       " ('MAGA', 2),\n",
       " ('Nsfas', 2),\n",
       " ('R3000', 2),\n",
       " ('ğŸ¤ğŸ½', 2),\n",
       " ('BoycottOnlineLearningUJ', 2),\n",
       " ('DAMN', 2),\n",
       " ('snobs', 2),\n",
       " ('Amwriting', 2),\n",
       " ('pero', 2),\n",
       " ('QuarantineLife', 2),\n",
       " ('sanitizer', 2),\n",
       " ('ğŸ‘‰ğŸ‘ˆ', 2),\n",
       " ('yadda', 2),\n",
       " ('Dominguez', 2),\n",
       " ('BUYING', 2),\n",
       " ('NUDES', 2),\n",
       " ('MIRROR', 2),\n",
       " ('PUSSY', 2),\n",
       " ('mf', 2),\n",
       " ('Afghanis', 2),\n",
       " ('dO', 2),\n",
       " ('FF7', 2),\n",
       " ('STAY', 2),\n",
       " ('SB19', 2),\n",
       " ('âœ‹', 2),\n",
       " ('Woke', 2),\n",
       " ('tarts', 2),\n",
       " ('Basu', 2),\n",
       " ('Yechury', 2),\n",
       " ('cavefish', 2),\n",
       " ('FridayMotivation', 2),\n",
       " ('VSAT', 2),\n",
       " ('Unplugged', 2),\n",
       " ('FamiliesFirst', 2),\n",
       " ('whew', 2),\n",
       " ('uncontrollably', 2),\n",
       " ('eyeroll', 2),\n",
       " ('booty', 2),\n",
       " ('VPG', 2),\n",
       " ('x1', 2),\n",
       " ('ğŸ”¥', 2),\n",
       " ('banger', 2),\n",
       " ('WhatsMiner', 2),\n",
       " ('Whatsminer', 2),\n",
       " ('MBT', 2),\n",
       " ('CryptoFinally', 2),\n",
       " ('\\U0001fa90âœ¨', 2),\n",
       " ('Solidarity', 2),\n",
       " ('darkskin', 2),\n",
       " ('elizabeth', 2),\n",
       " ('warren', 2),\n",
       " ('rachel', 2),\n",
       " ('distasteful', 2),\n",
       " ('biden', 2),\n",
       " ('runningmate', 2),\n",
       " ('Stacey', 2),\n",
       " ('shortlist', 2),\n",
       " ('rlly', 2),\n",
       " ('ğŸ˜©ğŸ˜©', 2),\n",
       " ('Maxie', 2),\n",
       " ('Paxie', 2),\n",
       " ('idc', 2),\n",
       " ('winded', 2),\n",
       " ('BEEN', 2),\n",
       " ('ICYMI', 2),\n",
       " ('MLCC', 2),\n",
       " ('AllInThisTogether', 2),\n",
       " ('everytime', 2),\n",
       " ('MADE', 2),\n",
       " ('omelette', 2),\n",
       " ('isnt', 2),\n",
       " ('ğŸ›', 2),\n",
       " ('FridayThoughts', 2),\n",
       " ('pubic', 2),\n",
       " ('ğŸ˜µ', 2),\n",
       " ('YO', 2),\n",
       " ('wank', 2),\n",
       " ('laughooo', 2),\n",
       " ('ğŸ’ğŸ˜', 2),\n",
       " ('ğŸ™ğŸ˜˜ğŸ˜Š', 2),\n",
       " ('hyped', 2),\n",
       " ('100K', 2),\n",
       " ('WWESuperCard', 2),\n",
       " ('Propaganda', 2),\n",
       " ('Feenix', 2),\n",
       " ('OWL', 2),\n",
       " ('disneysingalong', 2),\n",
       " ('momos', 2),\n",
       " ('Taurus', 2),\n",
       " ('NFG', 2),\n",
       " ('Wearing', 2),\n",
       " ('facetime', 2),\n",
       " ('ğŸ¤·\\u200dâ™‚ï¸', 2),\n",
       " ('reminiscing', 2),\n",
       " ('ğŸ’', 2),\n",
       " ('Youngdeji', 1),\n",
       " ('woah', 1),\n",
       " ('Denny', 1),\n",
       " ('Zaira', 1),\n",
       " ('Wasim', 1),\n",
       " ('hardwork', 1),\n",
       " ('madisonbeer', 1),\n",
       " ('LupeLoops', 1),\n",
       " ('disappointments', 1),\n",
       " ('disassociating', 1),\n",
       " ('myrtle', 1),\n",
       " ('spiraling', 1),\n",
       " ('STRATEGICALLY', 1),\n",
       " ('DYNAMICALLY', 1),\n",
       " ('grudges', 1),\n",
       " ('hyperventilate', 1),\n",
       " ('guaging', 1),\n",
       " ('fucj', 1),\n",
       " ('bcs', 1),\n",
       " ('natin', 1),\n",
       " ('WHYRUep12', 1),\n",
       " ('simpsons', 1),\n",
       " ('Hollyweird', 1),\n",
       " ('pedophile', 1),\n",
       " ('grandiloquent', 1),\n",
       " ('jumpin', 1),\n",
       " ('petulance', 1),\n",
       " ('gridlock', 1),\n",
       " ('vendettas', 1),\n",
       " ('Motel', 1),\n",
       " ('ğŸ¤·ğŸ»\\u200dâ™€ï¸ğŸ¤·ğŸ»\\u200dâ™€ï¸', 1),\n",
       " ('skateboard', 1),\n",
       " ('amphetamines', 1),\n",
       " ('somn', 1),\n",
       " ('NEEDğŸŒ¹SOLO', 1),\n",
       " ('ğŸŒ¹SANAğŸŒ¹PROJECTSğŸŒ¹', 1),\n",
       " ('SVTrainToBusan', 1),\n",
       " ('conflated', 1),\n",
       " ('DxvilishAngxl', 1),\n",
       " ('Veniece', 1),\n",
       " ('punks', 1),\n",
       " ('smuggle', 1),\n",
       " ('THOSE', 1),\n",
       " ('ShelleyMcElyea1', 1),\n",
       " ('â¤ï¸ğŸ’‹ğŸğŸ‰ğŸ°ğŸˆ', 1),\n",
       " ('24hours', 1),\n",
       " ('ğŸ”¥ğŸš€', 1),\n",
       " ('\\U0001f91fğŸ¼', 1),\n",
       " ('unconvincing', 1),\n",
       " ('consoler', 1),\n",
       " ('Hugger', 1),\n",
       " ('AAWAZ', 1),\n",
       " ('Eke', 1),\n",
       " ('Uti', 1),\n",
       " ('hardworking', 1),\n",
       " ('BobRisky', 1),\n",
       " ('Enkayy', 1),\n",
       " ('Mercenaries', 1),\n",
       " ('ZenMagazine', 1),\n",
       " ('liberianboii', 1),\n",
       " ('Twenties', 1),\n",
       " ('Shet', 1),\n",
       " ('ğŸ˜®ğŸ˜…', 1),\n",
       " ('celebratory', 1),\n",
       " ('disrespects', 1),\n",
       " ('sinning', 1),\n",
       " ('Seala', 1),\n",
       " ('FilmGob', 1),\n",
       " ('jodyscorner1', 1),\n",
       " ('filmgob', 1),\n",
       " ('jody', 1),\n",
       " ('overthinking', 1),\n",
       " ('13k', 1),\n",
       " ('MoHFW', 1),\n",
       " ('drharshvardhan', 1),\n",
       " ('PMOIndia', 1),\n",
       " ('decelerate', 1),\n",
       " ('dreading', 1),\n",
       " ('secs', 1),\n",
       " ('kellyinvegas', 1),\n",
       " ('vegasmurray', 1),\n",
       " ('Toppin', 1),\n",
       " ('ğŸ˜­â¤ï¸', 1),\n",
       " ('housekeeping', 1),\n",
       " ('decorate', 1),\n",
       " ('HOURRRSSSS', 1),\n",
       " ('shmsaaldh', 1),\n",
       " ('sweatshirt', 1),\n",
       " ('hammock', 1),\n",
       " ('ShehnaazGill', 1),\n",
       " ('ishehnaaz', 1),\n",
       " ('gill', 1),\n",
       " ('KaushalJoshi15', 1),\n",
       " ('goin', 1),\n",
       " ('Thorpe', 1),\n",
       " ('Alton', 1),\n",
       " ('TWITCH', 1),\n",
       " ('\\U0001f973\\U0001f929', 1),\n",
       " ('donos', 1),\n",
       " ('ğŸ’—', 1),\n",
       " ('ğŸ‘‹ğŸ»', 1),\n",
       " ('hunch', 1),\n",
       " ('Badger', 1),\n",
       " ('FSQ', 1),\n",
       " ('Retire', 1),\n",
       " ('GGs', 1),\n",
       " ('CetraLol', 1),\n",
       " ('mAAd', 1),\n",
       " ('PRL', 1),\n",
       " ('9PM', 1),\n",
       " ('Defiance', 1),\n",
       " ('condescending', 1),\n",
       " ('SchittsCreek', 1),\n",
       " ('AUDACITY', 1),\n",
       " ('9am', 1),\n",
       " ('fantasized', 1),\n",
       " ('smothering', 1),\n",
       " ('Verkis', 1),\n",
       " ('assğŸ˜©', 1),\n",
       " ('foggy', 1),\n",
       " ('aboogie', 1),\n",
       " ('OUSTDUTERTENOW', 1),\n",
       " ('philippines', 1),\n",
       " ('COLIATHGAMING', 1),\n",
       " ('vicdgordon', 1),\n",
       " ('StreamGamma', 1),\n",
       " ('kedabosch', 1),\n",
       " ('Day1neGaming', 1),\n",
       " ('JxckWSW', 1),\n",
       " ('Ncshredder', 1),\n",
       " ('Stardrix1', 1),\n",
       " ('GSO', 1),\n",
       " ('TSillysweat', 1),\n",
       " ('ChloeDonald', 1),\n",
       " ('xLexry', 1),\n",
       " ('MultynWolf', 1),\n",
       " ('SaycredAngel', 1),\n",
       " ('fuscyoface', 1),\n",
       " ('Storkyyy1', 1),\n",
       " ('Kamo', 1),\n",
       " ('Mphela', 1),\n",
       " ('intensions', 1),\n",
       " ('Steyer', 1),\n",
       " ('injustices', 1),\n",
       " ('ğŸ’¨ğŸ’¨', 1),\n",
       " ('READY', 1),\n",
       " ('CAUCASIANS', 1),\n",
       " ('CANCEL', 1),\n",
       " ('JULY', 1),\n",
       " ('meteoric', 1),\n",
       " ('StayHomeStaySafeSaveLives', 1),\n",
       " ('smallvictory', 1),\n",
       " ('AnimalCrossing', 1),\n",
       " ('dreamt', 1),\n",
       " ('Uddhav', 1),\n",
       " ('soproudofmyself', 1),\n",
       " ('Niggas', 1),\n",
       " ('hooping', 1),\n",
       " ('9Girl', 1),\n",
       " ('Cocoa', 1),\n",
       " ('repaint', 1),\n",
       " ('helluva', 1),\n",
       " ('Moir', 1),\n",
       " ('nowâœŒğŸ»', 1),\n",
       " ('Sidharth', 1),\n",
       " ('belive', 1),\n",
       " ('Jens', 1),\n",
       " ('TWELVE', 1),\n",
       " ('Gratitude', 1),\n",
       " ('theowaldspecht', 1),\n",
       " ('Nichtpartei', 1),\n",
       " ('MoSchaefer66', 1),\n",
       " ('ErdtrabantMaria', 1),\n",
       " ('humanbeinx', 1),\n",
       " ('idgaf', 1),\n",
       " ('636', 1),\n",
       " ('Emoji', 1),\n",
       " ('ğŸ˜ğŸ˜', 1),\n",
       " ('JazzrazDFS', 1),\n",
       " ('Clips', 1),\n",
       " ('realy', 1),\n",
       " ('dryer', 1),\n",
       " ('googled', 1),\n",
       " ('menopause', 1),\n",
       " ('Okudah', 1),\n",
       " ('ğŸ‘‡ğŸ‘‡ğŸ‘‡', 1),\n",
       " ('darkies', 1),\n",
       " ('koppaberg', 1),\n",
       " ('screwing', 1),\n",
       " ('Bronte', 1),\n",
       " ('BITCHES', 1),\n",
       " ('HEAVY', 1),\n",
       " ('HONEYMOON', 1),\n",
       " ('WEDDING', 1),\n",
       " ('amuck', 1),\n",
       " ('Hindutva', 1),\n",
       " ('cupboard', 1),\n",
       " ('Oddly', 1),\n",
       " ('Bourdain', 1),\n",
       " ('tht', 1),\n",
       " ('y2k', 1),\n",
       " ('UGLY', 1),\n",
       " ('TACKY', 1),\n",
       " ('HIDEOUS', 1),\n",
       " ('relive', 1),\n",
       " ('exhilarating', 1),\n",
       " ('9AM', 1),\n",
       " ('sorta', 1),\n",
       " ('blossom', 1),\n",
       " ('PieceOfArke', 1),\n",
       " ('coz', 1),\n",
       " ('ğŸ’•ğŸ’•', 1),\n",
       " ('ABPNews', 1),\n",
       " ('bwant', 1),\n",
       " ('moisturize', 1),\n",
       " ('ğŸ™‹ğŸ¿\\u200dâ™€ï¸', 1),\n",
       " ('DontSkipYourSkincareRoutine', 1),\n",
       " ...]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(unknown_text.items(), key=lambda d: d[1], reverse=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store preprocessed results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "      <th>reply</th>\n",
       "      <th>categories</th>\n",
       "      <th>mp4</th>\n",
       "      <th>map_punc_text</th>\n",
       "      <th>map_punc_reply</th>\n",
       "      <th>map_more_punc_text</th>\n",
       "      <th>map_more_punc_reply</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>we can all agree that any song by Niall Horan.</td>\n",
       "      <td>oui oui</td>\n",
       "      <td>[yes]</td>\n",
       "      <td>6dc39e96b11275f064fdaed88273b45e.mp4</td>\n",
       "      <td>we can all agree that any song by Niall Horan .</td>\n",
       "      <td>oui oui</td>\n",
       "      <td>we can all agree that any song by Niall Horan .</td>\n",
       "      <td>oui oui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Will you be installing #ScottyFromMarketing's ...</td>\n",
       "      <td></td>\n",
       "      <td>[no]</td>\n",
       "      <td>cfff051f05d8d3b7136c7d58ea6ad55f.mp4</td>\n",
       "      <td>Will you be installing  # ScottyFromMarketing ...</td>\n",
       "      <td></td>\n",
       "      <td>Will you be install  # ScottyFromMarketing  ' ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Growing up my mum would call me a Nigga despit...</td>\n",
       "      <td>And he joins in??? Pour some hot grits on em</td>\n",
       "      <td>[smh]</td>\n",
       "      <td>bf39e7bd9ad24354ce3ba6822b0104af.mp4</td>\n",
       "      <td>Growing up my mum would call me a Nigga despit...</td>\n",
       "      <td>And he joins in ?  ?  ?  Pour some hot grits o...</td>\n",
       "      <td>Growing up my mum would call me a Nigga despit...</td>\n",
       "      <td>And he joins in ?  ?  ?  Pour some hot grits o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Rest your head on my chest when the world feel...</td>\n",
       "      <td>ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚</td>\n",
       "      <td>[wink]</td>\n",
       "      <td>173a707a04c277354a2f23cf01d6151e.mp4</td>\n",
       "      <td>Rest your head on my chest when the world feel...</td>\n",
       "      <td>ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚</td>\n",
       "      <td>Rest your head on my chest when the world feel...</td>\n",
       "      <td>ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Imagine Will Hernandez and Wills both doing a ...</td>\n",
       "      <td></td>\n",
       "      <td>[yes]</td>\n",
       "      <td>aab6d6bfb0c1382269ddba9b71cc8b7a.mp4</td>\n",
       "      <td>Imagine Will Hernandez and Wills both doing a ...</td>\n",
       "      <td></td>\n",
       "      <td>Imagine Will Hernandez and Wills both doing a ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx                                               text  \\\n",
       "0    0     we can all agree that any song by Niall Horan.   \n",
       "1    1  Will you be installing #ScottyFromMarketing's ...   \n",
       "2    2  Growing up my mum would call me a Nigga despit...   \n",
       "3    3  Rest your head on my chest when the world feel...   \n",
       "4    4  Imagine Will Hernandez and Wills both doing a ...   \n",
       "\n",
       "                                          reply categories  \\\n",
       "0                                       oui oui      [yes]   \n",
       "1                                                     [no]   \n",
       "2  And he joins in??? Pour some hot grits on em      [smh]   \n",
       "3                                         ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚     [wink]   \n",
       "4                                                    [yes]   \n",
       "\n",
       "                                    mp4  \\\n",
       "0  6dc39e96b11275f064fdaed88273b45e.mp4   \n",
       "1  cfff051f05d8d3b7136c7d58ea6ad55f.mp4   \n",
       "2  bf39e7bd9ad24354ce3ba6822b0104af.mp4   \n",
       "3  173a707a04c277354a2f23cf01d6151e.mp4   \n",
       "4  aab6d6bfb0c1382269ddba9b71cc8b7a.mp4   \n",
       "\n",
       "                                       map_punc_text  \\\n",
       "0   we can all agree that any song by Niall Horan .    \n",
       "1  Will you be installing  # ScottyFromMarketing ...   \n",
       "2  Growing up my mum would call me a Nigga despit...   \n",
       "3  Rest your head on my chest when the world feel...   \n",
       "4  Imagine Will Hernandez and Wills both doing a ...   \n",
       "\n",
       "                                      map_punc_reply  \\\n",
       "0                                            oui oui   \n",
       "1                                                      \n",
       "2  And he joins in ?  ?  ?  Pour some hot grits o...   \n",
       "3                                              ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚   \n",
       "4                                                      \n",
       "\n",
       "                                  map_more_punc_text  \\\n",
       "0   we can all agree that any song by Niall Horan .    \n",
       "1  Will you be install  # ScottyFromMarketing  ' ...   \n",
       "2  Growing up my mum would call me a Nigga despit...   \n",
       "3  Rest your head on my chest when the world feel...   \n",
       "4  Imagine Will Hernandez and Wills both doing a ...   \n",
       "\n",
       "                                 map_more_punc_reply  \n",
       "0                                            oui oui  \n",
       "1                                                     \n",
       "2  And he joins in ?  ?  ?  Pour some hot grits o...  \n",
       "3                                              ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚  \n",
       "4                                                     "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "      <th>reply</th>\n",
       "      <th>map_punc_text</th>\n",
       "      <th>map_punc_reply</th>\n",
       "      <th>map_more_punc_text</th>\n",
       "      <th>map_more_punc_reply</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32000</td>\n",
       "      <td>Drop your cash app, use hashtag #BailoutHumansNow</td>\n",
       "      <td>$tyratomaro #BailoutHumans</td>\n",
       "      <td>Drop your cash app ,  use hashtag  # BailoutHu...</td>\n",
       "      <td>$ tyratomaro  # BailoutHumans</td>\n",
       "      <td>Drop your cash app ,  use hashtag  # BailoutHu...</td>\n",
       "      <td>$ tyratomaro  # BailoutHumans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32001</td>\n",
       "      <td>After interviewing with a few incredible peopl...</td>\n",
       "      <td>CONGRATS!!!!!</td>\n",
       "      <td>After interviewing with a few incredible peopl...</td>\n",
       "      <td>CONGRATS !  !  !  !  !</td>\n",
       "      <td>After interviewing with a few incredible peopl...</td>\n",
       "      <td>CONGRATS !  !  !  !  !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32002</td>\n",
       "      <td>I know GTC festival not happening next month b...</td>\n",
       "      <td></td>\n",
       "      <td>I know GTC festival not happening next month b...</td>\n",
       "      <td></td>\n",
       "      <td>I know GTC festival not happening next month b...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32003</td>\n",
       "      <td>Lordy, my daughter just said, â€œI wonder how th...</td>\n",
       "      <td></td>\n",
       "      <td>Lordy ,  my daughter just said ,    \"  I wonde...</td>\n",
       "      <td></td>\n",
       "      <td>Lordy ,  my daughter just said ,    \"  I wonde...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32004</td>\n",
       "      <td>THE UNEMPLOYMENT CLAIM SYSTEM SUCKS SO MUCH DICK</td>\n",
       "      <td>Watching everyone else get their weekly unempl...</td>\n",
       "      <td>THE UNEMPLOYMENT CLAIM SYSTEM SUCKS SO MUCH DICK</td>\n",
       "      <td>Watching everyone else get their weekly unempl...</td>\n",
       "      <td>THE UNEMPLOYMENT CLAIM SYSTEM SUCKS SO MUCH DICK</td>\n",
       "      <td>Watching everyone else get their weekly unempl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     idx                                               text  \\\n",
       "0  32000  Drop your cash app, use hashtag #BailoutHumansNow   \n",
       "1  32001  After interviewing with a few incredible peopl...   \n",
       "2  32002  I know GTC festival not happening next month b...   \n",
       "3  32003  Lordy, my daughter just said, â€œI wonder how th...   \n",
       "4  32004   THE UNEMPLOYMENT CLAIM SYSTEM SUCKS SO MUCH DICK   \n",
       "\n",
       "                                               reply  \\\n",
       "0                         $tyratomaro #BailoutHumans   \n",
       "1                                      CONGRATS!!!!!   \n",
       "2                                                      \n",
       "3                                                      \n",
       "4  Watching everyone else get their weekly unempl...   \n",
       "\n",
       "                                       map_punc_text  \\\n",
       "0  Drop your cash app ,  use hashtag  # BailoutHu...   \n",
       "1  After interviewing with a few incredible peopl...   \n",
       "2  I know GTC festival not happening next month b...   \n",
       "3  Lordy ,  my daughter just said ,    \"  I wonde...   \n",
       "4   THE UNEMPLOYMENT CLAIM SYSTEM SUCKS SO MUCH DICK   \n",
       "\n",
       "                                      map_punc_reply  \\\n",
       "0                      $ tyratomaro  # BailoutHumans   \n",
       "1                            CONGRATS !  !  !  !  !    \n",
       "2                                                      \n",
       "3                                                      \n",
       "4  Watching everyone else get their weekly unempl...   \n",
       "\n",
       "                                  map_more_punc_text  \\\n",
       "0  Drop your cash app ,  use hashtag  # BailoutHu...   \n",
       "1  After interviewing with a few incredible peopl...   \n",
       "2  I know GTC festival not happening next month b...   \n",
       "3  Lordy ,  my daughter just said ,    \"  I wonde...   \n",
       "4   THE UNEMPLOYMENT CLAIM SYSTEM SUCKS SO MUCH DICK   \n",
       "\n",
       "                                 map_more_punc_reply  \n",
       "0                      $ tyratomaro  # BailoutHumans  \n",
       "1                            CONGRATS !  !  !  !  !   \n",
       "2                                                     \n",
       "3                                                     \n",
       "4  Watching everyone else get their weekly unempl...  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "      <th>reply</th>\n",
       "      <th>map_punc_text</th>\n",
       "      <th>map_punc_reply</th>\n",
       "      <th>map_more_punc_text</th>\n",
       "      <th>map_more_punc_reply</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36000</td>\n",
       "      <td>@Youngdeji_ I think if uzi and carti dropping ...</td>\n",
       "      <td></td>\n",
       "      <td>@ Youngdeji  -   I think if uzi and carti dro...</td>\n",
       "      <td></td>\n",
       "      <td>@ Youngdeji  -   I think if uzi and carti dro...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36001</td>\n",
       "      <td>For the third year in a row we are discussing ...</td>\n",
       "      <td></td>\n",
       "      <td>For the third year in a row we are discussing ...</td>\n",
       "      <td></td>\n",
       "      <td>For the third year in a row we are discussing ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36002</td>\n",
       "      <td>dababy album sounds like it was made for nigga...</td>\n",
       "      <td>That's why you bought it.</td>\n",
       "      <td>dababy album sounds like it was made for nigga...</td>\n",
       "      <td>That  '  s why you bought it .</td>\n",
       "      <td>dababy album sounds like it was made for nigga...</td>\n",
       "      <td>That  '  s why you buy it .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36003</td>\n",
       "      <td>Majority of Indians do not watch any sport oth...</td>\n",
       "      <td>@ZairaWasimmm got a great story because of the...</td>\n",
       "      <td>Majority of Indians do not watch any sport oth...</td>\n",
       "      <td>@ ZairaWasimmm got a great story because of t...</td>\n",
       "      <td>Majority of Indians do not watch any sport oth...</td>\n",
       "      <td>@ ZairaWasimmm got a great story because of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36004</td>\n",
       "      <td>everybody is just now listening to @madisonbee...</td>\n",
       "      <td></td>\n",
       "      <td>everybody is just now listening to  @ madisonb...</td>\n",
       "      <td></td>\n",
       "      <td>everybody is just now listen to  @ madisonbeer...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     idx                                               text  \\\n",
       "0  36000  @Youngdeji_ I think if uzi and carti dropping ...   \n",
       "1  36001  For the third year in a row we are discussing ...   \n",
       "2  36002  dababy album sounds like it was made for nigga...   \n",
       "3  36003  Majority of Indians do not watch any sport oth...   \n",
       "4  36004  everybody is just now listening to @madisonbee...   \n",
       "\n",
       "                                               reply  \\\n",
       "0                                                      \n",
       "1                                                      \n",
       "2                          That's why you bought it.   \n",
       "3  @ZairaWasimmm got a great story because of the...   \n",
       "4                                                      \n",
       "\n",
       "                                       map_punc_text  \\\n",
       "0   @ Youngdeji  -   I think if uzi and carti dro...   \n",
       "1  For the third year in a row we are discussing ...   \n",
       "2  dababy album sounds like it was made for nigga...   \n",
       "3  Majority of Indians do not watch any sport oth...   \n",
       "4  everybody is just now listening to  @ madisonb...   \n",
       "\n",
       "                                      map_punc_reply  \\\n",
       "0                                                      \n",
       "1                                                      \n",
       "2                    That  '  s why you bought it .    \n",
       "3   @ ZairaWasimmm got a great story because of t...   \n",
       "4                                                      \n",
       "\n",
       "                                  map_more_punc_text  \\\n",
       "0   @ Youngdeji  -   I think if uzi and carti dro...   \n",
       "1  For the third year in a row we are discussing ...   \n",
       "2  dababy album sounds like it was made for nigga...   \n",
       "3  Majority of Indians do not watch any sport oth...   \n",
       "4  everybody is just now listen to  @ madisonbeer...   \n",
       "\n",
       "                                 map_more_punc_reply  \n",
       "0                                                     \n",
       "1                                                     \n",
       "2                       That  '  s why you buy it .   \n",
       "3   @ ZairaWasimmm got a great story because of t...  \n",
       "4                                                     "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output preprocessed to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_preprocessed = df_train[['idx', 'map_more_punc_text', 'map_more_punc_reply', 'categories']].copy()\n",
    "df_preprocessed.columns = ['idx', 'text', 'reply', 'categories']\n",
    "df_preprocessed.to_json('./preprocessed/preprocess_train.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed_dev = df_dev[['idx', 'map_more_punc_text', 'map_more_punc_reply']].copy()\n",
    "df_preprocessed_dev.columns = ['idx', 'text', 'reply']\n",
    "df_preprocessed_dev.to_json('./preprocessed/preprocess_dev.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed_test = df_test[['idx', 'map_more_punc_text', 'map_more_punc_reply']].copy()\n",
    "df_preprocessed_test.columns = ['idx', 'text', 'reply']\n",
    "df_preprocessed_test.to_json('./preprocessed/preprocess_test.json', orient='records', lines=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
