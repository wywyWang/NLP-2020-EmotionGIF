{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from random import random\n",
    "import emoji\n",
    "from tqdm import notebook\n",
    "def tqdm(x, **kargs):\n",
    "    return notebook.tqdm(x, leave=False, **kargs)\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter, defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0603 00:10:32.220917 140658852493120 file_utils.py:39] PyTorch version 1.5.0 available.\n",
      "/home/ino/anaconda3/envs/TrackNet/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ino/anaconda3/envs/TrackNet/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ino/anaconda3/envs/TrackNet/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ino/anaconda3/envs/TrackNet/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ino/anaconda3/envs/TrackNet/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ino/anaconda3/envs/TrackNet/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer, RobertaModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of text in training data: 32000\n",
      "Number of text in categories: 43\n",
      "Number of text in developing data: 4000\n",
      "Number of text in testing data: 4000\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_json('./source/train_gold.json', lines=True)\n",
    "categories_type = pd.read_json('./source/categories.json', lines=True)\n",
    "df_dev = pd.read_json('./source/dev_unlabeled.json', lines=True)\n",
    "df_test = pd.read_json('./source/test_unlabeled.json', lines=True)\n",
    "print(\"Number of text in training data: {}\".format(df_train.shape[0]))\n",
    "print(\"Number of text in categories: {}\".format(categories_type.shape[1]))\n",
    "print(\"Number of text in developing data: {}\".format(df_dev.shape[0]))\n",
    "print(\"Number of text in testing data: {}\".format(df_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0603 02:16:36.777105 140658852493120 tokenization_utils.py:1015] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /home/ino/.cache/torch/transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "I0603 02:16:36.777707 140658852493120 tokenization_utils.py:1015] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /home/ino/.cache/torch/transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "I0603 02:16:37.731026 140658852493120 configuration_utils.py:285] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at /home/ino/.cache/torch/transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690\n",
      "I0603 02:16:37.731829 140658852493120 configuration_utils.py:321] Model config RobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0603 02:16:38.079062 140658852493120 modeling_utils.py:650] loading weights file https://cdn.huggingface.co/roberta-base-pytorch_model.bin from cache at /home/ino/.cache/torch/transformers/80b4a484eddeb259bec2f06a6f2f05d90934111628e0e1c09a33bd4a121358e1.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "model = RobertaModel.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "roberta_vocab = pd.read_json('roberta_vocab/vocab.json', typ='series')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>',\n",
       " '<pad>',\n",
       " '</s>',\n",
       " '<unk>',\n",
       " '.',\n",
       " 'Ä the',\n",
       " ',',\n",
       " 'Ä to',\n",
       " 'Ä and',\n",
       " 'Ä of',\n",
       " 'Ä a',\n",
       " 'Ä in',\n",
       " '-',\n",
       " 'Ä for',\n",
       " 'Ä that',\n",
       " 'Ä on',\n",
       " 'Ä is',\n",
       " 'Ã¢Ä¢',\n",
       " \"'s\",\n",
       " 'Ä with',\n",
       " 'Ä The',\n",
       " 'Ä was',\n",
       " 'Ä \"',\n",
       " 'Ä at',\n",
       " 'Ä it',\n",
       " 'Ä as',\n",
       " 'Ä said',\n",
       " 'Ä»',\n",
       " 'Ä be',\n",
       " 's',\n",
       " 'Ä by',\n",
       " 'Ä from',\n",
       " 'Ä are',\n",
       " 'Ä have',\n",
       " 'Ä has',\n",
       " ':',\n",
       " 'Ä (',\n",
       " 'Ä he',\n",
       " 'Ä I',\n",
       " 'Ä his',\n",
       " 'Ä will',\n",
       " 'Ä an',\n",
       " 'Ä this',\n",
       " ')',\n",
       " 'Ä Ã¢Ä¢',\n",
       " 'Ä not',\n",
       " 'Ä¿',\n",
       " 'Ä you',\n",
       " 'Ä¾',\n",
       " 'Ä their',\n",
       " 'Ä or',\n",
       " 'Ä they',\n",
       " 'Ä we',\n",
       " 'Ä but',\n",
       " 'Ä who',\n",
       " 'Ä more',\n",
       " 'Ä had',\n",
       " 'Ä been',\n",
       " 'Ä were',\n",
       " 'Ä about',\n",
       " ',\"',\n",
       " 'Ä which',\n",
       " 'Ä up',\n",
       " 'Ä its',\n",
       " 'Ä can',\n",
       " 'Ä one',\n",
       " 'Ä out',\n",
       " 'Ä also',\n",
       " 'Ä $',\n",
       " 'Ä her',\n",
       " 'Ä all',\n",
       " 'Ä after',\n",
       " '.\"',\n",
       " '/',\n",
       " 'Ä would',\n",
       " \"'t\",\n",
       " 'Ä year',\n",
       " 'Ä when',\n",
       " 'Ä first',\n",
       " 'Ä she',\n",
       " 'Ä two',\n",
       " 'Ä over',\n",
       " 'Ä people',\n",
       " 'Ä A',\n",
       " 'Ä our',\n",
       " 'Ä It',\n",
       " 'Ä time',\n",
       " 'Ä than',\n",
       " 'Ä into',\n",
       " 'Ä there',\n",
       " 't',\n",
       " 'Ä He',\n",
       " 'Ä new',\n",
       " 'Ä Ã¢Ä¢Ä¶',\n",
       " 'Ä last',\n",
       " 'Ä just',\n",
       " 'Ä In',\n",
       " 'Ä other',\n",
       " 'Ä so',\n",
       " 'Ä what',\n",
       " 'I',\n",
       " 'Ä like',\n",
       " 'a',\n",
       " 'Ä some',\n",
       " 'S',\n",
       " 'ÃƒÂ«',\n",
       " 'Ä them',\n",
       " 'Ä years',\n",
       " \"'\",\n",
       " 'Ä do',\n",
       " 'Ä your',\n",
       " 'Ä -',\n",
       " 'Ä 1',\n",
       " '\"',\n",
       " 'Ä if',\n",
       " 'Ä could',\n",
       " '?',\n",
       " 'Ä no',\n",
       " 'i',\n",
       " 'm',\n",
       " 'Ä get',\n",
       " 'Ä U',\n",
       " 'Ä now',\n",
       " 'Ä him',\n",
       " 'Ä back',\n",
       " 'Ä But',\n",
       " 'Ä Ã¢Ä¢Äµ',\n",
       " 'Ä my',\n",
       " \"Ä '\",\n",
       " 'Ä only',\n",
       " 'Ä three',\n",
       " ';',\n",
       " 'Ä 2',\n",
       " 'The',\n",
       " '1',\n",
       " 'Ä percent',\n",
       " 'Ä against',\n",
       " 'Ä before',\n",
       " 'Ä company',\n",
       " 'o',\n",
       " 'Ä Trump',\n",
       " 'Ä how',\n",
       " 'Ä because',\n",
       " 'Ä any',\n",
       " 'Ä most',\n",
       " 'Ä being',\n",
       " 'Ä make',\n",
       " 'Ä where',\n",
       " 'Ä during',\n",
       " 'Ä through',\n",
       " 'Ä while',\n",
       " '000',\n",
       " 'Ä This',\n",
       " 'Ä million',\n",
       " 'ing',\n",
       " 'Ä 3',\n",
       " 'Ä made',\n",
       " 'Ä well',\n",
       " 'Ä 10',\n",
       " 'Ä down',\n",
       " 'Ä off',\n",
       " 'Ä says',\n",
       " 'Ä me',\n",
       " 'Ä B',\n",
       " 'Ä going',\n",
       " 'Ä team',\n",
       " 'Ä We',\n",
       " 'Ä those',\n",
       " 'Ä government',\n",
       " 'Ä way',\n",
       " 'We',\n",
       " 'Ä many',\n",
       " 'Ä then',\n",
       " 'Ä work',\n",
       " 'Ä told',\n",
       " 'com',\n",
       " '2',\n",
       " 'Ä game',\n",
       " 'Ä And',\n",
       " 'in',\n",
       " 'year',\n",
       " 'Ä p',\n",
       " 'Ä very',\n",
       " 'Ä day',\n",
       " 'Ä home',\n",
       " 'Ä take',\n",
       " 'Ä week',\n",
       " 'Ä since',\n",
       " 'Ä New',\n",
       " 'Ä may',\n",
       " 'Ä even',\n",
       " 'Ä season',\n",
       " 'Ä see',\n",
       " 'Ä 2017',\n",
       " 'Ä state',\n",
       " 'Ä 5',\n",
       " 'ed',\n",
       " 'Ä should',\n",
       " 'Ä around',\n",
       " 'Ä 2018',\n",
       " 'Ä second',\n",
       " 'Ä us',\n",
       " 'Ä still',\n",
       " 'Ä much',\n",
       " 'Ä 4',\n",
       " 'Ä good',\n",
       " 'Ä think',\n",
       " '%',\n",
       " 'Ä S',\n",
       " 'Ä these',\n",
       " 'Ä market',\n",
       " 'Ä D',\n",
       " 'th',\n",
       " 'Ä go',\n",
       " \"'re\",\n",
       " 'Ä such',\n",
       " 'Ä know',\n",
       " 'Ä including',\n",
       " 'Ä don',\n",
       " 'y',\n",
       " 'Ä next',\n",
       " 'Ä P',\n",
       " 'Ä did',\n",
       " 'Ä under',\n",
       " 'Ä say',\n",
       " 'en',\n",
       " 'Ä L',\n",
       " 'Ä between',\n",
       " 'Ä per',\n",
       " 'Ä K',\n",
       " 'Ä C',\n",
       " 'Ä 6',\n",
       " 'Ä world',\n",
       " 'Ä part',\n",
       " 'Ä N',\n",
       " 'Ä right',\n",
       " 'Ä want',\n",
       " 'Ä four',\n",
       " '),',\n",
       " 'Ä high',\n",
       " 'Ä need',\n",
       " 're',\n",
       " 'e',\n",
       " 'It',\n",
       " 'Ä help',\n",
       " '5',\n",
       " '3',\n",
       " 'Ä country',\n",
       " 'Ä R',\n",
       " 'Ä police',\n",
       " 'A',\n",
       " 'Ä long',\n",
       " 'Ä They',\n",
       " 'Ä end',\n",
       " 'er',\n",
       " 'Ä T',\n",
       " 'Ä M',\n",
       " 'u',\n",
       " 'Ä both',\n",
       " 'Ä here',\n",
       " 'an',\n",
       " 'on',\n",
       " 'Ä 7',\n",
       " 'Ä de',\n",
       " 'Ä She',\n",
       " 'Ä business',\n",
       " 'Ä report',\n",
       " 'j',\n",
       " 'ers',\n",
       " 'Ä really',\n",
       " 'Ä President',\n",
       " 'ar',\n",
       " 'Ä G',\n",
       " 'Ä Friday',\n",
       " 'Ä F',\n",
       " 'Ä best',\n",
       " 'Ä same',\n",
       " 'Ä another',\n",
       " 'Ä set',\n",
       " 'old',\n",
       " 'Ä That',\n",
       " 'as',\n",
       " 'n',\n",
       " 'Ä come',\n",
       " 'Ä family',\n",
       " 'Ä public',\n",
       " 'Ä For',\n",
       " 'Ä As',\n",
       " '0',\n",
       " 'Ä H',\n",
       " 'Ä 8',\n",
       " 'Ä 20',\n",
       " 'Ä five',\n",
       " 'es',\n",
       " 'Ä Tuesday',\n",
       " 'Ä n',\n",
       " 'Ä Thursday',\n",
       " 'Ä quarter',\n",
       " 'h',\n",
       " 'Ä top',\n",
       " 'Ä got',\n",
       " 'Ä life',\n",
       " 'Ä Monday',\n",
       " 'Ä found',\n",
       " 'Ä use',\n",
       " 'Ä W',\n",
       " '4',\n",
       " 'Ä Wednesday',\n",
       " 'Ä own',\n",
       " 'Ä according',\n",
       " 'Ä play',\n",
       " 'Ä show',\n",
       " 'Ä St',\n",
       " 'Ä man',\n",
       " 'Ä left',\n",
       " 'Ä United',\n",
       " 'Ä 12',\n",
       " 'Ä place',\n",
       " 'Ä If',\n",
       " 'Ä lot',\n",
       " 'Ä former',\n",
       " 'Ä 0',\n",
       " ').',\n",
       " 'Ä support',\n",
       " 'ie',\n",
       " 'Ä billion',\n",
       " 'Ä t',\n",
       " 'Ä shares',\n",
       " '!',\n",
       " 'z',\n",
       " 'k',\n",
       " 'Ä State',\n",
       " 'Ä points',\n",
       " 'Ä group',\n",
       " 'Ä school',\n",
       " 'Ä information',\n",
       " 'Ä 2016',\n",
       " 'al',\n",
       " 'r',\n",
       " 'Ä win',\n",
       " 'Ä news',\n",
       " 'Ä used',\n",
       " 'Ä put',\n",
       " 'Ä city',\n",
       " 'Ä J',\n",
       " 'Ä There',\n",
       " 'Ä number',\n",
       " 'C',\n",
       " \"'ve\",\n",
       " 'Ä each',\n",
       " 'Ä too',\n",
       " 'Ä won',\n",
       " 'ly',\n",
       " 'Ä month',\n",
       " 'is',\n",
       " 'Ä added',\n",
       " 'Ä look',\n",
       " 'Ä better',\n",
       " 'Ä every',\n",
       " 'Ä &',\n",
       " 'Ä days',\n",
       " 'Ä 9',\n",
       " 'Ä took',\n",
       " 'Ä night',\n",
       " 'Ä e',\n",
       " 'Ä 11',\n",
       " 'os',\n",
       " 'Ä few',\n",
       " 'or',\n",
       " 'Ä North',\n",
       " 'Ä You',\n",
       " 'Ä third',\n",
       " 'Ä great',\n",
       " 'Ä called',\n",
       " 'Ä On',\n",
       " 'Ä past',\n",
       " 'Ä came',\n",
       " 'Ä months',\n",
       " 'Ä Saturday',\n",
       " 'Ä 15',\n",
       " 'Ä big',\n",
       " 'Ä E',\n",
       " 'Ä US',\n",
       " 'Ä things',\n",
       " 'Ä O',\n",
       " 'Ä d',\n",
       " 'Ä start',\n",
       " 'B',\n",
       " 'Ä stock',\n",
       " 'Ä 30',\n",
       " 'Ä women',\n",
       " 'Ä South',\n",
       " 'Ä May',\n",
       " 'Ä never',\n",
       " 'Ä president',\n",
       " 'Ä Sunday',\n",
       " 'Ä without',\n",
       " 'man',\n",
       " '8',\n",
       " 'Ä didn',\n",
       " 'Ä local',\n",
       " '6',\n",
       " 'Ä something',\n",
       " 'Ä case',\n",
       " 'Ä All',\n",
       " 'it',\n",
       " '7',\n",
       " 'Ä So',\n",
       " 'Ä children',\n",
       " 'Ä away',\n",
       " 'Ä little',\n",
       " 'Ä six',\n",
       " 'Ä City',\n",
       " 'Ä County',\n",
       " 'Ä data',\n",
       " 'at',\n",
       " 'Ä already',\n",
       " 'd',\n",
       " 'Ä money',\n",
       " 'Ä early',\n",
       " 'Ä across',\n",
       " 'Ä expected',\n",
       " 'Ä run',\n",
       " 'Ä later',\n",
       " 'am',\n",
       " 'Ä price',\n",
       " 'Ä games',\n",
       " 'Ä Mr',\n",
       " 'b',\n",
       " 'Ä might',\n",
       " 'Ä different',\n",
       " 'Ä reported',\n",
       " 'Ä deal',\n",
       " 'Ä media',\n",
       " 'Ä growth',\n",
       " 'Ä community',\n",
       " 'Ä China',\n",
       " \"'m\",\n",
       " 'c',\n",
       " 'Ä went',\n",
       " 'Ä No',\n",
       " 'Ä able',\n",
       " 'Ä making',\n",
       " 'Ä area',\n",
       " 'Ä far',\n",
       " 'Ä statement',\n",
       " 'Ä House',\n",
       " 'Ä working',\n",
       " 'M',\n",
       " 'Ä k',\n",
       " 'Ä seen',\n",
       " 'Ä companies',\n",
       " 'Ä today',\n",
       " 'Ä members',\n",
       " 'Ä until',\n",
       " 'Ä full',\n",
       " 'Ä again',\n",
       " 'Ä half',\n",
       " 'Ä share',\n",
       " 'le',\n",
       " 'Ä always',\n",
       " 'Ä court',\n",
       " 'l',\n",
       " 'and',\n",
       " 'Ä change',\n",
       " 'Ä find',\n",
       " '9',\n",
       " 'Ä system',\n",
       " 'Ä V',\n",
       " 'Ä York',\n",
       " 'Ä American',\n",
       " 'Ä head',\n",
       " 'Ä players',\n",
       " 'Ä does',\n",
       " 'Ä health',\n",
       " 'Ä m',\n",
       " 'Ä power',\n",
       " 'Ä point',\n",
       " 'Ä hit',\n",
       " 'Ä .',\n",
       " 'Ä --',\n",
       " 'Ä free',\n",
       " '.,',\n",
       " 'Ä lead',\n",
       " 'Ä several',\n",
       " 'Ä recent',\n",
       " 'Ä call',\n",
       " 'N',\n",
       " 'Ä law',\n",
       " 'Ä keep',\n",
       " 'Ä open',\n",
       " 'Ä News',\n",
       " 'Ä give',\n",
       " 'ia',\n",
       " 'Ä March',\n",
       " 'D',\n",
       " 'Ä National',\n",
       " 'Ä At',\n",
       " 'Ä times',\n",
       " 'Ä future',\n",
       " 'R',\n",
       " 'Ä 14',\n",
       " 'Ä June',\n",
       " 'Ä officials',\n",
       " 'Ä 18',\n",
       " 'Ä important',\n",
       " 'f',\n",
       " 'Ä final',\n",
       " 'Ä 13',\n",
       " 'Ä One',\n",
       " 'P',\n",
       " 'Ä following',\n",
       " 'Ä car',\n",
       " 'Ä least',\n",
       " 'Ä water',\n",
       " 'Ä event',\n",
       " 'Ä line',\n",
       " 'Ä move',\n",
       " 'Ä services',\n",
       " 'Ä having',\n",
       " 'Ä When',\n",
       " 'Ä students',\n",
       " 'Ä Police',\n",
       " 'el',\n",
       " 'Ä am',\n",
       " 'Ä Z',\n",
       " 'Ä side',\n",
       " 'Ä story',\n",
       " 'Ä due',\n",
       " 'Ä meeting',\n",
       " 'K',\n",
       " 'Ä must',\n",
       " 'Ä States',\n",
       " 'Ä likely',\n",
       " 'G',\n",
       " 'Ä continue',\n",
       " 'Ä ago',\n",
       " 'Ä party',\n",
       " 'Ä major',\n",
       " 'Ä industry',\n",
       " 'Ä less',\n",
       " '30',\n",
       " 'Ä un',\n",
       " 'Ä hard',\n",
       " 'Ä service',\n",
       " 'Ä 16',\n",
       " 'Ä looking',\n",
       " 'Ä held',\n",
       " 've',\n",
       " 'Ä whether',\n",
       " 'Ä July',\n",
       " 'Ä taken',\n",
       " 'Ä along',\n",
       " 'Ä asked',\n",
       " 'Ä started',\n",
       " 'Ä become',\n",
       " 'Ä forward',\n",
       " 'Ä research',\n",
       " 'Ä office',\n",
       " 'Ä political',\n",
       " 'to',\n",
       " 'Ä together',\n",
       " 'Ä getting',\n",
       " 'Ä plan',\n",
       " 'Ä 25',\n",
       " 'T',\n",
       " 'Ä among',\n",
       " 'Ä coming',\n",
       " 'Ä decision',\n",
       " 'Ä video',\n",
       " 'Ä 2015',\n",
       " 'g',\n",
       " 'Ä After',\n",
       " 'Ä security',\n",
       " 'L',\n",
       " 'Ä care',\n",
       " 'Ä given',\n",
       " 'Ä available',\n",
       " 'Ã¢Ä¢Ä¶',\n",
       " 'Ä s',\n",
       " 'Ä West',\n",
       " \"'ll\",\n",
       " 'Ä pay',\n",
       " 'Ä near',\n",
       " 'Ä saying',\n",
       " 'Ä announced',\n",
       " 'Ä program',\n",
       " 'Ä April',\n",
       " 'Ä real',\n",
       " 'Ä University',\n",
       " 'Ä With',\n",
       " 'AP',\n",
       " 'Ä social',\n",
       " 'Ä close',\n",
       " 'et',\n",
       " 'Ä current',\n",
       " 'Ä why',\n",
       " 'F',\n",
       " 'Ä To',\n",
       " 'Ä Twitter',\n",
       " 'Ä though',\n",
       " 'Ä 17',\n",
       " 'Ä taking',\n",
       " 'Ä Inc',\n",
       " 'Ä men',\n",
       " 'w',\n",
       " 'Ä comes',\n",
       " 'ley',\n",
       " 'Ä doing',\n",
       " 'Ä process',\n",
       " 'Ä John',\n",
       " 'ch',\n",
       " '00',\n",
       " 'Ä financial',\n",
       " 'Ä low',\n",
       " 'Ä enough',\n",
       " 'Ä While',\n",
       " 'Ä further',\n",
       " 'Ä post',\n",
       " 'Ä feel',\n",
       " 'st',\n",
       " 'Ä person',\n",
       " 'Ä Facebook',\n",
       " 'Ä World',\n",
       " 'Ä within',\n",
       " 'ad',\n",
       " 'Ä done',\n",
       " 'the',\n",
       " 'Ä late',\n",
       " 'Ä tax',\n",
       " 'Ä doesn',\n",
       " 'Ä thing',\n",
       " 'Ä national',\n",
       " 'Ä job',\n",
       " 'Ä using',\n",
       " 'Ä However',\n",
       " 'ic',\n",
       " 'Ä campaign',\n",
       " 'Ä record',\n",
       " 'Ä behind',\n",
       " '://',\n",
       " 'Ä Department',\n",
       " 'p',\n",
       " 'Ä others',\n",
       " 'Ä January',\n",
       " 'Ä order',\n",
       " 'Ä [',\n",
       " 'Ä sales',\n",
       " 'Ä yet',\n",
       " 'Ã„',\n",
       " 'Ä small',\n",
       " 'Ä series',\n",
       " 'Ä face',\n",
       " 'Ä What',\n",
       " 'Ä 50',\n",
       " 'Ä ever',\n",
       " 'Ä earlier',\n",
       " 'Ä love',\n",
       " 'up',\n",
       " 'Ä rights',\n",
       " 'Ä An',\n",
       " 'ist',\n",
       " 'Ä morning',\n",
       " 'Ä Washington',\n",
       " 'Ä young',\n",
       " 'Ä latest',\n",
       " 'Ä India',\n",
       " 'Ä trying',\n",
       " 'Ä fire',\n",
       " 'Ä led',\n",
       " 'Ä strong',\n",
       " 'Ä return',\n",
       " 'Ä level',\n",
       " 'O',\n",
       " 'Ä average',\n",
       " 'Ä period',\n",
       " 'Ä experience',\n",
       " 'ak',\n",
       " 'Ä possible',\n",
       " 'Ä believe',\n",
       " 'Ä include',\n",
       " 'Ä oil',\n",
       " 'Ä recently',\n",
       " 'Ä once',\n",
       " 'Ä known',\n",
       " 'Ä lost',\n",
       " 'Ä sure',\n",
       " 'us',\n",
       " 'Ä weeks',\n",
       " 'Ä food',\n",
       " 'Ä reports',\n",
       " 'Ä rating',\n",
       " 'Ä Minister',\n",
       " 'Ä woman',\n",
       " 'Ä provide',\n",
       " 'Ä project',\n",
       " 'Ä issue',\n",
       " 'Ä live',\n",
       " '10',\n",
       " 'Ä clear',\n",
       " 'he',\n",
       " 'Ä cost',\n",
       " 'Ä played',\n",
       " 'Ä released',\n",
       " 'Ä coach',\n",
       " 'v',\n",
       " 'Ä 24',\n",
       " 'Ä seven',\n",
       " 'Ä plans',\n",
       " 'Ä development',\n",
       " 'ur',\n",
       " 'Äº',\n",
       " 'Ä increase',\n",
       " 'This',\n",
       " 'Ä policy',\n",
       " 'Ä cent',\n",
       " 'Ä based',\n",
       " 'E',\n",
       " 'il',\n",
       " 'Ä December',\n",
       " 'Ä global',\n",
       " 'Ä trade',\n",
       " 'Ä hours',\n",
       " 'Ä higher',\n",
       " 'Ä goal',\n",
       " 'H',\n",
       " 'Ä Al',\n",
       " 'Ä 100',\n",
       " 'Ä minutes',\n",
       " 'Ä election',\n",
       " 'Ä America',\n",
       " 'Ä rate',\n",
       " 'Ä Ch',\n",
       " 'Ä 21',\n",
       " '...',\n",
       " 'Ä White',\n",
       " 'Ä director',\n",
       " 'Ä position',\n",
       " 'Ä shot',\n",
       " 'Ä large',\n",
       " 'Ä c',\n",
       " 'Ä b',\n",
       " ']',\n",
       " 'Ä issues',\n",
       " 'Ä death',\n",
       " 'Ä building',\n",
       " 'Ä total',\n",
       " 'Ä often',\n",
       " 'Ä v',\n",
       " 'Ä countries',\n",
       " 'Ä history',\n",
       " 'Ä outside',\n",
       " 'Ä federal',\n",
       " 'Ä 19',\n",
       " 'Ä fact',\n",
       " 'Ä High',\n",
       " 'Ä career',\n",
       " 'im',\n",
       " 'Ä international',\n",
       " 'Ä November',\n",
       " 'Ä front',\n",
       " 'Ä kind',\n",
       " 'Ä key',\n",
       " 'ra',\n",
       " 'Ä San',\n",
       " 'Ä short',\n",
       " 'Ä name',\n",
       " 'Ä According',\n",
       " 'Ä course',\n",
       " 'Ä re',\n",
       " 'Ä wanted',\n",
       " 'W',\n",
       " 'Ä September',\n",
       " 'Ä interest',\n",
       " 'Ä role',\n",
       " 'Ä results',\n",
       " 'Ä economic',\n",
       " 'Ä 2014',\n",
       " 'Ä chance',\n",
       " 'Ä October',\n",
       " 'Ä special',\n",
       " 'Ä official',\n",
       " 'Ä needs',\n",
       " 'um',\n",
       " 'Ä l',\n",
       " 'Ä products',\n",
       " 'Ä non',\n",
       " 'Ä @',\n",
       " 'Ä Bank',\n",
       " 'Ä ahead',\n",
       " 'Ä house',\n",
       " 'U',\n",
       " 'Ä board',\n",
       " 'Ä old',\n",
       " 'Ä saw',\n",
       " 'Ä lower',\n",
       " 'Ä European',\n",
       " 'Ä control',\n",
       " 'Ä Russia',\n",
       " 'Ä eight',\n",
       " 'Ä release',\n",
       " 'Ä potential',\n",
       " 'Ä thought',\n",
       " 'Ä investigation',\n",
       " 'Ä online',\n",
       " 'based',\n",
       " 'Ä technology',\n",
       " 'Ä Donald',\n",
       " 'id',\n",
       " 'Ä body',\n",
       " 'Ä risk',\n",
       " 'ian',\n",
       " 'Ä capital',\n",
       " 'Ä staff',\n",
       " 'Ä action',\n",
       " 'Ä League',\n",
       " 'Ä playing',\n",
       " 'Ä makes',\n",
       " 'Ä almost',\n",
       " 'Ä performance',\n",
       " 'Ä 22',\n",
       " 'Ä g',\n",
       " 'Ä film',\n",
       " 'Ä nearly',\n",
       " 'Ä Center',\n",
       " 'Ä visit',\n",
       " 'Ä Group',\n",
       " 'Ä bank',\n",
       " 'Ä bit',\n",
       " 'Ä received',\n",
       " 'Ä August',\n",
       " 'Ä military',\n",
       " 'Ä His',\n",
       " 'ine',\n",
       " 'Ä chief',\n",
       " 'Ä School',\n",
       " 'Ä bring',\n",
       " 'Ä Court',\n",
       " 'Ä (@',\n",
       " 'Ä means',\n",
       " 'Ä Sh',\n",
       " 'Ä fans',\n",
       " 'Ä se',\n",
       " 'Ä 40',\n",
       " '20',\n",
       " '\".',\n",
       " 'V',\n",
       " 'Ä cut',\n",
       " 'Ä killed',\n",
       " 'Ä #',\n",
       " 'Ä prices',\n",
       " 'Ä gave',\n",
       " 'Ä Street',\n",
       " 'ir',\n",
       " 'Ä Y',\n",
       " 'Ä currently',\n",
       " 'Ä f',\n",
       " 'ay',\n",
       " 'ne',\n",
       " 'te',\n",
       " 'Ä try',\n",
       " 'Ä Park',\n",
       " 'Ä¥',\n",
       " 'J',\n",
       " 'Ä question',\n",
       " 'Ä hand',\n",
       " 'Ä economy',\n",
       " 'Ä investors',\n",
       " 'able',\n",
       " 'Ä player',\n",
       " 'Ä By',\n",
       " 'Ä David',\n",
       " 'Ä loss',\n",
       " 'ab',\n",
       " 'Ä below',\n",
       " 'Ä wrote',\n",
       " 'co',\n",
       " 'ate',\n",
       " 'Ä running',\n",
       " 'un',\n",
       " 'Ä began',\n",
       " 'Ä single',\n",
       " 'Ä field',\n",
       " 'Ä 23',\n",
       " 'Ä leader',\n",
       " 'Ä w',\n",
       " 'Ä California',\n",
       " 'Ä fourth',\n",
       " 'Ä actually',\n",
       " 'Ä list',\n",
       " 'll',\n",
       " 'Ä couple',\n",
       " 'Ä study',\n",
       " 'Ä teams',\n",
       " 'He',\n",
       " 'ah',\n",
       " 'Ä Canada',\n",
       " 'Ä la',\n",
       " 'Ä result',\n",
       " 'Ä access',\n",
       " 'Ä vote',\n",
       " 'Ä More',\n",
       " 'Ä February',\n",
       " 'Ä revenue',\n",
       " 'Ä offer',\n",
       " 'Ä let',\n",
       " 'ier',\n",
       " 'Ä buy',\n",
       " 'Ä attack',\n",
       " 'Ä black',\n",
       " 'Ä r',\n",
       " 'Ä areas',\n",
       " 'Ä stop',\n",
       " 'Ä impact',\n",
       " 'Ä match',\n",
       " 'Ä investment',\n",
       " 'Ä customers',\n",
       " 'Ä leaders',\n",
       " 'ies',\n",
       " 'Ä member',\n",
       " 'Ä child',\n",
       " 'Ä road',\n",
       " 'ul',\n",
       " 'Ä value',\n",
       " 'Ä shows',\n",
       " 'Ä Dr',\n",
       " 'Ä De',\n",
       " 'ant',\n",
       " 'Ä London',\n",
       " 'Ä room',\n",
       " 'Ä music',\n",
       " 'Ä production',\n",
       " 'Ä anything',\n",
       " 'Ä firm',\n",
       " 'Ä biggest',\n",
       " 'Ä air',\n",
       " 'Ä problem',\n",
       " 'Ä general',\n",
       " 'Ä wasn',\n",
       " 'Ä i',\n",
       " 'Ä private',\n",
       " 'Ä especially',\n",
       " 'Ä administration',\n",
       " 'Ä additional',\n",
       " 'Ä Co',\n",
       " 'Ä opportunity',\n",
       " 'Ä hold',\n",
       " '&',\n",
       " 'Ä matter',\n",
       " 'Ä senior',\n",
       " 'Ä club',\n",
       " 'Ä someone',\n",
       " 'Ä Ãƒ',\n",
       " 'Ä East',\n",
       " 'Ä 2019',\n",
       " \".'\",\n",
       " 'Ä needed',\n",
       " 'Ä James',\n",
       " 'time',\n",
       " 'Ä however',\n",
       " 'Ä everything',\n",
       " 'Ä everyone',\n",
       " 'Ä died',\n",
       " 'Ä involved',\n",
       " 'Ä friends',\n",
       " 'Ä isn',\n",
       " 'Ä worth',\n",
       " 'ik',\n",
       " 'Ä Cup',\n",
       " 'Ä showed',\n",
       " 'There',\n",
       " 'Ä 28',\n",
       " 'Ä meet',\n",
       " 'Ä 26',\n",
       " 'Ä 27',\n",
       " 'Y',\n",
       " 'Ä region',\n",
       " 'Ä Press',\n",
       " 'Ä Now',\n",
       " 'Ä son',\n",
       " 'Ä space',\n",
       " 'Ä leading',\n",
       " 'Ä states',\n",
       " 'Ä weekend',\n",
       " 'Ä Ã‚Â£',\n",
       " 'Ä mother',\n",
       " 'Ä previous',\n",
       " 'Ä UK',\n",
       " 'Ä Michael',\n",
       " 'Ä leave',\n",
       " 'est',\n",
       " 'em',\n",
       " 'Ä z',\n",
       " 'Ä Some',\n",
       " 'ors',\n",
       " 'out',\n",
       " '15',\n",
       " 'Ä war',\n",
       " 'Ä website',\n",
       " 'Ä star',\n",
       " ...]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(roberta_vocab.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab(corpus):\n",
    "    vocabulary = Counter()\n",
    "    for sentance in corpus:\n",
    "        for word in sentance.split():\n",
    "            vocabulary.update([word])\n",
    "    return vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_coverage(vocabs, roberta_vocab):\n",
    "    known_words = {}\n",
    "    unknown_words = {}\n",
    "    known_count = 0\n",
    "    unknown_count = 0\n",
    "    for word in tqdm(vocabs.keys(), desc='Checking: '):\n",
    "        if word in list(roberta_vocab.keys()):\n",
    "            known_words[word] = roberta_vocab[word]\n",
    "            known_count += vocabs[word]\n",
    "        else:\n",
    "            unknown_words[word] = vocabs[word]\n",
    "            unknown_count += vocabs[word]\n",
    "    print(\"Found embeddings for {:.3%} ({} / {}) of vocab\".format(len(known_words) / len(vocabs), len(known_words), len(vocabs)))\n",
    "    print(\"Found embeddings for {:.3%} ({} / {}) of all text\".format(known_count / (known_count + unknown_count), known_count, (known_count + unknown_count)))\n",
    "    return unknown_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train text unique vocab count is: 68961\n",
      "train reply unique vocab count is: 25542\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=68961.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 8.177% (5639 / 68961) of vocab\n",
      "Found embeddings for 65.985% (432177 / 654963) of all text\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=25542.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 14.451% (3691 / 25542) of vocab\n",
      "Found embeddings for 63.198% (68504 / 108395) of all text\n"
     ]
    }
   ],
   "source": [
    "train_text_vocab = get_vocab(df_train['text'].values)\n",
    "train_reply_vocab = get_vocab(df_train['reply'].values)\n",
    "print(\"train text unique vocab count is: {}\".format(len(train_text_vocab)))\n",
    "print(\"train reply unique vocab count is: {}\".format(len(train_reply_vocab)))\n",
    "unknown_text = check_coverage(train_text_vocab, roberta_vocab)\n",
    "print()\n",
    "unknown_reply = check_coverage(train_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev text unique vocab count is: 17684\n",
      "dev reply unique vocab count is: 5360\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=17684.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 17.830% (3153 / 17684) of vocab\n",
      "Found embeddings for 65.711% (54522 / 82972) of all text\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=5360.0, style=ProgressStyle(description_â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 26.978% (1446 / 5360) of vocab\n",
      "Found embeddings for 62.345% (8626 / 13836) of all text\n"
     ]
    }
   ],
   "source": [
    "dev_text_vocab = get_vocab(df_dev['text'].values)\n",
    "dev_reply_vocab = get_vocab(df_dev['reply'].values)\n",
    "print(\"dev text unique vocab count is: {}\".format(len(dev_text_vocab)))\n",
    "print(\"dev reply unique vocab count is: {}\".format(len(dev_reply_vocab)))\n",
    "unknown_text = check_coverage(dev_text_vocab, roberta_vocab)\n",
    "print()\n",
    "unknown_reply = check_coverage(dev_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try to convert to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab_lower(corpus):\n",
    "    vocabulary = Counter()\n",
    "    for sentance in corpus:\n",
    "        for word in sentance.lower().split():\n",
    "            vocabulary.update([word])\n",
    "    return vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train text unique vocab count is: 60613\n",
      "train reply unique vocab count is: 22586\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=60613.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 6.301% (3819 / 60613) of vocab\n",
      "Found embeddings for 65.900% (431618 / 654963) of all text\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=22586.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 11.804% (2666 / 22586) of vocab\n",
      "Found embeddings for 63.508% (68840 / 108395) of all text\n"
     ]
    }
   ],
   "source": [
    "train_text_vocab = get_vocab_lower(df_train['text'].values)\n",
    "train_reply_vocab = get_vocab_lower(df_train['reply'].values)\n",
    "print(\"train text unique vocab count is: {}\".format(len(train_text_vocab)))\n",
    "print(\"train reply unique vocab count is: {}\".format(len(train_reply_vocab)))\n",
    "unknown_text_lower = check_coverage(train_text_vocab, roberta_vocab)\n",
    "print()\n",
    "unknown_reply_lower = check_coverage(train_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev text unique vocab count is: 15888\n",
      "dev reply unique vocab count is: 4818\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=15888.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 14.772% (2347 / 15888) of vocab\n",
      "Found embeddings for 65.687% (54502 / 82972) of all text\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=4818.0, style=ProgressStyle(description_â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 24.408% (1176 / 4818) of vocab\n",
      "Found embeddings for 63.075% (8727 / 13836) of all text\n"
     ]
    }
   ],
   "source": [
    "dev_text_vocab = get_vocab_lower(df_dev['text'].values)\n",
    "dev_reply_vocab = get_vocab_lower(df_dev['reply'].values)\n",
    "print(\"dev text unique vocab count is: {}\".format(len(dev_text_vocab)))\n",
    "print(\"dev reply unique vocab count is: {}\".format(len(dev_reply_vocab)))\n",
    "unknown_text = check_coverage(dev_text_vocab, roberta_vocab)\n",
    "print()\n",
    "unknown_reply = check_coverage(dev_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add some known in tokenizer but unknown in lower case (zero is weird)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def add_lower(vocabs, roberta_vocab):\n",
    "#     count = 0\n",
    "#     add_tokens = []\n",
    "#     for word in tqdm(vocabs, desc='Searching: '):\n",
    "#         if word in list(roberta_vocab.keys()) and word.lower() not in list(roberta_vocab.keys()):\n",
    "#             add_tokens.append(word.lower())\n",
    "#             count += 1\n",
    "#     print(add_tokens)\n",
    "#     num_add = tokenizer.add_tokens(add_tokens)\n",
    "#     model.resize_token_embeddings(len(tokenizer))\n",
    "#     print(\"Added {} words to embedding\".format(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_lower(train_text_vocab, roberta_vocab)\n",
    "# add_lower(train_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show some unknown tokens!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'app,': 23,\n",
       " 'hashtag': 23,\n",
       " '#bailouthumansnow': 24,\n",
       " 'interviewing': 1,\n",
       " 'incredible': 5,\n",
       " 'exciting': 8,\n",
       " 'soil': 1,\n",
       " 'microbes': 1,\n",
       " 'grasslands,': 1,\n",
       " \"i'm\": 192,\n",
       " 'proud': 18,\n",
       " \"i'll\": 31,\n",
       " 'phd': 4,\n",
       " 'university': 5,\n",
       " 'kansas': 1,\n",
       " 'dr.': 72,\n",
       " 'jim': 2,\n",
       " 'bever': 1,\n",
       " 'fellow!!': 1,\n",
       " 'gtc': 1,\n",
       " 'festival': 1,\n",
       " 'happening': 4,\n",
       " 'jus': 3,\n",
       " 'confirmation': 1,\n",
       " 'bai': 1,\n",
       " 'lordy,': 1,\n",
       " 'said,': 6,\n",
       " 'â€œi': 7,\n",
       " 'wonder': 16,\n",
       " 'animals': 5,\n",
       " 'cooperate': 1,\n",
       " 'movie.â€': 1,\n",
       " 'weâ€™re': 23,\n",
       " 'lion': 1,\n",
       " 'ğŸ’€ğŸ’€': 1,\n",
       " 'unemployment': 4,\n",
       " 'sucks': 5,\n",
       " 'dick': 12,\n",
       " 'believe': 33,\n",
       " 'himself': 15,\n",
       " 'power?': 7,\n",
       " 'hunker': 4,\n",
       " '@primevideo': 4,\n",
       " 'surprise!': 4,\n",
       " 'enjoy': 16,\n",
       " 'support!': 6,\n",
       " 'â€œnancy': 11,\n",
       " 'pelosi,': 20,\n",
       " 'person.': 17,\n",
       " 'leader.': 13,\n",
       " 'america': 53,\n",
       " 'hates': 18,\n",
       " 'career': 14,\n",
       " 'politicians,': 11,\n",
       " 'yourself.â€': 11,\n",
       " '@seanhannity': 13,\n",
       " 'totally': 15,\n",
       " 'incompetent': 11,\n",
       " 'left,': 18,\n",
       " 'pathetic': 11,\n",
       " 'puppet.': 12,\n",
       " 'washington': 21,\n",
       " 'job!': 11,\n",
       " '#iwouldswapanythingfor': 2,\n",
       " \"alzheimer's.\": 1,\n",
       " 'ğŸ˜¢': 6,\n",
       " 'morning,': 4,\n",
       " 'lil': 9,\n",
       " 'sht': 1,\n",
       " 'ruined': 3,\n",
       " 'guys': 67,\n",
       " '6pm': 19,\n",
       " 'ğŸ˜Š': 24,\n",
       " 'waiting': 34,\n",
       " 'lack': 3,\n",
       " 'videos!': 1,\n",
       " 'iâ€™ve': 57,\n",
       " 'charity': 5,\n",
       " 'stream!': 2,\n",
       " 'excited.': 2,\n",
       " 'charity.': 1,\n",
       " 'others.': 5,\n",
       " 'd&d.': 1,\n",
       " 'charity!': 2,\n",
       " 'tired': 20,\n",
       " 'liquor.': 1,\n",
       " 'dropped': 10,\n",
       " 'twice': 4,\n",
       " 'trying': 37,\n",
       " 'bed.': 4,\n",
       " 'ğŸ˜©ğŸ˜©ğŸ˜©': 3,\n",
       " 'questions': 10,\n",
       " 'emmanuel': 1,\n",
       " 'hudson': 1,\n",
       " 'wasnt': 2,\n",
       " '\\U0001f92f': 5,\n",
       " 'weâ€™ve': 10,\n",
       " 'while,': 1,\n",
       " 'realised': 3,\n",
       " 'friday,': 5,\n",
       " 'hereâ€™s': 8,\n",
       " 'todayâ€™s': 5,\n",
       " '#ff': 22,\n",
       " '@sharigledhill': 1,\n",
       " '@mrdavidmrian': 1,\n",
       " '@mstloveicecream': 1,\n",
       " '@seeshaunvlog': 1,\n",
       " '@nathanstaker1': 1,\n",
       " '@carmenandbrian': 1,\n",
       " '@broadwaysaway': 1,\n",
       " '@3_bigkids': 1,\n",
       " '@oohgaryc': 1,\n",
       " '@smithdisneyadv1': 1,\n",
       " '@gemark1605': 1,\n",
       " '@tangledupinfun': 1,\n",
       " 'purrmaids': 1,\n",
       " 'telegram': 1,\n",
       " 'stickers?': 1,\n",
       " 'toygershark': 1,\n",
       " 'request.': 1,\n",
       " 'particular': 2,\n",
       " 'requests': 1,\n",
       " 'commissions?': 1,\n",
       " 'again.': 24,\n",
       " 'positioning.': 1,\n",
       " 'blame': 8,\n",
       " 'governors': 6,\n",
       " 'late.': 3,\n",
       " \"he's\": 23,\n",
       " 'deflect': 1,\n",
       " 'blame.': 1,\n",
       " \"it's\": 93,\n",
       " 'responsibility': 4,\n",
       " 'presidency': 1,\n",
       " 'ğŸ˜ƒğŸ‘ŠğŸ‰ğŸ’¯': 1,\n",
       " 'specializes': 1,\n",
       " 'drawing': 2,\n",
       " 'horny': 19,\n",
       " 'fuck.': 5,\n",
       " 'letâ€™s': 20,\n",
       " 'honest': 26,\n",
       " '.@camila_cabelloâ€™s': 1,\n",
       " '@shawnmendesâ€™s': 1,\n",
       " 'â€œsenoritaâ€': 1,\n",
       " 'increase': 6,\n",
       " '126,810': 1,\n",
       " '990,810': 1,\n",
       " 'yesterday.': 4,\n",
       " 'liberate': 17,\n",
       " 'michigan....â€˜s': 1,\n",
       " 'grocery': 10,\n",
       " 'tyranny': 1,\n",
       " 'â€œhispanic': 1,\n",
       " 'foodsâ€': 1,\n",
       " 'aisles': 1,\n",
       " 'â€œtacoâ€': 1,\n",
       " 'kits': 2,\n",
       " 'paso': 2,\n",
       " 'canned': 1,\n",
       " 'goods.': 1,\n",
       " 'me!': 6,\n",
       " 'freedom!': 1,\n",
       " 'victory!': 1,\n",
       " 'tortillas!': 1,\n",
       " 'yall': 15,\n",
       " 'caucasians': 1,\n",
       " 'cancel': 9,\n",
       " '4th': 7,\n",
       " 'july?!!!!!': 1,\n",
       " 'sad': 23,\n",
       " 'hear': 32,\n",
       " 'betty': 3,\n",
       " 'white.': 2,\n",
       " 'sheâ€™ll': 2,\n",
       " 'missed.': 2,\n",
       " '#rip.': 2,\n",
       " '(sheâ€™s': 2,\n",
       " 'fine,': 5,\n",
       " 'practicing)': 2,\n",
       " 'dinner': 17,\n",
       " 'tonight?': 10,\n",
       " 'vaccine': 10,\n",
       " 'plague': 1,\n",
       " '@.': 1,\n",
       " 'nicely.': 1,\n",
       " 'thanks,': 1,\n",
       " 'everyone,': 4,\n",
       " 'participating': 5,\n",
       " 'week!': 1,\n",
       " '@beyondtype1': 1,\n",
       " '@beyondtype2': 1,\n",
       " 'kudos!': 1,\n",
       " 'rocked': 1,\n",
       " 'it.': 100,\n",
       " '#diabetesathome': 1,\n",
       " 'tonight,': 12,\n",
       " '6:00': 21,\n",
       " 'p.m.': 21,\n",
       " '(eastern),': 12,\n",
       " 'explain': 18,\n",
       " 'guidelines': 15,\n",
       " 'again!': 17,\n",
       " 'iâ€™m': 292,\n",
       " 'drunk': 8,\n",
       " 'asl': 1,\n",
       " 'g.': 1,\n",
       " 'everyday?': 1,\n",
       " 'reaction': 47,\n",
       " 'jeff': 3,\n",
       " 'okudah': 4,\n",
       " '3:': 5,\n",
       " 'ğŸ‘‡ğŸ‘‡ğŸ‘‡': 3,\n",
       " 'gallup:': 1,\n",
       " \"trump's\": 19,\n",
       " 'approval': 11,\n",
       " 'rating,': 1,\n",
       " '43%,': 1,\n",
       " 'slipped': 1,\n",
       " 'percentage': 1,\n",
       " 'mid-march': 1,\n",
       " '49%': 3,\n",
       " 'approval,': 1,\n",
       " 'tied': 1,\n",
       " 'best.': 2,\n",
       " '54%': 1,\n",
       " 'disapprove.': 1,\n",
       " 'hugs': 18,\n",
       " 'pls': 11,\n",
       " 'socialism': 2,\n",
       " 'people.': 21,\n",
       " 'afraid': 11,\n",
       " 'socialism,': 1,\n",
       " 'yourself!': 1,\n",
       " 'chairman': 1,\n",
       " 'hampton': 1,\n",
       " 'raffle': 2,\n",
       " 'nail': 2,\n",
       " 'supply': 1,\n",
       " 'haul!': 1,\n",
       " '$3': 1,\n",
       " 'posting': 14,\n",
       " 'too!': 9,\n",
       " 'excited!': 4,\n",
       " 'hope': 47,\n",
       " 'happy!': 1,\n",
       " 'sean': 2,\n",
       " 'penn,': 2,\n",
       " 'interviewed': 2,\n",
       " 'pandemic': 25,\n",
       " 'expert': 2,\n",
       " 'cnn,': 2,\n",
       " 'cuomo': 13,\n",
       " 'brothers': 4,\n",
       " 'remind': 5,\n",
       " 'kennedy': 3,\n",
       " 'brothers.': 2,\n",
       " \"i'd\": 18,\n",
       " 'everything...': 4,\n",
       " 'week?': 3,\n",
       " '\\U0001f97a': 19,\n",
       " '$1,200?': 1,\n",
       " 'friend.': 3,\n",
       " 'admit,': 1,\n",
       " 'kim': 2,\n",
       " 'clijstersâ€™': 1,\n",
       " 'comeback.': 1,\n",
       " 'mood': 10,\n",
       " 'rn.': 6,\n",
       " 'hoping': 1,\n",
       " 'fans': 13,\n",
       " 'cheer': 8,\n",
       " 'up.': 22,\n",
       " '@kdlafrance': 1,\n",
       " 'dtc': 1,\n",
       " 'glasses': 3,\n",
       " 'consultation?': 1,\n",
       " 'struggling': 11,\n",
       " 'moment?': 1,\n",
       " 'hug': 49,\n",
       " 'soul.': 1,\n",
       " 'spent': 15,\n",
       " '1.5': 2,\n",
       " 'deeply': 7,\n",
       " 'heartfelt,20': 1,\n",
       " 'duplicate.': 1,\n",
       " 'attch,i': 1,\n",
       " 'back,twitter': 1,\n",
       " 'relaunches': 1,\n",
       " 'itself,completely': 1,\n",
       " 'deleting': 3,\n",
       " 'work.': 11,\n",
       " 'shitty': 5,\n",
       " 'sftwar': 1,\n",
       " 'write.?': 1,\n",
       " '@officialmacrosw': 1,\n",
       " 'all!': 4,\n",
       " 'casie': 1,\n",
       " 'msw': 1,\n",
       " 'buffalo!': 1,\n",
       " 'confused,': 1,\n",
       " 'work!ğŸ˜€': 1,\n",
       " '#macrosw': 1,\n",
       " 'isnâ€™t': 17,\n",
       " 'game-style': 1,\n",
       " 'conveyer': 1,\n",
       " 'worthlessness.i': 1,\n",
       " 'itâ€™s': 134,\n",
       " 'illness,neurotransmitter': 1,\n",
       " 'imbalance,': 1,\n",
       " 'powerful.': 1,\n",
       " 'dissociation': 1,\n",
       " 'suicidal': 1,\n",
       " 'ideation': 1,\n",
       " 'days,': 10,\n",
       " 'canâ€™t': 65,\n",
       " 'inflict': 1,\n",
       " 'sucks?': 1,\n",
       " 'doubt': 3,\n",
       " 'soo': 1,\n",
       " 'stabbing': 2,\n",
       " 'back.': 11,\n",
       " 'surprisingly,': 1,\n",
       " 'hurts': 5,\n",
       " 'damn': 20,\n",
       " 'time.': 19,\n",
       " 'mutuals': 2,\n",
       " 'nearly': 7,\n",
       " '#phd': 1,\n",
       " '@ougradsch': 1,\n",
       " '@openuniversity': 1,\n",
       " 'undergrad': 4,\n",
       " 'prospectus': 1,\n",
       " 'latin?': 1,\n",
       " 'spanish?': 1,\n",
       " 'creative': 3,\n",
       " 'writing?': 1,\n",
       " 'choose?': 1,\n",
       " 'okay': 28,\n",
       " 'day.': 26,\n",
       " '$200': 7,\n",
       " 'hours.': 10,\n",
       " 'retweet': 25,\n",
       " '@jiggedio': 2,\n",
       " 'myself': 43,\n",
       " ':)': 11,\n",
       " 'car,': 2,\n",
       " 'limbaugh,': 2,\n",
       " 'synopsis': 2,\n",
       " 'heard:': 2,\n",
       " 'â€œok,': 2,\n",
       " 'gotta': 12,\n",
       " 'stop.': 4,\n",
       " 'shutdown': 4,\n",
       " 'continue.': 2,\n",
       " 'doesnâ€™t': 23,\n",
       " 'die.': 8,\n",
       " 'unemployed.': 2,\n",
       " 'enough!': 3,\n",
       " 'died.': 2,\n",
       " 'weâ€™ll': 5,\n",
       " 'adapt.â€': 2,\n",
       " 'millions': 8,\n",
       " 'nodded.': 2,\n",
       " 'happens': 8,\n",
       " 'spots': 5,\n",
       " 'says': 33,\n",
       " 'officials': 10,\n",
       " 'â€œwhack': 4,\n",
       " 'it...â€': 4,\n",
       " 'workstation': 1,\n",
       " 'gifted': 1,\n",
       " '@nagisakee': 1,\n",
       " 'omg': 10,\n",
       " ':d': 5,\n",
       " 'yâ€™all': 71,\n",
       " 'wearing': 10,\n",
       " 'deodorant': 1,\n",
       " 'ğŸ¤”': 15,\n",
       " 'wondering...': 1,\n",
       " 'underage,': 1,\n",
       " 'iâ€™d': 17,\n",
       " 'liquor': 5,\n",
       " 'hooked': 1,\n",
       " '#demilovatoisoverparty': 2,\n",
       " 'donâ€™t': 155,\n",
       " 'winters': 1,\n",
       " ';_;': 1,\n",
       " 'you.': 52,\n",
       " 'outs,': 1,\n",
       " 'third.': 1,\n",
       " 'means,': 1,\n",
       " 'sounds': 3,\n",
       " 'basebally.': 1,\n",
       " 'baseball': 3,\n",
       " 'general.': 4,\n",
       " 'covid-19,': 3,\n",
       " 'yankees': 2,\n",
       " 'nothing.': 4,\n",
       " 'potus*': 1,\n",
       " 'struck': 1,\n",
       " 'out.': 16,\n",
       " 'strikes,': 1,\n",
       " 'balls.': 1,\n",
       " 'mind.ğŸ˜œ': 1,\n",
       " 'idea': 11,\n",
       " 'is?': 5,\n",
       " 'ğŸ¦': 1,\n",
       " 'midnight': 1,\n",
       " '@kabzadesmall_': 1,\n",
       " '@aymos_shili': 1,\n",
       " '@mas_musiq': 1,\n",
       " '@daliwongasa': 1,\n",
       " 'mdu': 1,\n",
       " 'trp': 1,\n",
       " 'bongza': 1,\n",
       " 'madumane': 1,\n",
       " 'scorpion': 1,\n",
       " 'kings': 1,\n",
       " 'streaming': 10,\n",
       " 'â¤ï¸': 26,\n",
       " 'biggest': 9,\n",
       " 'roommate': 2,\n",
       " 'peeveâ€™s': 1,\n",
       " 'york': 4,\n",
       " 'morons': 1,\n",
       " 'york.': 1,\n",
       " 'glad': 6,\n",
       " 'discovered': 2,\n",
       " '#writingcommunity': 10,\n",
       " '\\U0001f970': 10,\n",
       " 'somehow': 4,\n",
       " 'followers': 26,\n",
       " '1000!': 1,\n",
       " 'ğŸ˜³': 9,\n",
       " 'amazing': 23,\n",
       " 'more!': 1,\n",
       " 'âœğŸ¼': 1,\n",
       " 'book/#wip': 1,\n",
       " 'iâ€™ll': 49,\n",
       " 'it!': 11,\n",
       " 'ğŸ˜ŠğŸ™ğŸ¼': 1,\n",
       " '#writerlift': 3,\n",
       " '#lockdown': 3,\n",
       " '#thursday': 1,\n",
       " '#thursdaymorning': 1,\n",
       " '#writer': 3,\n",
       " 'fiona': 6,\n",
       " 'zodiac': 1,\n",
       " 'â™ˆï¸:': 1,\n",
       " 'taste': 14,\n",
       " 'â™‰ï¸:': 1,\n",
       " 'â™Šï¸:': 1,\n",
       " 'â™‹ï¸:': 1,\n",
       " 'valentine': 1,\n",
       " 'â™Œï¸:': 1,\n",
       " 'â™ï¸:': 1,\n",
       " 'parting': 1,\n",
       " 'gift': 6,\n",
       " 'â™ï¸:': 1,\n",
       " 'â™ï¸:': 1,\n",
       " 'â™ï¸:': 1,\n",
       " 'â™‘ï¸:': 1,\n",
       " 'shadowboxer': 1,\n",
       " 'â™’ï¸:': 1,\n",
       " 'extraordinary': 1,\n",
       " 'â™“ï¸:': 1,\n",
       " 'promise': 2,\n",
       " '@prez': 1,\n",
       " 'cowboys.': 1,\n",
       " \"let's\": 18,\n",
       " 'happen.': 1,\n",
       " 'you,': 18,\n",
       " '@howaboutafresca?': 1,\n",
       " 'person:': 1,\n",
       " 'hurt': 9,\n",
       " 'feelings?': 1,\n",
       " 'brain:': 1,\n",
       " 'heart:': 1,\n",
       " 'guts:': 1,\n",
       " 'mouth.': 2,\n",
       " '\"nope\"': 1,\n",
       " 'gimme': 5,\n",
       " 'h*ll': 1,\n",
       " 'youâ€™re': 56,\n",
       " 'humble': 1,\n",
       " 'correspondent': 1,\n",
       " 'venues': 1,\n",
       " 'across': 12,\n",
       " 'it,': 14,\n",
       " 'thereâ€™s': 15,\n",
       " 'forever': 9,\n",
       " 'gonna': 44,\n",
       " 'grateful': 2,\n",
       " 'landed': 4,\n",
       " 'have,': 2,\n",
       " 'ğŸ’œ': 9,\n",
       " 'howdy': 1,\n",
       " 'ğŸ‘‹ğŸ‘‹.': 1,\n",
       " 'friday': 9,\n",
       " '43rd': 2,\n",
       " 'april.': 3,\n",
       " 'boosie': 1,\n",
       " 'walked': 3,\n",
       " 'tory': 4,\n",
       " 'lanez': 1,\n",
       " 'shout': 7,\n",
       " '\"weird\"': 1,\n",
       " 'christian': 4,\n",
       " 'youth': 1,\n",
       " 'groups.': 1,\n",
       " 'turns': 2,\n",
       " \"you're\": 48,\n",
       " 'queer.': 1,\n",
       " 'annoying': 8,\n",
       " 'tonight': 23,\n",
       " 'touched': 3,\n",
       " 'so......it': 1,\n",
       " 'knowing': 3,\n",
       " 'ğŸ˜¬': 3,\n",
       " 'epic.': 1,\n",
       " 'fail.': 1,\n",
       " 'ğŸ¤¦ğŸ»\\u200dâ™€ï¸': 1,\n",
       " 'chore.': 1,\n",
       " 'cancun': 1,\n",
       " 'go.': 4,\n",
       " 'cringe': 5,\n",
       " 'aidan': 1,\n",
       " 'talks': 3,\n",
       " 'softly': 1,\n",
       " 'falling': 4,\n",
       " 'asleepğŸ˜­': 1,\n",
       " 'cuomo:': 2,\n",
       " '\"\\'it\\'s': 2,\n",
       " \"states'\": 2,\n",
       " 'reopen.': 4,\n",
       " 'states.': 7,\n",
       " 'what,': 2,\n",
       " 'grant': 3,\n",
       " 'constitution': 2,\n",
       " 'gave': 36,\n",
       " 'born?': 2,\n",
       " '10th': 2,\n",
       " 'amendment.': 8,\n",
       " \"didn't\": 28,\n",
       " 'governor.\"': 2,\n",
       " 'capitalism!': 1,\n",
       " 'lose': 15,\n",
       " 'chains!': 1,\n",
       " \"would've\": 2,\n",
       " 'minutes': 19,\n",
       " 'sooner,': 1,\n",
       " \"could've\": 1,\n",
       " 'rona': 2,\n",
       " ':-)': 2,\n",
       " 'alright': 4,\n",
       " 'bite:': 1,\n",
       " 'apple?': 2,\n",
       " 'mum': 8,\n",
       " 'caught': 5,\n",
       " 'porn': 10,\n",
       " 'embarrassed': 2,\n",
       " 'china': 28,\n",
       " '\"fulfill': 2,\n",
       " 'obligations\"': 2,\n",
       " 'organization': 3,\n",
       " 'restore': 2,\n",
       " 'fulfill': 2,\n",
       " 'obligations': 2,\n",
       " 'damages': 2,\n",
       " '22.5': 2,\n",
       " 'americans': 19,\n",
       " 'virus': 18,\n",
       " 'unleashed': 4,\n",
       " 'agree!': 2,\n",
       " 'eastern.': 9,\n",
       " 'you!': 13,\n",
       " '@zayenachobae': 1,\n",
       " 'tatted?': 1,\n",
       " 'now,': 22,\n",
       " 'took': 16,\n",
       " 'fedex': 1,\n",
       " 'not.': 5,\n",
       " '3-8:30': 1,\n",
       " 'fucking': 53,\n",
       " 'tired.': 4,\n",
       " 'niggas': 14,\n",
       " 'yearsss': 1,\n",
       " 'truly': 11,\n",
       " 'dont': 20,\n",
       " 'quiting': 1,\n",
       " 'june': 5,\n",
       " 'ğŸ˜“': 3,\n",
       " 'wrestling': 5,\n",
       " 'unnecessary': 3,\n",
       " 'honestly.': 1,\n",
       " 'idiot': 3,\n",
       " 'prereq': 1,\n",
       " 'licensure': 1,\n",
       " 'exam.': 1,\n",
       " 'snapchat': 2,\n",
       " 'cheating': 3,\n",
       " 'together.': 8,\n",
       " 'â€˜eh': 1,\n",
       " 'whatev,': 1,\n",
       " 'weird': 16,\n",
       " 'timeâ€™': 1,\n",
       " 'rly': 1,\n",
       " 'annoy': 4,\n",
       " 'me.': 46,\n",
       " 'professor': 5,\n",
       " 'bounced': 1,\n",
       " 'moots': 3,\n",
       " 'non-moots.': 1,\n",
       " 'decided': 17,\n",
       " 'cutie': 1,\n",
       " 'yea': 3,\n",
       " 'journey': 2,\n",
       " 'cutie.': 1,\n",
       " 'youre': 6,\n",
       " 'family.': 3,\n",
       " 'monday-': 1,\n",
       " 'okay,': 5,\n",
       " '44.5k': 1,\n",
       " 'novel': 2,\n",
       " 'now.': 42,\n",
       " '48k': 1,\n",
       " 'weekend.': 6,\n",
       " '3.5k': 1,\n",
       " 'edits': 1,\n",
       " 'sunday': 4,\n",
       " 'night.': 11,\n",
       " \"that's\": 27,\n",
       " 'do-able,': 1,\n",
       " 'right?': 15,\n",
       " 'accomplished': 2,\n",
       " 'moment.': 10,\n",
       " 'announce': 5,\n",
       " 'tweet': 39,\n",
       " 'addressing': 2,\n",
       " 'coronavirus.': 5,\n",
       " 'whenever': 4,\n",
       " 'day...': 2,\n",
       " 'somewhere': 3,\n",
       " \"behar's\": 1,\n",
       " 'gynecologist!': 1,\n",
       " 'anyone': 72,\n",
       " 'wanna': 53,\n",
       " 'brawler': 1,\n",
       " 'season?': 2,\n",
       " 'me...': 1,\n",
       " '#grinding': 1,\n",
       " '#staysafestayhome': 1,\n",
       " 'folks': 10,\n",
       " '#nbc': 1,\n",
       " 'ğŸ†': 1,\n",
       " '@nabthedentist': 1,\n",
       " '@iamriaz381': 1,\n",
       " '@jafriume': 1,\n",
       " '@laibaooe': 1,\n",
       " '@noor_pareesa': 1,\n",
       " '@made4pakistan': 1,\n",
       " '@make4pakistan': 1,\n",
       " '@mughazzal': 1,\n",
       " '@sawerasheikh12': 1,\n",
       " '@sanashah01': 1,\n",
       " '@rashkehina10': 1,\n",
       " '@hinakhan120': 1,\n",
       " '@coward_citizen': 1,\n",
       " '@agent381': 1,\n",
       " '@idresi1': 1,\n",
       " '@raokawish4': 1,\n",
       " '@ahmadsultan638': 1,\n",
       " '@afzalmalik381': 1,\n",
       " '@taskheer786pti': 1,\n",
       " 'rt,f&get': 1,\n",
       " 'magical': 2,\n",
       " 'featuring': 3,\n",
       " 'all-star': 1,\n",
       " 'cast:': 1,\n",
       " 'james': 3,\n",
       " 'corden,': 1,\n",
       " 'judi': 1,\n",
       " 'dench,': 1,\n",
       " 'jason': 4,\n",
       " 'derulo,': 1,\n",
       " 'idris': 1,\n",
       " 'elba': 1,\n",
       " 'jennifer': 1,\n",
       " 'hudson,': 1,\n",
       " 'mckellen,': 1,\n",
       " 'taylor': 4,\n",
       " 'swift,': 1,\n",
       " 'rebel': 1,\n",
       " 'wilson': 1,\n",
       " 'introducing': 2,\n",
       " 'francesca': 1,\n",
       " 'hayward.': 1,\n",
       " 'instantly.': 1,\n",
       " 'wtf': 7,\n",
       " 'saying': 33,\n",
       " 'hotter': 3,\n",
       " 'spoon': 2,\n",
       " 'demi': 1,\n",
       " 'lovatoâ€™s': 1,\n",
       " 'crib': 1,\n",
       " 'ğŸ’€': 4,\n",
       " 'lockdown': 31,\n",
       " 'wonâ€™t': 19,\n",
       " 'beards': 2,\n",
       " 'ğŸ’€ğŸ’”': 2,\n",
       " 'mum.': 1,\n",
       " \"can't\": 45,\n",
       " 'her.': 11,\n",
       " 'nurse,': 1,\n",
       " 'understood': 1,\n",
       " 'deal.': 1,\n",
       " 'sister': 8,\n",
       " 'line.': 3,\n",
       " 'them.': 12,\n",
       " 'alone.': 4,\n",
       " 'knew': 10,\n",
       " 'down.': 5,\n",
       " 'tomorrow': 25,\n",
       " 'better.': 22,\n",
       " 'covid': 19,\n",
       " 'greater': 1,\n",
       " '100ft': 1,\n",
       " 'tds': 1,\n",
       " 'stands': 6,\n",
       " 'funny': 19,\n",
       " 'hobby': 1,\n",
       " 'stuck': 4,\n",
       " 'home?': 3,\n",
       " '@lexiiik9': 1,\n",
       " 'liking': 3,\n",
       " 'tweets....': 1,\n",
       " 'honesty:': 1,\n",
       " 'hospitals': 4,\n",
       " 'week.': 12,\n",
       " 'havenâ€™t': 5,\n",
       " 'worried': 10,\n",
       " 'scared': 8,\n",
       " 'wks.': 1,\n",
       " 'hiv/aids,': 1,\n",
       " 'cdiff,': 1,\n",
       " 'mrsa,': 1,\n",
       " 'tb,': 1,\n",
       " 'pseudomonas,': 1,\n",
       " 'etc...': 1,\n",
       " 'protection.': 2,\n",
       " 'virus.': 10,\n",
       " 'scares': 1,\n",
       " 'home.': 14,\n",
       " 'murray': 2,\n",
       " 'djokovic': 1,\n",
       " 'instagram.': 1,\n",
       " 'innovation.': 1,\n",
       " 'improved': 2,\n",
       " 'least': 20,\n",
       " 'sport': 2,\n",
       " 'restocked': 1,\n",
       " 'copies': 1,\n",
       " 'refunded?!': 1,\n",
       " 'love.': 3,\n",
       " 'tiktok': 8,\n",
       " 'immediately': 9,\n",
       " 'sus': 1,\n",
       " 'guys,': 15,\n",
       " 'if,': 2,\n",
       " 'covid19,': 2,\n",
       " '80%': 4,\n",
       " 'salary,': 3,\n",
       " 'emails...': 1,\n",
       " 'pres.': 1,\n",
       " 'feb.': 1,\n",
       " '26,': 1,\n",
       " '2020.': 3,\n",
       " '\"the': 8,\n",
       " 'doctors': 31,\n",
       " 'fairly': 1,\n",
       " 'rapidly.â€': 1,\n",
       " 'averaged': 3,\n",
       " 'watched': 8,\n",
       " '<3': 3,\n",
       " 'motivations': 1,\n",
       " 'please:`<': 1,\n",
       " 'note,': 1,\n",
       " '@starbucks': 1,\n",
       " 'upppppppp': 1,\n",
       " 'book!': 1,\n",
       " 'hours!': 2,\n",
       " 'gif\\U0001f92f': 1,\n",
       " 'cuddle': 4,\n",
       " '\\U0001f97aâ˜¹ï¸': 1,\n",
       " 'filthy': 1,\n",
       " 'â€œsomething': 1,\n",
       " 'on:': 1,\n",
       " 'say?': 3,\n",
       " 'michael': 5,\n",
       " 'scott': 2,\n",
       " 'storyâ€': 1,\n",
       " 'by:': 2,\n",
       " 'dwight': 1,\n",
       " 'schrute': 1,\n",
       " 'fun,': 3,\n",
       " 'portland.': 1,\n",
       " 'burrito': 1,\n",
       " 'bowls': 1,\n",
       " 'montana.': 1,\n",
       " 'whole': 34,\n",
       " 'boyfriend': 15,\n",
       " 'youtuber???????': 1,\n",
       " '#jews': 1,\n",
       " 'kvetch': 1,\n",
       " '#netflix': 1,\n",
       " '#unorthodox': 1,\n",
       " 'portraying': 1,\n",
       " 'hasidic': 1,\n",
       " '100%': 6,\n",
       " 'accuracy,': 1,\n",
       " 'saddened': 3,\n",
       " 'shocked': 2,\n",
       " '#fauda': 1,\n",
       " \"isn't\": 16,\n",
       " 'either.': 1,\n",
       " 'merely': 2,\n",
       " 'productions': 1,\n",
       " 'meant': 4,\n",
       " 'entertainment': 3,\n",
       " 'magat': 2,\n",
       " 'talked': 2,\n",
       " 'nobody': 16,\n",
       " 'sucks.': 4,\n",
       " 'happy\\U0001f970': 1,\n",
       " 'off,': 3,\n",
       " 'drunk?': 1,\n",
       " 'xbox': 2,\n",
       " 'games.': 2,\n",
       " 'gates': 22,\n",
       " 'covid-19': 43,\n",
       " 'vaccine?': 16,\n",
       " 'bidenâ€™s': 1,\n",
       " 'progressive': 3,\n",
       " 'color.': 1,\n",
       " 'carti': 5,\n",
       " 'lmao': 5,\n",
       " 'dumb': 3,\n",
       " 'things,': 3,\n",
       " 'defunding': 1,\n",
       " 'winner.': 3,\n",
       " '\"china': 1,\n",
       " 'raises': 1,\n",
       " 'coronavirus': 36,\n",
       " 'toll': 7,\n",
       " 'wuhan': 4,\n",
       " '50%\"': 1,\n",
       " 'yeah?': 1,\n",
       " 'shit.': 5,\n",
       " \"they're\": 14,\n",
       " 'do,': 2,\n",
       " \"remember...they're\": 1,\n",
       " 'lying.': 2,\n",
       " 'ğŸ‘€': 12,\n",
       " 'helping': 13,\n",
       " '20,000': 1,\n",
       " 'followers.': 3,\n",
       " 're-elect': 3,\n",
       " '@realdonaldtrump': 19,\n",
       " 'encourage': 3,\n",
       " 'others': 10,\n",
       " 'last.': 2,\n",
       " 'years!': 1,\n",
       " 'gifs': 23,\n",
       " 'dizzy.': 1,\n",
       " 'sappy': 1,\n",
       " 'commercials,': 2,\n",
       " 'wailing,': 1,\n",
       " 'submissive': 1,\n",
       " 'terrified': 2,\n",
       " 'morons,': 1,\n",
       " 'ridiculous': 4,\n",
       " 'conferences,': 1,\n",
       " 'countsâ€”': 1,\n",
       " '#reopenamerica': 4,\n",
       " 'following': 36,\n",
       " 'suggestions!': 1,\n",
       " 'flavor': 1,\n",
       " 'popsicle': 1,\n",
       " 'choices': 1,\n",
       " 'red,': 2,\n",
       " 'orange,': 2,\n",
       " 'purple': 2,\n",
       " 'decision': 9,\n",
       " 'answer.': 1,\n",
       " 'dependable': 24,\n",
       " 'oz.': 24,\n",
       " 'go!': 25,\n",
       " 'pussy.': 3,\n",
       " 'lie!': 2,\n",
       " 'dedicate': 1,\n",
       " 'spanish': 1,\n",
       " 'iâ€˜m': 2,\n",
       " 'obsessed': 1,\n",
       " 'heartbreak': 1,\n",
       " 'last?': 1,\n",
       " '#gettoknowyourcustomersday': 1,\n",
       " 'doing.': 1,\n",
       " 'emojis': 2,\n",
       " 'ğŸ‘‡': 10,\n",
       " 'kicking': 3,\n",
       " 'trumps': 1,\n",
       " 'ass!': 1,\n",
       " 'thatâ€™s': 41,\n",
       " 'governor!!!': 1,\n",
       " '#cuomo': 1,\n",
       " 'lmaooo': 2,\n",
       " 'yâ€™all.': 3,\n",
       " 'dms': 5,\n",
       " 'guess': 21,\n",
       " 'â€œposting': 1,\n",
       " 'enoughâ€': 1,\n",
       " 'outfit': 1,\n",
       " 'excited': 14,\n",
       " 'ğŸ˜…': 7,\n",
       " 'wanted': 27,\n",
       " 'apartment': 3,\n",
       " 'ğŸ˜©\\U0001f97a': 1,\n",
       " 'birthday': 23,\n",
       " 'today.': 45,\n",
       " 'whoo.': 1,\n",
       " 'so..': 1,\n",
       " 'tik': 3,\n",
       " 'tok?!': 1,\n",
       " 'go?': 2,\n",
       " 'ğŸ¤·ğŸ»\\u200dâ™€ï¸': 3,\n",
       " 'haircut.': 2,\n",
       " 'selfie.': 2,\n",
       " 'florida': 3,\n",
       " 'panhandle': 1,\n",
       " 'supermarket': 3,\n",
       " 'freezer': 2,\n",
       " 'decent': 3,\n",
       " 'toilet': 7,\n",
       " 'shelves': 2,\n",
       " 'today!': 8,\n",
       " '#coronawillendsoon': 3,\n",
       " 'thats': 4,\n",
       " 'tweet.': 4,\n",
       " 'tweeted': 3,\n",
       " 'buying': 9,\n",
       " 'tennessee': 2,\n",
       " 'teammates.': 2,\n",
       " 'doing,': 2,\n",
       " 'building.': 2,\n",
       " 'boots': 2,\n",
       " 'ground.': 3,\n",
       " 'humans,': 2,\n",
       " 'gsp': 2,\n",
       " 'khabib': 3,\n",
       " 'fight??': 1,\n",
       " 'retired': 1,\n",
       " 'prime..': 1,\n",
       " 'titleholder': 1,\n",
       " 'life..': 1,\n",
       " 'itâ€™d': 1,\n",
       " 'slightly': 4,\n",
       " '5-10': 2,\n",
       " 'q&a': 2,\n",
       " 'year..?': 1,\n",
       " 'ğŸ’¤': 2,\n",
       " '@petsmart': 1,\n",
       " 'sells': 1,\n",
       " 'giraffes?': 1,\n",
       " 'so,': 9,\n",
       " 'deliver': 4,\n",
       " 'curbside': 1,\n",
       " 'pickup?': 1,\n",
       " 'cricket': 1,\n",
       " 'ğŸ’™ğŸ˜»': 1,\n",
       " 'trainer': 1,\n",
       " 'macho': 1,\n",
       " 'randy': 1,\n",
       " 'savage.': 1,\n",
       " 'recommended': 2,\n",
       " 'properly': 3,\n",
       " 'diet': 3,\n",
       " 'steroids': 1,\n",
       " 'cocaine.ğŸ¤”': 1,\n",
       " 'careful': 2,\n",
       " 'consideration,': 1,\n",
       " 'vulgar': 1,\n",
       " 'ğŸ˜­': 24,\n",
       " 'vulnerable': 3,\n",
       " 'other,': 2,\n",
       " 'advice.': 8,\n",
       " 'tempted': 2,\n",
       " 'selfies': 1,\n",
       " 'photos.': 2,\n",
       " 'distance,': 2,\n",
       " 'residents': 1,\n",
       " ...}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unknown_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean weird punctuations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No significantly improve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_weird(text):\n",
    "    specials = [\"â€™\", \"â€˜\", \"Â´\", \"`\"]\n",
    "    text = text.replace(\"â€™\", \"'\")\n",
    "    text = text.replace(\"â€˜\", \"'\")\n",
    "    text = text.replace(\"Â´\", \"'\")\n",
    "    text = text.replace(\"`\", \"'\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['text'] = df_train.text.apply(clean_weird)\n",
    "df_train['reply'] = df_train.reply.apply(clean_weird)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev['text'] = df_dev.text.apply(clean_weird)\n",
    "df_dev['reply'] = df_dev.reply.apply(clean_weird)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train text unique vocab count is: 68710\n",
      "train reply unique vocab count is: 25436\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=68710.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 8.211% (5642 / 68710) of vocab\n",
      "Found embeddings for 65.987% (432193 / 654963) of all text\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=25436.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 14.519% (3693 / 25436) of vocab\n",
      "Found embeddings for 63.200% (68506 / 108395) of all text\n"
     ]
    }
   ],
   "source": [
    "train_text_vocab = get_vocab(df_train['text'].values)\n",
    "train_reply_vocab = get_vocab(df_train['reply'].values)\n",
    "print(\"train text unique vocab count is: {}\".format(len(train_text_vocab)))\n",
    "print(\"train reply unique vocab count is: {}\".format(len(train_reply_vocab)))\n",
    "unknown_text = check_coverage(train_text_vocab, roberta_vocab)\n",
    "print()\n",
    "unknown_reply = check_coverage(train_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev text unique vocab count is: 15821\n",
      "dev reply unique vocab count is: 4789\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=15821.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 14.835% (2347 / 15821) of vocab\n",
      "Found embeddings for 65.688% (54503 / 82972) of all text\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=4789.0, style=ProgressStyle(description_â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 24.577% (1177 / 4789) of vocab\n",
      "Found embeddings for 63.082% (8728 / 13836) of all text\n"
     ]
    }
   ],
   "source": [
    "dev_text_vocab = get_vocab_lower(df_dev['text'].values)\n",
    "dev_reply_vocab = get_vocab_lower(df_dev['reply'].values)\n",
    "print(\"dev text unique vocab count is: {}\".format(len(dev_text_vocab)))\n",
    "print(\"dev reply unique vocab count is: {}\".format(len(dev_reply_vocab)))\n",
    "unknown_text = check_coverage(dev_text_vocab, roberta_vocab)\n",
    "print()\n",
    "unknown_reply = check_coverage(dev_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform apostrophes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "apostrophes = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\" }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_apostrophes(text):\n",
    "    # Replace apostrophes to original term\n",
    "    for key in apostrophes.keys():\n",
    "        text = text.replace(key, apostrophes[key])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train['text'] = df_train.text.apply(change_apostrophes)\n",
    "df_train['reply'] = df_train.reply.apply(change_apostrophes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev['text'] = df_dev.text.apply(change_apostrophes)\n",
    "df_dev['reply'] = df_dev.reply.apply(change_apostrophes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train text unique vocab count is: 68558\n",
      "train reply unique vocab count is: 25352\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=68558.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 8.230% (5642 / 68558) of vocab\n",
      "Found embeddings for 68.765% (460202 / 669242) of all text\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=25352.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 14.571% (3694 / 25352) of vocab\n",
      "Found embeddings for 66.097% (73228 / 110789) of all text\n"
     ]
    }
   ],
   "source": [
    "train_text_vocab = get_vocab(df_train['text'].values)\n",
    "train_reply_vocab = get_vocab(df_train['reply'].values)\n",
    "print(\"train text unique vocab count is: {}\".format(len(train_text_vocab)))\n",
    "print(\"train reply unique vocab count is: {}\".format(len(train_reply_vocab)))\n",
    "unknown_text = check_coverage(train_text_vocab, roberta_vocab)\n",
    "print()\n",
    "unknown_reply = check_coverage(train_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev text unique vocab count is: 15783\n",
      "dev reply unique vocab count is: 4763\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=15783.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 14.883% (2349 / 15783) of vocab\n",
      "Found embeddings for 68.515% (58102 / 84802) of all text\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=4763.0, style=ProgressStyle(description_â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 24.711% (1177 / 4763) of vocab\n",
      "Found embeddings for 66.087% (9352 / 14151) of all text\n"
     ]
    }
   ],
   "source": [
    "dev_text_vocab = get_vocab_lower(df_dev['text'].values)\n",
    "dev_reply_vocab = get_vocab_lower(df_dev['reply'].values)\n",
    "print(\"dev text unique vocab count is: {}\".format(len(dev_text_vocab)))\n",
    "print(\"dev reply unique vocab count is: {}\".format(len(dev_reply_vocab)))\n",
    "unknown_text = check_coverage(dev_text_vocab, roberta_vocab)\n",
    "print()\n",
    "unknown_reply = check_coverage(dev_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'app,': 23,\n",
       " 'hashtag': 23,\n",
       " '#bailouthumansnow': 24,\n",
       " 'interviewing': 1,\n",
       " 'incredible': 5,\n",
       " 'exciting': 8,\n",
       " 'soil': 1,\n",
       " 'microbes': 1,\n",
       " 'grasslands,': 1,\n",
       " 'proud': 18,\n",
       " 'phd': 4,\n",
       " 'university': 5,\n",
       " 'kansas': 1,\n",
       " 'dr.': 72,\n",
       " 'jim': 2,\n",
       " 'bever': 1,\n",
       " 'fellow!!': 1,\n",
       " 'gtc': 1,\n",
       " 'festival': 1,\n",
       " 'happening': 4,\n",
       " 'jus': 3,\n",
       " 'confirmation': 1,\n",
       " 'bai': 1,\n",
       " 'lordy,': 1,\n",
       " 'said,': 6,\n",
       " 'â€œi': 9,\n",
       " 'wonder': 16,\n",
       " 'animals': 5,\n",
       " 'cooperate': 1,\n",
       " 'movie.â€': 1,\n",
       " \"we're\": 15,\n",
       " 'lion': 1,\n",
       " 'ğŸ’€ğŸ’€': 1,\n",
       " 'unemployment': 4,\n",
       " 'sucks': 5,\n",
       " 'dick': 12,\n",
       " 'believe': 33,\n",
       " 'himself': 15,\n",
       " 'power?': 7,\n",
       " 'hunker': 4,\n",
       " '@primevideo': 4,\n",
       " 'surprise!': 4,\n",
       " 'enjoy': 16,\n",
       " 'support!': 6,\n",
       " 'â€œnancy': 11,\n",
       " 'pelosi,': 20,\n",
       " 'person.': 17,\n",
       " 'leader.': 13,\n",
       " 'america': 53,\n",
       " 'hates': 18,\n",
       " 'career': 14,\n",
       " 'politicians,': 11,\n",
       " 'yourself.â€': 11,\n",
       " '@seanhannity': 13,\n",
       " 'totally': 15,\n",
       " 'incompetent': 11,\n",
       " 'left,': 18,\n",
       " 'pathetic': 11,\n",
       " 'puppet.': 12,\n",
       " 'washington': 21,\n",
       " 'job!': 11,\n",
       " '#iwouldswapanythingfor': 2,\n",
       " \"alzheimer's.\": 1,\n",
       " 'ğŸ˜¢': 6,\n",
       " 'morning,': 4,\n",
       " 'lil': 9,\n",
       " 'sht': 1,\n",
       " 'ruined': 3,\n",
       " 'guys': 67,\n",
       " '6pm': 19,\n",
       " 'ğŸ˜Š': 24,\n",
       " 'waiting': 34,\n",
       " 'lack': 3,\n",
       " 'videos!': 1,\n",
       " 'charity': 5,\n",
       " 'stream!': 2,\n",
       " 'excited.': 2,\n",
       " 'charity.': 1,\n",
       " 'others.': 5,\n",
       " 'd&d.': 1,\n",
       " 'charity!': 2,\n",
       " 'tired': 20,\n",
       " 'liquor.': 1,\n",
       " 'dropped': 10,\n",
       " 'twice': 4,\n",
       " 'trying': 37,\n",
       " 'bed.': 4,\n",
       " 'ğŸ˜©ğŸ˜©ğŸ˜©': 3,\n",
       " 'questions': 10,\n",
       " 'emmanuel': 1,\n",
       " 'hudson': 1,\n",
       " 'wasnt': 2,\n",
       " '\\U0001f92f': 5,\n",
       " \"we've\": 5,\n",
       " 'while,': 1,\n",
       " 'realised': 3,\n",
       " 'friday,': 5,\n",
       " \"today's\": 11,\n",
       " '#ff': 22,\n",
       " '@sharigledhill': 1,\n",
       " '@mrdavidmrian': 1,\n",
       " '@mstloveicecream': 1,\n",
       " '@seeshaunvlog': 1,\n",
       " '@nathanstaker1': 1,\n",
       " '@carmenandbrian': 1,\n",
       " '@broadwaysaway': 1,\n",
       " '@3_bigkids': 1,\n",
       " '@oohgaryc': 1,\n",
       " '@smithdisneyadv1': 1,\n",
       " '@gemark1605': 1,\n",
       " '@tangledupinfun': 1,\n",
       " 'purrmaids': 1,\n",
       " 'telegram': 1,\n",
       " 'stickers?': 1,\n",
       " 'toygershark': 1,\n",
       " 'request.': 1,\n",
       " 'particular': 2,\n",
       " 'requests': 1,\n",
       " 'commissions?': 1,\n",
       " 'again.': 24,\n",
       " 'positioning.': 1,\n",
       " 'blame': 8,\n",
       " 'governors': 6,\n",
       " 'late.': 3,\n",
       " \"he's\": 12,\n",
       " 'deflect': 1,\n",
       " 'blame.': 1,\n",
       " \"it's\": 86,\n",
       " 'responsibility': 4,\n",
       " 'presidency': 1,\n",
       " 'ğŸ˜ƒğŸ‘ŠğŸ‰ğŸ’¯': 1,\n",
       " 'specializes': 1,\n",
       " 'drawing': 2,\n",
       " 'horny': 19,\n",
       " 'fuck.': 5,\n",
       " 'honest': 26,\n",
       " \".@camila_cabello's\": 1,\n",
       " \"@shawnmendes's\": 1,\n",
       " 'â€œsenoritaâ€': 1,\n",
       " 'increase': 6,\n",
       " '126,810': 1,\n",
       " '990,810': 1,\n",
       " 'yesterday.': 4,\n",
       " 'liberate': 17,\n",
       " \"michigan....'s\": 1,\n",
       " 'grocery': 10,\n",
       " 'tyranny': 1,\n",
       " 'â€œhispanic': 1,\n",
       " 'foodsâ€': 1,\n",
       " 'aisles': 1,\n",
       " 'â€œtacoâ€': 1,\n",
       " 'kits': 2,\n",
       " 'paso': 2,\n",
       " 'canned': 1,\n",
       " 'goods.': 1,\n",
       " 'me!': 6,\n",
       " 'freedom!': 1,\n",
       " 'victory!': 1,\n",
       " 'tortillas!': 1,\n",
       " 'yall': 15,\n",
       " 'caucasians': 1,\n",
       " 'cancel': 9,\n",
       " '4th': 7,\n",
       " 'july?!!!!!': 1,\n",
       " 'sad': 23,\n",
       " 'hear': 32,\n",
       " 'betty': 3,\n",
       " 'white.': 2,\n",
       " 'missed.': 2,\n",
       " '#rip.': 2,\n",
       " '(she': 2,\n",
       " 'fine,': 5,\n",
       " 'practicing)': 2,\n",
       " 'dinner': 17,\n",
       " 'tonight?': 10,\n",
       " 'vaccine': 10,\n",
       " 'plague': 1,\n",
       " '@.': 1,\n",
       " 'nicely.': 1,\n",
       " 'thanks,': 1,\n",
       " 'everyone,': 4,\n",
       " 'participating': 5,\n",
       " 'week!': 1,\n",
       " '@beyondtype1': 1,\n",
       " '@beyondtype2': 1,\n",
       " 'kudos!': 1,\n",
       " 'rocked': 1,\n",
       " 'it.': 100,\n",
       " '#diabetesathome': 1,\n",
       " 'tonight,': 12,\n",
       " '6:00': 21,\n",
       " 'p.m.': 21,\n",
       " '(eastern),': 12,\n",
       " 'explain': 18,\n",
       " 'guidelines': 15,\n",
       " 'again!': 17,\n",
       " 'drunk': 8,\n",
       " 'asl': 1,\n",
       " 'g.': 1,\n",
       " 'everyday?': 1,\n",
       " 'reaction': 47,\n",
       " 'jeff': 3,\n",
       " 'okudah': 4,\n",
       " '3:': 5,\n",
       " 'ğŸ‘‡ğŸ‘‡ğŸ‘‡': 3,\n",
       " 'gallup:': 1,\n",
       " \"trump's\": 28,\n",
       " 'approval': 11,\n",
       " 'rating,': 1,\n",
       " '43%,': 1,\n",
       " 'slipped': 1,\n",
       " 'percentage': 1,\n",
       " 'mid-march': 1,\n",
       " '49%': 3,\n",
       " 'approval,': 1,\n",
       " 'tied': 1,\n",
       " 'best.': 2,\n",
       " '54%': 1,\n",
       " 'disapprove.': 1,\n",
       " 'hugs': 18,\n",
       " 'pls': 11,\n",
       " 'socialism': 2,\n",
       " 'people.': 21,\n",
       " 'afraid': 11,\n",
       " 'socialism,': 1,\n",
       " 'yourself!': 1,\n",
       " 'chairman': 1,\n",
       " 'hampton': 1,\n",
       " 'raffle': 2,\n",
       " 'nail': 2,\n",
       " 'supply': 1,\n",
       " 'haul!': 1,\n",
       " '$3': 1,\n",
       " 'posting': 14,\n",
       " 'too!': 9,\n",
       " 'excited!': 4,\n",
       " 'hope': 47,\n",
       " 'happy!': 1,\n",
       " 'sean': 2,\n",
       " 'penn,': 2,\n",
       " 'interviewed': 2,\n",
       " 'pandemic': 25,\n",
       " 'expert': 2,\n",
       " 'cnn,': 2,\n",
       " 'cuomo': 13,\n",
       " 'brothers': 4,\n",
       " 'remind': 5,\n",
       " 'kennedy': 3,\n",
       " 'brothers.': 2,\n",
       " 'everything...': 4,\n",
       " 'week?': 3,\n",
       " '\\U0001f97a': 19,\n",
       " '$1,200?': 1,\n",
       " 'friend.': 3,\n",
       " 'admit,': 1,\n",
       " 'kim': 2,\n",
       " \"clijsters'\": 1,\n",
       " 'comeback.': 1,\n",
       " 'mood': 10,\n",
       " 'rn.': 6,\n",
       " 'hoping': 1,\n",
       " 'fans': 13,\n",
       " 'cheer': 8,\n",
       " 'up.': 22,\n",
       " '@kdlafrance': 1,\n",
       " 'dtc': 1,\n",
       " 'glasses': 3,\n",
       " 'consultation?': 1,\n",
       " 'struggling': 11,\n",
       " 'moment?': 1,\n",
       " 'hug': 49,\n",
       " 'soul.': 1,\n",
       " 'spent': 15,\n",
       " '1.5': 2,\n",
       " 'deeply': 7,\n",
       " 'heartfelt,20': 1,\n",
       " 'duplicate.': 1,\n",
       " 'attch,i': 1,\n",
       " 'back,twitter': 1,\n",
       " 'relaunches': 1,\n",
       " 'itself,completely': 1,\n",
       " 'deleting': 3,\n",
       " 'work.': 11,\n",
       " 'shitty': 5,\n",
       " 'sftwar': 1,\n",
       " 'write.?': 1,\n",
       " '@officialmacrosw': 1,\n",
       " 'all!': 4,\n",
       " 'casie': 1,\n",
       " 'msw': 1,\n",
       " 'buffalo!': 1,\n",
       " 'confused,': 1,\n",
       " 'work!ğŸ˜€': 1,\n",
       " '#macrosw': 1,\n",
       " 'game-style': 1,\n",
       " 'conveyer': 1,\n",
       " 'worthlessness.i': 1,\n",
       " 'illness,neurotransmitter': 1,\n",
       " 'imbalance,': 1,\n",
       " 'powerful.': 1,\n",
       " 'dissociation': 1,\n",
       " 'suicidal': 1,\n",
       " 'ideation': 1,\n",
       " 'days,': 10,\n",
       " 'cannot': 101,\n",
       " 'inflict': 1,\n",
       " 'sucks?': 1,\n",
       " 'doubt': 3,\n",
       " 'soo': 1,\n",
       " 'stabbing': 2,\n",
       " 'back.': 11,\n",
       " 'surprisingly,': 1,\n",
       " 'hurts': 5,\n",
       " 'damn': 20,\n",
       " 'time.': 19,\n",
       " 'mutuals': 2,\n",
       " 'nearly': 7,\n",
       " '#phd': 1,\n",
       " '@ougradsch': 1,\n",
       " '@openuniversity': 1,\n",
       " 'undergrad': 4,\n",
       " 'prospectus': 1,\n",
       " 'latin?': 1,\n",
       " 'spanish?': 1,\n",
       " 'creative': 3,\n",
       " 'writing?': 1,\n",
       " 'choose?': 1,\n",
       " 'okay': 28,\n",
       " 'day.': 26,\n",
       " '$200': 7,\n",
       " 'hours.': 10,\n",
       " 'retweet': 25,\n",
       " '@jiggedio': 2,\n",
       " 'myself': 43,\n",
       " ':)': 11,\n",
       " 'car,': 2,\n",
       " 'limbaugh,': 2,\n",
       " 'synopsis': 2,\n",
       " 'heard:': 2,\n",
       " 'â€œok,': 2,\n",
       " 'gotta': 12,\n",
       " 'stop.': 4,\n",
       " 'shutdown': 4,\n",
       " 'continue.': 2,\n",
       " 'die.': 8,\n",
       " 'unemployed.': 2,\n",
       " 'enough!': 3,\n",
       " 'died.': 2,\n",
       " \"we'll\": 8,\n",
       " 'adapt.â€': 2,\n",
       " 'millions': 8,\n",
       " 'nodded.': 2,\n",
       " 'happens': 8,\n",
       " 'spots': 5,\n",
       " 'says': 33,\n",
       " 'officials': 10,\n",
       " 'â€œwhack': 4,\n",
       " 'it...â€': 4,\n",
       " 'workstation': 1,\n",
       " 'gifted': 1,\n",
       " '@nagisakee': 1,\n",
       " 'omg': 10,\n",
       " ':d': 5,\n",
       " 'wearing': 10,\n",
       " 'deodorant': 1,\n",
       " 'ğŸ¤”': 15,\n",
       " 'wondering...': 1,\n",
       " 'underage,': 1,\n",
       " 'liquor': 5,\n",
       " 'hooked': 1,\n",
       " '#demilovatoisoverparty': 2,\n",
       " 'winters': 1,\n",
       " ';_;': 1,\n",
       " 'you.': 52,\n",
       " 'outs,': 1,\n",
       " 'third.': 1,\n",
       " 'means,': 1,\n",
       " 'sounds': 3,\n",
       " 'basebally.': 1,\n",
       " 'baseball': 3,\n",
       " 'general.': 4,\n",
       " 'covid-19,': 3,\n",
       " 'yankees': 2,\n",
       " 'nothing.': 4,\n",
       " 'potus*': 1,\n",
       " 'struck': 1,\n",
       " 'out.': 16,\n",
       " 'strikes,': 1,\n",
       " 'balls.': 1,\n",
       " 'mind.ğŸ˜œ': 1,\n",
       " 'idea': 11,\n",
       " 'is?': 5,\n",
       " 'ğŸ¦': 1,\n",
       " 'midnight': 1,\n",
       " '@kabzadesmall_': 1,\n",
       " '@aymos_shili': 1,\n",
       " '@mas_musiq': 1,\n",
       " '@daliwongasa': 1,\n",
       " 'mdu': 1,\n",
       " 'trp': 1,\n",
       " 'bongza': 1,\n",
       " 'madumane': 1,\n",
       " 'scorpion': 1,\n",
       " 'kings': 1,\n",
       " 'streaming': 10,\n",
       " 'â¤ï¸': 26,\n",
       " 'biggest': 9,\n",
       " 'roommate': 2,\n",
       " \"peeve's\": 1,\n",
       " 'york': 4,\n",
       " 'morons': 1,\n",
       " 'york.': 1,\n",
       " 'glad': 6,\n",
       " 'discovered': 2,\n",
       " '#writingcommunity': 10,\n",
       " '\\U0001f970': 10,\n",
       " 'somehow': 4,\n",
       " 'followers': 26,\n",
       " '1000!': 1,\n",
       " 'ğŸ˜³': 9,\n",
       " 'amazing': 23,\n",
       " 'more!': 1,\n",
       " 'âœğŸ¼': 1,\n",
       " 'book/#wip': 1,\n",
       " 'it!': 11,\n",
       " 'ğŸ˜ŠğŸ™ğŸ¼': 1,\n",
       " '#writerlift': 3,\n",
       " '#lockdown': 3,\n",
       " '#thursday': 1,\n",
       " '#thursdaymorning': 1,\n",
       " '#writer': 3,\n",
       " 'fiona': 6,\n",
       " 'zodiac': 1,\n",
       " 'â™ˆï¸:': 1,\n",
       " 'taste': 14,\n",
       " 'â™‰ï¸:': 1,\n",
       " 'â™Šï¸:': 1,\n",
       " 'â™‹ï¸:': 1,\n",
       " 'valentine': 1,\n",
       " 'â™Œï¸:': 1,\n",
       " 'â™ï¸:': 1,\n",
       " 'parting': 1,\n",
       " 'gift': 6,\n",
       " 'â™ï¸:': 1,\n",
       " 'â™ï¸:': 1,\n",
       " 'â™ï¸:': 1,\n",
       " 'â™‘ï¸:': 1,\n",
       " 'shadowboxer': 1,\n",
       " 'â™’ï¸:': 1,\n",
       " 'extraordinary': 1,\n",
       " 'â™“ï¸:': 1,\n",
       " 'promise': 2,\n",
       " '@prez': 1,\n",
       " 'cowboys.': 1,\n",
       " \"let's\": 21,\n",
       " 'happen.': 1,\n",
       " 'you,': 18,\n",
       " '@howaboutafresca?': 1,\n",
       " 'person:': 1,\n",
       " 'hurt': 9,\n",
       " 'feelings?': 1,\n",
       " 'brain:': 1,\n",
       " 'heart:': 1,\n",
       " 'guts:': 1,\n",
       " 'mouth.': 2,\n",
       " '\"nope\"': 1,\n",
       " 'gimme': 5,\n",
       " 'h*ll': 1,\n",
       " 'humble': 1,\n",
       " 'correspondent': 1,\n",
       " 'venues': 1,\n",
       " 'across': 12,\n",
       " 'it,': 14,\n",
       " 'forever': 9,\n",
       " 'gonna': 44,\n",
       " 'grateful': 2,\n",
       " 'landed': 4,\n",
       " 'have,': 2,\n",
       " 'ğŸ’œ': 9,\n",
       " 'howdy': 1,\n",
       " 'ğŸ‘‹ğŸ‘‹.': 1,\n",
       " 'friday': 9,\n",
       " '43rd': 2,\n",
       " 'april.': 3,\n",
       " 'boosie': 1,\n",
       " 'walked': 3,\n",
       " 'tory': 4,\n",
       " 'lanez': 1,\n",
       " 'shout': 7,\n",
       " '\"weird\"': 1,\n",
       " 'christian': 4,\n",
       " 'youth': 1,\n",
       " 'groups.': 1,\n",
       " 'turns': 2,\n",
       " 'queer.': 1,\n",
       " 'annoying': 8,\n",
       " 'tonight': 23,\n",
       " 'touched': 3,\n",
       " 'so......it': 1,\n",
       " 'knowing': 3,\n",
       " 'ğŸ˜¬': 3,\n",
       " 'epic.': 1,\n",
       " 'fail.': 1,\n",
       " 'ğŸ¤¦ğŸ»\\u200dâ™€ï¸': 1,\n",
       " 'chore.': 1,\n",
       " 'cancun': 1,\n",
       " 'go.': 4,\n",
       " 'cringe': 5,\n",
       " 'aidan': 1,\n",
       " 'talks': 3,\n",
       " 'softly': 1,\n",
       " 'falling': 4,\n",
       " 'asleepğŸ˜­': 1,\n",
       " 'cuomo:': 2,\n",
       " '\"\\'it\\'s': 2,\n",
       " \"states'\": 2,\n",
       " 'reopen.': 4,\n",
       " 'states.': 7,\n",
       " 'what,': 2,\n",
       " 'grant': 3,\n",
       " 'constitution': 2,\n",
       " 'gave': 36,\n",
       " 'born?': 2,\n",
       " '10th': 2,\n",
       " 'amendment.': 8,\n",
       " 'governor.\"': 2,\n",
       " 'capitalism!': 1,\n",
       " 'lose': 15,\n",
       " 'chains!': 1,\n",
       " 'minutes': 19,\n",
       " 'sooner,': 1,\n",
       " 'rona': 2,\n",
       " ':-)': 2,\n",
       " 'alright': 4,\n",
       " 'bite:': 1,\n",
       " 'apple?': 2,\n",
       " 'mum': 8,\n",
       " 'caught': 5,\n",
       " 'porn': 10,\n",
       " 'embarrassed': 2,\n",
       " 'china': 28,\n",
       " '\"fulfill': 2,\n",
       " 'obligations\"': 2,\n",
       " 'organization': 3,\n",
       " 'restore': 2,\n",
       " 'fulfill': 2,\n",
       " 'obligations': 2,\n",
       " 'damages': 2,\n",
       " '22.5': 2,\n",
       " 'americans': 19,\n",
       " 'virus': 18,\n",
       " 'unleashed': 4,\n",
       " 'agree!': 2,\n",
       " 'eastern.': 9,\n",
       " 'you!': 13,\n",
       " '@zayenachobae': 1,\n",
       " 'tatted?': 1,\n",
       " 'now,': 22,\n",
       " 'took': 16,\n",
       " 'fedex': 1,\n",
       " 'not.': 7,\n",
       " '3-8:30': 1,\n",
       " 'fucking': 53,\n",
       " 'tired.': 4,\n",
       " 'niggas': 14,\n",
       " 'yearsss': 1,\n",
       " 'truly': 11,\n",
       " 'dont': 20,\n",
       " 'quiting': 1,\n",
       " 'june': 5,\n",
       " 'ğŸ˜“': 3,\n",
       " 'wrestling': 5,\n",
       " 'unnecessary': 3,\n",
       " 'honestly.': 1,\n",
       " 'idiot': 3,\n",
       " 'prereq': 1,\n",
       " 'licensure': 1,\n",
       " 'exam.': 1,\n",
       " 'snapchat': 2,\n",
       " 'cheating': 3,\n",
       " 'together.': 8,\n",
       " \"'eh\": 1,\n",
       " 'whatev,': 1,\n",
       " 'weird': 16,\n",
       " \"time'\": 2,\n",
       " 'rly': 1,\n",
       " 'annoy': 4,\n",
       " 'me.': 46,\n",
       " 'professor': 5,\n",
       " 'bounced': 1,\n",
       " 'moots': 3,\n",
       " 'non-moots.': 1,\n",
       " 'decided': 17,\n",
       " 'cutie': 1,\n",
       " 'yea': 3,\n",
       " 'journey': 2,\n",
       " 'cutie.': 1,\n",
       " 'youre': 6,\n",
       " 'family.': 3,\n",
       " 'monday-': 1,\n",
       " 'okay,': 5,\n",
       " '44.5k': 1,\n",
       " 'novel': 2,\n",
       " 'now.': 42,\n",
       " '48k': 1,\n",
       " 'weekend.': 6,\n",
       " '3.5k': 1,\n",
       " 'edits': 1,\n",
       " 'sunday': 4,\n",
       " 'night.': 11,\n",
       " \"that's\": 32,\n",
       " 'do-able,': 1,\n",
       " 'right?': 15,\n",
       " 'accomplished': 2,\n",
       " 'moment.': 10,\n",
       " 'announce': 5,\n",
       " 'tweet': 39,\n",
       " 'addressing': 2,\n",
       " 'coronavirus.': 5,\n",
       " 'whenever': 4,\n",
       " 'day...': 2,\n",
       " 'somewhere': 3,\n",
       " \"behar's\": 1,\n",
       " 'gynecologist!': 1,\n",
       " 'anyone': 72,\n",
       " 'wanna': 53,\n",
       " 'brawler': 1,\n",
       " 'season?': 2,\n",
       " 'me...': 1,\n",
       " '#grinding': 1,\n",
       " '#staysafestayhome': 1,\n",
       " 'folks': 10,\n",
       " '#nbc': 1,\n",
       " 'ğŸ†': 1,\n",
       " '@nabthedentist': 1,\n",
       " '@iamriaz381': 1,\n",
       " '@jafriume': 1,\n",
       " '@laibaooe': 1,\n",
       " '@noor_pareesa': 1,\n",
       " '@made4pakistan': 1,\n",
       " '@make4pakistan': 1,\n",
       " '@mughazzal': 1,\n",
       " '@sawerasheikh12': 1,\n",
       " '@sanashah01': 1,\n",
       " '@rashkehina10': 1,\n",
       " '@hinakhan120': 1,\n",
       " '@coward_citizen': 1,\n",
       " '@agent381': 1,\n",
       " '@idresi1': 1,\n",
       " '@raokawish4': 1,\n",
       " '@ahmadsultan638': 1,\n",
       " '@afzalmalik381': 1,\n",
       " '@taskheer786pti': 1,\n",
       " 'rt,f&get': 1,\n",
       " 'magical': 2,\n",
       " 'featuring': 3,\n",
       " 'all-star': 1,\n",
       " 'cast:': 1,\n",
       " 'james': 3,\n",
       " 'corden,': 1,\n",
       " 'judi': 1,\n",
       " 'dench,': 1,\n",
       " 'jason': 4,\n",
       " 'derulo,': 1,\n",
       " 'idris': 1,\n",
       " 'elba': 1,\n",
       " 'jennifer': 1,\n",
       " 'hudson,': 1,\n",
       " 'mckellen,': 1,\n",
       " 'taylor': 4,\n",
       " 'swift,': 1,\n",
       " 'rebel': 1,\n",
       " 'wilson': 1,\n",
       " 'introducing': 2,\n",
       " 'francesca': 1,\n",
       " 'hayward.': 1,\n",
       " 'instantly.': 1,\n",
       " 'wtf': 7,\n",
       " 'saying': 33,\n",
       " 'hotter': 3,\n",
       " 'spoon': 2,\n",
       " 'demi': 1,\n",
       " \"lovato's\": 1,\n",
       " 'crib': 1,\n",
       " 'ğŸ’€': 4,\n",
       " 'lockdown': 31,\n",
       " 'beards': 2,\n",
       " 'ğŸ’€ğŸ’”': 2,\n",
       " 'mum.': 1,\n",
       " \"can't\": 15,\n",
       " 'her.': 11,\n",
       " 'nurse,': 1,\n",
       " 'understood': 1,\n",
       " 'deal.': 1,\n",
       " 'sister': 8,\n",
       " 'line.': 3,\n",
       " 'them.': 12,\n",
       " 'alone.': 4,\n",
       " 'knew': 10,\n",
       " 'down.': 5,\n",
       " 'tomorrow': 25,\n",
       " 'better.': 22,\n",
       " 'covid': 19,\n",
       " 'greater': 1,\n",
       " '100ft': 1,\n",
       " 'tds': 1,\n",
       " 'stands': 6,\n",
       " 'funny': 19,\n",
       " 'hobby': 1,\n",
       " 'stuck': 4,\n",
       " 'home?': 3,\n",
       " '@lexiiik9': 1,\n",
       " 'liking': 3,\n",
       " 'tweets....': 1,\n",
       " 'honesty:': 1,\n",
       " 'hospitals': 4,\n",
       " 'week.': 12,\n",
       " 'worried': 10,\n",
       " 'scared': 8,\n",
       " 'wks.': 1,\n",
       " 'hiv/aids,': 1,\n",
       " 'cdiff,': 1,\n",
       " 'mrsa,': 1,\n",
       " 'tb,': 1,\n",
       " 'pseudomonas,': 1,\n",
       " 'etc...': 1,\n",
       " 'protection.': 2,\n",
       " 'virus.': 10,\n",
       " 'scares': 1,\n",
       " 'home.': 14,\n",
       " 'murray': 2,\n",
       " 'djokovic': 1,\n",
       " 'instagram.': 1,\n",
       " 'innovation.': 1,\n",
       " 'improved': 2,\n",
       " 'least': 20,\n",
       " 'sport': 2,\n",
       " 'restocked': 1,\n",
       " 'copies': 1,\n",
       " 'refunded?!': 1,\n",
       " 'love.': 3,\n",
       " 'tiktok': 8,\n",
       " 'immediately': 9,\n",
       " 'sus': 1,\n",
       " 'guys,': 15,\n",
       " 'if,': 2,\n",
       " 'covid19,': 2,\n",
       " '80%': 4,\n",
       " 'salary,': 3,\n",
       " 'emails...': 1,\n",
       " 'pres.': 1,\n",
       " 'feb.': 1,\n",
       " '26,': 1,\n",
       " '2020.': 3,\n",
       " '\"the': 8,\n",
       " 'doctors': 31,\n",
       " 'fairly': 1,\n",
       " 'rapidly.â€': 1,\n",
       " 'averaged': 3,\n",
       " 'watched': 8,\n",
       " '<3': 3,\n",
       " 'motivations': 1,\n",
       " \"please:'<\": 1,\n",
       " 'note,': 1,\n",
       " '@starbucks': 1,\n",
       " 'upppppppp': 1,\n",
       " 'book!': 1,\n",
       " 'hours!': 2,\n",
       " 'gif\\U0001f92f': 1,\n",
       " 'cuddle': 4,\n",
       " '\\U0001f97aâ˜¹ï¸': 1,\n",
       " 'filthy': 1,\n",
       " 'â€œsomething': 1,\n",
       " 'on:': 1,\n",
       " 'say?': 3,\n",
       " 'michael': 5,\n",
       " 'scott': 2,\n",
       " 'storyâ€': 1,\n",
       " 'by:': 2,\n",
       " 'dwight': 1,\n",
       " 'schrute': 1,\n",
       " 'fun,': 3,\n",
       " 'portland.': 1,\n",
       " 'burrito': 1,\n",
       " 'bowls': 1,\n",
       " 'montana.': 1,\n",
       " 'whole': 34,\n",
       " 'boyfriend': 15,\n",
       " 'youtuber???????': 1,\n",
       " '#jews': 1,\n",
       " 'kvetch': 1,\n",
       " '#netflix': 1,\n",
       " '#unorthodox': 1,\n",
       " 'portraying': 1,\n",
       " 'hasidic': 1,\n",
       " '100%': 6,\n",
       " 'accuracy,': 1,\n",
       " 'saddened': 3,\n",
       " 'shocked': 2,\n",
       " '#fauda': 1,\n",
       " 'either.': 1,\n",
       " 'merely': 2,\n",
       " 'productions': 1,\n",
       " 'meant': 4,\n",
       " 'entertainment': 3,\n",
       " 'magat': 2,\n",
       " 'talked': 2,\n",
       " 'nobody': 16,\n",
       " 'sucks.': 4,\n",
       " 'happy\\U0001f970': 1,\n",
       " 'off,': 3,\n",
       " 'drunk?': 1,\n",
       " 'xbox': 2,\n",
       " 'games.': 2,\n",
       " 'gates': 22,\n",
       " 'covid-19': 43,\n",
       " 'vaccine?': 16,\n",
       " \"biden's\": 7,\n",
       " 'progressive': 3,\n",
       " 'color.': 1,\n",
       " 'carti': 5,\n",
       " 'lmao': 5,\n",
       " 'dumb': 3,\n",
       " 'things,': 3,\n",
       " 'defunding': 1,\n",
       " 'winner.': 3,\n",
       " '\"china': 1,\n",
       " 'raises': 1,\n",
       " 'coronavirus': 36,\n",
       " 'toll': 7,\n",
       " 'wuhan': 4,\n",
       " '50%\"': 1,\n",
       " 'yeah?': 1,\n",
       " 'shit.': 5,\n",
       " \"they're\": 10,\n",
       " 'do,': 2,\n",
       " 'remember...they': 1,\n",
       " 'lying.': 2,\n",
       " 'ğŸ‘€': 12,\n",
       " 'helping': 13,\n",
       " '20,000': 1,\n",
       " 'followers.': 3,\n",
       " 're-elect': 3,\n",
       " '@realdonaldtrump': 19,\n",
       " 'encourage': 3,\n",
       " 'others': 10,\n",
       " 'last.': 2,\n",
       " 'years!': 1,\n",
       " 'gifs': 23,\n",
       " 'dizzy.': 1,\n",
       " 'sappy': 1,\n",
       " 'commercials,': 2,\n",
       " 'wailing,': 1,\n",
       " 'submissive': 1,\n",
       " 'terrified': 2,\n",
       " 'morons,': 1,\n",
       " 'ridiculous': 4,\n",
       " 'conferences,': 1,\n",
       " 'countsâ€”': 1,\n",
       " '#reopenamerica': 4,\n",
       " 'following': 36,\n",
       " 'suggestions!': 1,\n",
       " 'flavor': 1,\n",
       " 'popsicle': 1,\n",
       " 'choices': 1,\n",
       " 'red,': 2,\n",
       " 'orange,': 2,\n",
       " 'purple': 2,\n",
       " 'decision': 9,\n",
       " 'answer.': 1,\n",
       " 'dependable': 24,\n",
       " 'oz.': 24,\n",
       " 'go!': 25,\n",
       " 'pussy.': 3,\n",
       " \"don't\": 33,\n",
       " 'lie!': 2,\n",
       " 'dedicate': 1,\n",
       " 'spanish': 1,\n",
       " 'obsessed': 1,\n",
       " 'heartbreak': 1,\n",
       " 'last?': 1,\n",
       " '#gettoknowyourcustomersday': 1,\n",
       " 'doing.': 1,\n",
       " 'emojis': 2,\n",
       " 'ğŸ‘‡': 10,\n",
       " 'kicking': 3,\n",
       " 'trumps': 1,\n",
       " 'ass!': 1,\n",
       " 'governor!!!': 1,\n",
       " '#cuomo': 1,\n",
       " 'lmaooo': 2,\n",
       " 'all.': 28,\n",
       " 'dms': 5,\n",
       " 'guess': 21,\n",
       " 'â€œposting': 1,\n",
       " 'enoughâ€': 1,\n",
       " 'outfit': 1,\n",
       " 'excited': 14,\n",
       " 'ğŸ˜…': 7,\n",
       " 'wanted': 27,\n",
       " 'apartment': 3,\n",
       " 'ğŸ˜©\\U0001f97a': 1,\n",
       " 'birthday': 23,\n",
       " 'today.': 45,\n",
       " 'whoo.': 1,\n",
       " 'so..': 1,\n",
       " 'tik': 3,\n",
       " 'tok?!': 1,\n",
       " 'go?': 2,\n",
       " 'ğŸ¤·ğŸ»\\u200dâ™€ï¸': 3,\n",
       " 'haircut.': 2,\n",
       " 'selfie.': 2,\n",
       " 'florida': 3,\n",
       " 'panhandle': 1,\n",
       " 'supermarket': 3,\n",
       " 'freezer': 2,\n",
       " 'decent': 3,\n",
       " 'toilet': 7,\n",
       " 'shelves': 2,\n",
       " 'today!': 8,\n",
       " '#coronawillendsoon': 3,\n",
       " 'thats': 4,\n",
       " 'tweet.': 4,\n",
       " 'tweeted': 3,\n",
       " 'buying': 9,\n",
       " 'tennessee': 2,\n",
       " 'teammates.': 2,\n",
       " 'doing,': 2,\n",
       " 'building.': 2,\n",
       " 'boots': 2,\n",
       " 'ground.': 3,\n",
       " 'humans,': 2,\n",
       " 'gsp': 2,\n",
       " 'khabib': 3,\n",
       " 'fight??': 1,\n",
       " 'retired': 1,\n",
       " 'prime..': 1,\n",
       " 'titleholder': 1,\n",
       " 'life..': 1,\n",
       " 'slightly': 4,\n",
       " '5-10': 2,\n",
       " 'q&a': 2,\n",
       " 'year..?': 1,\n",
       " 'ğŸ’¤': 2,\n",
       " '@petsmart': 1,\n",
       " 'sells': 1,\n",
       " 'giraffes?': 1,\n",
       " 'so,': 9,\n",
       " 'deliver': 4,\n",
       " 'curbside': 1,\n",
       " 'pickup?': 1,\n",
       " 'cricket': 1,\n",
       " 'ğŸ’™ğŸ˜»': 1,\n",
       " 'trainer': 1,\n",
       " 'macho': 1,\n",
       " 'randy': 1,\n",
       " 'savage.': 1,\n",
       " 'recommended': 2,\n",
       " 'properly': 3,\n",
       " 'diet': 3,\n",
       " 'steroids': 1,\n",
       " 'cocaine.ğŸ¤”': 1,\n",
       " 'careful': 2,\n",
       " 'consideration,': 1,\n",
       " 'vulgar': 1,\n",
       " 'ğŸ˜­': 24,\n",
       " 'vulnerable': 3,\n",
       " 'other,': 2,\n",
       " 'advice.': 8,\n",
       " 'tempted': 2,\n",
       " 'selfies': 1,\n",
       " 'photos.': 2,\n",
       " 'distance,': 2,\n",
       " 'residents': 1,\n",
       " 'exploit': 1,\n",
       " 'e.g': 1,\n",
       " 'trumpers.': 1,\n",
       " 'nurses': 2,\n",
       " 'distancing.': 5,\n",
       " 'to?': 2,\n",
       " 'bullshit.': 2,\n",
       " 'crave': 1,\n",
       " 'attention': 7,\n",
       " 'affection': 3,\n",
       " 'ğŸ˜”': 26,\n",
       " 'thesis': 3,\n",
       " 'surpassed': 2,\n",
       " 'cleaning': 1,\n",
       " 'exercising': 2,\n",
       " 'binging.': 1,\n",
       " 'switching': 2,\n",
       " 'binging': 3,\n",
       " 'cycles.': 1,\n",
       " 'guilty': 2,\n",
       " 'curing': 1,\n",
       " \"writer's\": 1,\n",
       " '#gradschool': 1,\n",
       " '#sendhelp': 1,\n",
       " 'goes': 8,\n",
       " 'hoes..': 1,\n",
       " ...}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unknown_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check punctuations that roberta unknown "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "punct = \"/-'?!.,#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~\" + '\"\"â€œâ€â€™' + 'âˆÎ¸Ã·Î±â€¢Ã âˆ’Î²âˆ…Â³Ï€â€˜â‚¹Â´Â°Â£â‚¬\\Ã—â„¢âˆšÂ²â€”â€“&'\n",
    "def unknown_punctuation(roberta_vocab):\n",
    "    unknown = ''\n",
    "    for char in punct:\n",
    "        if char not in list(roberta_vocab.keys()):\n",
    "            unknown += char\n",
    "            unknown += ' '\n",
    "    return unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Roberta unknown: \n",
      "â€œ â€ â€™ âˆ Î¸ Î± â€¢ âˆ’ Î² âˆ… Ï€ â€˜ â‚¹ â‚¬ â„¢ âˆš â€” â€“ \n"
     ]
    }
   ],
   "source": [
    "print(\"Roberta unknown: \")\n",
    "print(unknown_punctuation(roberta_vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping unknown to known punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_punc(text):\n",
    "    punct_mapping = {\"â€˜\": \"'\", \"â‚¹\": \"e\", \"Â´\": \"'\", \"Â°\": \"\", \"â‚¬\": \"e\", \"â„¢\": \"tm\", \"âˆš\": \" sqrt \", \"Ã—\": \"x\", \"Â²\": \"2\", \"â€”\": \"-\", \"â€“\": \"-\", \"â€™\": \"'\", \"_\": \"-\", \"`\": \"'\", 'â€œ': '\"', 'â€': '\"', 'â€œ': '\"', \"Â£\": \"e\", 'âˆ': 'infinity', 'Î¸': 'theta', 'Ã·': '/', 'Î±': 'alpha', 'â€¢': '.', 'Ã ': 'a', 'âˆ’': '-', 'Î²': 'beta', 'âˆ…': '', 'Â³': '3', 'Ï€': 'pi', }\n",
    "    for p in punct_mapping:\n",
    "        text = text.replace(p, punct_mapping[p])\n",
    "    for p in punct:\n",
    "        text = text.replace(p, ' {} '.format(p))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['map_punc_text'] = df_train.text.apply(change_punc)\n",
    "df_train['map_punc_reply'] = df_train.reply.apply(change_punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev['map_punc_text'] = df_dev.text.apply(change_punc)\n",
    "df_dev['map_punc_reply'] = df_dev.reply.apply(change_punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train text unique vocab count is: 46129\n",
      "train reply unique vocab count is: 18569\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=46129.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 13.464% (6211 / 46129) of vocab\n",
      "Found embeddings for 80.351% (645864 / 803801) of all text\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=18569.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 21.977% (4081 / 18569) of vocab\n",
      "Found embeddings for 79.704% (110219 / 138285) of all text\n"
     ]
    }
   ],
   "source": [
    "train_text_vocab = get_vocab(df_train['map_punc_text'].values)\n",
    "train_reply_vocab = get_vocab(df_train['map_punc_reply'].values)\n",
    "print(\"train text unique vocab count is: {}\".format(len(train_text_vocab)))\n",
    "print(\"train reply unique vocab count is: {}\".format(len(train_reply_vocab)))\n",
    "print()\n",
    "\n",
    "unknown_text = check_coverage(train_text_vocab, roberta_vocab)\n",
    "print()\n",
    "unknown_reply = check_coverage(train_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev text unique vocab count is: 11441\n",
      "dev reply unique vocab count is: 3899\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=11441.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 22.918% (2622 / 11441) of vocab\n",
      "Found embeddings for 80.208% (81777 / 101956) of all text\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=3899.0, style=ProgressStyle(description_â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 34.214% (1334 / 3899) of vocab\n",
      "Found embeddings for 79.201% (13891 / 17539) of all text\n"
     ]
    }
   ],
   "source": [
    "dev_text_vocab = get_vocab_lower(df_dev['map_punc_text'].values)\n",
    "dev_reply_vocab = get_vocab_lower(df_dev['map_punc_reply'].values)\n",
    "print(\"dev text unique vocab count is: {}\".format(len(dev_text_vocab)))\n",
    "print(\"dev reply unique vocab count is: {}\".format(len(dev_reply_vocab)))\n",
    "unknown_text = check_coverage(dev_text_vocab, roberta_vocab)\n",
    "print()\n",
    "unknown_reply = check_coverage(dev_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cannot', 102),\n",
       " ('guys', 95),\n",
       " ('covid', 88),\n",
       " ('quarantine', 79),\n",
       " ('anyone', 74),\n",
       " ('hug', 72),\n",
       " ('america', 69),\n",
       " ('tonight', 57),\n",
       " ('myself', 56),\n",
       " ('coronavirus', 56),\n",
       " ('wanna', 54),\n",
       " ('fucking', 53),\n",
       " ('hear', 51),\n",
       " ('hope', 51),\n",
       " ('biden', 50),\n",
       " ('reaction', 49),\n",
       " ('tweet', 45),\n",
       " ('feeling', 45),\n",
       " ('gonna', 44),\n",
       " ('okay', 43),\n",
       " ('weeks', 41),\n",
       " ('trying', 40),\n",
       " ('lockdown', 40),\n",
       " ('followers', 39),\n",
       " ('birthday', 39),\n",
       " ('sad', 38),\n",
       " ('china', 38),\n",
       " ('tomorrow', 38),\n",
       " ('following', 38),\n",
       " ('wants', 38),\n",
       " ('anymore', 38),\n",
       " ('pandemic', 37),\n",
       " ('says', 37),\n",
       " ('gave', 37),\n",
       " ('saying', 37),\n",
       " ('pelosi', 36),\n",
       " ('already', 36),\n",
       " ('nancy', 34),\n",
       " ('yourself', 34),\n",
       " ('waiting', 34),\n",
       " ('doctors', 34),\n",
       " ('whole', 34),\n",
       " ('believe', 33),\n",
       " ('covid19', 33),\n",
       " ('virus', 32),\n",
       " ('realdonaldtrump', 32),\n",
       " ('bitch', 32),\n",
       " ('vaccine', 31),\n",
       " ('hugs', 30),\n",
       " ('choose', 29),\n",
       " ('retweet', 29),\n",
       " ('amazing', 29),\n",
       " ('honest', 28),\n",
       " ('wanted', 28),\n",
       " ('tired', 27),\n",
       " ('gifs', 27),\n",
       " ('ğŸ˜”', 27),\n",
       " ('asked', 27),\n",
       " ('friday', 26),\n",
       " ('â¤ï¸', 26),\n",
       " ('minutes', 26),\n",
       " ('ğŸ˜‚', 26),\n",
       " ('knows', 26),\n",
       " ('hashtag', 25),\n",
       " ('yesterday', 25),\n",
       " ('ğŸ˜­', 25),\n",
       " ('bailouthumansnow', 24),\n",
       " ('ğŸ˜Š', 24),\n",
       " ('horny', 24),\n",
       " ('died', 24),\n",
       " ('dependable', 24),\n",
       " ('economy', 24),\n",
       " ('wish', 24),\n",
       " ('washington', 23),\n",
       " ('dinner', 23),\n",
       " ('eastern', 23),\n",
       " ('gates', 23),\n",
       " ('sick', 23),\n",
       " ('republican', 23),\n",
       " ('understand', 23),\n",
       " ('excited', 22),\n",
       " ('damn', 22),\n",
       " ('ğŸ¤”', 22),\n",
       " ('weekend', 22),\n",
       " ('guess', 22),\n",
       " ('crisis', 22),\n",
       " ('anxiety', 22),\n",
       " ('joe', 22),\n",
       " ('installing', 22),\n",
       " ('scottyfrommarketing', 22),\n",
       " ('proud', 21),\n",
       " ('liberate', 21),\n",
       " ('pls', 21),\n",
       " ('reopen', 21),\n",
       " ('dont', 21),\n",
       " ('funny', 21),\n",
       " ('describes', 21),\n",
       " ('explain', 20),\n",
       " ('americans', 20),\n",
       " ('least', 20),\n",
       " ('finally', 20),\n",
       " ('forget', 20),\n",
       " ('6pm', 19),\n",
       " ('guidelines', 19),\n",
       " ('\\U0001f97a', 19),\n",
       " ('weird', 19),\n",
       " ('nobody', 19),\n",
       " ('stimulus', 19),\n",
       " ('trash', 19),\n",
       " ('welcome', 19),\n",
       " ('lives', 19),\n",
       " ('came', 19),\n",
       " ('dick', 18),\n",
       " ('hates', 18),\n",
       " ('politicians', 18),\n",
       " ('means', 18),\n",
       " ('tweets', 18),\n",
       " ('lebron', 18),\n",
       " ('looks', 18),\n",
       " ('crying', 18),\n",
       " ('beautiful', 18),\n",
       " ('others', 17),\n",
       " ('moment', 17),\n",
       " ('decided', 17),\n",
       " ('folks', 17),\n",
       " ('american', 17),\n",
       " ('ventilators', 17),\n",
       " ('wonder', 16),\n",
       " ('enjoy', 16),\n",
       " ('yall', 16),\n",
       " ('cnn', 16),\n",
       " ('cuomo', 16),\n",
       " ('fans', 16),\n",
       " ('forever', 16),\n",
       " ('took', 16),\n",
       " ('boyfriend', 16),\n",
       " ('thoughts', 16),\n",
       " ('feels', 16),\n",
       " ('numbers', 16),\n",
       " ('realize', 16),\n",
       " ('democrats', 16),\n",
       " ('giveaway', 16),\n",
       " ('deserve', 16),\n",
       " ('himself', 15),\n",
       " ('totally', 15),\n",
       " ('posting', 15),\n",
       " ('mood', 15),\n",
       " ('spent', 15),\n",
       " ('lose', 15),\n",
       " ('niggas', 15),\n",
       " ('cute', 15),\n",
       " ('mj', 15),\n",
       " ('texas', 15),\n",
       " ('tried', 15),\n",
       " ('suck', 15),\n",
       " ('quickly', 15),\n",
       " ('campaigning', 15),\n",
       " ('dear', 15),\n",
       " ('happened', 15),\n",
       " ('obama', 15),\n",
       " ('woke', 15),\n",
       " ('awesome', 15),\n",
       " ('3rd', 15),\n",
       " ('career', 14),\n",
       " ('omg', 14),\n",
       " ('taste', 14),\n",
       " ('monday', 14),\n",
       " ('immediately', 14),\n",
       " ('dababy', 14),\n",
       " ('ppl', 14),\n",
       " ('seems', 14),\n",
       " ('deaths', 14),\n",
       " ('reopening', 14),\n",
       " ('businesses', 14),\n",
       " ('staying', 14),\n",
       " ('thankful', 14),\n",
       " ('losing', 14),\n",
       " ('takes', 14),\n",
       " ('seanhannity', 13),\n",
       " ('drunk', 13),\n",
       " ('everyday', 13),\n",
       " ('officials', 13),\n",
       " ('happen', 13),\n",
       " ('ğŸ‘€', 13),\n",
       " ('helping', 13),\n",
       " ('attention', 13),\n",
       " ('listen', 13),\n",
       " ('leadership', 13),\n",
       " ('zoom', 13),\n",
       " ('longer', 13),\n",
       " ('imagine', 13),\n",
       " ('couple', 13),\n",
       " ('cuz', 13),\n",
       " ('bored', 13),\n",
       " ('worse', 13),\n",
       " ('frequently', 13),\n",
       " ('happening', 12),\n",
       " ('incompetent', 12),\n",
       " ('pathetic', 12),\n",
       " ('puppet', 12),\n",
       " ('questions', 12),\n",
       " ('missed', 12),\n",
       " ('approval', 12),\n",
       " ('afraid', 12),\n",
       " ('gotta', 12),\n",
       " ('across', 12),\n",
       " ('governor', 12),\n",
       " ('honestly', 12),\n",
       " ('kinda', 12),\n",
       " ('appreciated', 12),\n",
       " ('earlier', 12),\n",
       " ('bailout', 12),\n",
       " ('likes', 12),\n",
       " ('beginning', 12),\n",
       " ('relationship', 12),\n",
       " ('entire', 12),\n",
       " ('showed', 12),\n",
       " ('lil', 11),\n",
       " ('dropped', 11),\n",
       " ('struggling', 11),\n",
       " ('idea', 11),\n",
       " ('writingcommunity', 11),\n",
       " ('truly', 11),\n",
       " ('instagram', 11),\n",
       " ('dms', 11),\n",
       " ('teammates', 11),\n",
       " ('distancing', 11),\n",
       " ('goes', 11),\n",
       " ('awake', 11),\n",
       " ('starts', 11),\n",
       " ('vibes', 11),\n",
       " ('officially', 11),\n",
       " ('spend', 11),\n",
       " ('virginia', 11),\n",
       " ('2nd', 11),\n",
       " ('idk', 11),\n",
       " ('approve', 11),\n",
       " ('sending', 11),\n",
       " ('bunch', 11),\n",
       " ('cant', 11),\n",
       " ('retweets', 11),\n",
       " ('therapy', 11),\n",
       " ('themselves', 11),\n",
       " ('become', 11),\n",
       " ('bout', 11),\n",
       " ('sucks', 10),\n",
       " ('blame', 10),\n",
       " ('grocery', 10),\n",
       " ('wearing', 10),\n",
       " ('wondering', 10),\n",
       " ('streaming', 10),\n",
       " ('biggest', 10),\n",
       " ('\\U0001f970', 10),\n",
       " ('thursday', 10),\n",
       " ('hurt', 10),\n",
       " ('feelings', 10),\n",
       " ('porn', 10),\n",
       " ('5k', 10),\n",
       " ('knew', 10),\n",
       " ('worried', 10),\n",
       " ('tiktok', 10),\n",
       " ('wuhan', 10),\n",
       " ('ğŸ‘‡', 10),\n",
       " ('advice', 10),\n",
       " ('stupid', 10),\n",
       " ('seriously', 10),\n",
       " ('definitely', 10),\n",
       " ('corona', 10),\n",
       " ('november', 10),\n",
       " ('learned', 10),\n",
       " ('moved', 10),\n",
       " ('ensure', 10),\n",
       " ('situation', 10),\n",
       " ('awful', 10),\n",
       " ('appreciate', 10),\n",
       " ('helped', 10),\n",
       " ('meme', 10),\n",
       " ('ğŸ¤£', 10),\n",
       " ('maga', 10),\n",
       " ('patriots', 10),\n",
       " ('apparently', 10),\n",
       " ('broke', 10),\n",
       " ('\\U0001f974', 10),\n",
       " ('hearing', 10),\n",
       " ('unfollow', 10),\n",
       " ('university', 9),\n",
       " ('cancel', 9),\n",
       " ('millions', 9),\n",
       " ('ğŸ˜³', 9),\n",
       " ('gift', 9),\n",
       " ('ğŸ’œ', 9),\n",
       " ('annoying', 9),\n",
       " ('amendment', 9),\n",
       " ('alright', 9),\n",
       " ('mum', 9),\n",
       " ('sister', 9),\n",
       " ('decision', 9),\n",
       " ('pussy', 9),\n",
       " ('buying', 9),\n",
       " ('celebrate', 9),\n",
       " ('govt', 9),\n",
       " ('toxic', 9),\n",
       " ('contest', 9),\n",
       " ('nathaniel', 9),\n",
       " ('coronavirusliar', 9),\n",
       " ('tweeting', 9),\n",
       " ('tears', 9),\n",
       " ('leaving', 9),\n",
       " ('several', 9),\n",
       " ('finish', 9),\n",
       " ('evening', 9),\n",
       " ('restrictions', 9),\n",
       " ('matt', 9),\n",
       " ('ladies', 9),\n",
       " ('exhausted', 9),\n",
       " ('supposed', 9),\n",
       " ('thousands', 9),\n",
       " ('supporter', 9),\n",
       " ('lunch', 9),\n",
       " ('prayers', 9),\n",
       " ('ğŸ˜Œ', 9),\n",
       " ('expansive', 9),\n",
       " ('accurate', 9),\n",
       " ('thousand', 9),\n",
       " ('paypal', 9),\n",
       " ('bacon', 9),\n",
       " ('families', 9),\n",
       " ('dealing', 9),\n",
       " ('everybody', 9),\n",
       " ('possible', 9),\n",
       " ('clap', 9),\n",
       " ('loved', 9),\n",
       " ('donate', 9),\n",
       " ('passed', 9),\n",
       " ('calls', 9),\n",
       " ('sitting', 9),\n",
       " ('defeated', 9),\n",
       " ('exciting', 8),\n",
       " ('charity', 8),\n",
       " ('governors', 8),\n",
       " ('4th', 8),\n",
       " ('cheer', 8),\n",
       " ('hurts', 8),\n",
       " ('happens', 8),\n",
       " ('april', 8),\n",
       " ('shout', 8),\n",
       " ('organization', 8),\n",
       " ('scared', 8),\n",
       " ('watched', 8),\n",
       " ('lmao', 8),\n",
       " ('goodnight', 8),\n",
       " ('sleeping', 8),\n",
       " ('2021', 8),\n",
       " ('marry', 8),\n",
       " ('somebody', 8),\n",
       " ('shower', 8),\n",
       " ('heaven', 8),\n",
       " ('meeting', 8),\n",
       " ('listening', 8),\n",
       " ('realized', 8),\n",
       " ('sources', 8),\n",
       " ('pepper', 8),\n",
       " ('basically', 8),\n",
       " ('polling', 8),\n",
       " ('dying', 8),\n",
       " ('forgot', 8),\n",
       " ('fucked', 8),\n",
       " ('tough', 8),\n",
       " ('permanently', 8),\n",
       " ('warren', 8),\n",
       " ('â™¥ï¸', 8),\n",
       " ('coach', 8),\n",
       " ('socialist', 8),\n",
       " ('billionaire', 8),\n",
       " ('ğŸ™', 8),\n",
       " ('ğŸ™ƒ', 8),\n",
       " ('masks', 8),\n",
       " ('cheese', 8),\n",
       " ('vegan', 8),\n",
       " ('endless', 8),\n",
       " ('further', 8),\n",
       " ('pray', 8),\n",
       " ('putting', 8),\n",
       " ('nigga', 8),\n",
       " ('reached', 8),\n",
       " ('funds', 8),\n",
       " ('lifetime', 8),\n",
       " ('randomly', 8),\n",
       " ('oprah', 8),\n",
       " ('schools', 8),\n",
       " ('smoke', 8),\n",
       " ('virologist', 8),\n",
       " ('incredible', 7),\n",
       " ('unemployment', 7),\n",
       " ('brothers', 7),\n",
       " ('deeply', 7),\n",
       " ('nearly', 7),\n",
       " ('moots', 7),\n",
       " ('wtf', 7),\n",
       " ('toll', 7),\n",
       " ('ğŸ˜…', 7),\n",
       " ('toilet', 7),\n",
       " ('pics', 7),\n",
       " ('haters', 7),\n",
       " ('shopping', 7),\n",
       " ('lately', 7),\n",
       " ('nfl', 7),\n",
       " ('siege', 7),\n",
       " ('makeup', 7),\n",
       " ('roof', 7),\n",
       " ('verge', 7),\n",
       " ('crap', 7),\n",
       " ('possibility', 7),\n",
       " ('assignment', 7),\n",
       " ('emotional', 7),\n",
       " ('positions', 7),\n",
       " ('crawl', 7),\n",
       " ('summer', 7),\n",
       " ('fauci', 7),\n",
       " ('dude', 7),\n",
       " ('wedding', 7),\n",
       " ('isolation', 7),\n",
       " ('precious', 7),\n",
       " ('2k', 7),\n",
       " ('gives', 7),\n",
       " ('elizabeth', 7),\n",
       " ('prefer', 7),\n",
       " ('attempt', 7),\n",
       " ('kindness', 7),\n",
       " ('ğŸš¨', 7),\n",
       " ('afford', 7),\n",
       " ('questionsâ€¦', 7),\n",
       " ('hugged', 7),\n",
       " ('memories', 7),\n",
       " ('terrible', 7),\n",
       " ('messages', 7),\n",
       " ('vacation', 7),\n",
       " ('â—', 7),\n",
       " ('suicide', 7),\n",
       " ('bottle', 7),\n",
       " ('streets', 7),\n",
       " ('cried', 7),\n",
       " ('till', 7),\n",
       " ('complaining', 7),\n",
       " ('senior', 7),\n",
       " ('hating', 7),\n",
       " ('blocked', 7),\n",
       " ('breakdown', 7),\n",
       " ('ğŸ˜­ğŸ˜­ğŸ˜­ğŸ˜­', 7),\n",
       " ('voting', 7),\n",
       " ('everytime', 7),\n",
       " ('dicks', 7),\n",
       " ('hungry', 7),\n",
       " ('lucky', 7),\n",
       " ('fantasy', 7),\n",
       " ('âœ…', 7),\n",
       " ('herself', 7),\n",
       " ('recover', 7),\n",
       " ('disaster', 7),\n",
       " ('handling', 7),\n",
       " ('website', 7),\n",
       " ('convinced', 7),\n",
       " ('quinn', 7),\n",
       " ('animals', 6),\n",
       " ('surprise', 6),\n",
       " ('ğŸ˜¢', 6),\n",
       " ('liquor', 6),\n",
       " ('responsibility', 6),\n",
       " ('increase', 6),\n",
       " ('july', 6),\n",
       " ('glad', 6),\n",
       " ('fiona', 6),\n",
       " ('youre', 6),\n",
       " ('sunday', 6),\n",
       " ('stands', 6),\n",
       " ('emails', 6),\n",
       " ('vulnerable', 6),\n",
       " ('bullshit', 6),\n",
       " ('slid', 6),\n",
       " ('swear', 6),\n",
       " ('effort', 6),\n",
       " ('followfriday', 6),\n",
       " ('proposal', 6),\n",
       " ('easily', 6),\n",
       " ('depression', 6),\n",
       " ('adams', 6),\n",
       " ('keeps', 6),\n",
       " ('liar', 6),\n",
       " ('decisions', 6),\n",
       " ('accounts', 6),\n",
       " ('judge', 6),\n",
       " ('flutter', 6),\n",
       " ('challenge', 6),\n",
       " ('returns', 6),\n",
       " ('platforms', 6),\n",
       " ('december', 6),\n",
       " ('alerting', 6),\n",
       " ('claims', 6),\n",
       " ('inaccurate', 6),\n",
       " ('misleading', 6),\n",
       " ('raiders', 6),\n",
       " ('recently', 6),\n",
       " ('tape', 6),\n",
       " ('valorant', 6),\n",
       " ('briefing', 6),\n",
       " ('screamed', 6),\n",
       " ('drew', 6),\n",
       " ('lady', 6),\n",
       " ('india', 6),\n",
       " ('seem', 6),\n",
       " ('headache', 6),\n",
       " ('wonderful', 6),\n",
       " ('plans', 6),\n",
       " ('bts', 6),\n",
       " ('bitches', 6),\n",
       " ('nose', 6),\n",
       " ('experts', 6),\n",
       " ('thinks', 6),\n",
       " ('reasons', 6),\n",
       " ('depressed', 6),\n",
       " ('teachers', 6),\n",
       " ('ğŸ˜', 6),\n",
       " ('decide', 6),\n",
       " ('pictures', 6),\n",
       " ('drink', 6),\n",
       " ('countries', 6),\n",
       " ('premier', 6),\n",
       " ('mike', 6),\n",
       " ('asleep', 6),\n",
       " ('visit', 6),\n",
       " ('angry', 6),\n",
       " ('drinking', 6),\n",
       " ('coffee', 6),\n",
       " ('plenty', 6),\n",
       " ('joke', 6),\n",
       " ('interview', 6),\n",
       " ('dangerous', 6),\n",
       " ('omie', 6),\n",
       " ('naked', 6),\n",
       " ('crossing', 6),\n",
       " ('nhs', 6),\n",
       " ('cryin', 6),\n",
       " ('chuck', 6),\n",
       " ('schumer', 6),\n",
       " ('legislation', 6),\n",
       " ('droz', 6),\n",
       " ('disney', 6),\n",
       " ('bernie', 6),\n",
       " ('speaks', 6),\n",
       " ('letting', 6),\n",
       " ('â˜€ï¸', 6),\n",
       " ('boom', 6),\n",
       " ('pregnant', 6),\n",
       " ('vibe', 6),\n",
       " ('breakfast', 6),\n",
       " ('lots', 6),\n",
       " ('ideas', 6),\n",
       " ('anniversary', 6),\n",
       " ('ğŸ˜', 6),\n",
       " ('easter', 6),\n",
       " ('homes', 6),\n",
       " ('ğŸ”‘', 6),\n",
       " ('statements', 6),\n",
       " ('bought', 6),\n",
       " ('extending', 6),\n",
       " ('lawn', 6),\n",
       " ('smile', 6),\n",
       " ('anybody', 6),\n",
       " ('ğŸ™„', 6),\n",
       " ('proper', 6),\n",
       " ('dems', 6),\n",
       " ('canada', 6),\n",
       " ('h1n1', 6),\n",
       " ('swine', 6),\n",
       " ('disastrous', 6),\n",
       " ('unnecessarily', 6),\n",
       " ('incompetence', 6),\n",
       " ('obamacare', 6),\n",
       " ('describe', 6),\n",
       " ('tribe', 6),\n",
       " ('candidate', 6),\n",
       " ('phd', 5),\n",
       " ('fellow', 5),\n",
       " ('\\U0001f92f', 5),\n",
       " ('betty', 5),\n",
       " ('participating', 5),\n",
       " ('okudah', 5),\n",
       " ('disapprove', 5),\n",
       " ('remind', 5),\n",
       " ('shitty', 5),\n",
       " ('confused', 5),\n",
       " ('unemployed', 5),\n",
       " ('spots', 5),\n",
       " ('whack', 5),\n",
       " ('potus', 5),\n",
       " ('york', 5),\n",
       " ('gimme', 5),\n",
       " ('tory', 5),\n",
       " ('cringe', 5),\n",
       " ('rona', 5),\n",
       " ('caught', 5),\n",
       " ('june', 5),\n",
       " ('wrestling', 5),\n",
       " ('annoy', 5),\n",
       " ('professor', 5),\n",
       " ('announce', 5),\n",
       " ('somewhere', 5),\n",
       " ('ğŸ’€', 5),\n",
       " ('nurse', 5),\n",
       " ('hospitals', 5),\n",
       " ('cuddle', 5),\n",
       " ('michael', 5),\n",
       " ('carti', 5),\n",
       " ('dumb', 5),\n",
       " ('haircut', 5),\n",
       " ('fav', 5),\n",
       " ('piss', 5),\n",
       " ('arrested', 5),\n",
       " ('brooks', 5),\n",
       " ('shaved', 5),\n",
       " ('nervous', 5),\n",
       " ('believes', 5),\n",
       " ('ease', 5),\n",
       " ('belongs', 5),\n",
       " ('schedule', 5),\n",
       " ('bears', 5),\n",
       " ('trey', 5),\n",
       " ('burton', 5),\n",
       " ('cooking', 5),\n",
       " ('corporate', 5),\n",
       " ('prove', 5),\n",
       " ('concern', 5),\n",
       " ('insane', 5),\n",
       " ('participate', 5),\n",
       " ('thru', 5),\n",
       " ('began', 5),\n",
       " ('lamar', 5),\n",
       " ('announcement', 5),\n",
       " ('wanting', 5),\n",
       " ('ugly', 5),\n",
       " ('nasty', 5),\n",
       " ('remix', 5),\n",
       " ('deleted', 5),\n",
       " ('receive', 5),\n",
       " ('experience', 5),\n",
       " ('dept', 5),\n",
       " ('upcoming', 5),\n",
       " ('congress', 5),\n",
       " ('taiwanese', 5),\n",
       " ('transmitted', 5),\n",
       " ('replies', 5),\n",
       " ('overall', 5),\n",
       " ('students', 5),\n",
       " ('stressed', 5),\n",
       " ('nigeria', 5),\n",
       " ('stunned', 5),\n",
       " ('patience', 5),\n",
       " ('anyways', 5),\n",
       " ('chatting', 5),\n",
       " ('laura', 5),\n",
       " ('reminds', 5),\n",
       " ('discuss', 5),\n",
       " ('fortnite', 5),\n",
       " ('princess', 5),\n",
       " ('ğŸ˜‰', 5),\n",
       " ('huh', 5),\n",
       " ('masterpiece', 5),\n",
       " ('frivolous', 5),\n",
       " ('heartbreaking', 5),\n",
       " ('familiesfirst', 5),\n",
       " ('safely', 5),\n",
       " ('groceries', 5),\n",
       " ('carolina', 5),\n",
       " ('democrat', 5),\n",
       " ('loves', 5),\n",
       " ('tuned', 5),\n",
       " ('shave', 5),\n",
       " ('laughing', 5),\n",
       " ('subs', 5),\n",
       " ('exactly', 5),\n",
       " ('streams', 5),\n",
       " ('ğŸ˜', 5),\n",
       " ('accidentally', 5),\n",
       " ('ğŸ™‚', 5),\n",
       " ('saved', 5),\n",
       " ('captain', 5),\n",
       " ('teach', 5),\n",
       " ('saturday', 5),\n",
       " ('canceled', 5),\n",
       " ('constantly', 5),\n",
       " ('teams', 5),\n",
       " ('committed', 5),\n",
       " ('minnesota', 5),\n",
       " ('california', 5),\n",
       " ('scrolling', 5),\n",
       " ('closely', 5),\n",
       " ('enjoyed', 5),\n",
       " ('hotline', 5),\n",
       " ('hanging', 5),\n",
       " ('normally', 5),\n",
       " ('frankly', 5),\n",
       " ('previously', 5),\n",
       " ('presentation', 5),\n",
       " ('ridiculously', 5),\n",
       " ('peeps', 5),\n",
       " ('neighbor', 5),\n",
       " ('idc', 5),\n",
       " ('riverdale', 5),\n",
       " ('loud', 5),\n",
       " ('infection', 5),\n",
       " ('dance', 5),\n",
       " ('anyway', 5),\n",
       " ('federal', 5),\n",
       " ('ğŸ’›', 5),\n",
       " ('matters', 5),\n",
       " ('pint', 5),\n",
       " ('selecting', 5),\n",
       " ('winğŸ’°', 5),\n",
       " ('roommates', 5),\n",
       " ('slap', 5),\n",
       " ('mentally', 5),\n",
       " ('ğŸ˜‚ğŸ˜‚', 5),\n",
       " ('replaced', 5),\n",
       " ('dvsn', 5),\n",
       " ('harris', 5),\n",
       " ('fault', 5),\n",
       " ('ğŸ’”', 5),\n",
       " ('island', 5),\n",
       " ('jealous', 5),\n",
       " ('songs', 5),\n",
       " ('ozark', 5),\n",
       " ('tryna', 5),\n",
       " ('steve', 5),\n",
       " ('paycheck', 5),\n",
       " ('offended', 5),\n",
       " ('smiling', 5),\n",
       " ('strategy', 5),\n",
       " ('bailouthumans', 5),\n",
       " ('greatest', 5),\n",
       " ('turning', 5),\n",
       " ('remake', 5),\n",
       " ('skills', 5),\n",
       " ('pigeon', 5),\n",
       " ('borders', 5),\n",
       " ('forgive', 5),\n",
       " ('understanding', 5),\n",
       " ('pero', 5),\n",
       " ('traded', 5),\n",
       " ('hunker', 4),\n",
       " ('primevideo', 4),\n",
       " ('twice', 4),\n",
       " ('march', 4),\n",
       " ('admit', 4),\n",
       " ('soul', 4),\n",
       " ('undergrad', 4),\n",
       " ('shutdown', 4),\n",
       " ('roommate', 4),\n",
       " ('somehow', 4),\n",
       " ('landed', 4),\n",
       " ('walked', 4),\n",
       " ('christian', 4),\n",
       " ('talks', 4),\n",
       " ('falling', 4),\n",
       " ('grant', 4),\n",
       " ('constitution', 4),\n",
       " ('fulfill', 4),\n",
       " ('obligations', 4),\n",
       " ('unleashed', 4),\n",
       " ('whenever', 4),\n",
       " ('james', 4),\n",
       " ('jason', 4),\n",
       " ('taylor', 4),\n",
       " ('stuck', 4),\n",
       " ('salary', 4),\n",
       " ('meant', 4),\n",
       " ('entertainment', 4),\n",
       " ('ridiculous', 4),\n",
       " ('reopenamerica', 4),\n",
       " ('apartment', 4),\n",
       " ('supermarket', 4),\n",
       " ('thats', 4),\n",
       " ('slightly', 4),\n",
       " ('deliver', 4),\n",
       " ('savage', 4),\n",
       " ('properly', 4),\n",
       " ('binging', 4),\n",
       " ('stacey', 4),\n",
       " ('abrams', 4),\n",
       " ('waking', 4),\n",
       " ('ğŸ’¯', 4),\n",
       " ('7th', 4),\n",
       " ('goddamn', 4),\n",
       " ('david', 4),\n",
       " ('monthly', 4),\n",
       " ('looked', 4),\n",
       " ('ğŸ˜–', 4),\n",
       " ('lesson', 4),\n",
       " ('hugging', 4),\n",
       " ('profiles', 4),\n",
       " ('sessions', 4),\n",
       " ('devil', 4),\n",
       " ('simps', 4),\n",
       " ('desire', 4),\n",
       " ('meh', 4),\n",
       " ('sir', 4),\n",
       " ('fuckin', 4),\n",
       " ('tend', 4),\n",
       " ('minister', 4),\n",
       " ('counting', 4),\n",
       " ('struggle', 4),\n",
       " ('titties', 4),\n",
       " ('technically', 4),\n",
       " ('naughty', 4),\n",
       " ('teacher', 4),\n",
       " ('trending', 4),\n",
       " ('ğŸ˜‘', 4),\n",
       " ('justin', 4),\n",
       " ('lamb', 4),\n",
       " ('tracing', 4),\n",
       " ('movies', 4),\n",
       " ('nap', 4),\n",
       " ('semester', 4),\n",
       " ('reminder', 4),\n",
       " ('enjoying', 4),\n",
       " ('anime', 4),\n",
       " ('republicans', 4),\n",
       " ('disgusting', 4),\n",
       " ('assume', 4),\n",
       " ('difficult', 4),\n",
       " ('lungs', 4),\n",
       " ('taken', 4),\n",
       " ('muslims', 4),\n",
       " ('regardless', 4),\n",
       " ('5am', 4),\n",
       " ('upset', 4),\n",
       " ('haha', 4),\n",
       " ('clapping', 4),\n",
       " ('brilliant', 4),\n",
       " ('crowd', 4),\n",
       " ('talent', 4),\n",
       " ('heck', 4),\n",
       " ('faked', 4),\n",
       " ('breathing', 4),\n",
       " ('emailed', 4),\n",
       " ('potential', 4),\n",
       " ('literary', 4),\n",
       " ('imreadyimreadyimready', 4),\n",
       " ('dontpanic', 4),\n",
       " ('messaged', 4),\n",
       " ('backyard', 4),\n",
       " ('stronger', 4),\n",
       " ('january', 4),\n",
       " ('suspended', 4),\n",
       " ('choke', 4),\n",
       " ('throat', 4),\n",
       " ('supporters', 4),\n",
       " ('sexy', 4),\n",
       " ('kitchen', 4),\n",
       " ('sap', 4),\n",
       " ('ğŸ’—', 4),\n",
       " ('silence', 4),\n",
       " ('kills', 4),\n",
       " ('useless', 4),\n",
       " ('restaurants', 4),\n",
       " ('liberals', 4),\n",
       " ('elite', 4),\n",
       " ('drake', 4),\n",
       " ('neighborhood', 4),\n",
       " ('realizing', 4),\n",
       " ('jones', 4),\n",
       " ('timeline', 4),\n",
       " ('cdc', 4),\n",
       " ('restaurant', 4),\n",
       " ('industry', 4),\n",
       " ('remembered', 4),\n",
       " ('stans', 4),\n",
       " ('extend', 4),\n",
       " ('horrible', 4),\n",
       " ('disease', 4),\n",
       " ('twist', 4),\n",
       " ('passing', 4),\n",
       " ('drowning', 4),\n",
       " ('cole', 4),\n",
       " ('ğŸ‘', 4),\n",
       " ('partner', 4),\n",
       " ('tells', 4),\n",
       " ('busy', 4),\n",
       " ('seniors', 4),\n",
       " ('signs', 4),\n",
       " ('spirits', 4),\n",
       " ('urged', 4),\n",
       " ('iraqis', 4),\n",
       " ('syrians', 4),\n",
       " ('kurds', 4),\n",
       " ('afghanis', 4),\n",
       " ('liberating', 4),\n",
       " ('applause', 4),\n",
       " ('dreams', 4),\n",
       " ('administration', 4),\n",
       " ('greatly', 4),\n",
       " ('physically', 4),\n",
       " ('films', 4),\n",
       " ('recommend', 4),\n",
       " ('fraction', 4),\n",
       " ('stockpile', 4),\n",
       " ('ğŸ’™', 4),\n",
       " ('neighbors', 4),\n",
       " ('valuable', 4),\n",
       " ('apologize', 4),\n",
       " ('privacy', 4),\n",
       " ('emergency', 4),\n",
       " ('yup', 4),\n",
       " ('switches', 4),\n",
       " ('madness', 4),\n",
       " ('centre', 4),\n",
       " ('clothes', 4),\n",
       " ('teeth', 4),\n",
       " ('trump2020', 4),\n",
       " ('follows', 4),\n",
       " ('grace', 4),\n",
       " ('mute', 4),\n",
       " ('juice', 4),\n",
       " ('removal', 4),\n",
       " ('joebiden', 4),\n",
       " ('accountable', 4),\n",
       " ('cough', 4),\n",
       " ('scheduled', 4),\n",
       " ('considering', 4),\n",
       " ('ğŸ˜’', 4),\n",
       " ('canadians', 4),\n",
       " ('laptop', 4),\n",
       " ('dancing', 4),\n",
       " ('sooooo', 4),\n",
       " ('accepted', 4),\n",
       " ('instant', 4),\n",
       " ('workout', 4),\n",
       " ('horniness', 4),\n",
       " ('basis', 4),\n",
       " ('emerge', 4),\n",
       " ('jesus', 4),\n",
       " ('sober', 4),\n",
       " ('attractive', 4),\n",
       " ('spreading', 4),\n",
       " ('tea', 4),\n",
       " ('alive', 4),\n",
       " ('isolating', 4),\n",
       " ('vitamin', 4),\n",
       " ('grind', 4),\n",
       " ('compare', 4),\n",
       " ('ğŸ˜‚ğŸ˜‚ğŸ˜‚', 4),\n",
       " ('rumors', 4),\n",
       " ('locals', 4),\n",
       " ('theyre', 4),\n",
       " ('passion', 4),\n",
       " ('debt', 4),\n",
       " ('emotionally', 4),\n",
       " ('diamond', 4),\n",
       " ('ğŸ’ğŸ’ğŸ’', 4),\n",
       " ('dragging', 4),\n",
       " ('1st', 4),\n",
       " ('spotify', 4),\n",
       " ('whitmer', 4),\n",
       " ('notifications', 4),\n",
       " ('happiness', 4),\n",
       " ('ğŸ‰', 4),\n",
       " ('lonely', 4),\n",
       " ('hundred', 4),\n",
       " ('conversation', 4),\n",
       " ('pulte', 4),\n",
       " ('prices', 4),\n",
       " ('however', 4),\n",
       " ('ppp', 4),\n",
       " ('drained', 4),\n",
       " ('combination', 4),\n",
       " ('dollars', 4),\n",
       " ('cassper', 4),\n",
       " ('tho', 4),\n",
       " ('previous', 4),\n",
       " ('clearly', 4),\n",
       " ('opportunity', 4),\n",
       " ('pets', 4),\n",
       " ('nudes', 4),\n",
       " ('extended', 4),\n",
       " ('coughing', 4),\n",
       " ('pissed', 4),\n",
       " ('ğŸ’–', 4),\n",
       " ('refer', 4),\n",
       " ('compared', 4),\n",
       " ('ğŸ˜ª', 4),\n",
       " ('unpopular', 4),\n",
       " ('opinion', 4),\n",
       " ('medication', 4),\n",
       " ('protest', 4),\n",
       " ('afro', 4),\n",
       " ('viewers', 4),\n",
       " ('hilarious', 4),\n",
       " ('10k', 4),\n",
       " ('mf', 4),\n",
       " ('worry', 4),\n",
       " ('failure', 4),\n",
       " ...]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(unknown_text.items(), key=lambda d: d[1], reverse=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform more words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "more_apostrophes = {'cannot': \"can not\", 'gonna': \"go to\", 'wanna': \"want to\", 'coronavirus': \"COVID\", 'wanted': \"want\", 'weeks': \"week\", 'feeling': \"feel\", 'says': \"say\", 'yourself': \"your self\", 'saying': \"say\", 'says': \"say\", 'GIF': \"gif\", 'waiting': \"wait\", 'Covid': \"COVID\", 'hugs': \"hug\", 'gave': \"give\", 'COVID19': \"COVID\", 'installing': \"install\", 'wants': \"want\", 'knows': \"know\", 'describes': \"describe\", 'following': \"follow\", 'asked': \"ask\", 'amazing': \"amaze\", 'finally': \"final\", 'minutes': \"minute\", 'died': \"die\", 'tired': \"tire\", 'quickly': \"quick\", 'gotta': \"go to\", 'deaths': \"death\", 'means': \"mean\", 'took': \"take\", 'feels': \"feel\", 'fans': \"fan\", 'numbers': \"number\", 'lives': \"live\", 'safely': \"safe\", 'tried': \"try\", 'businesses': \"business\", '2nd': \"second\", 'decided': \"decide\", '3rd': \"third\", 'hates': \"hate\", 'dont': \"do not\", 'lonely': \"lone\", 'totally': \"total\", 'excited': \"excite\", 'BREAKING': \"break\", 'gifs': \"gif\", 'goes': \"go\", 'thoughts': \"thought\", 'campaigning': \"campaign\", 'immediately': \"immediate\", 'teammates': \"team mate\", 'knew': \"know\", 'politicians': \"politician\", 'distancing': \"distance\", 'reopening': \"reopen\", 'pls': \"please\", 'AGAIN': \"again\", 'tears': \"tear\", 'supposed': \"suppose\", 'loved': \"love\", 'ppl': \"people\", 'drinking': \"drink\", 'Guidelines': \"guide line\", 'losing': \"lose\", 'Conference': \"conference\", 'officially': \"official\", 'OPENING': \"open\", 'buying': \"buy\", 'Gif': \"gif\", 'looks': \"look\", 'bought': \"buy\", 'likes': \"like\", 'truely': \"true\", 'happened': \"happen\", 'putting': \"put\", 'families': \"family\", 'moved': \"move\", 'Raise': \"raise\", 'helped': \"help\", 'vibes': \"vibe\", 'voting': \"vote\", 'showed': \"show\", 'Instagram': \"instagram\", 'spent': \"spend\", 'watched': \"watch\", 'kinda': \"kind of\", 'Governor': \"governor\", 'Coronavirus': \"COVID\", 'lmao': \"laugh\", 'seems': \"seem\", 'staying': \"stay\", 'listening': \"listen\", 'accounts': \"account\"}\n",
    "def change_punc(text):\n",
    "    for key in more_apostrophes.keys():\n",
    "        text = text.replace(key, more_apostrophes[key])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.tokenize('guide lines')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['map_more_punc_text'] = df_train.map_punc_text.apply(change_punc)\n",
    "df_train['map_more_punc_reply'] = df_train.map_punc_reply.apply(change_punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev['map_more_punc_text'] = df_dev.map_punc_text.apply(change_punc)\n",
    "df_dev['map_more_punc_reply'] = df_dev.map_punc_reply.apply(change_punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train text unique vocab count is: 46010\n",
      "train reply unique vocab count is: 18481\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=46010.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 13.488% (6206 / 46010) of vocab\n",
      "Found embeddings for 81.730% (658910 / 806199) of all text\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=18481.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 22.066% (4078 / 18481) of vocab\n",
      "Found embeddings for 80.666% (111902 / 138723) of all text\n"
     ]
    }
   ],
   "source": [
    "train_text_vocab = get_vocab(df_train['map_more_punc_text'].values)\n",
    "train_reply_vocab = get_vocab(df_train['map_more_punc_reply'].values)\n",
    "print(\"train text unique vocab count is: {}\".format(len(train_text_vocab)))\n",
    "print(\"train reply unique vocab count is: {}\".format(len(train_reply_vocab)))\n",
    "print()\n",
    "\n",
    "unknown_text = check_coverage(train_text_vocab, roberta_vocab)\n",
    "print()\n",
    "unknown_reply = check_coverage(train_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev text unique vocab count is: 11398\n",
      "dev reply unique vocab count is: 3854\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=11398.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 22.986% (2620 / 11398) of vocab\n",
      "Found embeddings for 81.460% (83292 / 102249) of all text\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=3854.0, style=ProgressStyle(description_â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 34.587% (1333 / 3854) of vocab\n",
      "Found embeddings for 80.247% (14125 / 17602) of all text\n"
     ]
    }
   ],
   "source": [
    "dev_text_vocab = get_vocab_lower(df_dev['map_more_punc_text'].values)\n",
    "dev_reply_vocab = get_vocab_lower(df_dev['map_more_punc_reply'].values)\n",
    "print(\"dev text unique vocab count is: {}\".format(len(dev_text_vocab)))\n",
    "print(\"dev reply unique vocab count is: {}\".format(len(dev_reply_vocab)))\n",
    "unknown_text = check_coverage(dev_text_vocab, roberta_vocab)\n",
    "print()\n",
    "unknown_reply = check_coverage(dev_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('covid', 162),\n",
       " ('hug', 101),\n",
       " ('guys', 95),\n",
       " ('quarantine', 79),\n",
       " ('anyone', 74),\n",
       " ('america', 69),\n",
       " ('tonight', 57),\n",
       " ('myself', 56),\n",
       " ('fucking', 53),\n",
       " ('hear', 51),\n",
       " ('hope', 51),\n",
       " ('biden', 50),\n",
       " ('reaction', 49),\n",
       " ('tweet', 45),\n",
       " ('okay', 43),\n",
       " ('trying', 40),\n",
       " ('lockdown', 40),\n",
       " ('followers', 39),\n",
       " ('birthday', 39),\n",
       " ('sad', 38),\n",
       " ('china', 38),\n",
       " ('tomorrow', 38),\n",
       " ('anymore', 38),\n",
       " ('pandemic', 37),\n",
       " ('pelosi', 36),\n",
       " ('already', 36),\n",
       " ('nancy', 34),\n",
       " ('doctors', 34),\n",
       " ('whole', 34),\n",
       " ('believe', 33),\n",
       " ('reopen', 33),\n",
       " ('virus', 32),\n",
       " ('realdonaldtrump', 32),\n",
       " ('bitch', 32),\n",
       " ('vaccine', 31),\n",
       " ('choose', 29),\n",
       " ('retweet', 29),\n",
       " ('lose', 29),\n",
       " ('honest', 28),\n",
       " ('happen', 28),\n",
       " ('ğŸ˜”', 27),\n",
       " ('describe', 27),\n",
       " ('friday', 26),\n",
       " ('â¤ï¸', 26),\n",
       " ('ğŸ˜‚', 26),\n",
       " ('hashtag', 25),\n",
       " ('yesterday', 25),\n",
       " ('ğŸ˜­', 25),\n",
       " ('bailouthumansnow', 24),\n",
       " ('ğŸ˜Š', 24),\n",
       " ('horny', 24),\n",
       " ('spend', 24),\n",
       " ('dependable', 24),\n",
       " ('economy', 24),\n",
       " ('wish', 24),\n",
       " ('washington', 23),\n",
       " ('dinner', 23),\n",
       " ('eastern', 23),\n",
       " ('decide', 23),\n",
       " ('gates', 23),\n",
       " ('sick', 23),\n",
       " ('republican', 23),\n",
       " ('understand', 23),\n",
       " ('tire', 22),\n",
       " ('damn', 22),\n",
       " ('ğŸ¤”', 22),\n",
       " ('weekend', 22),\n",
       " ('guess', 22),\n",
       " ('crisis', 22),\n",
       " ('anxiety', 22),\n",
       " ('joe', 22),\n",
       " ('scottyfrommarketing', 22),\n",
       " ('proud', 21),\n",
       " ('excite', 21),\n",
       " ('liberate', 21),\n",
       " ('amaze', 21),\n",
       " ('funny', 21),\n",
       " ('explain', 20),\n",
       " ('americans', 20),\n",
       " ('least', 20),\n",
       " ('listen', 20),\n",
       " ('forget', 20),\n",
       " ('politician', 19),\n",
       " ('6pm', 19),\n",
       " ('\\U0001f97a', 19),\n",
       " ('weird', 19),\n",
       " ('nobody', 19),\n",
       " ('stimulus', 19),\n",
       " ('trash', 19),\n",
       " ('welcome', 19),\n",
       " ('came', 19),\n",
       " ('dick', 18),\n",
       " ('tweets', 18),\n",
       " ('lebron', 18),\n",
       " ('crying', 18),\n",
       " ('beautiful', 18),\n",
       " ('others', 17),\n",
       " ('moment', 17),\n",
       " ('folks', 17),\n",
       " ('vibe', 17),\n",
       " ('american', 17),\n",
       " ('ventilators', 17),\n",
       " ('wonder', 16),\n",
       " ('enjoy', 16),\n",
       " ('yall', 16),\n",
       " ('cnn', 16),\n",
       " ('cuomo', 16),\n",
       " ('forever', 16),\n",
       " ('boyfriend', 16),\n",
       " ('realize', 16),\n",
       " ('democrats', 16),\n",
       " ('giveaway', 16),\n",
       " ('deserve', 16),\n",
       " ('himself', 15),\n",
       " ('posting', 15),\n",
       " ('mood', 15),\n",
       " ('niggas', 15),\n",
       " ('cute', 15),\n",
       " ('mj', 15),\n",
       " ('texas', 15),\n",
       " ('suck', 15),\n",
       " ('dear', 15),\n",
       " ('seem', 15),\n",
       " ('obama', 15),\n",
       " ('woke', 15),\n",
       " ('awesome', 15),\n",
       " ('career', 14),\n",
       " ('omg', 14),\n",
       " ('taste', 14),\n",
       " ('monday', 14),\n",
       " ('dababy', 14),\n",
       " ('thankful', 14),\n",
       " ('takes', 14),\n",
       " ('seanhannity', 13),\n",
       " ('drunk', 13),\n",
       " ('everyday', 13),\n",
       " ('officials', 13),\n",
       " ('immediate', 13),\n",
       " ('ğŸ‘€', 13),\n",
       " ('helping', 13),\n",
       " ('attention', 13),\n",
       " ('leadership', 13),\n",
       " ('zoom', 13),\n",
       " ('longer', 13),\n",
       " ('imagine', 13),\n",
       " ('couple', 13),\n",
       " ('cuz', 13),\n",
       " ('coronavirus', 13),\n",
       " ('bored', 13),\n",
       " ('worse', 13),\n",
       " ('frequently', 13),\n",
       " ('happening', 12),\n",
       " ('incompetent', 12),\n",
       " ('pathetic', 12),\n",
       " ('puppet', 12),\n",
       " ('questions', 12),\n",
       " ('missed', 12),\n",
       " ('approval', 12),\n",
       " ('afraid', 12),\n",
       " ('across', 12),\n",
       " ('governor', 12),\n",
       " ('honestly', 12),\n",
       " ('appreciated', 12),\n",
       " ('earlier', 12),\n",
       " ('bailout', 12),\n",
       " ('unfollow', 12),\n",
       " ('drink', 12),\n",
       " ('beginning', 12),\n",
       " ('relationship', 12),\n",
       " ('entire', 12),\n",
       " ('lil', 11),\n",
       " ('dropped', 11),\n",
       " ('struggling', 11),\n",
       " ('idea', 11),\n",
       " ('writingcommunity', 11),\n",
       " ('truly', 11),\n",
       " ('instagram', 11),\n",
       " ('dms', 11),\n",
       " ('awake', 11),\n",
       " ('starts', 11),\n",
       " ('virginia', 11),\n",
       " ('idk', 11),\n",
       " ('approve', 11),\n",
       " ('sending', 11),\n",
       " ('bunch', 11),\n",
       " ('cant', 11),\n",
       " ('retweets', 11),\n",
       " ('therapy', 11),\n",
       " ('themselves', 11),\n",
       " ('become', 11),\n",
       " ('bout', 11),\n",
       " ('sucks', 10),\n",
       " ('blame', 10),\n",
       " ('grocery', 10),\n",
       " ('wearing', 10),\n",
       " ('wondering', 10),\n",
       " ('streaming', 10),\n",
       " ('biggest', 10),\n",
       " ('\\U0001f970', 10),\n",
       " ('thursday', 10),\n",
       " ('hurt', 10),\n",
       " ('porn', 10),\n",
       " ('5k', 10),\n",
       " ('worried', 10),\n",
       " ('tiktok', 10),\n",
       " ('wuhan', 10),\n",
       " ('ğŸ‘‡', 10),\n",
       " ('advice', 10),\n",
       " ('stupid', 10),\n",
       " ('seriously', 10),\n",
       " ('definitely', 10),\n",
       " ('corona', 10),\n",
       " ('november', 10),\n",
       " ('learned', 10),\n",
       " ('ensure', 10),\n",
       " ('tear', 10),\n",
       " ('situation', 10),\n",
       " ('awful', 10),\n",
       " ('appreciate', 10),\n",
       " ('meme', 10),\n",
       " ('suppose', 10),\n",
       " ('ğŸ¤£', 10),\n",
       " ('maga', 10),\n",
       " ('patriots', 10),\n",
       " ('apparently', 10),\n",
       " ('broke', 10),\n",
       " ('\\U0001f974', 10),\n",
       " ('hearing', 10),\n",
       " ('university', 9),\n",
       " ('cancel', 9),\n",
       " ('millions', 9),\n",
       " ('ğŸ˜³', 9),\n",
       " ('gift', 9),\n",
       " ('ğŸ’œ', 9),\n",
       " ('annoying', 9),\n",
       " ('amendment', 9),\n",
       " ('alright', 9),\n",
       " ('mum', 9),\n",
       " ('sister', 9),\n",
       " ('decision', 9),\n",
       " ('pussy', 9),\n",
       " ('celebrate', 9),\n",
       " ('govt', 9),\n",
       " ('toxic', 9),\n",
       " ('contest', 9),\n",
       " ('nathaniel', 9),\n",
       " ('covidliar', 9),\n",
       " ('tweeting', 9),\n",
       " ('leaving', 9),\n",
       " ('several', 9),\n",
       " ('finish', 9),\n",
       " ('evening', 9),\n",
       " ('restrictions', 9),\n",
       " ('matt', 9),\n",
       " ('ladies', 9),\n",
       " ('exhausted', 9),\n",
       " ('thousands', 9),\n",
       " ('supporter', 9),\n",
       " ('lunch', 9),\n",
       " ('prayers', 9),\n",
       " ('ğŸ˜Œ', 9),\n",
       " ('expansive', 9),\n",
       " ('accurate', 9),\n",
       " ('thousand', 9),\n",
       " ('paypal', 9),\n",
       " ('bacon', 9),\n",
       " ('dealing', 9),\n",
       " ('everybody', 9),\n",
       " ('possible', 9),\n",
       " ('clap', 9),\n",
       " ('donate', 9),\n",
       " ('passed', 9),\n",
       " ('calls', 9),\n",
       " ('sitting', 9),\n",
       " ('defeated', 9),\n",
       " ('exciting', 8),\n",
       " ('charity', 8),\n",
       " ('governors', 8),\n",
       " ('4th', 8),\n",
       " ('cheer', 8),\n",
       " ('hurts', 8),\n",
       " ('happens', 8),\n",
       " ('april', 8),\n",
       " ('shout', 8),\n",
       " ('organization', 8),\n",
       " ('scared', 8),\n",
       " ('goodnight', 8),\n",
       " ('sleeping', 8),\n",
       " ('2021', 8),\n",
       " ('marry', 8),\n",
       " ('somebody', 8),\n",
       " ('shower', 8),\n",
       " ('heaven', 8),\n",
       " ('meeting', 8),\n",
       " ('realized', 8),\n",
       " ('sources', 8),\n",
       " ('pepper', 8),\n",
       " ('basically', 8),\n",
       " ('polling', 8),\n",
       " ('dying', 8),\n",
       " ('forgot', 8),\n",
       " ('fucked', 8),\n",
       " ('tough', 8),\n",
       " ('permanently', 8),\n",
       " ('warren', 8),\n",
       " ('â™¥ï¸', 8),\n",
       " ('coach', 8),\n",
       " ('socialist', 8),\n",
       " ('billionaire', 8),\n",
       " ('ğŸ™', 8),\n",
       " ('amazing', 8),\n",
       " ('ğŸ™ƒ', 8),\n",
       " ('masks', 8),\n",
       " ('cheese', 8),\n",
       " ('vegan', 8),\n",
       " ('endless', 8),\n",
       " ('further', 8),\n",
       " ('pray', 8),\n",
       " ('nigga', 8),\n",
       " ('reached', 8),\n",
       " ('funds', 8),\n",
       " ('lifetime', 8),\n",
       " ('randomly', 8),\n",
       " ('oprah', 8),\n",
       " ('schools', 8),\n",
       " ('smoke', 8),\n",
       " ('virologist', 8),\n",
       " ('incredible', 7),\n",
       " ('unemployment', 7),\n",
       " ('brothers', 7),\n",
       " ('deeply', 7),\n",
       " ('nearly', 7),\n",
       " ('apeoplee', 7),\n",
       " ('moots', 7),\n",
       " ('wtf', 7),\n",
       " ('toll', 7),\n",
       " ('ğŸ˜…', 7),\n",
       " ('toilet', 7),\n",
       " ('pics', 7),\n",
       " ('haters', 7),\n",
       " ('shopping', 7),\n",
       " ('lately', 7),\n",
       " ('nfl', 7),\n",
       " ('siege', 7),\n",
       " ('makeup', 7),\n",
       " ('roof', 7),\n",
       " ('verge', 7),\n",
       " ('crap', 7),\n",
       " ('possibility', 7),\n",
       " ('assignment', 7),\n",
       " ('emotional', 7),\n",
       " ('positions', 7),\n",
       " ('crawl', 7),\n",
       " ('summer', 7),\n",
       " ('fauci', 7),\n",
       " ('dude', 7),\n",
       " ('wedding', 7),\n",
       " ('isolation', 7),\n",
       " ('precious', 7),\n",
       " ('2k', 7),\n",
       " ('gives', 7),\n",
       " ('elizabeth', 7),\n",
       " ('prefer', 7),\n",
       " ('attempt', 7),\n",
       " ('kindness', 7),\n",
       " ('ğŸš¨', 7),\n",
       " ('afford', 7),\n",
       " ('questionsâ€¦', 7),\n",
       " ('hugged', 7),\n",
       " ('memories', 7),\n",
       " ('terrible', 7),\n",
       " ('messages', 7),\n",
       " ('vacation', 7),\n",
       " ('guidelines', 7),\n",
       " ('â—', 7),\n",
       " ('suicide', 7),\n",
       " ('bottle', 7),\n",
       " ('streets', 7),\n",
       " ('cried', 7),\n",
       " ('till', 7),\n",
       " ('complaining', 7),\n",
       " ('gonna', 7),\n",
       " ('senior', 7),\n",
       " ('hating', 7),\n",
       " ('blocked', 7),\n",
       " ('breakdown', 7),\n",
       " ('ğŸ˜­ğŸ˜­ğŸ˜­ğŸ˜­', 7),\n",
       " ('everytime', 7),\n",
       " ('dicks', 7),\n",
       " ('hungry', 7),\n",
       " ('lucky', 7),\n",
       " ('fantasy', 7),\n",
       " ('âœ…', 7),\n",
       " ('herself', 7),\n",
       " ('recover', 7),\n",
       " ('disaster', 7),\n",
       " ('handling', 7),\n",
       " ('website', 7),\n",
       " ('convinced', 7),\n",
       " ('quinn', 7),\n",
       " ('animals', 6),\n",
       " ('surprise', 6),\n",
       " ('ğŸ˜¢', 6),\n",
       " ('liquor', 6),\n",
       " ('responsibility', 6),\n",
       " ('increase', 6),\n",
       " ('july', 6),\n",
       " ('glad', 6),\n",
       " ('fiona', 6),\n",
       " ('youre', 6),\n",
       " ('sunday', 6),\n",
       " ('stands', 6),\n",
       " ('emails', 6),\n",
       " ('gifs', 6),\n",
       " ('vulnerable', 6),\n",
       " ('bullshit', 6),\n",
       " ('slid', 6),\n",
       " ('swear', 6),\n",
       " ('effort', 6),\n",
       " ('followfriday', 6),\n",
       " ('proposal', 6),\n",
       " ('easily', 6),\n",
       " ('finally', 6),\n",
       " ('depression', 6),\n",
       " ('adams', 6),\n",
       " ('keeps', 6),\n",
       " ('liar', 6),\n",
       " ('decisions', 6),\n",
       " ('judge', 6),\n",
       " ('flutter', 6),\n",
       " ('challenge', 6),\n",
       " ('returns', 6),\n",
       " ('platforms', 6),\n",
       " ('december', 6),\n",
       " ('alerting', 6),\n",
       " ('claims', 6),\n",
       " ('inaccurate', 6),\n",
       " ('misleading', 6),\n",
       " ('raiders', 6),\n",
       " ('recently', 6),\n",
       " ('tape', 6),\n",
       " ('valorant', 6),\n",
       " ('briefing', 6),\n",
       " ('screamed', 6),\n",
       " ('drew', 6),\n",
       " ('lady', 6),\n",
       " ('india', 6),\n",
       " ('headache', 6),\n",
       " ('wonderful', 6),\n",
       " ('plans', 6),\n",
       " ('bts', 6),\n",
       " ('bitches', 6),\n",
       " ('nose', 6),\n",
       " ('experts', 6),\n",
       " ('thinks', 6),\n",
       " ('reasons', 6),\n",
       " ('depressed', 6),\n",
       " ('teachers', 6),\n",
       " ('ğŸ˜', 6),\n",
       " ('pictures', 6),\n",
       " ('countries', 6),\n",
       " ('premier', 6),\n",
       " ('mike', 6),\n",
       " ('asleep', 6),\n",
       " ('visit', 6),\n",
       " ('angry', 6),\n",
       " ('coffee', 6),\n",
       " ('plenty', 6),\n",
       " ('joke', 6),\n",
       " ('interview', 6),\n",
       " ('dangerous', 6),\n",
       " ('omie', 6),\n",
       " ('naked', 6),\n",
       " ('crossing', 6),\n",
       " ('nhs', 6),\n",
       " ('cryin', 6),\n",
       " ('chuck', 6),\n",
       " ('schumer', 6),\n",
       " ('legislation', 6),\n",
       " ('droz', 6),\n",
       " ('disney', 6),\n",
       " ('bernie', 6),\n",
       " ('speaks', 6),\n",
       " ('letting', 6),\n",
       " ('â˜€ï¸', 6),\n",
       " ('boom', 6),\n",
       " ('pregnant', 6),\n",
       " ('breakfast', 6),\n",
       " ('lots', 6),\n",
       " ('ideas', 6),\n",
       " ('anniversary', 6),\n",
       " ('ğŸ˜', 6),\n",
       " ('easter', 6),\n",
       " ('homes', 6),\n",
       " ('ğŸ”‘', 6),\n",
       " ('statements', 6),\n",
       " ('extending', 6),\n",
       " ('lawn', 6),\n",
       " ('smile', 6),\n",
       " ('anybody', 6),\n",
       " ('ğŸ™„', 6),\n",
       " ('proper', 6),\n",
       " ('dems', 6),\n",
       " ('canada', 6),\n",
       " ('h1n1', 6),\n",
       " ('swine', 6),\n",
       " ('disastrous', 6),\n",
       " ('unnecessarily', 6),\n",
       " ('incompetence', 6),\n",
       " ('obamacare', 6),\n",
       " ('tribe', 6),\n",
       " ('candidate', 6),\n",
       " ('phd', 5),\n",
       " ('fellow', 5),\n",
       " ('\\U0001f92f', 5),\n",
       " ('betty', 5),\n",
       " ('participating', 5),\n",
       " ('okudah', 5),\n",
       " ('disapprove', 5),\n",
       " ('remind', 5),\n",
       " ('shitty', 5),\n",
       " ('confused', 5),\n",
       " ('unemployed', 5),\n",
       " ('spots', 5),\n",
       " ('whack', 5),\n",
       " ('potus', 5),\n",
       " ('york', 5),\n",
       " ('gimme', 5),\n",
       " ('tory', 5),\n",
       " ('cringe', 5),\n",
       " ('rona', 5),\n",
       " ('caught', 5),\n",
       " ('tired', 5),\n",
       " ('june', 5),\n",
       " ('wrestling', 5),\n",
       " ('annoy', 5),\n",
       " ('professor', 5),\n",
       " ('announce', 5),\n",
       " ('somewhere', 5),\n",
       " ('ğŸ’€', 5),\n",
       " ('nurse', 5),\n",
       " ('hospitals', 5),\n",
       " ('cuddle', 5),\n",
       " ('michael', 5),\n",
       " ('carti', 5),\n",
       " ('dumb', 5),\n",
       " ('haircut', 5),\n",
       " ('fav', 5),\n",
       " ('piss', 5),\n",
       " ('arrested', 5),\n",
       " ('brooks', 5),\n",
       " ('shaved', 5),\n",
       " ('nervous', 5),\n",
       " ('believes', 5),\n",
       " ('ease', 5),\n",
       " ('belongs', 5),\n",
       " ('schedule', 5),\n",
       " ('bears', 5),\n",
       " ('trey', 5),\n",
       " ('burton', 5),\n",
       " ('cooking', 5),\n",
       " ('corporate', 5),\n",
       " ('prove', 5),\n",
       " ('concern', 5),\n",
       " ('insane', 5),\n",
       " ('participate', 5),\n",
       " ('thru', 5),\n",
       " ('began', 5),\n",
       " ('lamar', 5),\n",
       " ('announcement', 5),\n",
       " ('wanting', 5),\n",
       " ('ugly', 5),\n",
       " ('nasty', 5),\n",
       " ('remix', 5),\n",
       " ('deleted', 5),\n",
       " ('receive', 5),\n",
       " ('experience', 5),\n",
       " ('dept', 5),\n",
       " ('upcoming', 5),\n",
       " ('congress', 5),\n",
       " ('taiwanese', 5),\n",
       " ('transmitted', 5),\n",
       " ('replies', 5),\n",
       " ('overall', 5),\n",
       " ('students', 5),\n",
       " ('stressed', 5),\n",
       " ('feeling', 5),\n",
       " ('nigeria', 5),\n",
       " ('seems', 5),\n",
       " ('stunned', 5),\n",
       " ('patience', 5),\n",
       " ('anyways', 5),\n",
       " ('chatting', 5),\n",
       " ('laura', 5),\n",
       " ('reminds', 5),\n",
       " ('discuss', 5),\n",
       " ('fortnite', 5),\n",
       " ('princess', 5),\n",
       " ('ğŸ˜‰', 5),\n",
       " ('huh', 5),\n",
       " ('masterpiece', 5),\n",
       " ('frivolous', 5),\n",
       " ('heartbreaking', 5),\n",
       " ('familiesfirst', 5),\n",
       " ('groceries', 5),\n",
       " ('carolina', 5),\n",
       " ('democrat', 5),\n",
       " ('loves', 5),\n",
       " ('tuned', 5),\n",
       " ('shave', 5),\n",
       " ('laughing', 5),\n",
       " ('subs', 5),\n",
       " ('exactly', 5),\n",
       " ('streams', 5),\n",
       " ('ğŸ˜', 5),\n",
       " ('accidentally', 5),\n",
       " ('ğŸ™‚', 5),\n",
       " ('saved', 5),\n",
       " ('captain', 5),\n",
       " ('teach', 5),\n",
       " ('saturday', 5),\n",
       " ('canceled', 5),\n",
       " ('constantly', 5),\n",
       " ('teams', 5),\n",
       " ('committed', 5),\n",
       " ('minnesota', 5),\n",
       " ('california', 5),\n",
       " ('scrolling', 5),\n",
       " ('closely', 5),\n",
       " ('enjoyed', 5),\n",
       " ('hotline', 5),\n",
       " ('hanging', 5),\n",
       " ('normally', 5),\n",
       " ('frankly', 5),\n",
       " ('previously', 5),\n",
       " ('presentation', 5),\n",
       " ('dont', 5),\n",
       " ('ridiculously', 5),\n",
       " ('peeps', 5),\n",
       " ('neighbor', 5),\n",
       " ('idc', 5),\n",
       " ('riverdale', 5),\n",
       " ('follows', 5),\n",
       " ('loud', 5),\n",
       " ('infection', 5),\n",
       " ('dance', 5),\n",
       " ('anyway', 5),\n",
       " ('federal', 5),\n",
       " ('ğŸ’›', 5),\n",
       " ('matters', 5),\n",
       " ('pint', 5),\n",
       " ('selecting', 5),\n",
       " ('winğŸ’°', 5),\n",
       " ('roommates', 5),\n",
       " ('slap', 5),\n",
       " ('mentally', 5),\n",
       " ('ğŸ˜‚ğŸ˜‚', 5),\n",
       " ('replaced', 5),\n",
       " ('dvsn', 5),\n",
       " ('harris', 5),\n",
       " ('fault', 5),\n",
       " ('ğŸ’”', 5),\n",
       " ('island', 5),\n",
       " ('jealous', 5),\n",
       " ('songs', 5),\n",
       " ('apeopley', 5),\n",
       " ('ozark', 5),\n",
       " ('tryna', 5),\n",
       " ('steve', 5),\n",
       " ('paycheck', 5),\n",
       " ('offended', 5),\n",
       " ('smiling', 5),\n",
       " ('strategy', 5),\n",
       " ('bailouthumans', 5),\n",
       " ('greatest', 5),\n",
       " ('turning', 5),\n",
       " ('remake', 5),\n",
       " ('skills', 5),\n",
       " ('pigeon', 5),\n",
       " ('borders', 5),\n",
       " ('forgive', 5),\n",
       " ('understanding', 5),\n",
       " ('pero', 5),\n",
       " ('traded', 5),\n",
       " ('hunker', 4),\n",
       " ('primevideo', 4),\n",
       " ('twice', 4),\n",
       " ('march', 4),\n",
       " ('admit', 4),\n",
       " ('soul', 4),\n",
       " ('undergrad', 4),\n",
       " ('shutdown', 4),\n",
       " ('roommate', 4),\n",
       " ('somehow', 4),\n",
       " ('landed', 4),\n",
       " ('walked', 4),\n",
       " ('christian', 4),\n",
       " ('talks', 4),\n",
       " ('falling', 4),\n",
       " ('grant', 4),\n",
       " ('constitution', 4),\n",
       " ('fulfill', 4),\n",
       " ('obligations', 4),\n",
       " ('unleashed', 4),\n",
       " ('whenever', 4),\n",
       " ('james', 4),\n",
       " ('jason', 4),\n",
       " ('taylor', 4),\n",
       " ('stuck', 4),\n",
       " ('salary', 4),\n",
       " ('meant', 4),\n",
       " ('entertainment', 4),\n",
       " ('ridiculous', 4),\n",
       " ('reopenamerica', 4),\n",
       " ('apartment', 4),\n",
       " ('supermarket', 4),\n",
       " ('thats', 4),\n",
       " ('slightly', 4),\n",
       " ('deliver', 4),\n",
       " ('savage', 4),\n",
       " ('properly', 4),\n",
       " ('binging', 4),\n",
       " ('stacey', 4),\n",
       " ('abrams', 4),\n",
       " ('waking', 4),\n",
       " ('ğŸ’¯', 4),\n",
       " ('7th', 4),\n",
       " ('goddamn', 4),\n",
       " ('david', 4),\n",
       " ('monthly', 4),\n",
       " ('looked', 4),\n",
       " ('ğŸ˜–', 4),\n",
       " ('lesson', 4),\n",
       " ('hugging', 4),\n",
       " ('profiles', 4),\n",
       " ('sessions', 4),\n",
       " ('devil', 4),\n",
       " ('simps', 4),\n",
       " ('desire', 4),\n",
       " ('meh', 4),\n",
       " ('sir', 4),\n",
       " ('fuckin', 4),\n",
       " ('tend', 4),\n",
       " ('minister', 4),\n",
       " ('lives', 4),\n",
       " ('counting', 4),\n",
       " ('struggle', 4),\n",
       " ('titties', 4),\n",
       " ('technically', 4),\n",
       " ('naughty', 4),\n",
       " ('teacher', 4),\n",
       " ('trending', 4),\n",
       " ('ğŸ˜‘', 4),\n",
       " ('justin', 4),\n",
       " ('lamb', 4),\n",
       " ('tracing', 4),\n",
       " ('movies', 4),\n",
       " ('nap', 4),\n",
       " ('semester', 4),\n",
       " ('reminder', 4),\n",
       " ('enjoying', 4),\n",
       " ('anime', 4),\n",
       " ('republicans', 4),\n",
       " ('disgusting', 4),\n",
       " ('assume', 4),\n",
       " ('difficult', 4),\n",
       " ('lungs', 4),\n",
       " ('taken', 4),\n",
       " ('muslims', 4),\n",
       " ('regardless', 4),\n",
       " ('5am', 4),\n",
       " ('upset', 4),\n",
       " ('haha', 4),\n",
       " ('clapping', 4),\n",
       " ('brilliant', 4),\n",
       " ('crowd', 4),\n",
       " ('talent', 4),\n",
       " ('heck', 4),\n",
       " ('faked', 4),\n",
       " ('breathing', 4),\n",
       " ('emailed', 4),\n",
       " ('potential', 4),\n",
       " ('literary', 4),\n",
       " ('imreadyimreadyimready', 4),\n",
       " ('notpanic', 4),\n",
       " ('messaged', 4),\n",
       " ('backyard', 4),\n",
       " ('stronger', 4),\n",
       " ('january', 4),\n",
       " ('suspended', 4),\n",
       " ('choke', 4),\n",
       " ('throat', 4),\n",
       " ('supporters', 4),\n",
       " ('sexy', 4),\n",
       " ('kitchen', 4),\n",
       " ('sap', 4),\n",
       " ('ğŸ’—', 4),\n",
       " ('silence', 4),\n",
       " ('kills', 4),\n",
       " ('useless', 4),\n",
       " ('restaurants', 4),\n",
       " ('liberals', 4),\n",
       " ('elite', 4),\n",
       " ('drake', 4),\n",
       " ('neighborhood', 4),\n",
       " ('realizing', 4),\n",
       " ('jones', 4),\n",
       " ('timeline', 4),\n",
       " ('cdc', 4),\n",
       " ('restaurant', 4),\n",
       " ('industry', 4),\n",
       " ('remembered', 4),\n",
       " ('stans', 4),\n",
       " ('extend', 4),\n",
       " ('horrible', 4),\n",
       " ('disease', 4),\n",
       " ('twist', 4),\n",
       " ('passing', 4),\n",
       " ('drowning', 4),\n",
       " ('cole', 4),\n",
       " ('ğŸ‘', 4),\n",
       " ('partner', 4),\n",
       " ('tells', 4),\n",
       " ('busy', 4),\n",
       " ('seniors', 4),\n",
       " ('signs', 4),\n",
       " ('spirits', 4),\n",
       " ('urged', 4),\n",
       " ('iraqis', 4),\n",
       " ('syrians', 4),\n",
       " ('kurds', 4),\n",
       " ('afghanis', 4),\n",
       " ('liberating', 4),\n",
       " ('apeopleause', 4),\n",
       " ('dreams', 4),\n",
       " ('administration', 4),\n",
       " ('greatly', 4),\n",
       " ('took', 4),\n",
       " ('physically', 4),\n",
       " ('films', 4),\n",
       " ('recommend', 4),\n",
       " ('fraction', 4),\n",
       " ('stockpile', 4),\n",
       " ('ğŸ’™', 4),\n",
       " ('neighbors', 4),\n",
       " ('valuable', 4),\n",
       " ('apologize', 4),\n",
       " ('privacy', 4),\n",
       " ('emergency', 4),\n",
       " ('yup', 4),\n",
       " ('switches', 4),\n",
       " ('madness', 4),\n",
       " ('centre', 4),\n",
       " ('clothes', 4),\n",
       " ('teeth', 4),\n",
       " ('trump2020', 4),\n",
       " ('grace', 4),\n",
       " ('mute', 4),\n",
       " ('juice', 4),\n",
       " ('removal', 4),\n",
       " ('joebiden', 4),\n",
       " ('accountable', 4),\n",
       " ('cough', 4),\n",
       " ('scheduled', 4),\n",
       " ('considering', 4),\n",
       " ('ğŸ˜’', 4),\n",
       " ('canadians', 4),\n",
       " ('laptop', 4),\n",
       " ('dancing', 4),\n",
       " ('sooooo', 4),\n",
       " ('accepted', 4),\n",
       " ('instant', 4),\n",
       " ('workout', 4),\n",
       " ('horniness', 4),\n",
       " ('basis', 4),\n",
       " ('emerge', 4),\n",
       " ('jesus', 4),\n",
       " ('sober', 4),\n",
       " ('attractive', 4),\n",
       " ('looks', 4),\n",
       " ('spreading', 4),\n",
       " ('tea', 4),\n",
       " ('alive', 4),\n",
       " ('isolating', 4),\n",
       " ('vitamin', 4),\n",
       " ('grind', 4),\n",
       " ('compare', 4),\n",
       " ('ğŸ˜‚ğŸ˜‚ğŸ˜‚', 4),\n",
       " ('rumors', 4),\n",
       " ('locals', 4),\n",
       " ('theyre', 4),\n",
       " ('passion', 4),\n",
       " ('debt', 4),\n",
       " ('emotionally', 4),\n",
       " ('diamond', 4),\n",
       " ('ğŸ’ğŸ’ğŸ’', 4),\n",
       " ('dragging', 4),\n",
       " ('1st', 4),\n",
       " ('spotify', 4),\n",
       " ('whitmer', 4),\n",
       " ('notifications', 4),\n",
       " ('happiness', 4),\n",
       " ('ğŸ‰', 4),\n",
       " ('lone', 4),\n",
       " ('hundred', 4),\n",
       " ('conversation', 4),\n",
       " ('pulte', 4),\n",
       " ('prices', 4),\n",
       " ('however', 4),\n",
       " ('ppp', 4),\n",
       " ('drained', 4),\n",
       " ('combination', 4),\n",
       " ('dollars', 4),\n",
       " ('cassper', 4),\n",
       " ('tho', 4),\n",
       " ('previous', 4),\n",
       " ('clearly', 4),\n",
       " ('opportunity', 4),\n",
       " ('pets', 4),\n",
       " ('nudes', 4),\n",
       " ('extended', 4),\n",
       " ('coughing', 4),\n",
       " ('pissed', 4),\n",
       " ('ğŸ’–', 4),\n",
       " ('refer', 4),\n",
       " ('compared', 4),\n",
       " ('ğŸ˜ª', 4),\n",
       " ('unpopular', 4),\n",
       " ('opinion', 4),\n",
       " ('medication', 4),\n",
       " ('protest', 4),\n",
       " ('afro', 4),\n",
       " ('viewers', 4),\n",
       " ('hilarious', 4),\n",
       " ('10k', 4),\n",
       " ('mf', 4),\n",
       " ('worry', 4),\n",
       " ('failure', 4),\n",
       " ('milk', 4),\n",
       " ('difference', 4),\n",
       " ('absence', 4),\n",
       " ('alx', 4),\n",
       " ('crush', 4),\n",
       " ('stayed', 4),\n",
       " ('planning', 4),\n",
       " ('chicken', 4),\n",
       " ('unfortunately', 4),\n",
       " ('millionaire', 4),\n",
       " ('infected', 4),\n",
       " ('supeopleies', 4),\n",
       " ('chinese', 4),\n",
       " ('\\U0001f970\\U0001f970\\U0001f970', 4),\n",
       " ('perform', 4),\n",
       " ('judging', 4),\n",
       " ('âŒ', 4),\n",
       " ('harder', 4),\n",
       " ('idiots', 4),\n",
       " ('smh', 4),\n",
       " ('erotica', 4),\n",
       " ('boobs', 4),\n",
       " ('welp', 4),\n",
       " ('â€¦', 4),\n",
       " ('kamala', 4),\n",
       " ('abbott', 4),\n",
       " ('requested', 4),\n",
       " ('tuning', 4),\n",
       " ('doubling', 4),\n",
       " ('invisible', 4),\n",
       " ('gop', 4),\n",
       " ('â˜†', 4),\n",
       " ('ï½¡', 4),\n",
       " ('followed', 4),\n",
       " ('individuals', 4),\n",
       " ('pushing', 4),\n",
       " ('carers', 4),\n",
       " ('efforts', 4),\n",
       " ('parade', 4),\n",
       " ('sane', 4),\n",
       " ('atm', 4),\n",
       " ('\\U0001f90d', 4),\n",
       " ('bathroom', 4),\n",
       " ('crack', 4),\n",
       " ('sierra', 4),\n",
       " ('nonsense', 4),\n",
       " ('bitter', 4),\n",
       " ('bob', 4),\n",
       " ('differently', 4),\n",
       " ('jets', 4),\n",
       " ('filed', 4),\n",
       " ('miami', 4),\n",
       " ('equally', 4),\n",
       " ('crash', 4),\n",
       " ('jus', 3),\n",
       " ('ruined', 3),\n",
       " ('lack', 3),\n",
       " ('ğŸ˜©ğŸ˜©ğŸ˜©', 3),\n",
       " ('realised', 3),\n",
       " ('telegram', 3),\n",
       " ('drawing', 3),\n",
       " ('michigan', 3),\n",
       " ...]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(unknown_text.items(), key=lambda d: d[1], reverse=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# still_more_apostrophes = {"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "      <th>reply</th>\n",
       "      <th>categories</th>\n",
       "      <th>mp4</th>\n",
       "      <th>map_punc_text</th>\n",
       "      <th>map_punc_reply</th>\n",
       "      <th>map_more_punc_text</th>\n",
       "      <th>map_more_punc_reply</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>we can all agree that any song by Niall Horan.</td>\n",
       "      <td>oui oui</td>\n",
       "      <td>[yes]</td>\n",
       "      <td>6dc39e96b11275f064fdaed88273b45e.mp4</td>\n",
       "      <td>we can all agree that any song by Niall Horan .</td>\n",
       "      <td>oui oui</td>\n",
       "      <td>we can all agree that any song by Niall Horan .</td>\n",
       "      <td>oui oui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Will you be installing #ScottyFromMarketing's ...</td>\n",
       "      <td></td>\n",
       "      <td>[no]</td>\n",
       "      <td>cfff051f05d8d3b7136c7d58ea6ad55f.mp4</td>\n",
       "      <td>Will you be installing  # ScottyFromMarketing ...</td>\n",
       "      <td></td>\n",
       "      <td>Will you be install  # ScottyFromMarketing  ' ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Growing up my mum would call me a Nigga despit...</td>\n",
       "      <td>And he joins in??? Pour some hot grits on em</td>\n",
       "      <td>[smh]</td>\n",
       "      <td>bf39e7bd9ad24354ce3ba6822b0104af.mp4</td>\n",
       "      <td>Growing up my mum would call me a Nigga despit...</td>\n",
       "      <td>And he joins in ?  ?  ?  Pour some hot grits o...</td>\n",
       "      <td>Growing up my mum would call me a Nigga despit...</td>\n",
       "      <td>And he joins in ?  ?  ?  Pour some hot grits o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Rest your head on my chest when the world feel...</td>\n",
       "      <td>ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚</td>\n",
       "      <td>[wink]</td>\n",
       "      <td>173a707a04c277354a2f23cf01d6151e.mp4</td>\n",
       "      <td>Rest your head on my chest when the world feel...</td>\n",
       "      <td>ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚</td>\n",
       "      <td>Rest your head on my chest when the world feel...</td>\n",
       "      <td>ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Imagine Will Hernandez and Wills both doing a ...</td>\n",
       "      <td></td>\n",
       "      <td>[yes]</td>\n",
       "      <td>aab6d6bfb0c1382269ddba9b71cc8b7a.mp4</td>\n",
       "      <td>Imagine Will Hernandez and Wills both doing a ...</td>\n",
       "      <td></td>\n",
       "      <td>Imagine Will Hernandez and Wills both doing a ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx                                               text  \\\n",
       "0    0     we can all agree that any song by Niall Horan.   \n",
       "1    1  Will you be installing #ScottyFromMarketing's ...   \n",
       "2    2  Growing up my mum would call me a Nigga despit...   \n",
       "3    3  Rest your head on my chest when the world feel...   \n",
       "4    4  Imagine Will Hernandez and Wills both doing a ...   \n",
       "\n",
       "                                          reply categories  \\\n",
       "0                                       oui oui      [yes]   \n",
       "1                                                     [no]   \n",
       "2  And he joins in??? Pour some hot grits on em      [smh]   \n",
       "3                                         ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚     [wink]   \n",
       "4                                                    [yes]   \n",
       "\n",
       "                                    mp4  \\\n",
       "0  6dc39e96b11275f064fdaed88273b45e.mp4   \n",
       "1  cfff051f05d8d3b7136c7d58ea6ad55f.mp4   \n",
       "2  bf39e7bd9ad24354ce3ba6822b0104af.mp4   \n",
       "3  173a707a04c277354a2f23cf01d6151e.mp4   \n",
       "4  aab6d6bfb0c1382269ddba9b71cc8b7a.mp4   \n",
       "\n",
       "                                       map_punc_text  \\\n",
       "0   we can all agree that any song by Niall Horan .    \n",
       "1  Will you be installing  # ScottyFromMarketing ...   \n",
       "2  Growing up my mum would call me a Nigga despit...   \n",
       "3  Rest your head on my chest when the world feel...   \n",
       "4  Imagine Will Hernandez and Wills both doing a ...   \n",
       "\n",
       "                                      map_punc_reply  \\\n",
       "0                                            oui oui   \n",
       "1                                                      \n",
       "2  And he joins in ?  ?  ?  Pour some hot grits o...   \n",
       "3                                              ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚   \n",
       "4                                                      \n",
       "\n",
       "                                  map_more_punc_text  \\\n",
       "0   we can all agree that any song by Niall Horan .    \n",
       "1  Will you be install  # ScottyFromMarketing  ' ...   \n",
       "2  Growing up my mum would call me a Nigga despit...   \n",
       "3  Rest your head on my chest when the world feel...   \n",
       "4  Imagine Will Hernandez and Wills both doing a ...   \n",
       "\n",
       "                                 map_more_punc_reply  \n",
       "0                                            oui oui  \n",
       "1                                                     \n",
       "2  And he joins in ?  ?  ?  Pour some hot grits o...  \n",
       "3                                              ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚  \n",
       "4                                                     "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "      <th>reply</th>\n",
       "      <th>map_punc_text</th>\n",
       "      <th>map_punc_reply</th>\n",
       "      <th>map_more_punc_text</th>\n",
       "      <th>map_more_punc_reply</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32000</td>\n",
       "      <td>Drop your cash app, use hashtag #BailoutHumansNow</td>\n",
       "      <td>$tyratomaro #BailoutHumans</td>\n",
       "      <td>Drop your cash app ,  use hashtag  # BailoutHu...</td>\n",
       "      <td>$ tyratomaro  # BailoutHumans</td>\n",
       "      <td>Drop your cash app ,  use hashtag  # BailoutHu...</td>\n",
       "      <td>$ tyratomaro  # BailoutHumans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32001</td>\n",
       "      <td>After interviewing with a few incredible peopl...</td>\n",
       "      <td>CONGRATS!!!!!</td>\n",
       "      <td>After interviewing with a few incredible peopl...</td>\n",
       "      <td>CONGRATS !  !  !  !  !</td>\n",
       "      <td>After interviewing with a few incredible peopl...</td>\n",
       "      <td>CONGRATS !  !  !  !  !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32002</td>\n",
       "      <td>I know GTC festival not happening next month b...</td>\n",
       "      <td></td>\n",
       "      <td>I know GTC festival not happening next month b...</td>\n",
       "      <td></td>\n",
       "      <td>I know GTC festival not happening next month b...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32003</td>\n",
       "      <td>Lordy, my daughter just said, â€œI wonder how th...</td>\n",
       "      <td></td>\n",
       "      <td>Lordy ,  my daughter just said ,    \"  I wonde...</td>\n",
       "      <td></td>\n",
       "      <td>Lordy ,  my daughter just said ,    \"  I wonde...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32004</td>\n",
       "      <td>THE UNEMPLOYMENT CLAIM SYSTEM SUCKS SO MUCH DICK</td>\n",
       "      <td>Watching everyone else get their weekly unempl...</td>\n",
       "      <td>THE UNEMPLOYMENT CLAIM SYSTEM SUCKS SO MUCH DICK</td>\n",
       "      <td>Watching everyone else get their weekly unempl...</td>\n",
       "      <td>THE UNEMPLOYMENT CLAIM SYSTEM SUCKS SO MUCH DICK</td>\n",
       "      <td>Watching everyone else get their weekly unempl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     idx                                               text  \\\n",
       "0  32000  Drop your cash app, use hashtag #BailoutHumansNow   \n",
       "1  32001  After interviewing with a few incredible peopl...   \n",
       "2  32002  I know GTC festival not happening next month b...   \n",
       "3  32003  Lordy, my daughter just said, â€œI wonder how th...   \n",
       "4  32004   THE UNEMPLOYMENT CLAIM SYSTEM SUCKS SO MUCH DICK   \n",
       "\n",
       "                                               reply  \\\n",
       "0                         $tyratomaro #BailoutHumans   \n",
       "1                                      CONGRATS!!!!!   \n",
       "2                                                      \n",
       "3                                                      \n",
       "4  Watching everyone else get their weekly unempl...   \n",
       "\n",
       "                                       map_punc_text  \\\n",
       "0  Drop your cash app ,  use hashtag  # BailoutHu...   \n",
       "1  After interviewing with a few incredible peopl...   \n",
       "2  I know GTC festival not happening next month b...   \n",
       "3  Lordy ,  my daughter just said ,    \"  I wonde...   \n",
       "4   THE UNEMPLOYMENT CLAIM SYSTEM SUCKS SO MUCH DICK   \n",
       "\n",
       "                                      map_punc_reply  \\\n",
       "0                      $ tyratomaro  # BailoutHumans   \n",
       "1                            CONGRATS !  !  !  !  !    \n",
       "2                                                      \n",
       "3                                                      \n",
       "4  Watching everyone else get their weekly unempl...   \n",
       "\n",
       "                                  map_more_punc_text  \\\n",
       "0  Drop your cash app ,  use hashtag  # BailoutHu...   \n",
       "1  After interviewing with a few incredible peopl...   \n",
       "2  I know GTC festival not happening next month b...   \n",
       "3  Lordy ,  my daughter just said ,    \"  I wonde...   \n",
       "4   THE UNEMPLOYMENT CLAIM SYSTEM SUCKS SO MUCH DICK   \n",
       "\n",
       "                                 map_more_punc_reply  \n",
       "0                      $ tyratomaro  # BailoutHumans  \n",
       "1                            CONGRATS !  !  !  !  !   \n",
       "2                                                     \n",
       "3                                                     \n",
       "4  Watching everyone else get their weekly unempl...  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output preprocessed to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_preprocessed = df_train[['idx', 'map_more_punc_text', 'map_more_punc_reply', 'categories']].copy()\n",
    "df_preprocessed.columns = ['idx', 'text', 'reply', 'categories']\n",
    "df_preprocessed.to_json('./preprocessed/preprocess_train.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed_dev = df_dev[['idx', 'map_more_punc_text', 'map_more_punc_reply']].copy()\n",
    "df_preprocessed_dev.columns = ['idx', 'text', 'reply']\n",
    "df_preprocessed_dev.to_json('./preprocessed/preprocess_dev.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
