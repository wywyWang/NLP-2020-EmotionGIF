{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from random import random\n",
    "import emoji\n",
    "from tqdm import notebook\n",
    "def tqdm(x, **kargs):\n",
    "    return notebook.tqdm(x, leave=False, **kargs)\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter, defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 23:38:24.530949 140680772192064 file_utils.py:39] PyTorch version 1.5.0 available.\n",
      "/home/ino/anaconda3/envs/TrackNet/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ino/anaconda3/envs/TrackNet/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ino/anaconda3/envs/TrackNet/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ino/anaconda3/envs/TrackNet/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ino/anaconda3/envs/TrackNet/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ino/anaconda3/envs/TrackNet/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer, RobertaModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of text in training data: 32000\n",
      "Number of text in categories: 43\n",
      "Number of text in developing data: 4000\n",
      "Number of text in testing data: 4000\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_json('./source/train_gold.json', lines=True)\n",
    "categories_type = pd.read_json('./source/categories.json', lines=True)\n",
    "df_dev = pd.read_json('./source/dev_unlabeled.json', lines=True)\n",
    "df_test = pd.read_json('./source/test_unlabeled.json', lines=True)\n",
    "print(\"Number of text in training data: {}\".format(df_train.shape[0]))\n",
    "print(\"Number of text in categories: {}\".format(categories_type.shape[1]))\n",
    "print(\"Number of text in developing data: {}\".format(df_dev.shape[0]))\n",
    "print(\"Number of text in testing data: {}\".format(df_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 23:38:28.482975 140680772192064 tokenization_utils.py:1015] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /home/ino/.cache/torch/transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "I0604 23:38:28.484291 140680772192064 tokenization_utils.py:1015] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /home/ino/.cache/torch/transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "I0604 23:38:29.440285 140680772192064 configuration_utils.py:285] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at /home/ino/.cache/torch/transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690\n",
      "I0604 23:38:29.441653 140680772192064 configuration_utils.py:321] Model config RobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0604 23:38:29.474719 140680772192064 modeling_utils.py:650] loading weights file https://cdn.huggingface.co/roberta-base-pytorch_model.bin from cache at /home/ino/.cache/torch/transformers/80b4a484eddeb259bec2f06a6f2f05d90934111628e0e1c09a33bd4a121358e1.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "model = RobertaModel.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "roberta_vocab = pd.read_json('roberta_vocab/vocab.json', typ='series')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>',\n",
       " '<pad>',\n",
       " '</s>',\n",
       " '<unk>',\n",
       " '.',\n",
       " 'Ġthe',\n",
       " ',',\n",
       " 'Ġto',\n",
       " 'Ġand',\n",
       " 'Ġof',\n",
       " 'Ġa',\n",
       " 'Ġin',\n",
       " '-',\n",
       " 'Ġfor',\n",
       " 'Ġthat',\n",
       " 'Ġon',\n",
       " 'Ġis',\n",
       " 'âĢ',\n",
       " \"'s\",\n",
       " 'Ġwith',\n",
       " 'ĠThe',\n",
       " 'Ġwas',\n",
       " 'Ġ\"',\n",
       " 'Ġat',\n",
       " 'Ġit',\n",
       " 'Ġas',\n",
       " 'Ġsaid',\n",
       " 'Ļ',\n",
       " 'Ġbe',\n",
       " 's',\n",
       " 'Ġby',\n",
       " 'Ġfrom',\n",
       " 'Ġare',\n",
       " 'Ġhave',\n",
       " 'Ġhas',\n",
       " ':',\n",
       " 'Ġ(',\n",
       " 'Ġhe',\n",
       " 'ĠI',\n",
       " 'Ġhis',\n",
       " 'Ġwill',\n",
       " 'Ġan',\n",
       " 'Ġthis',\n",
       " ')',\n",
       " 'ĠâĢ',\n",
       " 'Ġnot',\n",
       " 'Ŀ',\n",
       " 'Ġyou',\n",
       " 'ľ',\n",
       " 'Ġtheir',\n",
       " 'Ġor',\n",
       " 'Ġthey',\n",
       " 'Ġwe',\n",
       " 'Ġbut',\n",
       " 'Ġwho',\n",
       " 'Ġmore',\n",
       " 'Ġhad',\n",
       " 'Ġbeen',\n",
       " 'Ġwere',\n",
       " 'Ġabout',\n",
       " ',\"',\n",
       " 'Ġwhich',\n",
       " 'Ġup',\n",
       " 'Ġits',\n",
       " 'Ġcan',\n",
       " 'Ġone',\n",
       " 'Ġout',\n",
       " 'Ġalso',\n",
       " 'Ġ$',\n",
       " 'Ġher',\n",
       " 'Ġall',\n",
       " 'Ġafter',\n",
       " '.\"',\n",
       " '/',\n",
       " 'Ġwould',\n",
       " \"'t\",\n",
       " 'Ġyear',\n",
       " 'Ġwhen',\n",
       " 'Ġfirst',\n",
       " 'Ġshe',\n",
       " 'Ġtwo',\n",
       " 'Ġover',\n",
       " 'Ġpeople',\n",
       " 'ĠA',\n",
       " 'Ġour',\n",
       " 'ĠIt',\n",
       " 'Ġtime',\n",
       " 'Ġthan',\n",
       " 'Ġinto',\n",
       " 'Ġthere',\n",
       " 't',\n",
       " 'ĠHe',\n",
       " 'Ġnew',\n",
       " 'ĠâĢĶ',\n",
       " 'Ġlast',\n",
       " 'Ġjust',\n",
       " 'ĠIn',\n",
       " 'Ġother',\n",
       " 'Ġso',\n",
       " 'Ġwhat',\n",
       " 'I',\n",
       " 'Ġlike',\n",
       " 'a',\n",
       " 'Ġsome',\n",
       " 'S',\n",
       " 'Ã«',\n",
       " 'Ġthem',\n",
       " 'Ġyears',\n",
       " \"'\",\n",
       " 'Ġdo',\n",
       " 'Ġyour',\n",
       " 'Ġ-',\n",
       " 'Ġ1',\n",
       " '\"',\n",
       " 'Ġif',\n",
       " 'Ġcould',\n",
       " '?',\n",
       " 'Ġno',\n",
       " 'i',\n",
       " 'm',\n",
       " 'Ġget',\n",
       " 'ĠU',\n",
       " 'Ġnow',\n",
       " 'Ġhim',\n",
       " 'Ġback',\n",
       " 'ĠBut',\n",
       " 'ĠâĢĵ',\n",
       " 'Ġmy',\n",
       " \"Ġ'\",\n",
       " 'Ġonly',\n",
       " 'Ġthree',\n",
       " ';',\n",
       " 'Ġ2',\n",
       " 'The',\n",
       " '1',\n",
       " 'Ġpercent',\n",
       " 'Ġagainst',\n",
       " 'Ġbefore',\n",
       " 'Ġcompany',\n",
       " 'o',\n",
       " 'ĠTrump',\n",
       " 'Ġhow',\n",
       " 'Ġbecause',\n",
       " 'Ġany',\n",
       " 'Ġmost',\n",
       " 'Ġbeing',\n",
       " 'Ġmake',\n",
       " 'Ġwhere',\n",
       " 'Ġduring',\n",
       " 'Ġthrough',\n",
       " 'Ġwhile',\n",
       " '000',\n",
       " 'ĠThis',\n",
       " 'Ġmillion',\n",
       " 'ing',\n",
       " 'Ġ3',\n",
       " 'Ġmade',\n",
       " 'Ġwell',\n",
       " 'Ġ10',\n",
       " 'Ġdown',\n",
       " 'Ġoff',\n",
       " 'Ġsays',\n",
       " 'Ġme',\n",
       " 'ĠB',\n",
       " 'Ġgoing',\n",
       " 'Ġteam',\n",
       " 'ĠWe',\n",
       " 'Ġthose',\n",
       " 'Ġgovernment',\n",
       " 'Ġway',\n",
       " 'We',\n",
       " 'Ġmany',\n",
       " 'Ġthen',\n",
       " 'Ġwork',\n",
       " 'Ġtold',\n",
       " 'com',\n",
       " '2',\n",
       " 'Ġgame',\n",
       " 'ĠAnd',\n",
       " 'in',\n",
       " 'year',\n",
       " 'Ġp',\n",
       " 'Ġvery',\n",
       " 'Ġday',\n",
       " 'Ġhome',\n",
       " 'Ġtake',\n",
       " 'Ġweek',\n",
       " 'Ġsince',\n",
       " 'ĠNew',\n",
       " 'Ġmay',\n",
       " 'Ġeven',\n",
       " 'Ġseason',\n",
       " 'Ġsee',\n",
       " 'Ġ2017',\n",
       " 'Ġstate',\n",
       " 'Ġ5',\n",
       " 'ed',\n",
       " 'Ġshould',\n",
       " 'Ġaround',\n",
       " 'Ġ2018',\n",
       " 'Ġsecond',\n",
       " 'Ġus',\n",
       " 'Ġstill',\n",
       " 'Ġmuch',\n",
       " 'Ġ4',\n",
       " 'Ġgood',\n",
       " 'Ġthink',\n",
       " '%',\n",
       " 'ĠS',\n",
       " 'Ġthese',\n",
       " 'Ġmarket',\n",
       " 'ĠD',\n",
       " 'th',\n",
       " 'Ġgo',\n",
       " \"'re\",\n",
       " 'Ġsuch',\n",
       " 'Ġknow',\n",
       " 'Ġincluding',\n",
       " 'Ġdon',\n",
       " 'y',\n",
       " 'Ġnext',\n",
       " 'ĠP',\n",
       " 'Ġdid',\n",
       " 'Ġunder',\n",
       " 'Ġsay',\n",
       " 'en',\n",
       " 'ĠL',\n",
       " 'Ġbetween',\n",
       " 'Ġper',\n",
       " 'ĠK',\n",
       " 'ĠC',\n",
       " 'Ġ6',\n",
       " 'Ġworld',\n",
       " 'Ġpart',\n",
       " 'ĠN',\n",
       " 'Ġright',\n",
       " 'Ġwant',\n",
       " 'Ġfour',\n",
       " '),',\n",
       " 'Ġhigh',\n",
       " 'Ġneed',\n",
       " 're',\n",
       " 'e',\n",
       " 'It',\n",
       " 'Ġhelp',\n",
       " '5',\n",
       " '3',\n",
       " 'Ġcountry',\n",
       " 'ĠR',\n",
       " 'Ġpolice',\n",
       " 'A',\n",
       " 'Ġlong',\n",
       " 'ĠThey',\n",
       " 'Ġend',\n",
       " 'er',\n",
       " 'ĠT',\n",
       " 'ĠM',\n",
       " 'u',\n",
       " 'Ġboth',\n",
       " 'Ġhere',\n",
       " 'an',\n",
       " 'on',\n",
       " 'Ġ7',\n",
       " 'Ġde',\n",
       " 'ĠShe',\n",
       " 'Ġbusiness',\n",
       " 'Ġreport',\n",
       " 'j',\n",
       " 'ers',\n",
       " 'Ġreally',\n",
       " 'ĠPresident',\n",
       " 'ar',\n",
       " 'ĠG',\n",
       " 'ĠFriday',\n",
       " 'ĠF',\n",
       " 'Ġbest',\n",
       " 'Ġsame',\n",
       " 'Ġanother',\n",
       " 'Ġset',\n",
       " 'old',\n",
       " 'ĠThat',\n",
       " 'as',\n",
       " 'n',\n",
       " 'Ġcome',\n",
       " 'Ġfamily',\n",
       " 'Ġpublic',\n",
       " 'ĠFor',\n",
       " 'ĠAs',\n",
       " '0',\n",
       " 'ĠH',\n",
       " 'Ġ8',\n",
       " 'Ġ20',\n",
       " 'Ġfive',\n",
       " 'es',\n",
       " 'ĠTuesday',\n",
       " 'Ġn',\n",
       " 'ĠThursday',\n",
       " 'Ġquarter',\n",
       " 'h',\n",
       " 'Ġtop',\n",
       " 'Ġgot',\n",
       " 'Ġlife',\n",
       " 'ĠMonday',\n",
       " 'Ġfound',\n",
       " 'Ġuse',\n",
       " 'ĠW',\n",
       " '4',\n",
       " 'ĠWednesday',\n",
       " 'Ġown',\n",
       " 'Ġaccording',\n",
       " 'Ġplay',\n",
       " 'Ġshow',\n",
       " 'ĠSt',\n",
       " 'Ġman',\n",
       " 'Ġleft',\n",
       " 'ĠUnited',\n",
       " 'Ġ12',\n",
       " 'Ġplace',\n",
       " 'ĠIf',\n",
       " 'Ġlot',\n",
       " 'Ġformer',\n",
       " 'Ġ0',\n",
       " ').',\n",
       " 'Ġsupport',\n",
       " 'ie',\n",
       " 'Ġbillion',\n",
       " 'Ġt',\n",
       " 'Ġshares',\n",
       " '!',\n",
       " 'z',\n",
       " 'k',\n",
       " 'ĠState',\n",
       " 'Ġpoints',\n",
       " 'Ġgroup',\n",
       " 'Ġschool',\n",
       " 'Ġinformation',\n",
       " 'Ġ2016',\n",
       " 'al',\n",
       " 'r',\n",
       " 'Ġwin',\n",
       " 'Ġnews',\n",
       " 'Ġused',\n",
       " 'Ġput',\n",
       " 'Ġcity',\n",
       " 'ĠJ',\n",
       " 'ĠThere',\n",
       " 'Ġnumber',\n",
       " 'C',\n",
       " \"'ve\",\n",
       " 'Ġeach',\n",
       " 'Ġtoo',\n",
       " 'Ġwon',\n",
       " 'ly',\n",
       " 'Ġmonth',\n",
       " 'is',\n",
       " 'Ġadded',\n",
       " 'Ġlook',\n",
       " 'Ġbetter',\n",
       " 'Ġevery',\n",
       " 'Ġ&',\n",
       " 'Ġdays',\n",
       " 'Ġ9',\n",
       " 'Ġtook',\n",
       " 'Ġnight',\n",
       " 'Ġe',\n",
       " 'Ġ11',\n",
       " 'os',\n",
       " 'Ġfew',\n",
       " 'or',\n",
       " 'ĠNorth',\n",
       " 'ĠYou',\n",
       " 'Ġthird',\n",
       " 'Ġgreat',\n",
       " 'Ġcalled',\n",
       " 'ĠOn',\n",
       " 'Ġpast',\n",
       " 'Ġcame',\n",
       " 'Ġmonths',\n",
       " 'ĠSaturday',\n",
       " 'Ġ15',\n",
       " 'Ġbig',\n",
       " 'ĠE',\n",
       " 'ĠUS',\n",
       " 'Ġthings',\n",
       " 'ĠO',\n",
       " 'Ġd',\n",
       " 'Ġstart',\n",
       " 'B',\n",
       " 'Ġstock',\n",
       " 'Ġ30',\n",
       " 'Ġwomen',\n",
       " 'ĠSouth',\n",
       " 'ĠMay',\n",
       " 'Ġnever',\n",
       " 'Ġpresident',\n",
       " 'ĠSunday',\n",
       " 'Ġwithout',\n",
       " 'man',\n",
       " '8',\n",
       " 'Ġdidn',\n",
       " 'Ġlocal',\n",
       " '6',\n",
       " 'Ġsomething',\n",
       " 'Ġcase',\n",
       " 'ĠAll',\n",
       " 'it',\n",
       " '7',\n",
       " 'ĠSo',\n",
       " 'Ġchildren',\n",
       " 'Ġaway',\n",
       " 'Ġlittle',\n",
       " 'Ġsix',\n",
       " 'ĠCity',\n",
       " 'ĠCounty',\n",
       " 'Ġdata',\n",
       " 'at',\n",
       " 'Ġalready',\n",
       " 'd',\n",
       " 'Ġmoney',\n",
       " 'Ġearly',\n",
       " 'Ġacross',\n",
       " 'Ġexpected',\n",
       " 'Ġrun',\n",
       " 'Ġlater',\n",
       " 'am',\n",
       " 'Ġprice',\n",
       " 'Ġgames',\n",
       " 'ĠMr',\n",
       " 'b',\n",
       " 'Ġmight',\n",
       " 'Ġdifferent',\n",
       " 'Ġreported',\n",
       " 'Ġdeal',\n",
       " 'Ġmedia',\n",
       " 'Ġgrowth',\n",
       " 'Ġcommunity',\n",
       " 'ĠChina',\n",
       " \"'m\",\n",
       " 'c',\n",
       " 'Ġwent',\n",
       " 'ĠNo',\n",
       " 'Ġable',\n",
       " 'Ġmaking',\n",
       " 'Ġarea',\n",
       " 'Ġfar',\n",
       " 'Ġstatement',\n",
       " 'ĠHouse',\n",
       " 'Ġworking',\n",
       " 'M',\n",
       " 'Ġk',\n",
       " 'Ġseen',\n",
       " 'Ġcompanies',\n",
       " 'Ġtoday',\n",
       " 'Ġmembers',\n",
       " 'Ġuntil',\n",
       " 'Ġfull',\n",
       " 'Ġagain',\n",
       " 'Ġhalf',\n",
       " 'Ġshare',\n",
       " 'le',\n",
       " 'Ġalways',\n",
       " 'Ġcourt',\n",
       " 'l',\n",
       " 'and',\n",
       " 'Ġchange',\n",
       " 'Ġfind',\n",
       " '9',\n",
       " 'Ġsystem',\n",
       " 'ĠV',\n",
       " 'ĠYork',\n",
       " 'ĠAmerican',\n",
       " 'Ġhead',\n",
       " 'Ġplayers',\n",
       " 'Ġdoes',\n",
       " 'Ġhealth',\n",
       " 'Ġm',\n",
       " 'Ġpower',\n",
       " 'Ġpoint',\n",
       " 'Ġhit',\n",
       " 'Ġ.',\n",
       " 'Ġ--',\n",
       " 'Ġfree',\n",
       " '.,',\n",
       " 'Ġlead',\n",
       " 'Ġseveral',\n",
       " 'Ġrecent',\n",
       " 'Ġcall',\n",
       " 'N',\n",
       " 'Ġlaw',\n",
       " 'Ġkeep',\n",
       " 'Ġopen',\n",
       " 'ĠNews',\n",
       " 'Ġgive',\n",
       " 'ia',\n",
       " 'ĠMarch',\n",
       " 'D',\n",
       " 'ĠNational',\n",
       " 'ĠAt',\n",
       " 'Ġtimes',\n",
       " 'Ġfuture',\n",
       " 'R',\n",
       " 'Ġ14',\n",
       " 'ĠJune',\n",
       " 'Ġofficials',\n",
       " 'Ġ18',\n",
       " 'Ġimportant',\n",
       " 'f',\n",
       " 'Ġfinal',\n",
       " 'Ġ13',\n",
       " 'ĠOne',\n",
       " 'P',\n",
       " 'Ġfollowing',\n",
       " 'Ġcar',\n",
       " 'Ġleast',\n",
       " 'Ġwater',\n",
       " 'Ġevent',\n",
       " 'Ġline',\n",
       " 'Ġmove',\n",
       " 'Ġservices',\n",
       " 'Ġhaving',\n",
       " 'ĠWhen',\n",
       " 'Ġstudents',\n",
       " 'ĠPolice',\n",
       " 'el',\n",
       " 'Ġam',\n",
       " 'ĠZ',\n",
       " 'Ġside',\n",
       " 'Ġstory',\n",
       " 'Ġdue',\n",
       " 'Ġmeeting',\n",
       " 'K',\n",
       " 'Ġmust',\n",
       " 'ĠStates',\n",
       " 'Ġlikely',\n",
       " 'G',\n",
       " 'Ġcontinue',\n",
       " 'Ġago',\n",
       " 'Ġparty',\n",
       " 'Ġmajor',\n",
       " 'Ġindustry',\n",
       " 'Ġless',\n",
       " '30',\n",
       " 'Ġun',\n",
       " 'Ġhard',\n",
       " 'Ġservice',\n",
       " 'Ġ16',\n",
       " 'Ġlooking',\n",
       " 'Ġheld',\n",
       " 've',\n",
       " 'Ġwhether',\n",
       " 'ĠJuly',\n",
       " 'Ġtaken',\n",
       " 'Ġalong',\n",
       " 'Ġasked',\n",
       " 'Ġstarted',\n",
       " 'Ġbecome',\n",
       " 'Ġforward',\n",
       " 'Ġresearch',\n",
       " 'Ġoffice',\n",
       " 'Ġpolitical',\n",
       " 'to',\n",
       " 'Ġtogether',\n",
       " 'Ġgetting',\n",
       " 'Ġplan',\n",
       " 'Ġ25',\n",
       " 'T',\n",
       " 'Ġamong',\n",
       " 'Ġcoming',\n",
       " 'Ġdecision',\n",
       " 'Ġvideo',\n",
       " 'Ġ2015',\n",
       " 'g',\n",
       " 'ĠAfter',\n",
       " 'Ġsecurity',\n",
       " 'L',\n",
       " 'Ġcare',\n",
       " 'Ġgiven',\n",
       " 'Ġavailable',\n",
       " 'âĢĶ',\n",
       " 'Ġs',\n",
       " 'ĠWest',\n",
       " \"'ll\",\n",
       " 'Ġpay',\n",
       " 'Ġnear',\n",
       " 'Ġsaying',\n",
       " 'Ġannounced',\n",
       " 'Ġprogram',\n",
       " 'ĠApril',\n",
       " 'Ġreal',\n",
       " 'ĠUniversity',\n",
       " 'ĠWith',\n",
       " 'AP',\n",
       " 'Ġsocial',\n",
       " 'Ġclose',\n",
       " 'et',\n",
       " 'Ġcurrent',\n",
       " 'Ġwhy',\n",
       " 'F',\n",
       " 'ĠTo',\n",
       " 'ĠTwitter',\n",
       " 'Ġthough',\n",
       " 'Ġ17',\n",
       " 'Ġtaking',\n",
       " 'ĠInc',\n",
       " 'Ġmen',\n",
       " 'w',\n",
       " 'Ġcomes',\n",
       " 'ley',\n",
       " 'Ġdoing',\n",
       " 'Ġprocess',\n",
       " 'ĠJohn',\n",
       " 'ch',\n",
       " '00',\n",
       " 'Ġfinancial',\n",
       " 'Ġlow',\n",
       " 'Ġenough',\n",
       " 'ĠWhile',\n",
       " 'Ġfurther',\n",
       " 'Ġpost',\n",
       " 'Ġfeel',\n",
       " 'st',\n",
       " 'Ġperson',\n",
       " 'ĠFacebook',\n",
       " 'ĠWorld',\n",
       " 'Ġwithin',\n",
       " 'ad',\n",
       " 'Ġdone',\n",
       " 'the',\n",
       " 'Ġlate',\n",
       " 'Ġtax',\n",
       " 'Ġdoesn',\n",
       " 'Ġthing',\n",
       " 'Ġnational',\n",
       " 'Ġjob',\n",
       " 'Ġusing',\n",
       " 'ĠHowever',\n",
       " 'ic',\n",
       " 'Ġcampaign',\n",
       " 'Ġrecord',\n",
       " 'Ġbehind',\n",
       " '://',\n",
       " 'ĠDepartment',\n",
       " 'p',\n",
       " 'Ġothers',\n",
       " 'ĠJanuary',\n",
       " 'Ġorder',\n",
       " 'Ġ[',\n",
       " 'Ġsales',\n",
       " 'Ġyet',\n",
       " 'Ä',\n",
       " 'Ġsmall',\n",
       " 'Ġseries',\n",
       " 'Ġface',\n",
       " 'ĠWhat',\n",
       " 'Ġ50',\n",
       " 'Ġever',\n",
       " 'Ġearlier',\n",
       " 'Ġlove',\n",
       " 'up',\n",
       " 'Ġrights',\n",
       " 'ĠAn',\n",
       " 'ist',\n",
       " 'Ġmorning',\n",
       " 'ĠWashington',\n",
       " 'Ġyoung',\n",
       " 'Ġlatest',\n",
       " 'ĠIndia',\n",
       " 'Ġtrying',\n",
       " 'Ġfire',\n",
       " 'Ġled',\n",
       " 'Ġstrong',\n",
       " 'Ġreturn',\n",
       " 'Ġlevel',\n",
       " 'O',\n",
       " 'Ġaverage',\n",
       " 'Ġperiod',\n",
       " 'Ġexperience',\n",
       " 'ak',\n",
       " 'Ġpossible',\n",
       " 'Ġbelieve',\n",
       " 'Ġinclude',\n",
       " 'Ġoil',\n",
       " 'Ġrecently',\n",
       " 'Ġonce',\n",
       " 'Ġknown',\n",
       " 'Ġlost',\n",
       " 'Ġsure',\n",
       " 'us',\n",
       " 'Ġweeks',\n",
       " 'Ġfood',\n",
       " 'Ġreports',\n",
       " 'Ġrating',\n",
       " 'ĠMinister',\n",
       " 'Ġwoman',\n",
       " 'Ġprovide',\n",
       " 'Ġproject',\n",
       " 'Ġissue',\n",
       " 'Ġlive',\n",
       " '10',\n",
       " 'Ġclear',\n",
       " 'he',\n",
       " 'Ġcost',\n",
       " 'Ġplayed',\n",
       " 'Ġreleased',\n",
       " 'Ġcoach',\n",
       " 'v',\n",
       " 'Ġ24',\n",
       " 'Ġseven',\n",
       " 'Ġplans',\n",
       " 'Ġdevelopment',\n",
       " 'ur',\n",
       " 'ĺ',\n",
       " 'Ġincrease',\n",
       " 'This',\n",
       " 'Ġpolicy',\n",
       " 'Ġcent',\n",
       " 'Ġbased',\n",
       " 'E',\n",
       " 'il',\n",
       " 'ĠDecember',\n",
       " 'Ġglobal',\n",
       " 'Ġtrade',\n",
       " 'Ġhours',\n",
       " 'Ġhigher',\n",
       " 'Ġgoal',\n",
       " 'H',\n",
       " 'ĠAl',\n",
       " 'Ġ100',\n",
       " 'Ġminutes',\n",
       " 'Ġelection',\n",
       " 'ĠAmerica',\n",
       " 'Ġrate',\n",
       " 'ĠCh',\n",
       " 'Ġ21',\n",
       " '...',\n",
       " 'ĠWhite',\n",
       " 'Ġdirector',\n",
       " 'Ġposition',\n",
       " 'Ġshot',\n",
       " 'Ġlarge',\n",
       " 'Ġc',\n",
       " 'Ġb',\n",
       " ']',\n",
       " 'Ġissues',\n",
       " 'Ġdeath',\n",
       " 'Ġbuilding',\n",
       " 'Ġtotal',\n",
       " 'Ġoften',\n",
       " 'Ġv',\n",
       " 'Ġcountries',\n",
       " 'Ġhistory',\n",
       " 'Ġoutside',\n",
       " 'Ġfederal',\n",
       " 'Ġ19',\n",
       " 'Ġfact',\n",
       " 'ĠHigh',\n",
       " 'Ġcareer',\n",
       " 'im',\n",
       " 'Ġinternational',\n",
       " 'ĠNovember',\n",
       " 'Ġfront',\n",
       " 'Ġkind',\n",
       " 'Ġkey',\n",
       " 'ra',\n",
       " 'ĠSan',\n",
       " 'Ġshort',\n",
       " 'Ġname',\n",
       " 'ĠAccording',\n",
       " 'Ġcourse',\n",
       " 'Ġre',\n",
       " 'Ġwanted',\n",
       " 'W',\n",
       " 'ĠSeptember',\n",
       " 'Ġinterest',\n",
       " 'Ġrole',\n",
       " 'Ġresults',\n",
       " 'Ġeconomic',\n",
       " 'Ġ2014',\n",
       " 'Ġchance',\n",
       " 'ĠOctober',\n",
       " 'Ġspecial',\n",
       " 'Ġofficial',\n",
       " 'Ġneeds',\n",
       " 'um',\n",
       " 'Ġl',\n",
       " 'Ġproducts',\n",
       " 'Ġnon',\n",
       " 'Ġ@',\n",
       " 'ĠBank',\n",
       " 'Ġahead',\n",
       " 'Ġhouse',\n",
       " 'U',\n",
       " 'Ġboard',\n",
       " 'Ġold',\n",
       " 'Ġsaw',\n",
       " 'Ġlower',\n",
       " 'ĠEuropean',\n",
       " 'Ġcontrol',\n",
       " 'ĠRussia',\n",
       " 'Ġeight',\n",
       " 'Ġrelease',\n",
       " 'Ġpotential',\n",
       " 'Ġthought',\n",
       " 'Ġinvestigation',\n",
       " 'Ġonline',\n",
       " 'based',\n",
       " 'Ġtechnology',\n",
       " 'ĠDonald',\n",
       " 'id',\n",
       " 'Ġbody',\n",
       " 'Ġrisk',\n",
       " 'ian',\n",
       " 'Ġcapital',\n",
       " 'Ġstaff',\n",
       " 'Ġaction',\n",
       " 'ĠLeague',\n",
       " 'Ġplaying',\n",
       " 'Ġmakes',\n",
       " 'Ġalmost',\n",
       " 'Ġperformance',\n",
       " 'Ġ22',\n",
       " 'Ġg',\n",
       " 'Ġfilm',\n",
       " 'Ġnearly',\n",
       " 'ĠCenter',\n",
       " 'Ġvisit',\n",
       " 'ĠGroup',\n",
       " 'Ġbank',\n",
       " 'Ġbit',\n",
       " 'Ġreceived',\n",
       " 'ĠAugust',\n",
       " 'Ġmilitary',\n",
       " 'ĠHis',\n",
       " 'ine',\n",
       " 'Ġchief',\n",
       " 'ĠSchool',\n",
       " 'Ġbring',\n",
       " 'ĠCourt',\n",
       " 'Ġ(@',\n",
       " 'Ġmeans',\n",
       " 'ĠSh',\n",
       " 'Ġfans',\n",
       " 'Ġse',\n",
       " 'Ġ40',\n",
       " '20',\n",
       " '\".',\n",
       " 'V',\n",
       " 'Ġcut',\n",
       " 'Ġkilled',\n",
       " 'Ġ#',\n",
       " 'Ġprices',\n",
       " 'Ġgave',\n",
       " 'ĠStreet',\n",
       " 'ir',\n",
       " 'ĠY',\n",
       " 'Ġcurrently',\n",
       " 'Ġf',\n",
       " 'ay',\n",
       " 'ne',\n",
       " 'te',\n",
       " 'Ġtry',\n",
       " 'ĠPark',\n",
       " 'ĥ',\n",
       " 'J',\n",
       " 'Ġquestion',\n",
       " 'Ġhand',\n",
       " 'Ġeconomy',\n",
       " 'Ġinvestors',\n",
       " 'able',\n",
       " 'Ġplayer',\n",
       " 'ĠBy',\n",
       " 'ĠDavid',\n",
       " 'Ġloss',\n",
       " 'ab',\n",
       " 'Ġbelow',\n",
       " 'Ġwrote',\n",
       " 'co',\n",
       " 'ate',\n",
       " 'Ġrunning',\n",
       " 'un',\n",
       " 'Ġbegan',\n",
       " 'Ġsingle',\n",
       " 'Ġfield',\n",
       " 'Ġ23',\n",
       " 'Ġleader',\n",
       " 'Ġw',\n",
       " 'ĠCalifornia',\n",
       " 'Ġfourth',\n",
       " 'Ġactually',\n",
       " 'Ġlist',\n",
       " 'll',\n",
       " 'Ġcouple',\n",
       " 'Ġstudy',\n",
       " 'Ġteams',\n",
       " 'He',\n",
       " 'ah',\n",
       " 'ĠCanada',\n",
       " 'Ġla',\n",
       " 'Ġresult',\n",
       " 'Ġaccess',\n",
       " 'Ġvote',\n",
       " 'ĠMore',\n",
       " 'ĠFebruary',\n",
       " 'Ġrevenue',\n",
       " 'Ġoffer',\n",
       " 'Ġlet',\n",
       " 'ier',\n",
       " 'Ġbuy',\n",
       " 'Ġattack',\n",
       " 'Ġblack',\n",
       " 'Ġr',\n",
       " 'Ġareas',\n",
       " 'Ġstop',\n",
       " 'Ġimpact',\n",
       " 'Ġmatch',\n",
       " 'Ġinvestment',\n",
       " 'Ġcustomers',\n",
       " 'Ġleaders',\n",
       " 'ies',\n",
       " 'Ġmember',\n",
       " 'Ġchild',\n",
       " 'Ġroad',\n",
       " 'ul',\n",
       " 'Ġvalue',\n",
       " 'Ġshows',\n",
       " 'ĠDr',\n",
       " 'ĠDe',\n",
       " 'ant',\n",
       " 'ĠLondon',\n",
       " 'Ġroom',\n",
       " 'Ġmusic',\n",
       " 'Ġproduction',\n",
       " 'Ġanything',\n",
       " 'Ġfirm',\n",
       " 'Ġbiggest',\n",
       " 'Ġair',\n",
       " 'Ġproblem',\n",
       " 'Ġgeneral',\n",
       " 'Ġwasn',\n",
       " 'Ġi',\n",
       " 'Ġprivate',\n",
       " 'Ġespecially',\n",
       " 'Ġadministration',\n",
       " 'Ġadditional',\n",
       " 'ĠCo',\n",
       " 'Ġopportunity',\n",
       " 'Ġhold',\n",
       " '&',\n",
       " 'Ġmatter',\n",
       " 'Ġsenior',\n",
       " 'Ġclub',\n",
       " 'Ġsomeone',\n",
       " 'ĠÃ',\n",
       " 'ĠEast',\n",
       " 'Ġ2019',\n",
       " \".'\",\n",
       " 'Ġneeded',\n",
       " 'ĠJames',\n",
       " 'time',\n",
       " 'Ġhowever',\n",
       " 'Ġeverything',\n",
       " 'Ġeveryone',\n",
       " 'Ġdied',\n",
       " 'Ġinvolved',\n",
       " 'Ġfriends',\n",
       " 'Ġisn',\n",
       " 'Ġworth',\n",
       " 'ik',\n",
       " 'ĠCup',\n",
       " 'Ġshowed',\n",
       " 'There',\n",
       " 'Ġ28',\n",
       " 'Ġmeet',\n",
       " 'Ġ26',\n",
       " 'Ġ27',\n",
       " 'Y',\n",
       " 'Ġregion',\n",
       " 'ĠPress',\n",
       " 'ĠNow',\n",
       " 'Ġson',\n",
       " 'Ġspace',\n",
       " 'Ġleading',\n",
       " 'Ġstates',\n",
       " 'Ġweekend',\n",
       " 'ĠÂ£',\n",
       " 'Ġmother',\n",
       " 'Ġprevious',\n",
       " 'ĠUK',\n",
       " 'ĠMichael',\n",
       " 'Ġleave',\n",
       " 'est',\n",
       " 'em',\n",
       " 'Ġz',\n",
       " 'ĠSome',\n",
       " 'ors',\n",
       " 'out',\n",
       " '15',\n",
       " 'Ġwar',\n",
       " 'Ġwebsite',\n",
       " 'Ġstar',\n",
       " ...]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(roberta_vocab.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab(corpus):\n",
    "    vocabulary = Counter()\n",
    "    for sentance in corpus:\n",
    "        for word in sentance.split():\n",
    "            vocabulary.update([word])\n",
    "    return vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_coverage(vocabs, roberta_vocab):\n",
    "    known_words = {}\n",
    "    unknown_words = {}\n",
    "    known_count = 0\n",
    "    unknown_count = 0\n",
    "    for word in tqdm(vocabs.keys(), desc='Checking: '):\n",
    "        if word in list(roberta_vocab.keys()):\n",
    "            known_words[word] = roberta_vocab[word]\n",
    "            known_count += vocabs[word]\n",
    "        else:\n",
    "            unknown_words[word] = vocabs[word]\n",
    "            unknown_count += vocabs[word]\n",
    "    print(\"Found embeddings for {:.3%} ({} / {}) of vocab\".format(len(known_words) / len(vocabs), len(known_words), len(vocabs)))\n",
    "    print(\"Found embeddings for {:.3%} ({} / {}) of all text\".format(known_count / (known_count + unknown_count), known_count, (known_count + unknown_count)))\n",
    "    return unknown_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train text unique vocab count is: 68961\n",
      "train reply unique vocab count is: 25542\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=68961.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 8.177% (5639 / 68961) of vocab\n",
      "Found embeddings for 65.985% (432177 / 654963) of all text\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=25542.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 14.451% (3691 / 25542) of vocab\n",
      "Found embeddings for 63.198% (68504 / 108395) of all text\n"
     ]
    }
   ],
   "source": [
    "train_text_vocab = get_vocab(df_train['text'].values)\n",
    "train_reply_vocab = get_vocab(df_train['reply'].values)\n",
    "print(\"train text unique vocab count is: {}\".format(len(train_text_vocab)))\n",
    "print(\"train reply unique vocab count is: {}\".format(len(train_reply_vocab)))\n",
    "unknown_text = check_coverage(train_text_vocab, roberta_vocab)\n",
    "print()\n",
    "unknown_reply = check_coverage(train_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev text unique vocab count is: 17684\n",
      "dev reply unique vocab count is: 5360\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=17684.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 17.830% (3153 / 17684) of vocab\n",
      "Found embeddings for 65.711% (54522 / 82972) of all text\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=5360.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 26.978% (1446 / 5360) of vocab\n",
      "Found embeddings for 62.345% (8626 / 13836) of all text\n"
     ]
    }
   ],
   "source": [
    "dev_text_vocab = get_vocab(df_dev['text'].values)\n",
    "dev_reply_vocab = get_vocab(df_dev['reply'].values)\n",
    "print(\"dev text unique vocab count is: {}\".format(len(dev_text_vocab)))\n",
    "print(\"dev reply unique vocab count is: {}\".format(len(dev_reply_vocab)))\n",
    "unknown_text = check_coverage(dev_text_vocab, roberta_vocab)\n",
    "print()\n",
    "unknown_reply = check_coverage(dev_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test text unique vocab count is: 17338\n",
      "test reply unique vocab count is: 5187\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=17338.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 18.191% (3154 / 17338) of vocab\n",
      "Found embeddings for 66.134% (54166 / 81903) of all text\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=5187.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 28.070% (1456 / 5187) of vocab\n",
      "Found embeddings for 63.152% (8360 / 13238) of all text\n"
     ]
    }
   ],
   "source": [
    "test_text_vocab = get_vocab(df_test['text'].values)\n",
    "test_reply_vocab = get_vocab(df_test['reply'].values)\n",
    "print(\"test text unique vocab count is: {}\".format(len(test_text_vocab)))\n",
    "print(\"test reply unique vocab count is: {}\".format(len(test_reply_vocab)))\n",
    "unknown_text = check_coverage(test_text_vocab, roberta_vocab)\n",
    "print()\n",
    "unknown_reply = check_coverage(test_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try to convert to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab_lower(corpus):\n",
    "    vocabulary = Counter()\n",
    "    for sentance in corpus:\n",
    "        for word in sentance.lower().split():\n",
    "            vocabulary.update([word])\n",
    "    return vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train text unique vocab count is: 60613\n",
      "train reply unique vocab count is: 22586\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=60613.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 6.301% (3819 / 60613) of vocab\n",
      "Found embeddings for 65.900% (431618 / 654963) of all text\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=22586.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 11.804% (2666 / 22586) of vocab\n",
      "Found embeddings for 63.508% (68840 / 108395) of all text\n"
     ]
    }
   ],
   "source": [
    "train_text_vocab = get_vocab_lower(df_train['text'].values)\n",
    "train_reply_vocab = get_vocab_lower(df_train['reply'].values)\n",
    "print(\"train text unique vocab count is: {}\".format(len(train_text_vocab)))\n",
    "print(\"train reply unique vocab count is: {}\".format(len(train_reply_vocab)))\n",
    "unknown_text_lower = check_coverage(train_text_vocab, roberta_vocab)\n",
    "print()\n",
    "unknown_reply_lower = check_coverage(train_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev text unique vocab count is: 15888\n",
      "dev reply unique vocab count is: 4818\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=15888.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 14.772% (2347 / 15888) of vocab\n",
      "Found embeddings for 65.687% (54502 / 82972) of all text\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=4818.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 24.408% (1176 / 4818) of vocab\n",
      "Found embeddings for 63.075% (8727 / 13836) of all text\n"
     ]
    }
   ],
   "source": [
    "dev_text_vocab = get_vocab_lower(df_dev['text'].values)\n",
    "dev_reply_vocab = get_vocab_lower(df_dev['reply'].values)\n",
    "print(\"dev text unique vocab count is: {}\".format(len(dev_text_vocab)))\n",
    "print(\"dev reply unique vocab count is: {}\".format(len(dev_reply_vocab)))\n",
    "unknown_text = check_coverage(dev_text_vocab, roberta_vocab)\n",
    "print()\n",
    "unknown_reply = check_coverage(dev_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test text unique vocab count is: 15473\n",
      "test reply unique vocab count is: 4674\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=15473.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 15.130% (2341 / 15473) of vocab\n",
      "Found embeddings for 66.148% (54177 / 81903) of all text\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=4674.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 25.246% (1180 / 4674) of vocab\n",
      "Found embeddings for 63.484% (8404 / 13238) of all text\n"
     ]
    }
   ],
   "source": [
    "test_text_vocab = get_vocab_lower(df_test['text'].values)\n",
    "test_reply_vocab = get_vocab_lower(df_test['reply'].values)\n",
    "print(\"test text unique vocab count is: {}\".format(len(test_text_vocab)))\n",
    "print(\"test reply unique vocab count is: {}\".format(len(test_reply_vocab)))\n",
    "unknown_text = check_coverage(test_text_vocab, roberta_vocab)\n",
    "print()\n",
    "unknown_reply = check_coverage(test_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add some known in tokenizer but unknown in lower case (zero is weird)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def add_lower(vocabs, roberta_vocab):\n",
    "#     count = 0\n",
    "#     add_tokens = []\n",
    "#     for word in tqdm(vocabs, desc='Searching: '):\n",
    "#         if word in list(roberta_vocab.keys()) and word.lower() not in list(roberta_vocab.keys()):\n",
    "#             add_tokens.append(word.lower())\n",
    "#             count += 1\n",
    "#     print(add_tokens)\n",
    "#     num_add = tokenizer.add_tokens(add_tokens)\n",
    "#     model.resize_token_embeddings(len(tokenizer))\n",
    "#     print(\"Added {} words to embedding\".format(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_lower(train_text_vocab, roberta_vocab)\n",
    "# add_lower(train_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show some unknown tokens!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'@youngdeji_': 1,\n",
       " 'uzi': 2,\n",
       " 'carti': 4,\n",
       " 'monday': 3,\n",
       " 'gotta': 18,\n",
       " 'lil': 11,\n",
       " 'woah': 1,\n",
       " 'we’re': 27,\n",
       " 'discussing': 5,\n",
       " 'trading': 4,\n",
       " 'picks': 2,\n",
       " 'safety.': 1,\n",
       " 'dababy': 4,\n",
       " 'sounds': 6,\n",
       " 'niggas': 10,\n",
       " 'kitchen': 7,\n",
       " 'denny’s': 1,\n",
       " 'indians': 3,\n",
       " 'don’t': 126,\n",
       " 'sport': 2,\n",
       " 'cricket.': 1,\n",
       " 'would’ve': 3,\n",
       " 'came': 17,\n",
       " 'out.': 21,\n",
       " 'zaira': 1,\n",
       " 'wasim': 1,\n",
       " 'hardwork': 1,\n",
       " 'screen.': 1,\n",
       " 'justify': 2,\n",
       " 'mentality': 1,\n",
       " 'sick.': 4,\n",
       " 'everybody': 8,\n",
       " 'listening': 8,\n",
       " '@madisonbeer': 1,\n",
       " 'selfish': 1,\n",
       " 'i’ve': 57,\n",
       " '“as': 2,\n",
       " 'please”': 1,\n",
       " 'wtf': 8,\n",
       " '@lupeloops': 1,\n",
       " 'weekend': 10,\n",
       " '😓': 3,\n",
       " \"haven't\": 7,\n",
       " 'ops,': 1,\n",
       " \"ain't\": 6,\n",
       " 'biggest': 9,\n",
       " 'disappointments....': 1,\n",
       " 'hardest': 4,\n",
       " 'work.': 6,\n",
       " 'cried.': 1,\n",
       " 'hospitals': 4,\n",
       " 'settings,': 1,\n",
       " 'home,': 3,\n",
       " 'it.': 94,\n",
       " 'crap': 3,\n",
       " 'nightmare.': 3,\n",
       " 'accounts': 8,\n",
       " 'hacked': 5,\n",
       " 'spamming': 4,\n",
       " 'mad.': 4,\n",
       " 'couldn’t': 10,\n",
       " 'back.': 14,\n",
       " 'tried': 14,\n",
       " 'confronting': 4,\n",
       " 'hacker': 3,\n",
       " 'replying': 5,\n",
       " '“who': 4,\n",
       " 'are?!”': 3,\n",
       " 'physically': 5,\n",
       " 'attacked': 4,\n",
       " 'spam': 4,\n",
       " 'messages': 6,\n",
       " 'woke': 17,\n",
       " 'up.': 25,\n",
       " '😰': 4,\n",
       " 'understands.': 1,\n",
       " 'prophet.': 1,\n",
       " 'forgive': 1,\n",
       " 'doing?': 4,\n",
       " 'i’m': 263,\n",
       " 'quarantine': 44,\n",
       " 'therapist': 1,\n",
       " 'everyday': 9,\n",
       " 'trying': 37,\n",
       " 'navigate': 1,\n",
       " 'plans': 3,\n",
       " 'overwhelm': 1,\n",
       " 'overreacting,': 1,\n",
       " 'obsessing,': 1,\n",
       " 'worrying,': 1,\n",
       " 'eventually': 3,\n",
       " 'disassociating.': 1,\n",
       " 'here!': 2,\n",
       " 'gates': 15,\n",
       " 'covid-19': 34,\n",
       " 'vaccine?': 11,\n",
       " 'cancel': 6,\n",
       " 'myrtle': 1,\n",
       " 'am.': 3,\n",
       " 'spiraling.': 1,\n",
       " 'laughing': 8,\n",
       " 'strategically': 1,\n",
       " 'dynamically': 1,\n",
       " 'sucking': 8,\n",
       " 'dick': 20,\n",
       " 'grudges.': 1,\n",
       " 'so,': 7,\n",
       " 'mind,': 2,\n",
       " \"who's\": 9,\n",
       " 'apologise': 3,\n",
       " 'me?': 11,\n",
       " 'oldrich': 6,\n",
       " 'judging': 7,\n",
       " 'people,': 13,\n",
       " 'judgement,': 6,\n",
       " 'kindness,': 8,\n",
       " 'hungry': 7,\n",
       " 'followers': 23,\n",
       " '(now': 6,\n",
       " '“teammates”)!': 6,\n",
       " 'can’t': 55,\n",
       " 'hyperventilate': 1,\n",
       " 'bag.': 2,\n",
       " '☹️': 2,\n",
       " 'myself': 45,\n",
       " 'could.': 1,\n",
       " 'able,': 1,\n",
       " 'yeah?': 1,\n",
       " 'you.': 35,\n",
       " '💛': 2,\n",
       " 'supportive': 2,\n",
       " '\\U0001f97a': 14,\n",
       " 'hands,': 1,\n",
       " \"they're\": 12,\n",
       " \"you're\": 45,\n",
       " 'worried': 6,\n",
       " 'trump’s': 10,\n",
       " 'health?': 1,\n",
       " \"i'm\": 186,\n",
       " 'coffee': 11,\n",
       " 'lunch.': 1,\n",
       " \"who'd\": 1,\n",
       " 'join?': 1,\n",
       " 'guaging': 1,\n",
       " 'interest.': 2,\n",
       " 'trump,': 5,\n",
       " 'script,': 1,\n",
       " 'begins': 2,\n",
       " 'saying': 23,\n",
       " 'undertaken': 1,\n",
       " \"country's\": 1,\n",
       " 'greatest': 5,\n",
       " 'mobilization': 1,\n",
       " '\"since': 1,\n",
       " 'ii.\"': 1,\n",
       " 'says': 31,\n",
       " 'unleashed': 1,\n",
       " '\"most': 1,\n",
       " 'potent': 1,\n",
       " 'all\":': 1,\n",
       " \"americans'\": 1,\n",
       " 'courage.': 2,\n",
       " 'tells': 7,\n",
       " \"who've\": 2,\n",
       " 'loved': 10,\n",
       " 'pain.': 6,\n",
       " 'yesterday.': 2,\n",
       " 'screenshots': 2,\n",
       " 'idk': 13,\n",
       " 'hear': 22,\n",
       " 'proud': 12,\n",
       " 'blonde': 3,\n",
       " 'me.': 58,\n",
       " 'better.': 14,\n",
       " 'wna': 2,\n",
       " 'fucj': 1,\n",
       " 'bcs': 1,\n",
       " 'insecure': 1,\n",
       " 'relationship': 10,\n",
       " 'fucked': 14,\n",
       " 'shout': 10,\n",
       " 'trash.': 2,\n",
       " 'trash': 12,\n",
       " 'yourself.': 2,\n",
       " 'natin': 1,\n",
       " 'joke': 6,\n",
       " 'circulating': 1,\n",
       " 'germany:': 1,\n",
       " '\"what': 3,\n",
       " 'borders': 2,\n",
       " 'stupidity?\"': 1,\n",
       " '\"mexico': 1,\n",
       " 'canada!\"': 1,\n",
       " 'already': 18,\n",
       " 'taken': 10,\n",
       " 'what?!': 1,\n",
       " 'waiting': 20,\n",
       " '#whyruep12': 1,\n",
       " 'simpsons': 2,\n",
       " 'installing': 23,\n",
       " \"#scottyfrommarketing's\": 23,\n",
       " 'app.': 26,\n",
       " 'gif.': 26,\n",
       " 'hollyweird': 1,\n",
       " 'pedophile': 1,\n",
       " 'i’ll': 47,\n",
       " 'grandiloquent': 1,\n",
       " 'hypocrites': 1,\n",
       " 'kissed': 3,\n",
       " 'joe': 24,\n",
       " 'biden,': 1,\n",
       " 'teenage': 4,\n",
       " '“i': 7,\n",
       " 'jumpin’': 1,\n",
       " 'lap”': 1,\n",
       " 'biden': 26,\n",
       " 'congress': 6,\n",
       " 'now,': 20,\n",
       " 'petulance,': 1,\n",
       " 'gridlock,': 1,\n",
       " 'vendettas': 1,\n",
       " 'downright': 1,\n",
       " 'belongs': 3,\n",
       " 'idea': 15,\n",
       " 'it’s': 117,\n",
       " 'watches': 1,\n",
       " '‘bates': 1,\n",
       " 'motel’??': 1,\n",
       " 'spoilers!!': 1,\n",
       " '3.': 7,\n",
       " 'damn': 22,\n",
       " 'y’all,': 1,\n",
       " 'norman’s': 1,\n",
       " 'nerves.': 1,\n",
       " 'he’s': 27,\n",
       " 'punch': 1,\n",
       " '🤷🏻\\u200d♀️🤷🏻\\u200d♀️': 1,\n",
       " 'wanted': 25,\n",
       " 'tonight': 21,\n",
       " 'feelings': 5,\n",
       " 'hurt': 6,\n",
       " \"i've\": 31,\n",
       " 'hiding': 5,\n",
       " 'night.': 9,\n",
       " 'feeling': 42,\n",
       " 'bombarded': 2,\n",
       " 'hurtful': 3,\n",
       " 'words.': 2,\n",
       " 'sapped': 2,\n",
       " 'dry.': 2,\n",
       " '#salt': 2,\n",
       " 'fancy': 1,\n",
       " 'skateboard': 1,\n",
       " 'i’d': 12,\n",
       " 'liberate': 16,\n",
       " 'ass.': 4,\n",
       " '🙌': 2,\n",
       " 'york': 8,\n",
       " \"post's\": 1,\n",
       " \"halladay's\": 1,\n",
       " 'fucking': 46,\n",
       " 'garbage': 2,\n",
       " 'today.': 41,\n",
       " '\"some': 2,\n",
       " 'won’t': 9,\n",
       " 'halladay': 1,\n",
       " 'transportation': 2,\n",
       " 'fame': 2,\n",
       " 'pitcher': 1,\n",
       " 'amphetamines': 1,\n",
       " 'morphine\"': 1,\n",
       " '$$?': 2,\n",
       " '$200': 3,\n",
       " 'hours.': 14,\n",
       " '@loyalgiveaways': 2,\n",
       " ':)': 10,\n",
       " 'hug': 78,\n",
       " 'somn': 1,\n",
       " 'suck': 15,\n",
       " 'dick,': 3,\n",
       " 'ain’t': 13,\n",
       " 'stopping': 2,\n",
       " \"don't\": 97,\n",
       " 'talent': 2,\n",
       " 'conversation': 7,\n",
       " 'going,': 3,\n",
       " 'lot.': 3,\n",
       " \"it's\": 125,\n",
       " 'reopen': 9,\n",
       " 'america.': 7,\n",
       " '🙋\\u200d♂️🙋\\u200d♂️🙋\\u200d♂️': 2,\n",
       " 'in:': 8,\n",
       " 'china': 27,\n",
       " 'denies': 6,\n",
       " 'extent': 6,\n",
       " 'coronavirus': 41,\n",
       " 'outbreak': 7,\n",
       " 'need🌹solo': 1,\n",
       " '🌹sana🌹projects🌹': 1,\n",
       " 'knows': 10,\n",
       " 'rapists?': 1,\n",
       " 'em?': 1,\n",
       " 'morning!': 1,\n",
       " 'today!': 7,\n",
       " 'specifically?': 1,\n",
       " '#svtraintobusan': 1,\n",
       " 'hugs': 20,\n",
       " 'smh': 6,\n",
       " 'unlimited': 1,\n",
       " '😭': 16,\n",
       " '2020!': 2,\n",
       " 'lockdowns': 3,\n",
       " 'quarantining.': 1,\n",
       " 'conflated.': 1,\n",
       " 'welcomed': 2,\n",
       " 'assume': 3,\n",
       " 'risk.': 1,\n",
       " '@dxvilishangxl': 1,\n",
       " 'cute': 12,\n",
       " 'honestly': 14,\n",
       " 'veniece': 1,\n",
       " 'drive-in': 1,\n",
       " 'theater': 4,\n",
       " 'punks': 1,\n",
       " 'nowadays': 1,\n",
       " 'smuggle': 1,\n",
       " 'trunk': 1,\n",
       " 'beers': 1,\n",
       " 'days!': 1,\n",
       " 'america': 65,\n",
       " 'up?': 10,\n",
       " 'no?': 11,\n",
       " 'prepare': 6,\n",
       " 'rounds': 3,\n",
       " 'negotiations,': 3,\n",
       " 'reiterate': 3,\n",
       " \"government's\": 3,\n",
       " 'transition': 8,\n",
       " 'following': 25,\n",
       " 'withdrawal': 3,\n",
       " 'eu.': 3,\n",
       " 'december': 6,\n",
       " 'year.': 10,\n",
       " 'extend': 6,\n",
       " 'no.': 12,\n",
       " '1/2': 4,\n",
       " 'app,': 24,\n",
       " 'hashtag': 26,\n",
       " '#bailouthumansnow': 25,\n",
       " '@shelleymcelyea1': 1,\n",
       " 'birthday,': 3,\n",
       " 'darling': 2,\n",
       " '❤️💋🎁🎉🍰🎈': 1,\n",
       " '#giveaway': 3,\n",
       " '$25': 4,\n",
       " '24hours..': 1,\n",
       " 'like/rt/tag': 1,\n",
       " '(must': 1,\n",
       " 'me)': 1,\n",
       " 'sponsor': 1,\n",
       " 'following?': 1,\n",
       " 'discuss': 3,\n",
       " 'grow!': 1,\n",
       " 'lovely': 6,\n",
       " 'quickly': 10,\n",
       " '🔥🚀': 1,\n",
       " \"how's\": 4,\n",
       " 'experience': 10,\n",
       " 'flutter?': 1,\n",
       " 'gifs': 17,\n",
       " '\\U0001f91f🏼': 1,\n",
       " '#flutter': 1,\n",
       " 'also,': 21,\n",
       " \"win's\": 1,\n",
       " '\"how': 2,\n",
       " 'till': 5,\n",
       " 'drop\"': 1,\n",
       " 'improvised': 1,\n",
       " 'struggling': 7,\n",
       " 'reconcile': 1,\n",
       " 'govt': 10,\n",
       " \"'stay\": 1,\n",
       " \"lives'\": 2,\n",
       " 'mantra': 1,\n",
       " 'allowing': 4,\n",
       " '15,000': 1,\n",
       " 'checks,': 4,\n",
       " 'worst-hit': 1,\n",
       " 'nyc': 4,\n",
       " 'italy.': 1,\n",
       " 'something?': 2,\n",
       " '@seanhannity': 18,\n",
       " 'minutes.': 4,\n",
       " 'tune': 5,\n",
       " 'in!': 4,\n",
       " 'believe': 36,\n",
       " 'himself': 8,\n",
       " 'power?': 4,\n",
       " '‘promoter': 1,\n",
       " 'wholly': 1,\n",
       " 'unconvincing': 1,\n",
       " 'consoler': 1,\n",
       " 'chief.': 1,\n",
       " 'hugger,': 1,\n",
       " '~s': 1,\n",
       " 'news:': 2,\n",
       " 'wonderful': 5,\n",
       " 'years,': 2,\n",
       " 'leaving': 6,\n",
       " '@tes.': 1,\n",
       " 'director.': 1,\n",
       " 'organisation': 1,\n",
       " 'whom': 3,\n",
       " 'journalism.': 1,\n",
       " '1/': 1,\n",
       " 'sister': 6,\n",
       " 'didn’t': 32,\n",
       " 'sister.': 3,\n",
       " '20’s': 2,\n",
       " 'sperm': 4,\n",
       " 'meeting': 12,\n",
       " 'moms': 4,\n",
       " '-famu': 3,\n",
       " 'sources': 3,\n",
       " 'cnbc': 1,\n",
       " 'aawaz': 1,\n",
       " 'announce': 8,\n",
       " 'stimulus': 20,\n",
       " 'package.': 3,\n",
       " '30th': 3,\n",
       " 'days.': 4,\n",
       " 'wanna': 46,\n",
       " 'took': 21,\n",
       " 'celebrate': 8,\n",
       " 'birthday.': 8,\n",
       " 'beautiful': 24,\n",
       " 'queen': 4,\n",
       " 'mercy': 1,\n",
       " 'eke,': 1,\n",
       " 'stylish': 1,\n",
       " 'uti,': 1,\n",
       " 'hardworking': 1,\n",
       " 'bobrisky,': 1,\n",
       " 'awesome': 13,\n",
       " 'enkayy': 1,\n",
       " 'amazing': 18,\n",
       " 'mercenaries': 1,\n",
       " 'spartans.': 1,\n",
       " 'bless': 2,\n",
       " '❤️': 21,\n",
       " '#zenmagazine': 1,\n",
       " '@liberianboii': 1,\n",
       " 'twenties.': 1,\n",
       " 'married.': 2,\n",
       " 'people.': 18,\n",
       " 'follow.': 6,\n",
       " 'you,': 22,\n",
       " 'pineapple': 3,\n",
       " 'pizza': 11,\n",
       " 'decision': 10,\n",
       " 'there.': 8,\n",
       " 'horny': 23,\n",
       " 'day?': 4,\n",
       " 'shet': 1,\n",
       " 'disappointment': 1,\n",
       " '😮😅': 1,\n",
       " 'ago,': 4,\n",
       " 'tinder': 2,\n",
       " 'discounted': 1,\n",
       " 'premium': 1,\n",
       " 'services.': 1,\n",
       " 'decided': 22,\n",
       " 'premium,': 1,\n",
       " 'liked': 5,\n",
       " 'profile,': 1,\n",
       " 'theirs.': 1,\n",
       " 'expecting': 5,\n",
       " 'celebratory': 1,\n",
       " 'dinner': 24,\n",
       " 'there’s': 21,\n",
       " 'stew': 2,\n",
       " '😐': 5,\n",
       " 'monday!': 2,\n",
       " '👻👻👻': 2,\n",
       " 'hosted': 2,\n",
       " 'interacted': 1,\n",
       " 'communities': 3,\n",
       " 'various': 2,\n",
       " 'backgrounds': 1,\n",
       " 'disrespects': 1,\n",
       " 'sentiment': 1,\n",
       " 'religion.': 1,\n",
       " 'equivalent': 1,\n",
       " 'wasting': 1,\n",
       " 'sins': 1,\n",
       " 'tbh...at': 1,\n",
       " 'least': 33,\n",
       " 'sinning': 1,\n",
       " 'seala': 1,\n",
       " 'definitely': 10,\n",
       " 'putting': 12,\n",
       " 'reaction': 48,\n",
       " '@filmgob': 1,\n",
       " '@jodyscorner1': 1,\n",
       " 'nonsense.': 1,\n",
       " 'indeed': 2,\n",
       " 'filmgob': 1,\n",
       " 'jody': 1,\n",
       " 'there?': 1,\n",
       " 'interesting.': 4,\n",
       " 'supporter': 16,\n",
       " 'thankful': 20,\n",
       " '$1,200': 12,\n",
       " \"trump's\": 16,\n",
       " 'obama': 16,\n",
       " \"he's\": 23,\n",
       " 'socialist': 13,\n",
       " 'billionaire': 12,\n",
       " 'afford': 12,\n",
       " 'questions…': 12,\n",
       " 'minister': 6,\n",
       " '(not': 4,\n",
       " \"isn't\": 17,\n",
       " 'ill,': 3,\n",
       " 'holiday,': 2,\n",
       " 'fridge)': 2,\n",
       " 'cabinet,': 3,\n",
       " 'parliament:': 2,\n",
       " 'pandemic': 16,\n",
       " 'crisis': 9,\n",
       " 'forthcoming': 2,\n",
       " 'brexit-induced': 2,\n",
       " 'crisis:': 3,\n",
       " 'competent': 2,\n",
       " 'steer': 2,\n",
       " 'through.': 2,\n",
       " 'apologize': 2,\n",
       " 'sending': 10,\n",
       " '\"\\U0001f97a\"': 1,\n",
       " 'emojis': 2,\n",
       " 'admit': 5,\n",
       " 'signs': 5,\n",
       " 'afraid': 3,\n",
       " 'up,': 13,\n",
       " 'down.': 9,\n",
       " 'overthinking': 1,\n",
       " 'takes': 8,\n",
       " 'away.': 5,\n",
       " 'guys..?': 1,\n",
       " 's/o': 1,\n",
       " 'loyal': 1,\n",
       " 'y’all': 39,\n",
       " '13k+': 1,\n",
       " '#covid_19': 7,\n",
       " 'india,': 1,\n",
       " 'recovered.': 1,\n",
       " 'deaths': 12,\n",
       " '400+.': 1,\n",
       " 'situation,': 1,\n",
       " '@mohfw_india': 1,\n",
       " '@drharshvardhan': 1,\n",
       " '@pmoindia': 1,\n",
       " 'consider:': 1,\n",
       " 'decelerate': 1,\n",
       " 'panic,': 1,\n",
       " 'weigh': 1,\n",
       " 'prone,': 1,\n",
       " 'patients': 5,\n",
       " 'others': 9,\n",
       " 'neglected?': 1,\n",
       " 'am,': 1,\n",
       " 'overdue': 1,\n",
       " 'appointment': 3,\n",
       " 'tomorrow': 35,\n",
       " 'dreading,': 1,\n",
       " 'vibes': 5,\n",
       " 'nudes': 5,\n",
       " 'u.s': 2,\n",
       " 'it???': 1,\n",
       " 'attention': 7,\n",
       " 'despise': 1,\n",
       " 'intro.': 1,\n",
       " 'two.': 1,\n",
       " 'spending': 5,\n",
       " '50+': 1,\n",
       " 'secs': 1,\n",
       " '—': 8,\n",
       " 'nope.': 3,\n",
       " '@kellyinvegas': 1,\n",
       " '@vegasmurray': 1,\n",
       " 'signed,': 1,\n",
       " 'producer': 1,\n",
       " 'rhode': 1,\n",
       " 'island': 2,\n",
       " 'jacob': 1,\n",
       " 'toppin': 1,\n",
       " 'committed': 6,\n",
       " 'kentucky,': 1,\n",
       " 'page.': 2,\n",
       " '😭❤️': 1,\n",
       " 'somebody': 8,\n",
       " 'housekeeping': 1,\n",
       " 'yet.': 5,\n",
       " 'they’re': 12,\n",
       " 'in.': 4,\n",
       " 'decorate': 1,\n",
       " 'doesn’t': 25,\n",
       " 'bland': 1,\n",
       " 'sad': 28,\n",
       " 'absurd': 1,\n",
       " 'ridiculous.': 1,\n",
       " '👀': 8,\n",
       " '.@joebiden': 1,\n",
       " '🤔': 21,\n",
       " 'irresponsible': 4,\n",
       " 'chinese': 11,\n",
       " 'communist': 5,\n",
       " '#covid19pandemic': 4,\n",
       " 'thousands': 18,\n",
       " 'americans': 29,\n",
       " 'alive': 5,\n",
       " 'jobs.': 4,\n",
       " 'responsible.': 4,\n",
       " 'account.': 6,\n",
       " 'hourrrssss': 1,\n",
       " '@shmsaaldh': 1,\n",
       " 'wearing': 12,\n",
       " 'exact': 2,\n",
       " 'sweatshirt': 1,\n",
       " 'questions': 9,\n",
       " 'time.': 20,\n",
       " 'haven’t': 14,\n",
       " 'hammock': 1,\n",
       " 'isolation,': 1,\n",
       " 'offers': 1,\n",
       " 'tests?': 1,\n",
       " 'fun:': 1,\n",
       " 'freely': 1,\n",
       " 'shehnaaz': 2,\n",
       " 'gill': 1,\n",
       " 'question,': 3,\n",
       " 'be.': 6,\n",
       " 'one.': 9,\n",
       " '#shehnaazgill': 1,\n",
       " '@ishehnaaz_gill': 1,\n",
       " '@kaushaljoshi15': 1,\n",
       " 'suffering': 3,\n",
       " 'depression.': 2,\n",
       " 'worse.': 9,\n",
       " 'hi.': 15,\n",
       " 'isn’t': 13,\n",
       " 'covering': 7,\n",
       " 'nose....': 1,\n",
       " 'pointless.': 1,\n",
       " 'please.': 3,\n",
       " \"doesn't\": 24,\n",
       " 'exist;': 1,\n",
       " 'choose': 22,\n",
       " 'trump:': 15,\n",
       " '\"i': 17,\n",
       " 'campaigning.\"': 8,\n",
       " 'who’s': 11,\n",
       " 'goin': 1,\n",
       " 'thorpe': 1,\n",
       " 'park/alton': 1,\n",
       " 'towers': 3,\n",
       " 'y’all!!!': 1,\n",
       " 'twitch!!!': 1,\n",
       " '\\U0001f973\\U0001f929': 1,\n",
       " 'continues': 2,\n",
       " 'me!': 10,\n",
       " 'y’all!': 1,\n",
       " 'gifted': 1,\n",
       " 'subs': 4,\n",
       " 'donos': 1,\n",
       " '💗': 1,\n",
       " 'who-the-hell-even-knows-anymore': 18,\n",
       " 'quarantine:': 19,\n",
       " 'gif,': 21,\n",
       " 'honest': 22,\n",
       " 'read/hear': 18,\n",
       " '\"we\\'re': 18,\n",
       " 'together\".': 18,\n",
       " '👋🏻': 1,\n",
       " 'stressed': 4,\n",
       " 'coloring': 2,\n",
       " 'meant': 2,\n",
       " 'relaxation?': 1,\n",
       " 'hunch': 1,\n",
       " 'page,': 1,\n",
       " 'pencil,': 1,\n",
       " 'choice.': 3,\n",
       " 'done,': 10,\n",
       " 'therapy.': 9,\n",
       " 'reminding': 3,\n",
       " 'invaded': 1,\n",
       " 'chickens': 1,\n",
       " '@the_badger_jm': 1,\n",
       " 'fsq!!': 1,\n",
       " 'retired': 1,\n",
       " 'players.': 2,\n",
       " 'not.': 11,\n",
       " 'memory?': 1,\n",
       " 'weren’t': 4,\n",
       " 'great,': 2,\n",
       " 'nostalgia': 1,\n",
       " 'memories': 5,\n",
       " 'were?': 1,\n",
       " 'childhood:': 1,\n",
       " 'sprinkled': 1,\n",
       " 'sugar': 6,\n",
       " 'avocado': 2,\n",
       " '😋': 4,\n",
       " '65th': 2,\n",
       " 'birthday': 26,\n",
       " 'son’s': 5,\n",
       " 'yup': 2,\n",
       " 'gif?': 2,\n",
       " 'sick': 14,\n",
       " '$50,000': 2,\n",
       " 'run?': 2,\n",
       " '#btc': 3,\n",
       " 'debate': 5,\n",
       " 'biden?': 5,\n",
       " 'ggs': 1,\n",
       " '@cetralol': 1,\n",
       " 'maad': 1,\n",
       " '1-0': 2,\n",
       " 'prl!': 1,\n",
       " '9pm': 1,\n",
       " 'defiance.': 1,\n",
       " 'grateful': 12,\n",
       " 'passion/happiness': 1,\n",
       " 'life....or': 1,\n",
       " 'appreciate': 14,\n",
       " 'condescending!!': 1,\n",
       " 'evening': 6,\n",
       " 'everyone.': 5,\n",
       " 'awful.': 4,\n",
       " 'dear': 11,\n",
       " 'covid19.': 4,\n",
       " 'screamed': 3,\n",
       " 'minutes': 18,\n",
       " 'straight.': 5,\n",
       " 'stunned': 3,\n",
       " 'her.': 8,\n",
       " 'crawl': 3,\n",
       " 'forever.': 4,\n",
       " 'mentally': 3,\n",
       " 'unwell': 2,\n",
       " '@schittscreek': 1,\n",
       " 'finale': 1,\n",
       " 'disney’s': 1,\n",
       " 'shitty': 7,\n",
       " 'along...': 1,\n",
       " '@stageit': 2,\n",
       " 'week?': 3,\n",
       " '\"we\"': 2,\n",
       " 'we.': 2,\n",
       " \"can't\": 51,\n",
       " 'alone...that': 2,\n",
       " 'sad.': 3,\n",
       " 'dropped': 7,\n",
       " '4/20': 2,\n",
       " 'interview': 4,\n",
       " 'audacity': 1,\n",
       " 'skype': 1,\n",
       " '9am.': 1,\n",
       " 'sleeping': 4,\n",
       " '11am?': 1,\n",
       " 'busy': 4,\n",
       " 'let’s': 15,\n",
       " 'volunteered': 1,\n",
       " 'reduce': 2,\n",
       " 'fantasized': 1,\n",
       " 'smothering': 1,\n",
       " 'pillow.': 2,\n",
       " 'karma': 1,\n",
       " 'scale?': 1,\n",
       " 'virginia,': 14,\n",
       " '2nd': 18,\n",
       " 'amendment.': 11,\n",
       " 'siege!': 11,\n",
       " 'while.': 6,\n",
       " 'hella': 4,\n",
       " 'now.': 21,\n",
       " 'verkis': 1,\n",
       " 'broke': 6,\n",
       " 'posting': 4,\n",
       " 'treating': 7,\n",
       " 'y’all?': 1,\n",
       " 'pregnancy': 2,\n",
       " 'kicking': 2,\n",
       " 'ass😩': 1,\n",
       " 'scared': 8,\n",
       " 'nerds': 1,\n",
       " 'glasses,': 1,\n",
       " 'surgical': 2,\n",
       " 'creates': 1,\n",
       " 'visibility': 2,\n",
       " 'foggy': 1,\n",
       " 'specs!!!': 1,\n",
       " '#covid19': 16,\n",
       " 'smoke': 2,\n",
       " 'to,': 1,\n",
       " 'to.': 4,\n",
       " '.@who': 1,\n",
       " 'pandemic,': 3,\n",
       " 'providing': 3,\n",
       " 'advice,': 1,\n",
       " 'training,': 1,\n",
       " 'equipment': 1,\n",
       " 'crucial': 2,\n",
       " 'lives—including': 1,\n",
       " 'americans’.': 1,\n",
       " 'dangerous—trump': 1,\n",
       " 'authority': 1,\n",
       " 'know:': 3,\n",
       " 'violating': 1,\n",
       " 'impeached.': 1,\n",
       " 'nigga': 6,\n",
       " 'aboogie': 1,\n",
       " 'prime,': 2,\n",
       " 'hurt.': 2,\n",
       " \"that's\": 30,\n",
       " 'redskins': 1,\n",
       " 'morning.': 12,\n",
       " 'uh.': 1,\n",
       " '#oustduterenow': 3,\n",
       " 'turns': 6,\n",
       " 'martial': 1,\n",
       " 'advantage': 3,\n",
       " 'inability': 2,\n",
       " 'mobilize': 1,\n",
       " '#oustdutertenow': 1,\n",
       " 'philippines': 1,\n",
       " 'dictator': 1,\n",
       " 'todd': 1,\n",
       " 'wins': 4,\n",
       " 'gamers': 1,\n",
       " '@coliathgaming': 1,\n",
       " '@baker_tv_': 1,\n",
       " '@vicdgordon': 1,\n",
       " '@streamgamma': 1,\n",
       " '@kedabosch': 1,\n",
       " '@day1negaming': 1,\n",
       " '@jxckwsw': 1,\n",
       " '@ncshredder_': 1,\n",
       " '@samurai_ree': 1,\n",
       " '@stardrix1': 1,\n",
       " '@gso_joey': 1,\n",
       " '@tsillysweat': 1,\n",
       " '@chloedonald_': 1,\n",
       " '@xlexry': 1,\n",
       " '@multynwolf': 1,\n",
       " '@saycredangel': 1,\n",
       " '@fuscyoface': 1,\n",
       " '@storkyyy1': 1,\n",
       " 'kamo': 1,\n",
       " 'mphela': 1,\n",
       " 'whole': 29,\n",
       " 'blueprint': 1,\n",
       " 'moves': 4,\n",
       " '\"she': 1,\n",
       " 'dances': 1,\n",
       " 'shit\"': 2,\n",
       " '😕': 1,\n",
       " 'sober': 6,\n",
       " 'hurts': 4,\n",
       " 'intensions.': 1,\n",
       " 'learned': 8,\n",
       " 'actions.': 1,\n",
       " 'steyer': 1,\n",
       " 'lives.': 5,\n",
       " 'california.': 3,\n",
       " 'newsom': 2,\n",
       " 'recovery': 2,\n",
       " 'force,': 1,\n",
       " 'injustices': 1,\n",
       " 'revealed': 3,\n",
       " 'crisis.': 4,\n",
       " 'reasonable,': 1,\n",
       " 'zoom': 9,\n",
       " 'calls': 6,\n",
       " 'fart': 3,\n",
       " 'meetings': 2,\n",
       " 'mute': 2,\n",
       " 'know.': 9,\n",
       " '💨💨': 1,\n",
       " 'yall': 15,\n",
       " 'caucasians': 1,\n",
       " '4th': 7,\n",
       " 'july?!!!!!': 1,\n",
       " 'convo': 4,\n",
       " 'meteoric': 1,\n",
       " 'again.': 21,\n",
       " 'soon.': 4,\n",
       " 'nathaniel': 14,\n",
       " 'cnn': 16,\n",
       " 'here.': 20,\n",
       " 'you?': 21,\n",
       " '7th': 8,\n",
       " 'slid': 7,\n",
       " 'dms?': 7,\n",
       " 'sweep': 2,\n",
       " 'did.': 3,\n",
       " 'bump': 2,\n",
       " 'pronounced': 4,\n",
       " 'orders.': 2,\n",
       " 'oklahoma': 1,\n",
       " '53%': 1,\n",
       " 'increase': 3,\n",
       " 'jumped': 1,\n",
       " '60%': 3,\n",
       " 'arkansas,': 1,\n",
       " '74%': 1,\n",
       " 'nebraska,': 1,\n",
       " '82%': 1,\n",
       " 'iowa.': 1,\n",
       " 'dakota': 3,\n",
       " 'whopping': 1,\n",
       " '205%': 1,\n",
       " 'spike.': 1,\n",
       " '#stayhomestaysafesavelives': 1,\n",
       " 'chick': 3,\n",
       " 'sauce': 4,\n",
       " 'body.': 4,\n",
       " \"what's\": 13,\n",
       " 'funny': 11,\n",
       " 'hurry': 2,\n",
       " 'asked': 20,\n",
       " 'first.': 4,\n",
       " '#smallvictory': 1,\n",
       " 'sucks': 2,\n",
       " 'decorating': 1,\n",
       " '#animalcrossing': 1,\n",
       " 'november': 5,\n",
       " 'headline': 2,\n",
       " 'preview:': 2,\n",
       " 'defeated': 18,\n",
       " 'landslide': 2,\n",
       " 'mitch': 2,\n",
       " 'mcconnell': 2,\n",
       " 'lindsey': 4,\n",
       " 'graham': 7,\n",
       " 'susan': 2,\n",
       " 'collins': 4,\n",
       " 'martha': 2,\n",
       " 'mcsally': 2,\n",
       " 'cory': 2,\n",
       " 'gardner': 2,\n",
       " 'kelly': 4,\n",
       " 'loeffler': 3,\n",
       " 'thom': 2,\n",
       " 'tillis': 2,\n",
       " 'yeah,': 6,\n",
       " 'night,': 2,\n",
       " 'dreamt': 1,\n",
       " 'journalists,': 2,\n",
       " 'uddhav': 1,\n",
       " 'pm.': 2,\n",
       " 'aide': 1,\n",
       " 'approaches': 1,\n",
       " 'informal': 1,\n",
       " 'mine,': 1,\n",
       " 'no,': 7,\n",
       " '#soproudofmyself': 1,\n",
       " 'bout': 8,\n",
       " 'shooting': 3,\n",
       " 'hooping': 1,\n",
       " '$50': 8,\n",
       " 'retweets': 6,\n",
       " '@k_9girl': 1,\n",
       " 'myself.': 11,\n",
       " 'sitting': 15,\n",
       " 'cocoa': 1,\n",
       " 'krispies': 2,\n",
       " 'strange': 2,\n",
       " 'hits': 6,\n",
       " 'this?': 4,\n",
       " 'wasted.': 1,\n",
       " 'finally': 27,\n",
       " 'agreed': 3,\n",
       " 'repaint': 1,\n",
       " 'stuck': 7,\n",
       " 'home.': 6,\n",
       " 'requesting': 2,\n",
       " 'thoughts': 10,\n",
       " 'prayers': 4,\n",
       " 'difficult': 5,\n",
       " '😊': 18,\n",
       " 'listen': 11,\n",
       " 'man-half': 1,\n",
       " 'assholes': 2,\n",
       " 'concerns': 3,\n",
       " 'exercise,': 1,\n",
       " 'shit,': 2,\n",
       " 'smoke,': 1,\n",
       " 'drink': 7,\n",
       " 'excessive': 1,\n",
       " ...}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unknown_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean weird punctuations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No significantly improve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_weird(text):\n",
    "    specials = [\"’\", \"‘\", \"´\", \"`\"]\n",
    "    text = text.replace(\"’\", \"'\")\n",
    "    text = text.replace(\"‘\", \"'\")\n",
    "    text = text.replace(\"´\", \"'\")\n",
    "    text = text.replace(\"`\", \"'\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['text'] = df_train.text.apply(clean_weird)\n",
    "df_train['reply'] = df_train.reply.apply(clean_weird)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev['text'] = df_dev.text.apply(clean_weird)\n",
    "df_dev['reply'] = df_dev.reply.apply(clean_weird)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['text'] = df_test.text.apply(clean_weird)\n",
    "df_test['reply'] = df_test.reply.apply(clean_weird)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train text unique vocab count is: 68710\n",
      "train reply unique vocab count is: 25436\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=68710.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 8.211% (5642 / 68710) of vocab\n",
      "Found embeddings for 65.987% (432193 / 654963) of all text\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=25436.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 14.519% (3693 / 25436) of vocab\n",
      "Found embeddings for 63.200% (68506 / 108395) of all text\n"
     ]
    }
   ],
   "source": [
    "train_text_vocab = get_vocab(df_train['text'].values)\n",
    "train_reply_vocab = get_vocab(df_train['reply'].values)\n",
    "print(\"train text unique vocab count is: {}\".format(len(train_text_vocab)))\n",
    "print(\"train reply unique vocab count is: {}\".format(len(train_reply_vocab)))\n",
    "unknown_text = check_coverage(train_text_vocab, roberta_vocab)\n",
    "print()\n",
    "unknown_reply = check_coverage(train_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev text unique vocab count is: 17597\n",
      "dev reply unique vocab count is: 5322\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=17597.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 17.918% (3153 / 17597) of vocab\n",
      "Found embeddings for 65.713% (54523 / 82972) of all text\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=5322.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 27.189% (1447 / 5322) of vocab\n",
      "Found embeddings for 62.352% (8627 / 13836) of all text\n"
     ]
    }
   ],
   "source": [
    "dev_text_vocab = get_vocab(df_dev['text'].values)\n",
    "dev_reply_vocab = get_vocab(df_dev['reply'].values)\n",
    "print(\"dev text unique vocab count is: {}\".format(len(dev_text_vocab)))\n",
    "print(\"dev reply unique vocab count is: {}\".format(len(dev_reply_vocab)))\n",
    "unknown_text = check_coverage(dev_text_vocab, roberta_vocab)\n",
    "print()\n",
    "unknown_reply = check_coverage(dev_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test text unique vocab count is: 17246\n",
      "test reply unique vocab count is: 5152\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=17246.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 18.294% (3155 / 17246) of vocab\n",
      "Found embeddings for 66.136% (54167 / 81903) of all text\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=5152.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 28.261% (1456 / 5152) of vocab\n",
      "Found embeddings for 63.152% (8360 / 13238) of all text\n"
     ]
    }
   ],
   "source": [
    "test_text_vocab = get_vocab(df_test['text'].values)\n",
    "test_reply_vocab = get_vocab(df_test['reply'].values)\n",
    "print(\"test text unique vocab count is: {}\".format(len(test_text_vocab)))\n",
    "print(\"test reply unique vocab count is: {}\".format(len(test_reply_vocab)))\n",
    "unknown_text = check_coverage(test_text_vocab, roberta_vocab)\n",
    "print()\n",
    "unknown_reply = check_coverage(test_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform apostrophes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "apostrophes = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\" }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_apostrophes(text):\n",
    "    # Replace apostrophes to original term\n",
    "    for key in apostrophes.keys():\n",
    "        text = text.replace(key, apostrophes[key])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train['text'] = df_train.text.apply(change_apostrophes)\n",
    "df_train['reply'] = df_train.reply.apply(change_apostrophes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev['text'] = df_dev.text.apply(change_apostrophes)\n",
    "df_dev['reply'] = df_dev.reply.apply(change_apostrophes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['text'] = df_test.text.apply(change_apostrophes)\n",
    "df_test['reply'] = df_test.reply.apply(change_apostrophes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train text unique vocab count is: 68558\n",
      "train reply unique vocab count is: 25352\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=68558.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 8.230% (5642 / 68558) of vocab\n",
      "Found embeddings for 68.765% (460202 / 669242) of all text\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=25352.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 14.571% (3694 / 25352) of vocab\n",
      "Found embeddings for 66.097% (73228 / 110789) of all text\n"
     ]
    }
   ],
   "source": [
    "train_text_vocab = get_vocab(df_train['text'].values)\n",
    "train_reply_vocab = get_vocab(df_train['reply'].values)\n",
    "print(\"train text unique vocab count is: {}\".format(len(train_text_vocab)))\n",
    "print(\"train reply unique vocab count is: {}\".format(len(train_reply_vocab)))\n",
    "unknown_text = check_coverage(train_text_vocab, roberta_vocab)\n",
    "print()\n",
    "unknown_reply = check_coverage(train_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev text unique vocab count is: 17524\n",
      "dev reply unique vocab count is: 5273\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=17524.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 18.004% (3155 / 17524) of vocab\n",
      "Found embeddings for 68.538% (58122 / 84802) of all text\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=5273.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 27.442% (1447 / 5273) of vocab\n",
      "Found embeddings for 65.373% (9251 / 14151) of all text\n"
     ]
    }
   ],
   "source": [
    "dev_text_vocab = get_vocab(df_dev['text'].values)\n",
    "dev_reply_vocab = get_vocab(df_dev['reply'].values)\n",
    "print(\"dev text unique vocab count is: {}\".format(len(dev_text_vocab)))\n",
    "print(\"dev reply unique vocab count is: {}\".format(len(dev_reply_vocab)))\n",
    "unknown_text = check_coverage(dev_text_vocab, roberta_vocab)\n",
    "print()\n",
    "unknown_reply = check_coverage(dev_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test text unique vocab count is: 17171\n",
      "test reply unique vocab count is: 5108\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=17171.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 18.380% (3156 / 17171) of vocab\n",
      "Found embeddings for 68.775% (57497 / 83601) of all text\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=5108.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 28.504% (1456 / 5108) of vocab\n",
      "Found embeddings for 66.051% (8938 / 13532) of all text\n"
     ]
    }
   ],
   "source": [
    "test_text_vocab = get_vocab(df_test['text'].values)\n",
    "test_reply_vocab = get_vocab(df_test['reply'].values)\n",
    "print(\"test text unique vocab count is: {}\".format(len(test_text_vocab)))\n",
    "print(\"test reply unique vocab count is: {}\".format(len(test_reply_vocab)))\n",
    "unknown_text = check_coverage(test_text_vocab, roberta_vocab)\n",
    "print()\n",
    "unknown_reply = check_coverage(test_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'@Youngdeji_': 1,\n",
       " 'uzi': 2,\n",
       " 'carti': 3,\n",
       " 'gotta': 16,\n",
       " 'lil': 10,\n",
       " 'woah': 1,\n",
       " 'discussing': 5,\n",
       " 'trading': 4,\n",
       " 'picks': 2,\n",
       " 'safety.': 1,\n",
       " 'dababy': 3,\n",
       " 'sounds': 5,\n",
       " 'niggas': 6,\n",
       " 'kitchen': 7,\n",
       " \"Denny's\": 1,\n",
       " 'Majority': 2,\n",
       " 'Indians': 3,\n",
       " 'sport': 2,\n",
       " 'cricket.': 1,\n",
       " 'came': 16,\n",
       " 'out.': 21,\n",
       " 'Zaira': 1,\n",
       " 'Wasim': 1,\n",
       " 'hardwork': 1,\n",
       " 'screen.': 1,\n",
       " 'justify': 2,\n",
       " 'mentality': 1,\n",
       " 'sick.': 4,\n",
       " 'everybody': 5,\n",
       " 'listening': 8,\n",
       " '@madisonbeer': 1,\n",
       " 'selfish': 1,\n",
       " '“as': 2,\n",
       " 'please”': 1,\n",
       " 'wtf': 5,\n",
       " 'Might': 4,\n",
       " '@LupeLoops': 1,\n",
       " 'weekend': 9,\n",
       " '😓': 3,\n",
       " 'ops,': 1,\n",
       " 'biggest': 9,\n",
       " 'disappointments....': 1,\n",
       " 'hardest': 4,\n",
       " 'work.': 6,\n",
       " 'cried.': 1,\n",
       " 'hospitals': 4,\n",
       " 'settings,': 1,\n",
       " 'home,': 3,\n",
       " 'it.': 93,\n",
       " 'crap': 3,\n",
       " 'nightmare.': 3,\n",
       " 'accounts': 8,\n",
       " 'hacked': 5,\n",
       " 'spamming': 4,\n",
       " 'mad.': 4,\n",
       " 'back.': 13,\n",
       " 'tried': 13,\n",
       " 'confronting': 4,\n",
       " 'hacker': 3,\n",
       " 'replying': 5,\n",
       " '“Who': 3,\n",
       " 'are?!”': 3,\n",
       " 'PHYSICALLY': 3,\n",
       " 'attacked': 4,\n",
       " 'spam': 3,\n",
       " 'messages': 6,\n",
       " 'woke': 15,\n",
       " 'up.': 25,\n",
       " '😰': 4,\n",
       " 'understands.': 1,\n",
       " 'prophet.': 1,\n",
       " 'forgive': 1,\n",
       " 'Doing?': 1,\n",
       " 'quarantine': 33,\n",
       " 'therapist': 1,\n",
       " 'everyday': 8,\n",
       " 'trying': 35,\n",
       " 'navigate': 1,\n",
       " 'plans': 3,\n",
       " 'overwhelm': 1,\n",
       " 'overreacting,': 1,\n",
       " 'obsessing,': 1,\n",
       " 'worrying,': 1,\n",
       " 'eventually': 3,\n",
       " 'disassociating.': 1,\n",
       " 'Doing': 3,\n",
       " 'here!': 2,\n",
       " 'Gates': 14,\n",
       " 'Covid-19': 15,\n",
       " 'Vaccine?': 11,\n",
       " 'cancel': 4,\n",
       " 'myrtle': 1,\n",
       " 'am.': 3,\n",
       " 'spiraling.': 1,\n",
       " 'laughing': 8,\n",
       " 'STRATEGICALLY': 1,\n",
       " 'DYNAMICALLY': 1,\n",
       " 'sucking': 8,\n",
       " 'dick': 16,\n",
       " 'grudges.': 1,\n",
       " 'So,': 5,\n",
       " 'mind,': 2,\n",
       " 'apologise': 3,\n",
       " 'me?': 9,\n",
       " 'OldRich': 6,\n",
       " 'judging': 6,\n",
       " 'people,': 12,\n",
       " 'judgement,': 6,\n",
       " 'kindness,': 8,\n",
       " 'HUNGRY': 6,\n",
       " 'followers': 20,\n",
       " '(now': 6,\n",
       " '“teammates”)!': 6,\n",
       " 'cannot': 87,\n",
       " 'hyperventilate': 1,\n",
       " 'bag.': 1,\n",
       " '☹️': 2,\n",
       " 'myself': 44,\n",
       " 'could.': 1,\n",
       " 'able,': 1,\n",
       " 'yeah?': 1,\n",
       " 'you.': 33,\n",
       " '💛': 2,\n",
       " 'supportive': 2,\n",
       " '\\U0001f97a': 14,\n",
       " 'hands,': 1,\n",
       " \"You're\": 9,\n",
       " 'worried': 6,\n",
       " \"Trump's\": 25,\n",
       " 'health?': 1,\n",
       " 'coffee': 10,\n",
       " 'lunch.': 1,\n",
       " \"who'd\": 3,\n",
       " 'join?': 1,\n",
       " 'guaging': 1,\n",
       " 'interest.': 2,\n",
       " 'Trump,': 3,\n",
       " 'script,': 1,\n",
       " 'begins': 2,\n",
       " 'saying': 22,\n",
       " 'undertaken': 1,\n",
       " \"country's\": 3,\n",
       " 'greatest': 4,\n",
       " 'mobilization': 1,\n",
       " '\"since': 1,\n",
       " 'II.\"': 1,\n",
       " 'says': 29,\n",
       " 'unleashed': 1,\n",
       " '\"most': 1,\n",
       " 'potent': 1,\n",
       " 'all\":': 1,\n",
       " \"Americans'\": 1,\n",
       " 'courage.': 1,\n",
       " 'tells': 7,\n",
       " 'loved': 10,\n",
       " 'pain.': 6,\n",
       " 'yesterday.': 2,\n",
       " 'screenshots': 2,\n",
       " 'idk': 5,\n",
       " 'hear': 20,\n",
       " 'proud': 12,\n",
       " 'blonde': 1,\n",
       " 'me.': 56,\n",
       " 'better.': 14,\n",
       " 'wna': 2,\n",
       " 'fucj': 1,\n",
       " 'bcs': 1,\n",
       " 'insecure': 1,\n",
       " 'relationship': 9,\n",
       " 'fucked': 14,\n",
       " 'shout': 4,\n",
       " 'trash.': 2,\n",
       " 'trash': 11,\n",
       " 'yourself.': 2,\n",
       " 'natin': 1,\n",
       " 'joke': 6,\n",
       " 'circulating': 1,\n",
       " 'Germany:': 1,\n",
       " '\"What': 2,\n",
       " 'borders': 2,\n",
       " 'stupidity?\"': 1,\n",
       " '\"Mexico': 1,\n",
       " 'Canada!\"': 1,\n",
       " 'already': 18,\n",
       " 'taken': 9,\n",
       " 'what?!': 1,\n",
       " 'waiting': 18,\n",
       " '#WHYRUep12': 1,\n",
       " 'simpsons': 1,\n",
       " 'installing': 23,\n",
       " \"#ScottyFromMarketing's\": 23,\n",
       " 'app.': 25,\n",
       " 'gif.': 25,\n",
       " 'Hollyweird': 1,\n",
       " 'pedophile': 1,\n",
       " 'grandiloquent': 1,\n",
       " 'hypocrites': 1,\n",
       " 'kissed': 3,\n",
       " 'Biden,': 1,\n",
       " 'teenage': 4,\n",
       " 'THEIR': 2,\n",
       " '“I': 7,\n",
       " \"jumpin'\": 1,\n",
       " 'lap”': 1,\n",
       " 'Biden': 23,\n",
       " 'now,': 17,\n",
       " 'petulance,': 1,\n",
       " 'gridlock,': 1,\n",
       " 'vendettas': 1,\n",
       " 'downright': 1,\n",
       " 'belongs': 3,\n",
       " 'idea': 15,\n",
       " 'watches': 1,\n",
       " \"'Bates\": 1,\n",
       " \"Motel'??\": 1,\n",
       " 'spoilers!!': 1,\n",
       " '3.': 7,\n",
       " 'damn': 14,\n",
       " 'all,': 8,\n",
       " \"Norman's\": 1,\n",
       " 'nerves.': 1,\n",
       " \"He's\": 16,\n",
       " 'punch': 1,\n",
       " '🤷🏻\\u200d♀️🤷🏻\\u200d♀️': 1,\n",
       " 'wanted': 25,\n",
       " 'tonight': 21,\n",
       " 'feelings': 5,\n",
       " 'hurt': 6,\n",
       " 'hiding': 5,\n",
       " 'night.': 9,\n",
       " 'feeling': 36,\n",
       " 'bombarded': 2,\n",
       " 'hurtful': 3,\n",
       " 'words.': 2,\n",
       " 'sapped': 2,\n",
       " 'dry.': 2,\n",
       " '#salt': 2,\n",
       " 'fancy': 1,\n",
       " 'skateboard': 1,\n",
       " 'liberate': 3,\n",
       " 'ass.': 3,\n",
       " '🙌': 2,\n",
       " \"Post's\": 1,\n",
       " \"Halladay's\": 1,\n",
       " 'fucking': 43,\n",
       " 'garbage': 2,\n",
       " 'today.': 41,\n",
       " '\"Some': 2,\n",
       " 'Halladay': 1,\n",
       " 'Transportation': 1,\n",
       " 'Fame': 1,\n",
       " 'pitcher': 1,\n",
       " 'amphetamines': 1,\n",
       " 'morphine\"': 1,\n",
       " '$$?': 2,\n",
       " '$200': 3,\n",
       " 'hours.': 14,\n",
       " '@LoyalGiveaways': 2,\n",
       " ':)': 10,\n",
       " 'hug': 78,\n",
       " 'somn': 1,\n",
       " 'suck': 13,\n",
       " 'dick,': 3,\n",
       " 'stopping': 2,\n",
       " 'talent': 2,\n",
       " 'conversation': 7,\n",
       " 'going,': 3,\n",
       " 'lot.': 3,\n",
       " 'Raise': 8,\n",
       " 'reopen': 8,\n",
       " 'America.': 7,\n",
       " '🙋\\u200d♂️🙋\\u200d♂️🙋\\u200d♂️': 2,\n",
       " 'IN:': 7,\n",
       " 'denies': 6,\n",
       " 'extent': 6,\n",
       " 'coronavirus': 27,\n",
       " 'outbreak': 6,\n",
       " 'NEED🌹SOLO': 1,\n",
       " '🌹SANA🌹PROJECTS🌹': 1,\n",
       " 'knows': 9,\n",
       " 'rapists?': 1,\n",
       " 'em?': 1,\n",
       " 'morning!': 1,\n",
       " 'today!': 5,\n",
       " 'specifically?': 1,\n",
       " '#SVTrainToBusan': 1,\n",
       " 'hugs': 19,\n",
       " 'smh': 6,\n",
       " 'unlimited': 1,\n",
       " '😭': 16,\n",
       " '2020!': 2,\n",
       " 'Ending': 1,\n",
       " 'lockdowns': 3,\n",
       " 'quarantining.': 1,\n",
       " 'conflated.': 1,\n",
       " 'welcomed': 2,\n",
       " 'assume': 3,\n",
       " 'risk.': 1,\n",
       " '@DxvilishAngxl': 1,\n",
       " 'cute': 10,\n",
       " 'Veniece': 1,\n",
       " 'Drive-In': 1,\n",
       " 'theater': 3,\n",
       " 'punks': 1,\n",
       " 'nowadays': 1,\n",
       " 'smuggle': 1,\n",
       " 'trunk': 1,\n",
       " 'beers': 1,\n",
       " 'THOSE': 1,\n",
       " 'days!': 1,\n",
       " 'up?': 10,\n",
       " 'no?': 10,\n",
       " 'prepare': 5,\n",
       " 'Rounds': 3,\n",
       " 'negotiations,': 3,\n",
       " 'reiterate': 3,\n",
       " \"Government's\": 3,\n",
       " 'transition': 5,\n",
       " 'following': 21,\n",
       " 'withdrawal': 3,\n",
       " 'EU.': 3,\n",
       " 'Transition': 3,\n",
       " 'year.': 10,\n",
       " 'extend': 6,\n",
       " 'no.': 6,\n",
       " '1/2': 4,\n",
       " 'app,': 24,\n",
       " 'hashtag': 26,\n",
       " '#BailoutHumansNow': 24,\n",
       " '@ShelleyMcElyea1': 1,\n",
       " 'birthday,': 3,\n",
       " 'darling': 2,\n",
       " '❤️💋🎁🎉🍰🎈': 1,\n",
       " '#Giveaway': 2,\n",
       " '$25': 4,\n",
       " '24hours..': 1,\n",
       " 'Like/RT/Tag': 1,\n",
       " '(must': 1,\n",
       " 'me)': 1,\n",
       " 'sponsor': 1,\n",
       " 'following?': 1,\n",
       " 'discuss': 3,\n",
       " 'grow!': 1,\n",
       " 'lovely': 6,\n",
       " 'quickly': 10,\n",
       " '🔥🚀': 1,\n",
       " \"How's\": 6,\n",
       " 'experience': 10,\n",
       " 'Flutter?': 1,\n",
       " 'gifs': 12,\n",
       " '\\U0001f91f🏼': 1,\n",
       " '#Flutter': 1,\n",
       " 'Also,': 21,\n",
       " \"Win's\": 1,\n",
       " '\"How': 2,\n",
       " 'till': 5,\n",
       " 'drop\"': 1,\n",
       " 'improvised': 1,\n",
       " 'struggling': 4,\n",
       " 'reconcile': 1,\n",
       " 'Govt': 5,\n",
       " \"'stay\": 1,\n",
       " \"lives'\": 1,\n",
       " 'mantra': 1,\n",
       " 'allowing': 4,\n",
       " '15,000': 1,\n",
       " 'checks,': 4,\n",
       " 'worst-hit': 1,\n",
       " 'NYC': 4,\n",
       " 'Italy.': 1,\n",
       " 'something?': 2,\n",
       " '@seanhannity': 18,\n",
       " 'minutes.': 2,\n",
       " 'Tune': 4,\n",
       " 'in!': 4,\n",
       " 'believe': 35,\n",
       " 'himself': 8,\n",
       " 'power?': 4,\n",
       " \"'promoter\": 1,\n",
       " 'wholly': 1,\n",
       " 'unconvincing': 1,\n",
       " 'consoler': 1,\n",
       " 'Chief.': 1,\n",
       " 'Hugger,': 1,\n",
       " '~S': 1,\n",
       " 'news:': 1,\n",
       " 'wonderful': 5,\n",
       " 'years,': 2,\n",
       " 'leaving': 6,\n",
       " '@Tes.': 1,\n",
       " 'director.': 1,\n",
       " 'organisation': 1,\n",
       " 'whom': 3,\n",
       " 'journalism.': 1,\n",
       " '1/': 1,\n",
       " 'sister': 6,\n",
       " 'sister.': 3,\n",
       " \"20's\": 2,\n",
       " 'sperm': 4,\n",
       " 'meeting': 12,\n",
       " 'moms': 4,\n",
       " '-famu': 3,\n",
       " 'CNBC': 1,\n",
       " 'AAWAZ': 1,\n",
       " 'announce': 8,\n",
       " 'Stimulus': 2,\n",
       " 'Package.': 1,\n",
       " '30th': 3,\n",
       " 'days.': 4,\n",
       " 'wanna': 43,\n",
       " 'took': 19,\n",
       " 'celebrate': 8,\n",
       " 'birthday.': 8,\n",
       " 'beautiful': 23,\n",
       " 'Mercy': 1,\n",
       " 'Eke,': 1,\n",
       " 'stylish': 1,\n",
       " 'Uti,': 1,\n",
       " 'hardworking': 1,\n",
       " 'BobRisky,': 1,\n",
       " 'awesome': 13,\n",
       " 'Enkayy': 1,\n",
       " 'amazing': 18,\n",
       " 'Mercenaries': 1,\n",
       " 'Spartans.': 1,\n",
       " 'bless': 2,\n",
       " '❤️': 21,\n",
       " '#ZenMagazine': 1,\n",
       " '@liberianboii': 1,\n",
       " 'Twenties.': 1,\n",
       " 'married.': 2,\n",
       " 'people.': 18,\n",
       " 'follow.': 6,\n",
       " 'you,': 18,\n",
       " 'pineapple': 2,\n",
       " 'pizza': 11,\n",
       " 'decision': 10,\n",
       " 'there.': 8,\n",
       " 'Horny': 4,\n",
       " 'Day?': 1,\n",
       " \"It's\": 90,\n",
       " 'Shet': 1,\n",
       " 'disappointment': 1,\n",
       " '😮😅': 1,\n",
       " 'ago,': 4,\n",
       " 'Tinder': 2,\n",
       " 'discounted': 1,\n",
       " 'premium': 1,\n",
       " 'services.': 1,\n",
       " 'decided': 21,\n",
       " 'premium,': 1,\n",
       " 'liked': 4,\n",
       " 'profile,': 1,\n",
       " 'theirs.': 1,\n",
       " 'expecting': 5,\n",
       " 'celebratory': 1,\n",
       " 'dinner': 23,\n",
       " 'stew': 2,\n",
       " '😐': 5,\n",
       " 'COMING': 3,\n",
       " 'MONDAY!': 2,\n",
       " '👻👻👻': 2,\n",
       " 'hosted': 2,\n",
       " 'interacted': 1,\n",
       " 'communities': 3,\n",
       " 'various': 2,\n",
       " 'backgrounds': 1,\n",
       " 'disrespects': 1,\n",
       " 'sentiment': 1,\n",
       " 'religion.': 1,\n",
       " 'Trash': 1,\n",
       " 'equivalent': 1,\n",
       " 'wasting': 1,\n",
       " 'sins': 1,\n",
       " 'tbh...at': 1,\n",
       " 'least': 33,\n",
       " 'sinning': 1,\n",
       " 'Seala': 1,\n",
       " 'definitely': 10,\n",
       " 'putting': 11,\n",
       " 'reaction': 47,\n",
       " '@FilmGob': 1,\n",
       " '@jodyscorner1': 1,\n",
       " 'nonsense.': 1,\n",
       " 'indeed': 2,\n",
       " 'filmgob': 1,\n",
       " 'jody': 1,\n",
       " 'there?': 1,\n",
       " 'interesting.': 4,\n",
       " 'supporter': 16,\n",
       " 'thankful': 19,\n",
       " '$1,200': 12,\n",
       " 'socialist': 13,\n",
       " 'billionaire': 12,\n",
       " 'afford': 12,\n",
       " 'questions…': 12,\n",
       " 'Minister': 6,\n",
       " '(not': 4,\n",
       " 'ill,': 3,\n",
       " 'holiday,': 2,\n",
       " 'fridge)': 2,\n",
       " 'Cabinet,': 2,\n",
       " 'Parliament:': 2,\n",
       " 'pandemic': 16,\n",
       " 'crisis': 7,\n",
       " 'forthcoming': 2,\n",
       " 'Brexit-induced': 2,\n",
       " 'crisis:': 3,\n",
       " 'competent': 2,\n",
       " 'steer': 2,\n",
       " 'through.': 2,\n",
       " 'apologize': 2,\n",
       " 'sending': 7,\n",
       " '\"\\U0001f97a\"': 1,\n",
       " 'emojis': 2,\n",
       " 'admit': 3,\n",
       " 'signs': 5,\n",
       " 'afraid': 3,\n",
       " 'up,': 13,\n",
       " 'down.': 9,\n",
       " 'overthinking': 1,\n",
       " 'takes': 8,\n",
       " 'away.': 5,\n",
       " 'guys..?': 1,\n",
       " 's/o': 1,\n",
       " 'loyal': 1,\n",
       " \"Y'all\": 16,\n",
       " '13k+': 1,\n",
       " '#Covid_19': 6,\n",
       " 'India,': 1,\n",
       " 'recovered.': 1,\n",
       " 'Deaths': 1,\n",
       " '400+.': 1,\n",
       " 'situation,': 1,\n",
       " '@MoHFW_INDIA': 1,\n",
       " '@drharshvardhan': 1,\n",
       " '@PMOIndia': 1,\n",
       " 'consider:': 1,\n",
       " 'decelerate': 1,\n",
       " 'panic,': 1,\n",
       " 'weigh': 1,\n",
       " 'prone,': 1,\n",
       " 'patients': 5,\n",
       " 'others': 9,\n",
       " 'neglected?': 1,\n",
       " 'am,': 1,\n",
       " 'overdue': 1,\n",
       " 'appointment': 3,\n",
       " 'tomorrow': 33,\n",
       " 'dreading,': 1,\n",
       " 'vibes': 4,\n",
       " 'nudes': 3,\n",
       " 'U.S': 2,\n",
       " 'it???': 1,\n",
       " 'LOL': 2,\n",
       " 'attention': 7,\n",
       " 'despise': 1,\n",
       " 'intro.': 1,\n",
       " 'two.': 1,\n",
       " 'spending': 5,\n",
       " '50+': 1,\n",
       " 'secs': 1,\n",
       " '—': 8,\n",
       " 'nope.': 2,\n",
       " '@kellyinvegas': 1,\n",
       " '@vegasmurray': 1,\n",
       " 'Signed,': 1,\n",
       " 'Producer': 1,\n",
       " 'Rhode': 1,\n",
       " 'Island': 1,\n",
       " 'Toppin': 1,\n",
       " 'committed': 6,\n",
       " 'Kentucky,': 1,\n",
       " 'page.': 2,\n",
       " '😭❤️': 1,\n",
       " 'Somebody': 4,\n",
       " 'housekeeping': 1,\n",
       " 'yet.': 5,\n",
       " \"They're\": 4,\n",
       " 'in.': 4,\n",
       " 'decorate': 1,\n",
       " 'bland': 1,\n",
       " 'sad': 26,\n",
       " 'absurd': 1,\n",
       " 'ridiculous.': 1,\n",
       " '👀': 8,\n",
       " '.@JoeBiden': 1,\n",
       " '🤔': 21,\n",
       " 'irresponsible': 4,\n",
       " 'communist': 5,\n",
       " '#COVID19Pandemic': 4,\n",
       " 'alive': 5,\n",
       " 'jobs.': 4,\n",
       " 'responsible.': 4,\n",
       " 'account.': 6,\n",
       " 'HOURRRSSSS': 1,\n",
       " '@shmsaaldh': 1,\n",
       " 'wearing': 10,\n",
       " 'exact': 2,\n",
       " 'sweatshirt': 1,\n",
       " 'questions': 8,\n",
       " 'time.': 20,\n",
       " \"Can't\": 27,\n",
       " 'hammock': 1,\n",
       " 'isolation,': 1,\n",
       " 'offers': 1,\n",
       " 'tests?': 1,\n",
       " 'fun:': 1,\n",
       " 'freely': 1,\n",
       " 'Shehnaaz': 2,\n",
       " 'Gill': 1,\n",
       " 'question,': 3,\n",
       " 'be.': 6,\n",
       " 'ONLY': 6,\n",
       " 'ONE.': 1,\n",
       " '#ShehnaazGill': 1,\n",
       " '@ishehnaaz_gill': 1,\n",
       " '@KaushalJoshi15': 1,\n",
       " 'suffering': 3,\n",
       " 'depression.': 2,\n",
       " 'worse.': 9,\n",
       " 'Hi.': 15,\n",
       " 'covering': 7,\n",
       " 'nose....': 1,\n",
       " 'pointless.': 1,\n",
       " 'Wear': 1,\n",
       " 'please.': 3,\n",
       " 'exist;': 1,\n",
       " 'choose': 7,\n",
       " 'Trump:': 15,\n",
       " '\"I': 19,\n",
       " 'campaigning.\"': 8,\n",
       " 'goin': 1,\n",
       " 'Thorpe': 1,\n",
       " 'Park/Alton': 1,\n",
       " 'Towers': 1,\n",
       " \"Y'ALL!!!\": 1,\n",
       " 'HIT': 4,\n",
       " 'FOLLOWERS': 3,\n",
       " 'TWITCH!!!': 1,\n",
       " '\\U0001f973\\U0001f929': 1,\n",
       " 'continues': 2,\n",
       " 'me!': 10,\n",
       " 'all!': 5,\n",
       " 'gifted': 1,\n",
       " 'subs': 3,\n",
       " 'donos': 1,\n",
       " '💗': 1,\n",
       " 'who-the-hell-even-knows-anymore': 18,\n",
       " 'quarantine:': 19,\n",
       " 'GIF,': 19,\n",
       " 'honest': 20,\n",
       " 'read/hear': 18,\n",
       " '\"we': 19,\n",
       " 'together\".': 18,\n",
       " '👋🏻': 1,\n",
       " 'stressed': 4,\n",
       " 'coloring': 2,\n",
       " 'meant': 2,\n",
       " 'relaxation?': 1,\n",
       " 'hunch': 1,\n",
       " 'page,': 1,\n",
       " 'pencil,': 1,\n",
       " 'choice.': 3,\n",
       " 'done,': 10,\n",
       " 'therapy.': 9,\n",
       " 'reminding': 3,\n",
       " 'invaded': 1,\n",
       " 'chickens': 1,\n",
       " '@The_Badger_jm': 1,\n",
       " 'FSQ!!': 1,\n",
       " 'Retired': 1,\n",
       " 'players.': 2,\n",
       " 'not.': 14,\n",
       " 'memory?': 1,\n",
       " 'great,': 2,\n",
       " 'nostalgia': 1,\n",
       " 'memories': 5,\n",
       " 'were?': 1,\n",
       " 'Childhood:': 1,\n",
       " 'sprinkled': 1,\n",
       " 'sugar': 6,\n",
       " 'avocado': 2,\n",
       " '😋': 4,\n",
       " '65th': 2,\n",
       " 'birthday': 20,\n",
       " \"son's\": 5,\n",
       " 'Yup': 2,\n",
       " 'GIF?': 2,\n",
       " 'sick': 13,\n",
       " '$50,000': 2,\n",
       " 'run?': 2,\n",
       " '#BTC': 3,\n",
       " 'debate': 5,\n",
       " 'Biden?': 5,\n",
       " 'GGs': 1,\n",
       " '@CetraLol': 1,\n",
       " 'mAAd': 1,\n",
       " '1-0': 2,\n",
       " 'PRL!': 1,\n",
       " '9PM': 1,\n",
       " 'Defiance.': 1,\n",
       " 'grateful': 10,\n",
       " 'passion/happiness': 1,\n",
       " 'life....or': 1,\n",
       " 'appreciate': 12,\n",
       " 'condescending!!': 1,\n",
       " 'Evening': 3,\n",
       " 'everyone.': 4,\n",
       " 'awful.': 4,\n",
       " 'dear': 4,\n",
       " 'Covid19.': 3,\n",
       " 'screamed': 3,\n",
       " 'minutes': 18,\n",
       " 'straight.': 5,\n",
       " 'stunned': 3,\n",
       " 'her.': 8,\n",
       " 'crawl': 3,\n",
       " 'forever.': 4,\n",
       " 'mentally': 3,\n",
       " 'unwell': 2,\n",
       " '@SchittsCreek': 1,\n",
       " 'finale': 1,\n",
       " \"Disney's\": 1,\n",
       " 'shitty': 6,\n",
       " 'along...': 1,\n",
       " '@stageit': 2,\n",
       " 'week?': 3,\n",
       " '\"we\"': 2,\n",
       " 'we.': 2,\n",
       " 'alone...that': 2,\n",
       " 'sad.': 3,\n",
       " 'dropped': 6,\n",
       " '4/20': 2,\n",
       " 'interview': 4,\n",
       " 'AUDACITY': 1,\n",
       " 'Skype': 1,\n",
       " '9am.': 1,\n",
       " 'sleeping': 4,\n",
       " '11am?': 1,\n",
       " 'busy': 4,\n",
       " \"Let's\": 31,\n",
       " 'volunteered': 1,\n",
       " 'reduce': 2,\n",
       " 'fantasized': 1,\n",
       " 'smothering': 1,\n",
       " 'pillow.': 2,\n",
       " 'karma': 1,\n",
       " 'scale?': 1,\n",
       " 'LIBERATE': 13,\n",
       " 'VIRGINIA,': 11,\n",
       " '2nd': 18,\n",
       " 'Amendment.': 11,\n",
       " 'siege!': 11,\n",
       " 'while.': 6,\n",
       " 'Feeling': 5,\n",
       " 'hella': 4,\n",
       " 'now.': 21,\n",
       " 'Verkis': 1,\n",
       " 'broke': 6,\n",
       " 'posting': 4,\n",
       " 'treating': 6,\n",
       " 'all?': 3,\n",
       " 'pregnancy': 2,\n",
       " 'kicking': 2,\n",
       " 'ass😩': 1,\n",
       " 'scared': 8,\n",
       " 'nerds': 1,\n",
       " 'glasses,': 1,\n",
       " 'surgical': 2,\n",
       " 'creates': 1,\n",
       " 'visibility': 2,\n",
       " 'foggy': 1,\n",
       " 'specs!!!': 1,\n",
       " '#COVID19': 16,\n",
       " 'smoke': 1,\n",
       " 'to,': 1,\n",
       " 'to.': 4,\n",
       " '.@WHO': 1,\n",
       " 'pandemic,': 3,\n",
       " 'providing': 3,\n",
       " 'advice,': 1,\n",
       " 'training,': 1,\n",
       " 'equipment': 1,\n",
       " 'crucial': 2,\n",
       " 'lives—including': 1,\n",
       " \"Americans'.\": 1,\n",
       " 'Cutting': 1,\n",
       " 'dangerous—Trump': 1,\n",
       " 'authority': 1,\n",
       " 'know:': 3,\n",
       " 'violating': 1,\n",
       " 'impeached.': 1,\n",
       " 'nigga': 6,\n",
       " 'aboogie': 1,\n",
       " 'prime,': 2,\n",
       " 'hurt.': 2,\n",
       " 'Redskins': 1,\n",
       " 'morning.': 10,\n",
       " 'Uh.': 1,\n",
       " '#OUSTDUTERENOW': 3,\n",
       " 'turns': 4,\n",
       " 'martial': 1,\n",
       " 'advantage': 3,\n",
       " 'inability': 2,\n",
       " 'mobilize': 1,\n",
       " '#OUSTDUTERTENOW': 1,\n",
       " 'thousands': 12,\n",
       " 'philippines': 1,\n",
       " 'dictator': 1,\n",
       " 'todd': 1,\n",
       " 'wins': 4,\n",
       " 'gamers': 1,\n",
       " '@COLIATHGAMING': 1,\n",
       " '@Baker_TV_': 1,\n",
       " '@vicdgordon': 1,\n",
       " '@StreamGamma': 1,\n",
       " '@kedabosch': 1,\n",
       " '@Day1neGaming': 1,\n",
       " '@JxckWSW': 1,\n",
       " '@Ncshredder_': 1,\n",
       " '@Samurai_Ree': 1,\n",
       " '@Stardrix1': 1,\n",
       " '@GSO_Joey': 1,\n",
       " '@TSillysweat': 1,\n",
       " '@ChloeDonald_': 1,\n",
       " '@xLexry': 1,\n",
       " '@MultynWolf': 1,\n",
       " '@SaycredAngel': 1,\n",
       " '@fuscyoface': 1,\n",
       " '@Storkyyy1': 1,\n",
       " 'Kamo': 1,\n",
       " 'Mphela': 1,\n",
       " 'whole': 29,\n",
       " 'blueprint': 1,\n",
       " 'moves': 4,\n",
       " '\"she': 1,\n",
       " 'dances': 1,\n",
       " 'shit\"': 2,\n",
       " '😕': 1,\n",
       " 'sober': 5,\n",
       " 'hurts': 3,\n",
       " 'intensions.': 1,\n",
       " 'learned': 8,\n",
       " 'actions.': 1,\n",
       " 'Steyer': 1,\n",
       " 'lives.': 5,\n",
       " 'California.': 3,\n",
       " 'Named': 1,\n",
       " 'Newsom': 2,\n",
       " 'recovery': 2,\n",
       " 'force,': 1,\n",
       " 'injustices': 1,\n",
       " 'revealed': 3,\n",
       " 'crisis.': 4,\n",
       " 'reasonable,': 1,\n",
       " 'zoom': 3,\n",
       " 'calls': 6,\n",
       " 'fart': 3,\n",
       " 'meetings': 2,\n",
       " 'mute': 2,\n",
       " 'know.': 9,\n",
       " '💨💨': 1,\n",
       " 'YALL': 3,\n",
       " 'READY': 1,\n",
       " 'CAUCASIANS': 1,\n",
       " 'THEY': 4,\n",
       " 'CANCEL': 1,\n",
       " '4TH': 3,\n",
       " 'JULY?!!!!!': 1,\n",
       " 'convo': 4,\n",
       " 'meteoric': 1,\n",
       " 'again.': 19,\n",
       " 'soon.': 4,\n",
       " 'Nathaniel': 14,\n",
       " 'here.': 20,\n",
       " 'you?': 19,\n",
       " '7th': 8,\n",
       " 'slid': 7,\n",
       " 'DMs?': 7,\n",
       " 'Sweep': 1,\n",
       " 'did.': 3,\n",
       " 'bump': 2,\n",
       " 'pronounced': 4,\n",
       " 'orders.': 2,\n",
       " 'Oklahoma': 1,\n",
       " '53%': 1,\n",
       " 'increase': 3,\n",
       " 'jumped': 1,\n",
       " '60%': 3,\n",
       " 'Arkansas,': 1,\n",
       " '74%': 1,\n",
       " 'Nebraska,': 1,\n",
       " '82%': 1,\n",
       " 'Iowa.': 1,\n",
       " 'Dakota': 3,\n",
       " 'whopping': 1,\n",
       " '205%': 1,\n",
       " 'spike.': 1,\n",
       " '#StayHomeStaySafeSaveLives': 1,\n",
       " 'chick': 3,\n",
       " 'sauce': 4,\n",
       " 'body.': 4,\n",
       " 'yall': 11,\n",
       " \"What's\": 15,\n",
       " 'funny': 9,\n",
       " 'hurry': 2,\n",
       " 'asked': 19,\n",
       " 'first.': 4,\n",
       " '#smallvictory': 1,\n",
       " 'sucks': 2,\n",
       " 'decorating': 1,\n",
       " '#AnimalCrossing': 1,\n",
       " 'NOVEMBER': 2,\n",
       " 'headline': 2,\n",
       " 'preview:': 2,\n",
       " 'defeated': 18,\n",
       " 'landslide': 2,\n",
       " 'Mitch': 2,\n",
       " 'McConnell': 2,\n",
       " 'Lindsey': 4,\n",
       " 'Martha': 2,\n",
       " 'McSally': 2,\n",
       " 'Cory': 2,\n",
       " 'Gardner': 2,\n",
       " 'Loeffler': 3,\n",
       " 'Tillis': 2,\n",
       " 'Yeah,': 3,\n",
       " 'night,': 2,\n",
       " 'dreamt': 1,\n",
       " 'journalists,': 1,\n",
       " 'Uddhav': 1,\n",
       " 'PM.': 2,\n",
       " 'aide': 1,\n",
       " 'approaches': 1,\n",
       " 'informal': 1,\n",
       " 'mine,': 1,\n",
       " 'no,': 3,\n",
       " '#soproudofmyself': 1,\n",
       " 'Niggas': 1,\n",
       " 'bout': 8,\n",
       " 'shooting': 3,\n",
       " 'hooping': 1,\n",
       " '$50': 8,\n",
       " 'retweets': 6,\n",
       " 'Minutes.': 2,\n",
       " '@K_9Girl': 1,\n",
       " 'Myself.': 2,\n",
       " 'sitting': 13,\n",
       " 'Cocoa': 1,\n",
       " 'Krispies': 2,\n",
       " 'strange': 2,\n",
       " 'Rice': 1,\n",
       " 'hits': 5,\n",
       " 'this?': 4,\n",
       " 'wasted.': 1,\n",
       " 'finally': 21,\n",
       " 'agreed': 3,\n",
       " 'repaint': 1,\n",
       " 'stuck': 7,\n",
       " 'home.': 5,\n",
       " 'requesting': 2,\n",
       " 'thoughts': 9,\n",
       " 'prayers': 3,\n",
       " 'difficult': 5,\n",
       " '😊': 18,\n",
       " 'man-half': 1,\n",
       " 'assholes': 2,\n",
       " 'concerns': 3,\n",
       " 'exercise,': 1,\n",
       " 'shit,': 2,\n",
       " 'smoke,': 1,\n",
       " 'drink': 7,\n",
       " 'excessive': 1,\n",
       " 'alcohol.': 2,\n",
       " 'helluva': 1,\n",
       " 'disease': 2,\n",
       " 'Covid.': 1,\n",
       " 'Wake': 3,\n",
       " 'Lebron': 7,\n",
       " 'MJ.': 7,\n",
       " \"That's\": 33,\n",
       " 'passing': 1,\n",
       " 'Moir.': 1,\n",
       " 'detox': 1,\n",
       " 'now✌🏻': 1,\n",
       " 'Brooks': 3,\n",
       " 'hates': 22,\n",
       " 'millennials': 3,\n",
       " 'marry': 11,\n",
       " 'Sidharth': 1,\n",
       " 'mention': 5,\n",
       " 'please?': 3,\n",
       " 'deserves': 3,\n",
       " 'please.😭': 1,\n",
       " 'dont': 16,\n",
       " 'belive': 1,\n",
       " 'loosing': 2,\n",
       " '\"nah': 1,\n",
       " 'somebody': 4,\n",
       " ...}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unknown_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check punctuations that roberta unknown "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "punct = \"/-'?!.,#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~\" + '\"\"“”’' + '∞θ÷α•à−β∅³π‘₹´°£€\\×™√²—–&'\n",
    "def unknown_punctuation(roberta_vocab):\n",
    "    unknown = ''\n",
    "    for char in punct:\n",
    "        if char not in list(roberta_vocab.keys()):\n",
    "            unknown += char\n",
    "            unknown += ' '\n",
    "    return unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Roberta unknown: \n",
      "“ ” ’ ∞ θ α • − β ∅ π ‘ ₹ € ™ √ — – \n"
     ]
    }
   ],
   "source": [
    "print(\"Roberta unknown: \")\n",
    "print(unknown_punctuation(roberta_vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping unknown to known punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_punc(text):\n",
    "    punct_mapping = {\"‘\": \"'\", \"₹\": \"e\", \"´\": \"'\", \"°\": \"\", \"€\": \"e\", \"™\": \"tm\", \"√\": \" sqrt \", \"×\": \"x\", \"²\": \"2\", \"—\": \"-\", \"–\": \"-\", \"’\": \"'\", \"_\": \"-\", \"`\": \"'\", '“': '\"', '”': '\"', '“': '\"', \"£\": \"e\", '∞': 'infinity', 'θ': 'theta', '÷': '/', 'α': 'alpha', '•': '.', 'à': 'a', '−': '-', 'β': 'beta', '∅': '', '³': '3', 'π': 'pi', }\n",
    "    for p in punct_mapping:\n",
    "        text = text.replace(p, punct_mapping[p])\n",
    "    for p in punct:\n",
    "        text = text.replace(p, ' {} '.format(p))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['map_punc_text'] = df_train.text.apply(change_punc)\n",
    "df_train['map_punc_reply'] = df_train.reply.apply(change_punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev['map_punc_text'] = df_dev.text.apply(change_punc)\n",
    "df_dev['map_punc_reply'] = df_dev.reply.apply(change_punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['map_punc_text'] = df_test.text.apply(change_punc)\n",
    "df_test['map_punc_reply'] = df_test.reply.apply(change_punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train text unique vocab count is: 46129\n",
      "train reply unique vocab count is: 18569\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=46129.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 13.464% (6211 / 46129) of vocab\n",
      "Found embeddings for 80.351% (645864 / 803801) of all text\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=18569.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 21.977% (4081 / 18569) of vocab\n",
      "Found embeddings for 79.704% (110219 / 138285) of all text\n"
     ]
    }
   ],
   "source": [
    "train_text_vocab = get_vocab(df_train['map_punc_text'].values)\n",
    "train_reply_vocab = get_vocab(df_train['map_punc_reply'].values)\n",
    "print(\"train text unique vocab count is: {}\".format(len(train_text_vocab)))\n",
    "print(\"train reply unique vocab count is: {}\".format(len(train_reply_vocab)))\n",
    "print()\n",
    "\n",
    "unknown_text = check_coverage(train_text_vocab, roberta_vocab)\n",
    "print()\n",
    "unknown_reply = check_coverage(train_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev text unique vocab count is: 13357\n",
      "dev reply unique vocab count is: 4473\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=13357.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 26.698% (3566 / 13357) of vocab\n",
      "Found embeddings for 80.274% (81844 / 101956) of all text\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=4473.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 36.977% (1654 / 4473) of vocab\n",
      "Found embeddings for 78.665% (13797 / 17539) of all text\n"
     ]
    }
   ],
   "source": [
    "dev_text_vocab = get_vocab(df_dev['map_punc_text'].values)\n",
    "dev_reply_vocab = get_vocab(df_dev['map_punc_reply'].values)\n",
    "print(\"dev text unique vocab count is: {}\".format(len(dev_text_vocab)))\n",
    "print(\"dev reply unique vocab count is: {}\".format(len(dev_reply_vocab)))\n",
    "unknown_text = check_coverage(dev_text_vocab, roberta_vocab)\n",
    "print()\n",
    "unknown_reply = check_coverage(dev_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test text unique vocab count is: 13174\n",
      "test reply unique vocab count is: 4263\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=13174.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 27.228% (3587 / 13174) of vocab\n",
      "Found embeddings for 80.222% (80192 / 99962) of all text\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=4263.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 39.268% (1674 / 4263) of vocab\n",
      "Found embeddings for 79.877% (13548 / 16961) of all text\n"
     ]
    }
   ],
   "source": [
    "test_text_vocab = get_vocab(df_test['map_punc_text'].values)\n",
    "test_reply_vocab = get_vocab(df_test['map_punc_reply'].values)\n",
    "print(\"test text unique vocab count is: {}\".format(len(test_text_vocab)))\n",
    "print(\"test reply unique vocab count is: {}\".format(len(test_reply_vocab)))\n",
    "unknown_text = check_coverage(test_text_vocab, roberta_vocab)\n",
    "print()\n",
    "unknown_reply = check_coverage(test_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hug', 96),\n",
       " ('cannot', 90),\n",
       " ('quarantine', 68),\n",
       " ('tonight', 64),\n",
       " ('myself', 58),\n",
       " ('gonna', 55),\n",
       " ('Biden', 52),\n",
       " ('reaction', 48),\n",
       " ('tomorrow', 47),\n",
       " ('fucking', 43),\n",
       " ('coronavirus', 43),\n",
       " ('wanna', 43),\n",
       " ('Pelosi', 42),\n",
       " ('Nancy', 40),\n",
       " ('hear', 39),\n",
       " ('feeling', 39),\n",
       " ('guys', 39),\n",
       " ('weeks', 39),\n",
       " ('Oz', 39),\n",
       " ('anyone', 39),\n",
       " ('COVID', 38),\n",
       " ('believe', 37),\n",
       " ('trying', 36),\n",
       " ('followers', 36),\n",
       " ('yourself', 36),\n",
       " ('tweet', 36),\n",
       " ('died', 36),\n",
       " ('lockdown', 36),\n",
       " ('least', 35),\n",
       " ('gave', 35),\n",
       " ('sad', 34),\n",
       " ('GIF', 34),\n",
       " ('hope', 34),\n",
       " ('birthday', 33),\n",
       " ('anymore', 33),\n",
       " ('Covid', 32),\n",
       " ('COVID19', 31),\n",
       " ('economy', 31),\n",
       " ('says', 30),\n",
       " ('whole', 30),\n",
       " ('wants', 29),\n",
       " ('virus', 29),\n",
       " ('already', 28),\n",
       " ('knows', 28),\n",
       " ('wanted', 27),\n",
       " ('pandemic', 27),\n",
       " ('fans', 27),\n",
       " ('hashtag', 26),\n",
       " ('beautiful', 26),\n",
       " ('dinner', 26),\n",
       " ('saying', 25),\n",
       " ('wish', 25),\n",
       " ('weekend', 24),\n",
       " ('hugs', 24),\n",
       " ('BailoutHumansNow', 24),\n",
       " ('totally', 24),\n",
       " ('dependable', 24),\n",
       " ('forget', 24),\n",
       " ('😂', 24),\n",
       " ('installing', 23),\n",
       " ('ScottyFromMarketing', 23),\n",
       " ('lives', 23),\n",
       " ('minutes', 23),\n",
       " ('❤️', 23),\n",
       " ('🤔', 23),\n",
       " ('honest', 23),\n",
       " ('career', 23),\n",
       " ('dick', 22),\n",
       " ('following', 22),\n",
       " ('finally', 22),\n",
       " ('hates', 22),\n",
       " ('explain', 22),\n",
       " ('decided', 21),\n",
       " ('tired', 21),\n",
       " ('Crazy', 21),\n",
       " ('numbers', 21),\n",
       " ('sick', 20),\n",
       " ('suck', 20),\n",
       " ('amazing', 20),\n",
       " ('thankful', 20),\n",
       " ('asked', 20),\n",
       " ('feels', 20),\n",
       " ('businesses', 20),\n",
       " ('horny', 20),\n",
       " ('Guys', 20),\n",
       " ('\\U0001f97a', 19),\n",
       " ('😭', 19),\n",
       " ('seanhannity', 19),\n",
       " ('took', 19),\n",
       " ('2nd', 19),\n",
       " ('politicians', 19),\n",
       " ('Radical', 19),\n",
       " ('WritingCommunity', 19),\n",
       " ('Cuomo', 19),\n",
       " ('moment', 19),\n",
       " ('teammates', 18),\n",
       " ('waiting', 18),\n",
       " ('defeated', 18),\n",
       " ('😊', 18),\n",
       " ('pathetic', 18),\n",
       " ('stimulus', 18),\n",
       " ('idea', 17),\n",
       " ('gifs', 17),\n",
       " ('supporter', 17),\n",
       " ('crisis', 17),\n",
       " ('excited', 17),\n",
       " ('incompetent', 17),\n",
       " ('puppet', 17),\n",
       " ('giveaway', 17),\n",
       " ('guess', 17),\n",
       " ('deaths', 17),\n",
       " ('Conference', 17),\n",
       " ('AGAIN', 17),\n",
       " ('gotta', 16),\n",
       " ('came', 16),\n",
       " ('awesome', 16),\n",
       " ('dont', 16),\n",
       " ('become', 16),\n",
       " ('voting', 16),\n",
       " ('😔', 16),\n",
       " ('stupid', 16),\n",
       " ('describes', 16),\n",
       " ('bitch', 16),\n",
       " ('Guidelines', 16),\n",
       " ('OPENING', 16),\n",
       " ('AMERICA', 16),\n",
       " ('woke', 15),\n",
       " ('Gates', 15),\n",
       " ('fucked', 15),\n",
       " ('damn', 15),\n",
       " ('supposed', 15),\n",
       " ('distancing', 15),\n",
       " ('lonely', 15),\n",
       " ('cares', 15),\n",
       " ('trash', 14),\n",
       " ('cute', 14),\n",
       " ('quickly', 14),\n",
       " ('meeting', 14),\n",
       " ('socialist', 14),\n",
       " ('others', 14),\n",
       " ('LIBERATE', 14),\n",
       " ('Nathaniel', 14),\n",
       " ('sitting', 14),\n",
       " ('mood', 14),\n",
       " ('showed', 14),\n",
       " ('tears', 14),\n",
       " ('buying', 14),\n",
       " ('lmao', 14),\n",
       " ('helped', 14),\n",
       " ('happened', 14),\n",
       " ('ugly', 14),\n",
       " ('understand', 14),\n",
       " ('deserve', 14),\n",
       " ('tried', 13),\n",
       " ('proud', 13),\n",
       " ('worse', 13),\n",
       " ('yall', 13),\n",
       " ('thoughts', 13),\n",
       " ('marry', 13),\n",
       " ('longer', 13),\n",
       " ('ensure', 13),\n",
       " ('corona', 13),\n",
       " ('anxiety', 13),\n",
       " ('folks', 13),\n",
       " ('spend', 13),\n",
       " ('realize', 13),\n",
       " ('tweets', 13),\n",
       " ('safely', 13),\n",
       " ('6pm', 13),\n",
       " ('🙃', 13),\n",
       " ('stopped', 13),\n",
       " ('Vaccine', 12),\n",
       " ('coffee', 12),\n",
       " ('pizza', 12),\n",
       " ('decision', 12),\n",
       " ('billionaire', 12),\n",
       " ('afford', 12),\n",
       " ('questions…', 12),\n",
       " ('attention', 12),\n",
       " ('questions', 12),\n",
       " ('appreciate', 12),\n",
       " ('thousands', 12),\n",
       " ('funny', 12),\n",
       " ('covid', 12),\n",
       " ('approval', 12),\n",
       " ('students', 12),\n",
       " ('entire', 12),\n",
       " ('looks', 12),\n",
       " ('complaining', 12),\n",
       " ('truly', 12),\n",
       " ('thinks', 12),\n",
       " ('kinda', 12),\n",
       " ('loved', 11),\n",
       " ('reopen', 11),\n",
       " ('experience', 11),\n",
       " ('putting', 11),\n",
       " ('wearing', 11),\n",
       " ('grateful', 11),\n",
       " ('VIRGINIA', 11),\n",
       " ('Amendment', 11),\n",
       " ('siege', 11),\n",
       " ('scared', 11),\n",
       " ('DMs', 11),\n",
       " ('replies', 11),\n",
       " ('handling', 11),\n",
       " ('Dollar', 11),\n",
       " ('streaming', 11),\n",
       " ('possible', 11),\n",
       " ('nobody', 11),\n",
       " ('\\U0001f974', 11),\n",
       " ('knew', 11),\n",
       " ('boyfriend', 11),\n",
       " ('crying', 11),\n",
       " ('Ventilators', 11),\n",
       " ('leadership', 11),\n",
       " ('Governor', 11),\n",
       " ('😳', 11),\n",
       " ('1st', 11),\n",
       " ('spent', 11),\n",
       " ('means', 11),\n",
       " ('across', 11),\n",
       " ('listen', 11),\n",
       " ('couple', 11),\n",
       " ('lil', 10),\n",
       " ('everyday', 10),\n",
       " ('kindness', 10),\n",
       " ('relationship', 10),\n",
       " ('conversation', 10),\n",
       " ('sister', 10),\n",
       " ('definitely', 10),\n",
       " ('forever', 10),\n",
       " ('ventilators', 10),\n",
       " ('passed', 10),\n",
       " ('THAT', 10),\n",
       " ('goes', 10),\n",
       " ('summer', 10),\n",
       " ('disaster', 10),\n",
       " ('H1N1', 10),\n",
       " ('Swine', 10),\n",
       " ('Flu', 10),\n",
       " ('Polling', 10),\n",
       " ('disastrous', 10),\n",
       " ('unnecessarily', 10),\n",
       " ('incompetence', 10),\n",
       " ('Billion', 10),\n",
       " ('Obamacare', 10),\n",
       " ('website', 10),\n",
       " ('excuse', 10),\n",
       " ('moved', 10),\n",
       " ('randomly', 10),\n",
       " ('cuz', 10),\n",
       " ('😂😂😂', 10),\n",
       " ('themselves', 10),\n",
       " ('reopening', 10),\n",
       " ('realized', 10),\n",
       " ('opinion', 10),\n",
       " ('BREAKING', 10),\n",
       " ('5k', 10),\n",
       " ('biggest', 9),\n",
       " ('laughing', 9),\n",
       " ('sucking', 9),\n",
       " ('taken', 9),\n",
       " ('hurt', 9),\n",
       " ('himself', 9),\n",
       " ('situation', 9),\n",
       " ('patients', 9),\n",
       " ('👀', 9),\n",
       " ('choose', 9),\n",
       " ('therapy', 9),\n",
       " ('awful', 9),\n",
       " ('😭😭', 9),\n",
       " ('difference', 9),\n",
       " ('3rd', 9),\n",
       " ('Idk', 9),\n",
       " ('drunk', 9),\n",
       " ('weird', 9),\n",
       " ('🙄', 9),\n",
       " ('wonder', 9),\n",
       " ('honestly', 9),\n",
       " ('NEED', 9),\n",
       " ('staying', 9),\n",
       " ('showing', 9),\n",
       " ('bought', 9),\n",
       " ('cheese', 9),\n",
       " ('okay', 9),\n",
       " ('expansive', 9),\n",
       " ('accurate', 9),\n",
       " ('reminds', 9),\n",
       " ('happen', 9),\n",
       " ('angry', 9),\n",
       " ('dude', 9),\n",
       " ('helping', 9),\n",
       " ('worry', 9),\n",
       " ('shower', 9),\n",
       " ('ppl', 9),\n",
       " ('seriously', 9),\n",
       " ('unemployment', 9),\n",
       " ('pls', 9),\n",
       " ('retweet', 9),\n",
       " ('grocery', 9),\n",
       " ('pregnant', 9),\n",
       " ('listening', 8),\n",
       " ('accounts', 8),\n",
       " ('idk', 8),\n",
       " ('Raise', 8),\n",
       " ('leaving', 8),\n",
       " ('announce', 8),\n",
       " ('celebrate', 8),\n",
       " ('takes', 8),\n",
       " ('depression', 8),\n",
       " ('campaigning', 8),\n",
       " ('sugar', 8),\n",
       " ('11am', 8),\n",
       " ('broke', 8),\n",
       " ('advice', 8),\n",
       " ('nigga', 8),\n",
       " ('learned', 8),\n",
       " ('7th', 8),\n",
       " ('sucks', 8),\n",
       " ('bout', 8),\n",
       " ('Frequently', 8),\n",
       " ('opportunity', 8),\n",
       " ('LIKE', 8),\n",
       " ('finish', 8),\n",
       " ('cheating', 8),\n",
       " ('partner', 8),\n",
       " ('→', 8),\n",
       " ('heaven', 8),\n",
       " ('attempt', 8),\n",
       " ('LOVE', 8),\n",
       " ('chill', 8),\n",
       " ('💕', 8),\n",
       " ('beds', 8),\n",
       " ('causing', 8),\n",
       " ('funeral', 8),\n",
       " ('Coronavirus', 8),\n",
       " ('MUCH', 8),\n",
       " ('pray', 8),\n",
       " ('enjoy', 8),\n",
       " ('teacher', 8),\n",
       " ('Gif', 8),\n",
       " ('additional', 8),\n",
       " ('approve', 8),\n",
       " ('dying', 8),\n",
       " ('✅', 8),\n",
       " ('welcome', 8),\n",
       " ('HAVE', 8),\n",
       " ('🤝', 8),\n",
       " ('terrible', 8),\n",
       " ('keeps', 8),\n",
       " ('FollowFriday', 8),\n",
       " ('likes', 8),\n",
       " ('relief', 8),\n",
       " ('idiot', 8),\n",
       " ('apartment', 8),\n",
       " ('upset', 8),\n",
       " ('sounds', 7),\n",
       " ('kitchen', 7),\n",
       " ('messages', 7),\n",
       " ('OldRich', 7),\n",
       " ('tells', 7),\n",
       " ('joke', 7),\n",
       " ('NYC', 7),\n",
       " ('sending', 7),\n",
       " ('alive', 7),\n",
       " ('ONLY', 7),\n",
       " ('covering', 7),\n",
       " ('dear', 7),\n",
       " ('dropped', 7),\n",
       " ('treating', 7),\n",
       " ('calls', 7),\n",
       " ('slid', 7),\n",
       " ('sauce', 7),\n",
       " ('stuck', 7),\n",
       " ('drink', 7),\n",
       " ('Lebron', 7),\n",
       " ('masks', 7),\n",
       " ('Genuinely', 7),\n",
       " ('Rashford', 7),\n",
       " ('clothes', 7),\n",
       " ('lately', 7),\n",
       " ('fraud', 7),\n",
       " ('discussion', 7),\n",
       " ('harder', 7),\n",
       " ('Instagram', 7),\n",
       " ('herself', 7),\n",
       " ('lucky', 7),\n",
       " ('incredibly', 7),\n",
       " ('expect', 7),\n",
       " ('glad', 7),\n",
       " ('RETWEET', 7),\n",
       " ('Zoom', 7),\n",
       " ('disgusting', 7),\n",
       " ('TESTING', 7),\n",
       " ('exam', 7),\n",
       " ('yours', 7),\n",
       " ('Been', 7),\n",
       " ('turning', 7),\n",
       " ('Birthday', 7),\n",
       " ('loves', 7),\n",
       " ('comedy', 7),\n",
       " ('evening', 7),\n",
       " ('complain', 7),\n",
       " ('waste', 7),\n",
       " ('songs', 7),\n",
       " ('afternoon', 7),\n",
       " ('QUARANTINE', 7),\n",
       " ('EVER', 7),\n",
       " ('FUCK', 7),\n",
       " ('slide', 7),\n",
       " ('apparently', 7),\n",
       " ('barely', 7),\n",
       " ('officials', 7),\n",
       " ('Respond', 7),\n",
       " ('\\U0001f970', 7),\n",
       " ('heavily', 7),\n",
       " ('awake', 7),\n",
       " ('blocked', 7),\n",
       " ('sexy', 7),\n",
       " ('clearly', 7),\n",
       " ('problems', 7),\n",
       " ('pics', 7),\n",
       " ('officially', 7),\n",
       " ('funds', 7),\n",
       " ('meme', 7),\n",
       " ('annoying', 7),\n",
       " ('KNOW', 7),\n",
       " ('appreciated', 7),\n",
       " ('surprise', 7),\n",
       " ('🔑', 7),\n",
       " ('niggas', 6),\n",
       " ('everybody', 6),\n",
       " ('nightmare', 6),\n",
       " ('judging', 6),\n",
       " ('judgement', 6),\n",
       " ('HUNGRY', 6),\n",
       " ('worried', 6),\n",
       " ('yesterday', 6),\n",
       " ('feelings', 6),\n",
       " ('denies', 6),\n",
       " ('extent', 6),\n",
       " ('outbreak', 6),\n",
       " ('smh', 6),\n",
       " ('extend', 6),\n",
       " ('lovely', 6),\n",
       " ('expecting', 6),\n",
       " ('Minister', 6),\n",
       " ('vibes', 6),\n",
       " ('committed', 6),\n",
       " ('communist', 6),\n",
       " ('isolation', 6),\n",
       " ('Covid19', 6),\n",
       " ('shitty', 6),\n",
       " ('interview', 6),\n",
       " ('dangerous', 6),\n",
       " ('retweets', 6),\n",
       " ('difficult', 6),\n",
       " ('😪', 6),\n",
       " ('amwriting', 6),\n",
       " ('Neymar', 6),\n",
       " ('starts', 6),\n",
       " ('senior', 6),\n",
       " ('makeup', 6),\n",
       " ('personally', 6),\n",
       " ('pictures', 6),\n",
       " ('experts', 6),\n",
       " ('lowkey', 6),\n",
       " ('dumb', 6),\n",
       " ('fellow', 6),\n",
       " ('fear', 6),\n",
       " ('blessed', 6),\n",
       " ('university', 6),\n",
       " ('Cassper', 6),\n",
       " ('survive', 6),\n",
       " ('thousand', 6),\n",
       " ('crush', 6),\n",
       " ('viewers', 6),\n",
       " ('Bailout', 6),\n",
       " ('Humans', 6),\n",
       " ('MUST', 6),\n",
       " ('Shout', 6),\n",
       " ('🤣', 6),\n",
       " ('Quarantine', 6),\n",
       " ('Vikings', 6),\n",
       " ('scary', 6),\n",
       " ('groceries', 6),\n",
       " ('visit', 6),\n",
       " ('Lol', 6),\n",
       " ('strategy', 6),\n",
       " ('watched', 6),\n",
       " ('supporters', 6),\n",
       " ('gift', 6),\n",
       " ('breakfast', 6),\n",
       " ('suddenly', 6),\n",
       " ('miles', 6),\n",
       " ('voted', 6),\n",
       " ('ventilator', 6),\n",
       " ('unprecedented', 6),\n",
       " ('follows', 6),\n",
       " ('bunch', 6),\n",
       " ('vaccine', 6),\n",
       " ('chocolate', 6),\n",
       " ('cuddle', 6),\n",
       " ('missed', 6),\n",
       " ('employees', 6),\n",
       " ('possibility', 6),\n",
       " ('CoronaVirus', 6),\n",
       " ('Democrat', 6),\n",
       " ('immediately', 6),\n",
       " ('asleep', 6),\n",
       " ('POTUS', 6),\n",
       " ('governors', 6),\n",
       " ('appointing', 6),\n",
       " ('pussy', 6),\n",
       " ('losing', 6),\n",
       " ('promise', 6),\n",
       " ('RIGHT', 6),\n",
       " ('boobs', 6),\n",
       " ('WAS', 6),\n",
       " ('governor', 6),\n",
       " ('Guess', 6),\n",
       " ('notifications', 6),\n",
       " ('families', 6),\n",
       " ('tough', 6),\n",
       " ('seems', 6),\n",
       " ('dance', 6),\n",
       " ('CoronavirusLiar', 6),\n",
       " ('spirits', 6),\n",
       " ('👏🏼', 6),\n",
       " ('discussing', 5),\n",
       " ('wtf', 5),\n",
       " ('cried', 5),\n",
       " ('hacked', 5),\n",
       " ('replying', 5),\n",
       " ('attacked', 5),\n",
       " ('stupidity', 5),\n",
       " ('hiding', 5),\n",
       " ('prepare', 5),\n",
       " ('transition', 5),\n",
       " ('till', 5),\n",
       " ('Govt', 5),\n",
       " ('wonderful', 5),\n",
       " ('😐', 5),\n",
       " ('tbh', 5),\n",
       " ('fridge', 5),\n",
       " ('Parliament', 5),\n",
       " ('signs', 5),\n",
       " ('spending', 5),\n",
       " ('ridiculous', 5),\n",
       " ('memories', 5),\n",
       " ('debate', 5),\n",
       " ('happiness', 5),\n",
       " ('Feeling', 5),\n",
       " ('sober', 5),\n",
       " ('meetings', 5),\n",
       " ('hits', 5),\n",
       " ('prayers', 5),\n",
       " ('disease', 5),\n",
       " ('mention', 5),\n",
       " ('somebody', 5),\n",
       " ('☺️', 5),\n",
       " ('drinks', 5),\n",
       " ('compassion', 5),\n",
       " ('Zack', 5),\n",
       " ('teams', 5),\n",
       " ('WILL', 5),\n",
       " ('BABY', 5),\n",
       " ('remain', 5),\n",
       " ('hearing', 5),\n",
       " ('huh', 5),\n",
       " ('Fauci', 5),\n",
       " ('boring', 5),\n",
       " ('waking', 5),\n",
       " ('doctors', 5),\n",
       " ('slowly', 5),\n",
       " ('expand', 5),\n",
       " ('cancelled', 5),\n",
       " ('Trey', 5),\n",
       " ('Burton', 5),\n",
       " ('cant', 5),\n",
       " ('selecting', 5),\n",
       " ('donate', 5),\n",
       " ('win💰', 5),\n",
       " ('plenty', 5),\n",
       " ('laid', 5),\n",
       " ('journey', 5),\n",
       " ('peaceful', 5),\n",
       " ('beach', 5),\n",
       " ('mutuals', 5),\n",
       " ('anywhere', 5),\n",
       " ('choked', 5),\n",
       " ('politician', 5),\n",
       " ('homes', 5),\n",
       " ('🙏', 5),\n",
       " ('cough', 5),\n",
       " ('bipartisan', 5),\n",
       " ('🇺🇸', 5),\n",
       " ('desk', 5),\n",
       " ('doubling', 5),\n",
       " ('Invisible', 5),\n",
       " ('Enemy', 5),\n",
       " ('concerned', 5),\n",
       " ('YOUR', 5),\n",
       " ('WHY', 5),\n",
       " ('bitches', 5),\n",
       " ('challenge', 5),\n",
       " ('butter', 5),\n",
       " ('shoes', 5),\n",
       " ('10k', 5),\n",
       " ('GOOD', 5),\n",
       " ('pounds', 5),\n",
       " ('FIRST', 5),\n",
       " ('loud', 5),\n",
       " ('loan', 5),\n",
       " ('tiktok', 5),\n",
       " ('dudes', 5),\n",
       " ('streets', 5),\n",
       " ('timeline', 5),\n",
       " ('freak', 5),\n",
       " ('haircut', 5),\n",
       " ('garden', 5),\n",
       " ('selfie', 5),\n",
       " ('DrOz', 5),\n",
       " ('imagine', 5),\n",
       " ('entering', 5),\n",
       " ('Dems', 5),\n",
       " ('realizing', 5),\n",
       " ('liquor', 5),\n",
       " ('RAT', 5),\n",
       " ('guest', 5),\n",
       " ('HIM', 5),\n",
       " ('rally', 5),\n",
       " ('naked', 5),\n",
       " ('horrible', 5),\n",
       " ('Retweet', 5),\n",
       " ('movies', 5),\n",
       " ('shopping', 5),\n",
       " ('roof', 5),\n",
       " ('Verge', 5),\n",
       " ('consistently', 5),\n",
       " ('mistake', 5),\n",
       " ('suspect', 5),\n",
       " ('furloughed', 5),\n",
       " ('writerslift', 5),\n",
       " ('milk', 5),\n",
       " ('drinking', 5),\n",
       " ('leaves', 5),\n",
       " ('everywhere', 5),\n",
       " ('followed', 5),\n",
       " ('govt', 5),\n",
       " ('LikewiseApp', 5),\n",
       " ('Yay', 5),\n",
       " ('infected', 5),\n",
       " ('attend', 5),\n",
       " ('Lockdown', 5),\n",
       " ('simply', 5),\n",
       " ('boo', 5),\n",
       " ('✨', 5),\n",
       " ('juliemac1000', 5),\n",
       " ('Congressional', 5),\n",
       " ('lawyer', 5),\n",
       " ('payments', 5),\n",
       " ('bored', 5),\n",
       " ('OKAY', 5),\n",
       " ('TODAY', 5),\n",
       " ('happens', 5),\n",
       " ('screenshot', 5),\n",
       " ('Uncle', 5),\n",
       " ('2021', 5),\n",
       " ('interact', 5),\n",
       " ('saved', 5),\n",
       " ('fuckin', 5),\n",
       " ('murder', 5),\n",
       " ('nursing', 5),\n",
       " ('jumping', 5),\n",
       " ('Wuhan', 5),\n",
       " ('teach', 5),\n",
       " ('memes', 5),\n",
       " ('swear', 5),\n",
       " ('cheer', 5),\n",
       " ('earlier', 5),\n",
       " ('applause', 5),\n",
       " ('younger', 5),\n",
       " ('😔😔', 5),\n",
       " ('neighbor', 5),\n",
       " ('pushing', 5),\n",
       " ('WOW', 5),\n",
       " ('Kanye', 5),\n",
       " ('bills', 5),\n",
       " ('eggs', 5),\n",
       " ('tho', 5),\n",
       " ('sisters', 5),\n",
       " ('Couldn', 5),\n",
       " ('Lawrence', 5),\n",
       " ('sacrifice', 5),\n",
       " ('trading', 4),\n",
       " ('Might', 4),\n",
       " ('hardest', 4),\n",
       " ('hospitals', 4),\n",
       " ('spamming', 4),\n",
       " ('confronting', 4),\n",
       " ('😰', 4),\n",
       " ('Doing', 4),\n",
       " ('eventually', 4),\n",
       " ('cancel', 4),\n",
       " ('lunch', 4),\n",
       " ('begins', 4),\n",
       " ('greatest', 4),\n",
       " ('shout', 4),\n",
       " ('teenage', 4),\n",
       " ('salt', 4),\n",
       " ('liberate', 4),\n",
       " ('talent', 4),\n",
       " ('theater', 4),\n",
       " ('struggling', 4),\n",
       " ('allowing', 4),\n",
       " ('Tune', 4),\n",
       " ('sperm', 4),\n",
       " ('moms', 4),\n",
       " ('Horny', 4),\n",
       " ('liked', 4),\n",
       " ('communities', 4),\n",
       " ('apologize', 4),\n",
       " ('admit', 4),\n",
       " ('afraid', 4),\n",
       " ('recovered', 4),\n",
       " ('appointment', 4),\n",
       " ('LOL', 4),\n",
       " ('Somebody', 4),\n",
       " ('irresponsible', 4),\n",
       " ('COVID19Pandemic', 4),\n",
       " ('nose', 4),\n",
       " ('HIT', 4),\n",
       " ('stressed', 4),\n",
       " ('😋', 4),\n",
       " ('Yup', 4),\n",
       " ('sleeping', 4),\n",
       " ('busy', 4),\n",
       " ('pillow', 4),\n",
       " ('hella', 4),\n",
       " ('posting', 4),\n",
       " ('turns', 4),\n",
       " ('wins', 4),\n",
       " ('moves', 4),\n",
       " ('hurts', 4),\n",
       " ('THEY', 4),\n",
       " ('convo', 4),\n",
       " ('pronounced', 4),\n",
       " ('Lindsey', 4),\n",
       " ('exercise', 4),\n",
       " ('writingcommunity', 4),\n",
       " ('Giants', 4),\n",
       " ('libs', 4),\n",
       " ('otherwise', 4),\n",
       " ('AEW', 4),\n",
       " ('Cody', 4),\n",
       " ('Suite', 4),\n",
       " ('lesson', 4),\n",
       " ('souls', 4),\n",
       " ('Thoughts', 4),\n",
       " ('spreading', 4),\n",
       " ('planning', 4),\n",
       " ('decide', 4),\n",
       " ('HATE', 4),\n",
       " ('slapped', 4),\n",
       " ('giveaways', 4),\n",
       " ('mum', 4),\n",
       " ('wondering', 4),\n",
       " ('😅', 4),\n",
       " ('potential', 4),\n",
       " ('faster', 4),\n",
       " ('Raiders', 4),\n",
       " ('Ruggs', 4),\n",
       " ('Jeudy', 4),\n",
       " ('Lamb', 4),\n",
       " ('idiots', 4),\n",
       " ('tweeting', 4),\n",
       " ('VoteSafe', 4),\n",
       " ('polling', 4),\n",
       " ('→No', 4),\n",
       " ('absentee', 4),\n",
       " ('→At', 4),\n",
       " ('Voting', 4),\n",
       " ('fundamental', 4),\n",
       " ('REALLY', 4),\n",
       " ('🤣🤣🤣', 4),\n",
       " ('💔', 4),\n",
       " ('sake', 4),\n",
       " ('Pls', 4),\n",
       " ('Bears', 4),\n",
       " ('shaking', 4),\n",
       " ('toxic', 4),\n",
       " ('throughout', 4),\n",
       " ('impossible', 4),\n",
       " ('4th', 4),\n",
       " ('SpeakerPelosi', 4),\n",
       " ('Ozark', 4),\n",
       " ('Creek', 4),\n",
       " ('texts', 4),\n",
       " ('creators', 4),\n",
       " ('conspiracy', 4),\n",
       " ('customers', 4),\n",
       " ('goodbye', 4),\n",
       " ('shutdown', 4),\n",
       " ('fever', 4),\n",
       " ('recently', 4),\n",
       " ('couch', 4),\n",
       " ('Explain', 4),\n",
       " ('PPP', 4),\n",
       " ('sink', 4),\n",
       " ('assignment', 4),\n",
       " ('symptoms', 4),\n",
       " ('hopefully', 4),\n",
       " ('familiar', 4),\n",
       " ('💀', 4),\n",
       " ('Cowboys', 4),\n",
       " ('wanting', 4),\n",
       " ('positivity', 4),\n",
       " ('workout', 4),\n",
       " ('prepared', 4),\n",
       " ('peanut', 4),\n",
       " ('subscribers', 4),\n",
       " ('😈', 4),\n",
       " ('Walmart', 4),\n",
       " ('affection', 4),\n",
       " ('arguments', 4),\n",
       " ('streamer', 4),\n",
       " ('☀️', 4),\n",
       " ('depressed', 4),\n",
       " ('\\U0001f973', 4),\n",
       " ('receiving', 4),\n",
       " ('porn', 4),\n",
       " ('😉', 4),\n",
       " ('baseball', 4),\n",
       " ('strongly', 4),\n",
       " ('countries', 4),\n",
       " ('disapprove', 4),\n",
       " ('FCE', 4),\n",
       " ('protest', 4),\n",
       " ('Drew', 4),\n",
       " ('friday', 4),\n",
       " ('heroes', 4),\n",
       " ('NHS', 4),\n",
       " ('millions', 4),\n",
       " ('cleaned', 4),\n",
       " ('spit', 4),\n",
       " ('appearance', 4),\n",
       " ('BOY', 4),\n",
       " ('Titans', 4),\n",
       " ('WITH', 4),\n",
       " ('encourage', 4),\n",
       " ('😢', 4),\n",
       " ('burden', 4),\n",
       " ('😘', 4),\n",
       " ('Watching', 4),\n",
       " ('CashApp', 4),\n",
       " ('paycheck', 4),\n",
       " ('HUGE', 4),\n",
       " ('daddy', 4),\n",
       " ('records', 4),\n",
       " ('publicly', 4),\n",
       " ('Rona', 4),\n",
       " ('friendship', 4),\n",
       " ('caused', 4),\n",
       " ('brilliant', 4),\n",
       " ('supply', 4),\n",
       " ('several', 4),\n",
       " ('easily', 4),\n",
       " ('wedding', 4),\n",
       " ('StayAtHome', 4),\n",
       " ('😌', 4),\n",
       " ('hugged', 4),\n",
       " ('OANN', 4),\n",
       " ('Carolina', 4),\n",
       " ('combination', 4),\n",
       " ('remembered', 4),\n",
       " ('Welp', 4),\n",
       " ('horror', 4),\n",
       " ('serve', 4),\n",
       " ('invited', 4),\n",
       " ('breath', 4),\n",
       " ('hoping', 4),\n",
       " ('filing', 4),\n",
       " ('revive', 4),\n",
       " ('potato', 4),\n",
       " ('virologist', 4),\n",
       " ('puzzle', 4),\n",
       " ('proved', 4),\n",
       " ('taste', 4),\n",
       " ('EVERYONE', 4),\n",
       " ('companies', 4),\n",
       " ('regret', 4),\n",
       " ('provide', 4),\n",
       " ('Wish', 4),\n",
       " ('fandom', 4),\n",
       " ('imma', 4),\n",
       " ('chips', 4),\n",
       " ('gym', 4),\n",
       " ('OMG', 4),\n",
       " ('whilst', 4),\n",
       " ('Oprah', 4),\n",
       " ('heartbreaking', 4),\n",
       " ('kills', 4),\n",
       " ('replaced', 4),\n",
       " ('crack', 4),\n",
       " ('WENT', 4),\n",
       " ('BATHROOM', 4),\n",
       " ('HAD', 4),\n",
       " ('SWUM', 4),\n",
       " ('TOILET', 4),\n",
       " ('THOUGHT', 4),\n",
       " ('URBAN', 4),\n",
       " ('LEGEND', 4),\n",
       " ('MOVE', 4),\n",
       " ('nasty', 4),\n",
       " ('covid19', 4),\n",
       " ('restrictions', 4),\n",
       " ('tuned', 4),\n",
       " ('jail', 4),\n",
       " ('truck', 4),\n",
       " ('caught', 4),\n",
       " ('Apologies', 4),\n",
       " ('Lemme', 4),\n",
       " ('THANK', 4),\n",
       " ('fault', 4),\n",
       " ('divorce', 4),\n",
       " ('thick', 4),\n",
       " ('supporting', 4),\n",
       " ('cleaning', 4),\n",
       " ('Catch', 4),\n",
       " ('Fortnite', 4),\n",
       " ('joking', 4),\n",
       " ('whack', 4),\n",
       " ('artists', 4),\n",
       " ('nervous', 4),\n",
       " ('Drake', 4),\n",
       " ('discussed', 4),\n",
       " ('Newcastle', 4),\n",
       " ('😩', 4),\n",
       " ('exhausted', 4),\n",
       " ('WHEN', 4),\n",
       " ('Packers', 4),\n",
       " ('contest', 4),\n",
       " ('unemployed', 4),\n",
       " ('ideas', 4),\n",
       " ('germ', 4),\n",
       " ('hundred', 4),\n",
       " ('talked', 4),\n",
       " ('gimme', 4),\n",
       " ('receive', 4),\n",
       " ('opinions', 4),\n",
       " ('toes', 4),\n",
       " ('monthly', 4),\n",
       " ('twice', 4),\n",
       " ('realise', 4),\n",
       " ('warned', 4),\n",
       " ('comfortable', 4),\n",
       " ('Trout', 4),\n",
       " ('12k', 4),\n",
       " ('exciting', 4),\n",
       " ('😒', 4),\n",
       " ('cheated', 4),\n",
       " ('snow', 4),\n",
       " ('walked', 4),\n",
       " ('choices', 4),\n",
       " ('denied', 4),\n",
       " ('🎉', 4),\n",
       " ('ignoring', 4),\n",
       " ('SHIT', 4),\n",
       " ('considered', 4),\n",
       " ('😭😭😭', 4),\n",
       " ('😁', 4),\n",
       " ('drank', 4),\n",
       " ('Sierra', 4),\n",
       " ('pulp', 4),\n",
       " ('💰', 4),\n",
       " ('geng', 4),\n",
       " ('restaurants', 4),\n",
       " ('Boom', 4),\n",
       " ('carti', 3),\n",
       " ('dababy', 3),\n",
       " ('Indians', 3),\n",
       " ('😓', 3),\n",
       " ('crap', 3),\n",
       " ('hacker', 3),\n",
       " ('PHYSICALLY', 3),\n",
       " ('spam', 3),\n",
       " ('therapist', 3),\n",
       " ('plans', 3),\n",
       " ('apologise', 3),\n",
       " ('supportive', 3),\n",
       " ('kissed', 3),\n",
       " ('belongs', 3),\n",
       " ('spoilers', 3),\n",
       " ('hurtful', 3),\n",
       " ('lockdowns', 3),\n",
       " ('quarantining', 3),\n",
       " ('welcomed', 3),\n",
       " ('assume', 3),\n",
       " ('Rounds', 3),\n",
       " ...]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(unknown_text.items(), key=lambda d: d[1], reverse=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform more words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "more_apostrophes = {'cannot': \"can not\", 'gonna': \"go to\", 'wanna': \"want to\", 'coronavirus': \"COVID\", 'wanted': \"want\", 'weeks': \"week\", 'feeling': \"feel\", 'says': \"say\", 'yourself': \"your self\", 'saying': \"say\", 'says': \"say\", 'GIF': \"gif\", 'waiting': \"wait\", 'Covid': \"COVID\", 'hugs': \"hug\", 'gave': \"give\", 'COVID19': \"COVID\", 'installing': \"install\", 'wants': \"want\", 'knows': \"know\", 'describes': \"describe\", 'following': \"follow\", 'asked': \"ask\", 'amazing': \"amaze\", 'finally': \"final\", 'minutes': \"minute\", 'died': \"die\", 'tired': \"tire\", 'quickly': \"quick\", 'gotta': \"go to\", 'deaths': \"death\", 'means': \"mean\", 'took': \"take\", 'feels': \"feel\", 'fans': \"fan\", 'numbers': \"number\", 'lives': \"live\", 'safely': \"safe\", 'tried': \"try\", 'businesses': \"business\", '2nd': \"second\", 'decided': \"decide\", '3rd': \"third\", 'hates': \"hate\", 'dont': \"do not\", 'lonely': \"lone\", 'totally': \"total\", 'excited': \"excite\", 'BREAKING': \"break\", 'gifs': \"gif\", 'goes': \"go\", 'thoughts': \"thought\", 'campaigning': \"campaign\", 'immediately': \"immediate\", 'teammates': \"team mate\", 'knew': \"know\", 'politicians': \"politician\", 'distancing': \"distance\", 'reopening': \"reopen\", 'pls': \"please\", 'AGAIN': \"again\", 'tears': \"tear\", 'supposed': \"suppose\", 'loved': \"love\", 'ppl': \"people\", 'drinking': \"drink\", 'Guidelines': \"guide line\", 'losing': \"lose\", 'Conference': \"conference\", 'officially': \"official\", 'OPENING': \"open\", 'buying': \"buy\", 'Gif': \"gif\", 'looks': \"look\", 'bought': \"buy\", 'likes': \"like\", 'truely': \"true\", 'happened': \"happen\", 'putting': \"put\", 'families': \"family\", 'moved': \"move\", 'Raise': \"raise\", 'helped': \"help\", 'vibes': \"vibe\", 'voting': \"vote\", 'showed': \"show\", 'Instagram': \"instagram\", 'spent': \"spend\", 'watched': \"watch\", 'kinda': \"kind of\", 'Governor': \"governor\", 'Coronavirus': \"COVID\", 'lmao': \"laugh\", 'seems': \"seem\", 'staying': \"stay\", 'listening': \"listen\", 'accounts': \"account\"}\n",
    "def change_punc(text):\n",
    "    for key in more_apostrophes.keys():\n",
    "        text = text.replace(key, more_apostrophes[key])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.tokenize('guide lines')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['map_more_punc_text'] = df_train.map_punc_text.apply(change_punc)\n",
    "df_train['map_more_punc_reply'] = df_train.map_punc_reply.apply(change_punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev['map_more_punc_text'] = df_dev.map_punc_text.apply(change_punc)\n",
    "df_dev['map_more_punc_reply'] = df_dev.map_punc_reply.apply(change_punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['map_more_punc_text'] = df_test.map_punc_text.apply(change_punc)\n",
    "df_test['map_more_punc_reply'] = df_test.map_punc_reply.apply(change_punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train text unique vocab count is: 46010\n",
      "train reply unique vocab count is: 18481\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=46010.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 13.488% (6206 / 46010) of vocab\n",
      "Found embeddings for 81.730% (658910 / 806199) of all text\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=18481.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 22.066% (4078 / 18481) of vocab\n",
      "Found embeddings for 80.666% (111902 / 138723) of all text\n"
     ]
    }
   ],
   "source": [
    "train_text_vocab = get_vocab(df_train['map_more_punc_text'].values)\n",
    "train_reply_vocab = get_vocab(df_train['map_more_punc_reply'].values)\n",
    "print(\"train text unique vocab count is: {}\".format(len(train_text_vocab)))\n",
    "print(\"train reply unique vocab count is: {}\".format(len(train_reply_vocab)))\n",
    "print()\n",
    "\n",
    "unknown_text = check_coverage(train_text_vocab, roberta_vocab)\n",
    "print()\n",
    "unknown_reply = check_coverage(train_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev text unique vocab count is: 13257\n",
      "dev reply unique vocab count is: 4415\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=13257.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 26.869% (3562 / 13257) of vocab\n",
      "Found embeddings for 81.635% (83471 / 102249) of all text\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=4415.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 37.531% (1657 / 4415) of vocab\n",
      "Found embeddings for 79.735% (14035 / 17602) of all text\n"
     ]
    }
   ],
   "source": [
    "dev_text_vocab = get_vocab(df_dev['map_more_punc_text'].values)\n",
    "dev_reply_vocab = get_vocab(df_dev['map_more_punc_reply'].values)\n",
    "print(\"dev text unique vocab count is: {}\".format(len(dev_text_vocab)))\n",
    "print(\"dev reply unique vocab count is: {}\".format(len(dev_reply_vocab)))\n",
    "unknown_text = check_coverage(dev_text_vocab, roberta_vocab)\n",
    "print()\n",
    "unknown_reply = check_coverage(dev_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test text unique vocab count is: 13076\n",
      "test reply unique vocab count is: 4209\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=13076.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 27.432% (3587 / 13076) of vocab\n",
      "Found embeddings for 81.643% (81863 / 100269) of all text\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=4209.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 39.796% (1675 / 4209) of vocab\n",
      "Found embeddings for 80.731% (13734 / 17012) of all text\n"
     ]
    }
   ],
   "source": [
    "test_text_vocab = get_vocab(df_test['map_more_punc_text'].values)\n",
    "test_reply_vocab = get_vocab(df_test['map_more_punc_reply'].values)\n",
    "print(\"test text unique vocab count is: {}\".format(len(test_text_vocab)))\n",
    "print(\"test reply unique vocab count is: {}\".format(len(test_reply_vocab)))\n",
    "unknown_text = check_coverage(test_text_vocab, roberta_vocab)\n",
    "print()\n",
    "unknown_reply = check_coverage(test_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('COVID', 158),\n",
       " ('hug', 120),\n",
       " ('quarantine', 68),\n",
       " ('tonight', 64),\n",
       " ('myself', 58),\n",
       " ('Biden', 52),\n",
       " ('reaction', 48),\n",
       " ('tomorrow', 47),\n",
       " ('fucking', 43),\n",
       " ('Pelosi', 42),\n",
       " ('Nancy', 40),\n",
       " ('hear', 39),\n",
       " ('guys', 39),\n",
       " ('Oz', 39),\n",
       " ('anyone', 39),\n",
       " ('believe', 37),\n",
       " ('trying', 36),\n",
       " ('followers', 36),\n",
       " ('tweet', 36),\n",
       " ('lockdown', 36),\n",
       " ('least', 35),\n",
       " ('sad', 34),\n",
       " ('hope', 34),\n",
       " ('birthday', 33),\n",
       " ('anymore', 33),\n",
       " ('economy', 31),\n",
       " ('whole', 30),\n",
       " ('virus', 29),\n",
       " ('already', 28),\n",
       " ('pandemic', 27),\n",
       " ('hashtag', 26),\n",
       " ('beautiful', 26),\n",
       " ('dinner', 26),\n",
       " ('decide', 25),\n",
       " ('wish', 25),\n",
       " ('weekend', 24),\n",
       " ('BailoutHumansNow', 24),\n",
       " ('politician', 24),\n",
       " ('dependable', 24),\n",
       " ('forget', 24),\n",
       " ('😂', 24),\n",
       " ('spend', 24),\n",
       " ('ScottyFromMarketing', 23),\n",
       " ('❤️', 23),\n",
       " ('🤔', 23),\n",
       " ('honest', 23),\n",
       " ('career', 23),\n",
       " ('happen', 23),\n",
       " ('dick', 22),\n",
       " ('explain', 22),\n",
       " ('reopen', 21),\n",
       " ('amaze', 21),\n",
       " ('tire', 21),\n",
       " ('Crazy', 21),\n",
       " ('sick', 20),\n",
       " ('suck', 20),\n",
       " ('thankful', 20),\n",
       " ('horny', 20),\n",
       " ('Guys', 20),\n",
       " ('listen', 19),\n",
       " ('\\U0001f97a', 19),\n",
       " ('😭', 19),\n",
       " ('seanhannity', 19),\n",
       " ('Radical', 19),\n",
       " ('WritingCommunity', 19),\n",
       " ('Cuomo', 19),\n",
       " ('moment', 19),\n",
       " ('defeated', 18),\n",
       " ('😊', 18),\n",
       " ('pathetic', 18),\n",
       " ('stimulus', 18),\n",
       " ('idea', 17),\n",
       " ('supporter', 17),\n",
       " ('crisis', 17),\n",
       " ('excite', 17),\n",
       " ('incompetent', 17),\n",
       " ('puppet', 17),\n",
       " ('describe', 17),\n",
       " ('giveaway', 17),\n",
       " ('guess', 17),\n",
       " ('governor', 17),\n",
       " ('came', 16),\n",
       " ('awesome', 16),\n",
       " ('become', 16),\n",
       " ('😔', 16),\n",
       " ('stupid', 16),\n",
       " ('bitch', 16),\n",
       " ('AMERICA', 16),\n",
       " ('lone', 16),\n",
       " ('woke', 15),\n",
       " ('Gates', 15),\n",
       " ('fucked', 15),\n",
       " ('damn', 15),\n",
       " ('suppose', 15),\n",
       " ('cares', 15),\n",
       " ('trash', 14),\n",
       " ('cute', 14),\n",
       " ('meeting', 14),\n",
       " ('socialist', 14),\n",
       " ('others', 14),\n",
       " ('LIBERATE', 14),\n",
       " ('Nathaniel', 14),\n",
       " ('sitting', 14),\n",
       " ('mood', 14),\n",
       " ('tear', 14),\n",
       " ('ugly', 14),\n",
       " ('understand', 14),\n",
       " ('deserve', 14),\n",
       " ('proud', 13),\n",
       " ('worse', 13),\n",
       " ('yall', 13),\n",
       " ('marry', 13),\n",
       " ('longer', 13),\n",
       " ('ensure', 13),\n",
       " ('corona', 13),\n",
       " ('anxiety', 13),\n",
       " ('folks', 13),\n",
       " ('realize', 13),\n",
       " ('tweets', 13),\n",
       " ('6pm', 13),\n",
       " ('🙃', 13),\n",
       " ('stopped', 13),\n",
       " ('Vaccine', 12),\n",
       " ('coffee', 12),\n",
       " ('pizza', 12),\n",
       " ('decision', 12),\n",
       " ('billionaire', 12),\n",
       " ('afford', 12),\n",
       " ('questions…', 12),\n",
       " ('attention', 12),\n",
       " ('questions', 12),\n",
       " ('appreciate', 12),\n",
       " ('thousands', 12),\n",
       " ('funny', 12),\n",
       " ('drink', 12),\n",
       " ('covid', 12),\n",
       " ('approval', 12),\n",
       " ('students', 12),\n",
       " ('entire', 12),\n",
       " ('complaining', 12),\n",
       " ('truly', 12),\n",
       " ('thinks', 12),\n",
       " ('experience', 11),\n",
       " ('wearing', 11),\n",
       " ('grateful', 11),\n",
       " ('VIRGINIA', 11),\n",
       " ('Amendment', 11),\n",
       " ('siege', 11),\n",
       " ('scared', 11),\n",
       " ('DMs', 11),\n",
       " ('replies', 11),\n",
       " ('handling', 11),\n",
       " ('Dollar', 11),\n",
       " ('streaming', 11),\n",
       " ('possible', 11),\n",
       " ('nobody', 11),\n",
       " ('\\U0001f974', 11),\n",
       " ('boyfriend', 11),\n",
       " ('crying', 11),\n",
       " ('Ventilators', 11),\n",
       " ('leadership', 11),\n",
       " ('😳', 11),\n",
       " ('1st', 11),\n",
       " ('across', 11),\n",
       " ('couple', 11),\n",
       " ('lil', 10),\n",
       " ('everyday', 10),\n",
       " ('kindness', 10),\n",
       " ('relationship', 10),\n",
       " ('conversation', 10),\n",
       " ('sister', 10),\n",
       " ('definitely', 10),\n",
       " ('forever', 10),\n",
       " ('ventilators', 10),\n",
       " ('passed', 10),\n",
       " ('THAT', 10),\n",
       " ('summer', 10),\n",
       " ('disaster', 10),\n",
       " ('H1N1', 10),\n",
       " ('Swine', 10),\n",
       " ('Flu', 10),\n",
       " ('Polling', 10),\n",
       " ('disastrous', 10),\n",
       " ('unnecessarily', 10),\n",
       " ('incompetence', 10),\n",
       " ('Billion', 10),\n",
       " ('Obamacare', 10),\n",
       " ('website', 10),\n",
       " ('excuse', 10),\n",
       " ('randomly', 10),\n",
       " ('cuz', 10),\n",
       " ('😂😂😂', 10),\n",
       " ('themselves', 10),\n",
       " ('realized', 10),\n",
       " ('opinion', 10),\n",
       " ('5k', 10),\n",
       " ('biggest', 9),\n",
       " ('laughing', 9),\n",
       " ('sucking', 9),\n",
       " ('taken', 9),\n",
       " ('hurt', 9),\n",
       " ('himself', 9),\n",
       " ('situation', 9),\n",
       " ('patients', 9),\n",
       " ('vibe', 9),\n",
       " ('👀', 9),\n",
       " ('choose', 9),\n",
       " ('therapy', 9),\n",
       " ('awful', 9),\n",
       " ('😭😭', 9),\n",
       " ('difference', 9),\n",
       " ('Idk', 9),\n",
       " ('drunk', 9),\n",
       " ('weird', 9),\n",
       " ('🙄', 9),\n",
       " ('wonder', 9),\n",
       " ('honestly', 9),\n",
       " ('NEED', 9),\n",
       " ('showing', 9),\n",
       " ('cheese', 9),\n",
       " ('okay', 9),\n",
       " ('expansive', 9),\n",
       " ('accurate', 9),\n",
       " ('reminds', 9),\n",
       " ('angry', 9),\n",
       " ('dude', 9),\n",
       " ('helping', 9),\n",
       " ('worry', 9),\n",
       " ('shower', 9),\n",
       " ('seriously', 9),\n",
       " ('unemployment', 9),\n",
       " ('retweet', 9),\n",
       " ('grocery', 9),\n",
       " ('pregnant', 9),\n",
       " ('idk', 8),\n",
       " ('leaving', 8),\n",
       " ('announce', 8),\n",
       " ('celebrate', 8),\n",
       " ('takes', 8),\n",
       " ('depression', 8),\n",
       " ('sugar', 8),\n",
       " ('11am', 8),\n",
       " ('broke', 8),\n",
       " ('advice', 8),\n",
       " ('nigga', 8),\n",
       " ('learned', 8),\n",
       " ('7th', 8),\n",
       " ('sucks', 8),\n",
       " ('bout', 8),\n",
       " ('Frequently', 8),\n",
       " ('opportunity', 8),\n",
       " ('LIKE', 8),\n",
       " ('finish', 8),\n",
       " ('cheating', 8),\n",
       " ('instagram', 8),\n",
       " ('partner', 8),\n",
       " ('→', 8),\n",
       " ('heaven', 8),\n",
       " ('attempt', 8),\n",
       " ('LOVE', 8),\n",
       " ('chill', 8),\n",
       " ('💕', 8),\n",
       " ('beds', 8),\n",
       " ('causing', 8),\n",
       " ('funeral', 8),\n",
       " ('MUCH', 8),\n",
       " ('pray', 8),\n",
       " ('enjoy', 8),\n",
       " ('teacher', 8),\n",
       " ('additional', 8),\n",
       " ('approve', 8),\n",
       " ('dying', 8),\n",
       " ('✅', 8),\n",
       " ('welcome', 8),\n",
       " ('HAVE', 8),\n",
       " ('🤝', 8),\n",
       " ('terrible', 8),\n",
       " ('keeps', 8),\n",
       " ('FollowFriday', 8),\n",
       " ('governors', 8),\n",
       " ('relief', 8),\n",
       " ('idiot', 8),\n",
       " ('lose', 8),\n",
       " ('apartment', 8),\n",
       " ('upset', 8),\n",
       " ('sounds', 7),\n",
       " ('kitchen', 7),\n",
       " ('messages', 7),\n",
       " ('OldRich', 7),\n",
       " ('tells', 7),\n",
       " ('joke', 7),\n",
       " ('NYC', 7),\n",
       " ('sending', 7),\n",
       " ('alive', 7),\n",
       " ('ONLY', 7),\n",
       " ('covering', 7),\n",
       " ('dear', 7),\n",
       " ('dropped', 7),\n",
       " ('treating', 7),\n",
       " ('calls', 7),\n",
       " ('slid', 7),\n",
       " ('sauce', 7),\n",
       " ('stuck', 7),\n",
       " ('Lebron', 7),\n",
       " ('masks', 7),\n",
       " ('Genuinely', 7),\n",
       " ('Rashford', 7),\n",
       " ('clothes', 7),\n",
       " ('lately', 7),\n",
       " ('fraud', 7),\n",
       " ('discussion', 7),\n",
       " ('harder', 7),\n",
       " ('herself', 7),\n",
       " ('lucky', 7),\n",
       " ('incredibly', 7),\n",
       " ('expect', 7),\n",
       " ('glad', 7),\n",
       " ('RETWEET', 7),\n",
       " ('Zoom', 7),\n",
       " ('disgusting', 7),\n",
       " ('TESTING', 7),\n",
       " ('exam', 7),\n",
       " ('yours', 7),\n",
       " ('Been', 7),\n",
       " ('turning', 7),\n",
       " ('Birthday', 7),\n",
       " ('loves', 7),\n",
       " ('comedy', 7),\n",
       " ('evening', 7),\n",
       " ('complain', 7),\n",
       " ('waste', 7),\n",
       " ('songs', 7),\n",
       " ('afternoon', 7),\n",
       " ('QUARANTINE', 7),\n",
       " ('EVER', 7),\n",
       " ('FUCK', 7),\n",
       " ('slide', 7),\n",
       " ('apparently', 7),\n",
       " ('barely', 7),\n",
       " ('officials', 7),\n",
       " ('Respond', 7),\n",
       " ('\\U0001f970', 7),\n",
       " ('immediate', 7),\n",
       " ('heavily', 7),\n",
       " ('awake', 7),\n",
       " ('blocked', 7),\n",
       " ('sexy', 7),\n",
       " ('clearly', 7),\n",
       " ('problems', 7),\n",
       " ('pics', 7),\n",
       " ('funds', 7),\n",
       " ('meme', 7),\n",
       " ('annoying', 7),\n",
       " ('KNOW', 7),\n",
       " ('appreciated', 7),\n",
       " ('seem', 7),\n",
       " ('surprise', 7),\n",
       " ('🔑', 7),\n",
       " ('niggas', 6),\n",
       " ('everybody', 6),\n",
       " ('nightmare', 6),\n",
       " ('judging', 6),\n",
       " ('judgement', 6),\n",
       " ('HUNGRY', 6),\n",
       " ('worried', 6),\n",
       " ('yesterday', 6),\n",
       " ('denies', 6),\n",
       " ('extent', 6),\n",
       " ('outbreak', 6),\n",
       " ('smh', 6),\n",
       " ('extend', 6),\n",
       " ('lovely', 6),\n",
       " ('expecting', 6),\n",
       " ('Minister', 6),\n",
       " ('committed', 6),\n",
       " ('communist', 6),\n",
       " ('isolation', 6),\n",
       " ('shitty', 6),\n",
       " ('interview', 6),\n",
       " ('dangerous', 6),\n",
       " ('retweets', 6),\n",
       " ('difficult', 6),\n",
       " ('😪', 6),\n",
       " ('amwriting', 6),\n",
       " ('Neymar', 6),\n",
       " ('starts', 6),\n",
       " ('senior', 6),\n",
       " ('makeup', 6),\n",
       " ('personally', 6),\n",
       " ('pictures', 6),\n",
       " ('experts', 6),\n",
       " ('lowkey', 6),\n",
       " ('dumb', 6),\n",
       " ('fellow', 6),\n",
       " ('fear', 6),\n",
       " ('blessed', 6),\n",
       " ('university', 6),\n",
       " ('Cassper', 6),\n",
       " ('survive', 6),\n",
       " ('thousand', 6),\n",
       " ('crush', 6),\n",
       " ('viewers', 6),\n",
       " ('Bailout', 6),\n",
       " ('Humans', 6),\n",
       " ('MUST', 6),\n",
       " ('Shout', 6),\n",
       " ('🤣', 6),\n",
       " ('Quarantine', 6),\n",
       " ('Vikings', 6),\n",
       " ('scary', 6),\n",
       " ('groceries', 6),\n",
       " ('visit', 6),\n",
       " ('Lol', 6),\n",
       " ('strategy', 6),\n",
       " ('supporters', 6),\n",
       " ('gift', 6),\n",
       " ('breakfast', 6),\n",
       " ('suddenly', 6),\n",
       " ('miles', 6),\n",
       " ('voted', 6),\n",
       " ('ventilator', 6),\n",
       " ('unprecedented', 6),\n",
       " ('follows', 6),\n",
       " ('bunch', 6),\n",
       " ('vaccine', 6),\n",
       " ('chocolate', 6),\n",
       " ('cuddle', 6),\n",
       " ('missed', 6),\n",
       " ('employees', 6),\n",
       " ('possibility', 6),\n",
       " ('CoronaVirus', 6),\n",
       " ('Democrat', 6),\n",
       " ('asleep', 6),\n",
       " ('POTUS', 6),\n",
       " ('appointing', 6),\n",
       " ('pussy', 6),\n",
       " ('promise', 6),\n",
       " ('RIGHT', 6),\n",
       " ('boobs', 6),\n",
       " ('WAS', 6),\n",
       " ('Guess', 6),\n",
       " ('notifications', 6),\n",
       " ('tough', 6),\n",
       " ('dance', 6),\n",
       " ('COVIDLiar', 6),\n",
       " ('spirits', 6),\n",
       " ('👏🏼', 6),\n",
       " ('discussing', 5),\n",
       " ('wtf', 5),\n",
       " ('cried', 5),\n",
       " ('hacked', 5),\n",
       " ('replying', 5),\n",
       " ('attacked', 5),\n",
       " ('stupidity', 5),\n",
       " ('hiding', 5),\n",
       " ('prepare', 5),\n",
       " ('transition', 5),\n",
       " ('till', 5),\n",
       " ('Govt', 5),\n",
       " ('wonderful', 5),\n",
       " ('😐', 5),\n",
       " ('tbh', 5),\n",
       " ('fridge', 5),\n",
       " ('Parliament', 5),\n",
       " ('signs', 5),\n",
       " ('spending', 5),\n",
       " ('ridiculous', 5),\n",
       " ('memories', 5),\n",
       " ('debate', 5),\n",
       " ('happiness', 5),\n",
       " ('Feeling', 5),\n",
       " ('sober', 5),\n",
       " ('meetings', 5),\n",
       " ('hits', 5),\n",
       " ('prayers', 5),\n",
       " ('disease', 5),\n",
       " ('mention', 5),\n",
       " ('somebody', 5),\n",
       " ('☺️', 5),\n",
       " ('drinks', 5),\n",
       " ('compassion', 5),\n",
       " ('Zack', 5),\n",
       " ('teams', 5),\n",
       " ('WILL', 5),\n",
       " ('BABY', 5),\n",
       " ('remain', 5),\n",
       " ('hearing', 5),\n",
       " ('huh', 5),\n",
       " ('Fauci', 5),\n",
       " ('boring', 5),\n",
       " ('waking', 5),\n",
       " ('doctors', 5),\n",
       " ('slowly', 5),\n",
       " ('expand', 5),\n",
       " ('cancelled', 5),\n",
       " ('Trey', 5),\n",
       " ('Burton', 5),\n",
       " ('cant', 5),\n",
       " ('selecting', 5),\n",
       " ('donate', 5),\n",
       " ('win💰', 5),\n",
       " ('plenty', 5),\n",
       " ('laid', 5),\n",
       " ('journey', 5),\n",
       " ('peaceful', 5),\n",
       " ('beach', 5),\n",
       " ('apeopley', 5),\n",
       " ('mutuals', 5),\n",
       " ('anywhere', 5),\n",
       " ('choked', 5),\n",
       " ('homes', 5),\n",
       " ('🙏', 5),\n",
       " ('cough', 5),\n",
       " ('bipartisan', 5),\n",
       " ('🇺🇸', 5),\n",
       " ('desk', 5),\n",
       " ('doubling', 5),\n",
       " ('Invisible', 5),\n",
       " ('Enemy', 5),\n",
       " ('concerned', 5),\n",
       " ('YOUR', 5),\n",
       " ('WHY', 5),\n",
       " ('bitches', 5),\n",
       " ('challenge', 5),\n",
       " ('butter', 5),\n",
       " ('shoes', 5),\n",
       " ('10k', 5),\n",
       " ('GOOD', 5),\n",
       " ('pounds', 5),\n",
       " ('FIRST', 5),\n",
       " ('loud', 5),\n",
       " ('loan', 5),\n",
       " ('tiktok', 5),\n",
       " ('dudes', 5),\n",
       " ('streets', 5),\n",
       " ('timeline', 5),\n",
       " ('freak', 5),\n",
       " ('haircut', 5),\n",
       " ('garden', 5),\n",
       " ('selfie', 5),\n",
       " ('DrOz', 5),\n",
       " ('imagine', 5),\n",
       " ('entering', 5),\n",
       " ('Dems', 5),\n",
       " ('realizing', 5),\n",
       " ('liquor', 5),\n",
       " ('RAT', 5),\n",
       " ('guest', 5),\n",
       " ('HIM', 5),\n",
       " ('rally', 5),\n",
       " ('naked', 5),\n",
       " ('horrible', 5),\n",
       " ('Retweet', 5),\n",
       " ('movies', 5),\n",
       " ('shopping', 5),\n",
       " ('roof', 5),\n",
       " ('Verge', 5),\n",
       " ('consistently', 5),\n",
       " ('mistake', 5),\n",
       " ('suspect', 5),\n",
       " ('furloughed', 5),\n",
       " ('writerslift', 5),\n",
       " ('milk', 5),\n",
       " ('leaves', 5),\n",
       " ('everywhere', 5),\n",
       " ('followed', 5),\n",
       " ('govt', 5),\n",
       " ('LikewiseApp', 5),\n",
       " ('Yay', 5),\n",
       " ('infected', 5),\n",
       " ('attend', 5),\n",
       " ('Lockdown', 5),\n",
       " ('simply', 5),\n",
       " ('boo', 5),\n",
       " ('✨', 5),\n",
       " ('juliemac1000', 5),\n",
       " ('Congressional', 5),\n",
       " ('lawyer', 5),\n",
       " ('payments', 5),\n",
       " ('bored', 5),\n",
       " ('OKAY', 5),\n",
       " ('TODAY', 5),\n",
       " ('happens', 5),\n",
       " ('screenshot', 5),\n",
       " ('Uncle', 5),\n",
       " ('2021', 5),\n",
       " ('interact', 5),\n",
       " ('saved', 5),\n",
       " ('fuckin', 5),\n",
       " ('murder', 5),\n",
       " ('nursing', 5),\n",
       " ('jumping', 5),\n",
       " ('Wuhan', 5),\n",
       " ('teach', 5),\n",
       " ('memes', 5),\n",
       " ('swear', 5),\n",
       " ('cheer', 5),\n",
       " ('earlier', 5),\n",
       " ('apeopleause', 5),\n",
       " ('younger', 5),\n",
       " ('😔😔', 5),\n",
       " ('neighbor', 5),\n",
       " ('pushing', 5),\n",
       " ('WOW', 5),\n",
       " ('Kanye', 5),\n",
       " ('bills', 5),\n",
       " ('eggs', 5),\n",
       " ('tho', 5),\n",
       " ('sisters', 5),\n",
       " ('Couldn', 5),\n",
       " ('Lawrence', 5),\n",
       " ('sacrifice', 5),\n",
       " ('trading', 4),\n",
       " ('Might', 4),\n",
       " ('hardest', 4),\n",
       " ('hospitals', 4),\n",
       " ('spamming', 4),\n",
       " ('confronting', 4),\n",
       " ('😰', 4),\n",
       " ('Doing', 4),\n",
       " ('eventually', 4),\n",
       " ('cancel', 4),\n",
       " ('lunch', 4),\n",
       " ('begins', 4),\n",
       " ('greatest', 4),\n",
       " ('shout', 4),\n",
       " ('teenage', 4),\n",
       " ('salt', 4),\n",
       " ('liberate', 4),\n",
       " ('talent', 4),\n",
       " ('theater', 4),\n",
       " ('struggling', 4),\n",
       " ('allowing', 4),\n",
       " ('Tune', 4),\n",
       " ('sperm', 4),\n",
       " ('moms', 4),\n",
       " ('Horny', 4),\n",
       " ('liked', 4),\n",
       " ('communities', 4),\n",
       " ('apologize', 4),\n",
       " ('admit', 4),\n",
       " ('afraid', 4),\n",
       " ('recovered', 4),\n",
       " ('appointment', 4),\n",
       " ('LOL', 4),\n",
       " ('Somebody', 4),\n",
       " ('irresponsible', 4),\n",
       " ('COVIDPandemic', 4),\n",
       " ('nose', 4),\n",
       " ('HIT', 4),\n",
       " ('stressed', 4),\n",
       " ('😋', 4),\n",
       " ('Yup', 4),\n",
       " ('sleeping', 4),\n",
       " ('busy', 4),\n",
       " ('pillow', 4),\n",
       " ('hella', 4),\n",
       " ('posting', 4),\n",
       " ('turns', 4),\n",
       " ('wins', 4),\n",
       " ('moves', 4),\n",
       " ('hurts', 4),\n",
       " ('THEY', 4),\n",
       " ('convo', 4),\n",
       " ('pronounced', 4),\n",
       " ('Lindsey', 4),\n",
       " ('exercise', 4),\n",
       " ('writingcommunity', 4),\n",
       " ('Giants', 4),\n",
       " ('libs', 4),\n",
       " ('otherwise', 4),\n",
       " ('AEW', 4),\n",
       " ('Cody', 4),\n",
       " ('Suite', 4),\n",
       " ('lesson', 4),\n",
       " ('souls', 4),\n",
       " ('Thoughts', 4),\n",
       " ('spreading', 4),\n",
       " ('planning', 4),\n",
       " ('HATE', 4),\n",
       " ('slapped', 4),\n",
       " ('giveaways', 4),\n",
       " ('mum', 4),\n",
       " ('wondering', 4),\n",
       " ('😅', 4),\n",
       " ('potential', 4),\n",
       " ('faster', 4),\n",
       " ('Raiders', 4),\n",
       " ('Ruggs', 4),\n",
       " ('Jeudy', 4),\n",
       " ('Lamb', 4),\n",
       " ('idiots', 4),\n",
       " ('tweeting', 4),\n",
       " ('VoteSafe', 4),\n",
       " ('polling', 4),\n",
       " ('→No', 4),\n",
       " ('absentee', 4),\n",
       " ('→At', 4),\n",
       " ('Voting', 4),\n",
       " ('fundamental', 4),\n",
       " ('REALLY', 4),\n",
       " ('🤣🤣🤣', 4),\n",
       " ('💔', 4),\n",
       " ('sake', 4),\n",
       " ('Pls', 4),\n",
       " ('Bears', 4),\n",
       " ('shaking', 4),\n",
       " ('toxic', 4),\n",
       " ('throughout', 4),\n",
       " ('impossible', 4),\n",
       " ('4th', 4),\n",
       " ('SpeakerPelosi', 4),\n",
       " ('Ozark', 4),\n",
       " ('Creek', 4),\n",
       " ('texts', 4),\n",
       " ('creators', 4),\n",
       " ('conspiracy', 4),\n",
       " ('customers', 4),\n",
       " ('goodbye', 4),\n",
       " ('shutdown', 4),\n",
       " ('fever', 4),\n",
       " ('recently', 4),\n",
       " ('couch', 4),\n",
       " ('Explain', 4),\n",
       " ('PPP', 4),\n",
       " ('sink', 4),\n",
       " ('assignment', 4),\n",
       " ('symptoms', 4),\n",
       " ('hopefully', 4),\n",
       " ('familiar', 4),\n",
       " ('💀', 4),\n",
       " ('Cowboys', 4),\n",
       " ('wanting', 4),\n",
       " ('positivity', 4),\n",
       " ('workout', 4),\n",
       " ('prepared', 4),\n",
       " ('peanut', 4),\n",
       " ('subscribers', 4),\n",
       " ('😈', 4),\n",
       " ('Walmart', 4),\n",
       " ('affection', 4),\n",
       " ('arguments', 4),\n",
       " ('streamer', 4),\n",
       " ('☀️', 4),\n",
       " ('depressed', 4),\n",
       " ('\\U0001f973', 4),\n",
       " ('receiving', 4),\n",
       " ('porn', 4),\n",
       " ('😉', 4),\n",
       " ('baseball', 4),\n",
       " ('strongly', 4),\n",
       " ('countries', 4),\n",
       " ('disapprove', 4),\n",
       " ('FCE', 4),\n",
       " ('protest', 4),\n",
       " ('Drew', 4),\n",
       " ('friday', 4),\n",
       " ('heroes', 4),\n",
       " ('NHS', 4),\n",
       " ('millions', 4),\n",
       " ('cleaned', 4),\n",
       " ('spit', 4),\n",
       " ('appearance', 4),\n",
       " ('BOY', 4),\n",
       " ('Titans', 4),\n",
       " ('WITH', 4),\n",
       " ('encourage', 4),\n",
       " ('😢', 4),\n",
       " ('burden', 4),\n",
       " ('😘', 4),\n",
       " ('Watching', 4),\n",
       " ('CashApp', 4),\n",
       " ('paycheck', 4),\n",
       " ('HUGE', 4),\n",
       " ('daddy', 4),\n",
       " ('records', 4),\n",
       " ('publicly', 4),\n",
       " ('Rona', 4),\n",
       " ('friendship', 4),\n",
       " ('caused', 4),\n",
       " ('brilliant', 4),\n",
       " ('supeopley', 4),\n",
       " ('several', 4),\n",
       " ('easily', 4),\n",
       " ('wedding', 4),\n",
       " ('StayAtHome', 4),\n",
       " ('😌', 4),\n",
       " ('hugged', 4),\n",
       " ('OANN', 4),\n",
       " ('Carolina', 4),\n",
       " ('combination', 4),\n",
       " ('remembered', 4),\n",
       " ('Welp', 4),\n",
       " ('horror', 4),\n",
       " ('serve', 4),\n",
       " ('invited', 4),\n",
       " ('breath', 4),\n",
       " ('hoping', 4),\n",
       " ('filing', 4),\n",
       " ('revive', 4),\n",
       " ('potato', 4),\n",
       " ('virologist', 4),\n",
       " ('puzzle', 4),\n",
       " ('proved', 4),\n",
       " ('taste', 4),\n",
       " ('EVERYONE', 4),\n",
       " ('companies', 4),\n",
       " ('regret', 4),\n",
       " ('provide', 4),\n",
       " ('Wish', 4),\n",
       " ('fandom', 4),\n",
       " ('imma', 4),\n",
       " ('chips', 4),\n",
       " ('gym', 4),\n",
       " ('OMG', 4),\n",
       " ('whilst', 4),\n",
       " ('Oprah', 4),\n",
       " ('heartbreaking', 4),\n",
       " ('kills', 4),\n",
       " ('replaced', 4),\n",
       " ('crack', 4),\n",
       " ('WENT', 4),\n",
       " ('BATHROOM', 4),\n",
       " ('HAD', 4),\n",
       " ('SWUM', 4),\n",
       " ('TOILET', 4),\n",
       " ('THOUGHT', 4),\n",
       " ('URBAN', 4),\n",
       " ('LEGEND', 4),\n",
       " ('MOVE', 4),\n",
       " ('nasty', 4),\n",
       " ('covid19', 4),\n",
       " ('restrictions', 4),\n",
       " ('tuned', 4),\n",
       " ('jail', 4),\n",
       " ('truck', 4),\n",
       " ('caught', 4),\n",
       " ('Apologies', 4),\n",
       " ('Lemme', 4),\n",
       " ('THANK', 4),\n",
       " ('fault', 4),\n",
       " ('divorce', 4),\n",
       " ('thick', 4),\n",
       " ('supporting', 4),\n",
       " ('cleaning', 4),\n",
       " ('Catch', 4),\n",
       " ('Fortnite', 4),\n",
       " ('joking', 4),\n",
       " ('whack', 4),\n",
       " ('artists', 4),\n",
       " ('nervous', 4),\n",
       " ('Drake', 4),\n",
       " ('discussed', 4),\n",
       " ('Newcastle', 4),\n",
       " ('😩', 4),\n",
       " ('exhausted', 4),\n",
       " ('WHEN', 4),\n",
       " ('Packers', 4),\n",
       " ('contest', 4),\n",
       " ('unemployed', 4),\n",
       " ('ideas', 4),\n",
       " ('germ', 4),\n",
       " ('hundred', 4),\n",
       " ('talked', 4),\n",
       " ('gimme', 4),\n",
       " ('receive', 4),\n",
       " ('opinions', 4),\n",
       " ('toes', 4),\n",
       " ('monthly', 4),\n",
       " ('twice', 4),\n",
       " ('realise', 4),\n",
       " ('warned', 4),\n",
       " ('Apeoplee', 4),\n",
       " ('comfortable', 4),\n",
       " ('Trout', 4),\n",
       " ('12k', 4),\n",
       " ('exciting', 4),\n",
       " ('😒', 4),\n",
       " ('cheated', 4),\n",
       " ('snow', 4),\n",
       " ('walked', 4),\n",
       " ('choices', 4),\n",
       " ('denied', 4),\n",
       " ('🎉', 4),\n",
       " ('ignoring', 4),\n",
       " ('SHIT', 4),\n",
       " ('considered', 4),\n",
       " ('😭😭😭', 4),\n",
       " ('😁', 4),\n",
       " ('drank', 4),\n",
       " ('Sierra', 4),\n",
       " ('pulp', 4),\n",
       " ('💰', 4),\n",
       " ('geng', 4),\n",
       " ('restaurants', 4),\n",
       " ('Boom', 4),\n",
       " ('carti', 3),\n",
       " ('dababy', 3),\n",
       " ('Indians', 3),\n",
       " ('😓', 3),\n",
       " ('crap', 3),\n",
       " ('hacker', 3),\n",
       " ('PHYSICALLY', 3),\n",
       " ('spam', 3),\n",
       " ('therapist', 3),\n",
       " ('plans', 3),\n",
       " ('apologise', 3),\n",
       " ('supportive', 3),\n",
       " ('kissed', 3),\n",
       " ('belongs', 3),\n",
       " ('spoilers', 3),\n",
       " ('hurtful', 3),\n",
       " ('lockdowns', 3),\n",
       " ('quarantining', 3),\n",
       " ('welcomed', 3),\n",
       " ('assume', 3),\n",
       " ('Rounds', 3),\n",
       " ('negotiations', 3),\n",
       " ('reiterate', 3),\n",
       " ('withdrawal', 3),\n",
       " ('Transition', 3),\n",
       " ('Giveaway', 3),\n",
       " ('discuss', 3),\n",
       " ('whom', 3),\n",
       " ('famu', 3),\n",
       " ('30th', 3),\n",
       " ('COMING', 3),\n",
       " ('nudes', 3),\n",
       " ('JoeBiden', 3),\n",
       " ('suffering', 3),\n",
       " ('FOLLOWERS', 3),\n",
       " ('continues', 3),\n",
       " ('subs', 3),\n",
       " ('reminding', 3),\n",
       " ('Evening', 3),\n",
       " ('screamed', 3),\n",
       " ('stunned', 3),\n",
       " ('crawl', 3),\n",
       " ('mentally', 3),\n",
       " ('finale', 3),\n",
       " ('smoke', 3),\n",
       " ('providing', 3),\n",
       " ('OUSTDUTERENOW', 3),\n",
       " ('advantage', 3),\n",
       " ('Newsom', 3),\n",
       " ('recovery', 3),\n",
       " ('revealed', 3),\n",
       " ('zoom', 3),\n",
       " ('fart', 3),\n",
       " ('YALL', 3),\n",
       " ('4TH', 3),\n",
       " ('increase', 3),\n",
       " ('Dakota', 3),\n",
       " ('chick', 3),\n",
       " ('preview', 3),\n",
       " ('Loeffler', 3),\n",
       " ('shooting', 3),\n",
       " ('Minutes', 3),\n",
       " ('agreed', 3),\n",
       " ('concerns', 3),\n",
       " ('Wake', 3),\n",
       " ('Brooks', 3),\n",
       " ('millennials', 3),\n",
       " ('deserves', 3),\n",
       " ('stole', 3),\n",
       " ('junior', 3),\n",
       " ('drives', 3),\n",
       " ('manuscript', 3),\n",
       " ('Derrick', 3),\n",
       " ('MAGAts', 3),\n",
       " ('owning', 3),\n",
       " ('slaves', 3),\n",
       " ('regarding', 3),\n",
       " ('Blonde', 3),\n",
       " ('cans', 3),\n",
       " ('Crossing', 3),\n",
       " ('NEVER', 3),\n",
       " ('clubs', 3),\n",
       " ('controversial', 3),\n",
       " ('proposal', 3),\n",
       " ('curious', 3),\n",
       " ('colors', 3),\n",
       " ('chosen', 3),\n",
       " ('prize', 3),\n",
       " ('switches', 3),\n",
       " ('commented', 3),\n",
       " ('disturbing', 3),\n",
       " ('horrific', 3),\n",
       " ('grieving', 3),\n",
       " ('emailed', 3),\n",
       " ('clap', 3),\n",
       " ('compared', 3),\n",
       " ('streamers', 3),\n",
       " ('AWAY', 3),\n",
       " ('yelling', 3),\n",
       " ('routine', 3),\n",
       " ('scientists', 3),\n",
       " ('Jefferson', 3),\n",
       " ('overall', 3),\n",
       " ('RaiderNation', 3),\n",
       " ...]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(unknown_text.items(), key=lambda d: d[1], reverse=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try demojize to text and unique same emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distinct_emoji_lis(string):\n",
    "    \"\"\"Resturns distinct list of emojis from the string\"\"\"\n",
    "    distinct_list = list({c for c in string if c in emoji.unicode_codes.UNICODE_EMOJI})\n",
    "    return distinct_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_emoji_to_text(text):\n",
    "    \"\"\"\n",
    "    Input: text\n",
    "    Output: demojize text\n",
    "    \"\"\"\n",
    "    ori_text = text\n",
    "    distinct_emoji = distinct_emoji_lis(text)\n",
    "    for each_emoji in distinct_emoji:\n",
    "        first_appear = ori_text.index(each_emoji)\n",
    "        new_text = ''\n",
    "        for tid, token in enumerate(ori_text):\n",
    "            if token == each_emoji and tid != first_appear:\n",
    "                new_text += ''\n",
    "            else:\n",
    "                new_text += token\n",
    "        ori_text = new_text\n",
    "    ori_text = emoji.demojize(ori_text).replace(':', ' ').replace('_', ' ')\n",
    "    return ori_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['map_demojize_text'] = df_train.map_more_punc_text.apply(change_emoji_to_text)\n",
    "df_train['map_demojize_reply'] = df_train.map_more_punc_reply.apply(change_emoji_to_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev['map_demojize_text'] = df_dev.map_more_punc_text.apply(change_emoji_to_text)\n",
    "df_dev['map_demojize_reply'] = df_dev.map_more_punc_reply.apply(change_emoji_to_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['map_demojize_text'] = df_test.map_more_punc_text.apply(change_emoji_to_text)\n",
    "df_test['map_demojize_reply'] = df_test.map_more_punc_reply.apply(change_emoji_to_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train text unique vocab count is: 43503\n",
      "train reply unique vocab count is: 17184\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=43503.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 14.300% (6221 / 43503) of vocab\n",
      "Found embeddings for 81.902% (674962 / 824110) of all text\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=17184.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 23.889% (4105 / 17184) of vocab\n",
      "Found embeddings for 81.091% (120173 / 148196) of all text\n"
     ]
    }
   ],
   "source": [
    "train_text_vocab = get_vocab(df_train['map_demojize_text'].values)\n",
    "train_reply_vocab = get_vocab(df_train['map_demojize_reply'].values)\n",
    "print(\"train text unique vocab count is: {}\".format(len(train_text_vocab)))\n",
    "print(\"train reply unique vocab count is: {}\".format(len(train_reply_vocab)))\n",
    "print()\n",
    "\n",
    "unknown_text = check_coverage(train_text_vocab, roberta_vocab)\n",
    "print()\n",
    "unknown_reply = check_coverage(train_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev text unique vocab count is: 12887\n",
      "dev reply unique vocab count is: 4312\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=12887.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 27.826% (3586 / 12887) of vocab\n",
      "Found embeddings for 81.828% (85413 / 104381) of all text\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=4312.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 39.471% (1702 / 4312) of vocab\n",
      "Found embeddings for 80.221% (15153 / 18889) of all text\n"
     ]
    }
   ],
   "source": [
    "dev_text_vocab = get_vocab(df_dev['map_demojize_text'].values)\n",
    "dev_reply_vocab = get_vocab(df_dev['map_demojize_reply'].values)\n",
    "print(\"dev text unique vocab count is: {}\".format(len(dev_text_vocab)))\n",
    "print(\"dev reply unique vocab count is: {}\".format(len(dev_reply_vocab)))\n",
    "print()\n",
    "\n",
    "unknown_text = check_coverage(dev_text_vocab, roberta_vocab)\n",
    "print()\n",
    "unknown_reply = check_coverage(dev_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test text unique vocab count is: 12695\n",
      "test reply unique vocab count is: 4086\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=12695.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 28.452% (3612 / 12695) of vocab\n",
      "Found embeddings for 81.799% (83612 / 102217) of all text\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=4086.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 41.997% (1716 / 4086) of vocab\n",
      "Found embeddings for 81.206% (14682 / 18080) of all text\n"
     ]
    }
   ],
   "source": [
    "test_text_vocab = get_vocab(df_test['map_demojize_text'].values)\n",
    "test_reply_vocab = get_vocab(df_test['map_demojize_reply'].values)\n",
    "print(\"test text unique vocab count is: {}\".format(len(test_text_vocab)))\n",
    "print(\"test reply unique vocab count is: {}\".format(len(test_reply_vocab)))\n",
    "print()\n",
    "\n",
    "unknown_text = check_coverage(test_text_vocab, roberta_vocab)\n",
    "print()\n",
    "unknown_reply = check_coverage(test_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('COVID', 158),\n",
       " ('hug', 121),\n",
       " ('smiling', 104),\n",
       " ('crying', 83),\n",
       " ('quarantine', 68),\n",
       " ('tonight', 64),\n",
       " ('tears', 63),\n",
       " ('loudly', 61),\n",
       " ('myself', 58),\n",
       " ('Biden', 52),\n",
       " ('reaction', 48),\n",
       " ('tomorrow', 47),\n",
       " ('pleading', 44),\n",
       " ('fucking', 43),\n",
       " ('Pelosi', 42),\n",
       " ('guys', 40),\n",
       " ('Nancy', 40),\n",
       " ('hear', 39),\n",
       " ('Oz', 39),\n",
       " ('anyone', 39),\n",
       " ('believe', 37),\n",
       " ('trying', 36),\n",
       " ('followers', 36),\n",
       " ('tweet', 36),\n",
       " ('lockdown', 36),\n",
       " ('least', 35),\n",
       " ('hearts', 35),\n",
       " ('birthday', 34),\n",
       " ('sad', 34),\n",
       " ('hope', 34),\n",
       " ('anymore', 33),\n",
       " ('economy', 31),\n",
       " ('whole', 30),\n",
       " ('virus', 29),\n",
       " ('already', 28),\n",
       " ('laughing', 27),\n",
       " ('pandemic', 27),\n",
       " ('hashtag', 26),\n",
       " ('beautiful', 26),\n",
       " ('dinner', 26),\n",
       " ('pensive', 26),\n",
       " ('decide', 25),\n",
       " ('wish', 25),\n",
       " ('weekend', 24),\n",
       " ('BailoutHumansNow', 24),\n",
       " ('politician', 24),\n",
       " ('dependable', 24),\n",
       " ('forget', 24),\n",
       " ('spend', 24),\n",
       " ('ScottyFromMarketing', 23),\n",
       " ('honest', 23),\n",
       " ('career', 23),\n",
       " ('happen', 23),\n",
       " ('dick', 22),\n",
       " ('explain', 22),\n",
       " ('reopen', 21),\n",
       " ('amaze', 21),\n",
       " ('tire', 21),\n",
       " ('Crazy', 21),\n",
       " ('sick', 20),\n",
       " ('listen', 20),\n",
       " ('sweat', 20),\n",
       " ('suck', 20),\n",
       " ('medium-light', 20),\n",
       " ('thankful', 20),\n",
       " ('flushed', 20),\n",
       " ('folded', 20),\n",
       " ('horny', 20),\n",
       " ('Guys', 20),\n",
       " ('seanhannity', 19),\n",
       " ('grinning', 19),\n",
       " ('Radical', 19),\n",
       " ('WritingCommunity', 19),\n",
       " ('Cuomo', 19),\n",
       " ('moment', 19),\n",
       " ('defeated', 18),\n",
       " ('pointing', 18),\n",
       " ('pathetic', 18),\n",
       " ('stimulus', 18),\n",
       " ('idea', 17),\n",
       " ('supporter', 17),\n",
       " ('crisis', 17),\n",
       " ('excite', 17),\n",
       " ('backhand', 17),\n",
       " ('incompetent', 17),\n",
       " ('puppet', 17),\n",
       " ('describe', 17),\n",
       " ('bitch', 17),\n",
       " ('giveaway', 17),\n",
       " ('guess', 17),\n",
       " ('governor', 17),\n",
       " ('came', 16),\n",
       " ('awesome', 16),\n",
       " ('become', 16),\n",
       " ('stupid', 16),\n",
       " ('AMERICA', 16),\n",
       " ('upside-down', 16),\n",
       " ('lone', 16),\n",
       " ('woke', 15),\n",
       " ('Gates', 15),\n",
       " ('fucked', 15),\n",
       " ('damn', 15),\n",
       " ('shrugging', 15),\n",
       " ('weary', 15),\n",
       " ('tear', 15),\n",
       " ('medium-dark', 15),\n",
       " ('suppose', 15),\n",
       " ('cares', 15),\n",
       " ('proud', 14),\n",
       " ('trash', 14),\n",
       " ('cute', 14),\n",
       " ('meeting', 14),\n",
       " ('socialist', 14),\n",
       " ('others', 14),\n",
       " ('LIBERATE', 14),\n",
       " ('Nathaniel', 14),\n",
       " ('sitting', 14),\n",
       " ('mood', 14),\n",
       " ('woozy', 14),\n",
       " ('clapping', 14),\n",
       " ('ugly', 14),\n",
       " ('understand', 14),\n",
       " ('deserve', 14),\n",
       " ('questions', 13),\n",
       " ('worse', 13),\n",
       " ('yall', 13),\n",
       " ('marry', 13),\n",
       " ('longer', 13),\n",
       " ('ensure', 13),\n",
       " ('corona', 13),\n",
       " ('anxiety', 13),\n",
       " ('facepalming', 13),\n",
       " ('folks', 13),\n",
       " ('blowing', 13),\n",
       " ('realize', 13),\n",
       " ('tweets', 13),\n",
       " ('6pm', 13),\n",
       " ('stopped', 13),\n",
       " ('Vaccine', 12),\n",
       " ('coffee', 12),\n",
       " ('pizza', 12),\n",
       " ('decision', 12),\n",
       " ('billionaire', 12),\n",
       " ('afford', 12),\n",
       " ('questions…', 12),\n",
       " ('attention', 12),\n",
       " ('grateful', 12),\n",
       " ('appreciate', 12),\n",
       " ('thousands', 12),\n",
       " ('funny', 12),\n",
       " ('drink', 12),\n",
       " ('covid', 12),\n",
       " ('approval', 12),\n",
       " ('sparkles', 12),\n",
       " ('students', 12),\n",
       " ('entire', 12),\n",
       " ('beaming', 12),\n",
       " ('complaining', 12),\n",
       " ('heart-eyes', 12),\n",
       " ('truly', 12),\n",
       " ('thinks', 12),\n",
       " ('everyday', 11),\n",
       " ('experience', 11),\n",
       " ('wearing', 11),\n",
       " ('VIRGINIA', 11),\n",
       " ('Amendment', 11),\n",
       " ('siege', 11),\n",
       " ('scared', 11),\n",
       " ('DMs', 11),\n",
       " ('replies', 11),\n",
       " ('handling', 11),\n",
       " ('Dollar', 11),\n",
       " ('streaming', 11),\n",
       " ('showing', 11),\n",
       " ('possible', 11),\n",
       " ('nobody', 11),\n",
       " ('boyfriend', 11),\n",
       " ('Ventilators', 11),\n",
       " ('leadership', 11),\n",
       " ('1st', 11),\n",
       " ('angry', 11),\n",
       " ('across', 11),\n",
       " ('couple', 11),\n",
       " ('lil', 10),\n",
       " ('kindness', 10),\n",
       " ('relationship', 10),\n",
       " ('conversation', 10),\n",
       " ('NEED', 10),\n",
       " ('sister', 10),\n",
       " ('definitely', 10),\n",
       " ('nose', 10),\n",
       " ('forever', 10),\n",
       " ('ventilators', 10),\n",
       " ('passed', 10),\n",
       " ('THAT', 10),\n",
       " ('summer', 10),\n",
       " ('disaster', 10),\n",
       " ('H1N1', 10),\n",
       " ('Swine', 10),\n",
       " ('Flu', 10),\n",
       " ('Polling', 10),\n",
       " ('disastrous', 10),\n",
       " ('unnecessarily', 10),\n",
       " ('incompetence', 10),\n",
       " ('Billion', 10),\n",
       " ('Obamacare', 10),\n",
       " ('website', 10),\n",
       " ('excuse', 10),\n",
       " ('randomly', 10),\n",
       " ('cuz', 10),\n",
       " ('themselves', 10),\n",
       " ('realized', 10),\n",
       " ('opinion', 10),\n",
       " ('5k', 10),\n",
       " ('fingers', 10),\n",
       " ('biggest', 9),\n",
       " ('sucking', 9),\n",
       " ('idk', 9),\n",
       " ('taken', 9),\n",
       " ('hurt', 9),\n",
       " ('himself', 9),\n",
       " ('situation', 9),\n",
       " ('patients', 9),\n",
       " ('vibe', 9),\n",
       " ('choose', 9),\n",
       " ('partying', 9),\n",
       " ('therapy', 9),\n",
       " ('awful', 9),\n",
       " ('difference', 9),\n",
       " ('Idk', 9),\n",
       " ('drunk', 9),\n",
       " ('weird', 9),\n",
       " ('fear', 9),\n",
       " ('wonder', 9),\n",
       " ('honestly', 9),\n",
       " ('cheese', 9),\n",
       " ('okay', 9),\n",
       " ('expansive', 9),\n",
       " ('accurate', 9),\n",
       " ('thumbs', 9),\n",
       " ('skull', 9),\n",
       " ('horns', 9),\n",
       " ('reminds', 9),\n",
       " ('dude', 9),\n",
       " ('helping', 9),\n",
       " ('worry', 9),\n",
       " ('shower', 9),\n",
       " ('seriously', 9),\n",
       " ('unemployment', 9),\n",
       " ('retweet', 9),\n",
       " ('grocery', 9),\n",
       " ('pregnant', 9),\n",
       " ('popper', 8),\n",
       " ('leaving', 8),\n",
       " ('announce', 8),\n",
       " ('celebrate', 8),\n",
       " ('takes', 8),\n",
       " ('depression', 8),\n",
       " ('sugar', 8),\n",
       " ('11am', 8),\n",
       " ('broke', 8),\n",
       " ('advice', 8),\n",
       " ('nigga', 8),\n",
       " ('learned', 8),\n",
       " ('7th', 8),\n",
       " ('sucks', 8),\n",
       " ('bout', 8),\n",
       " ('sleepy', 8),\n",
       " ('Frequently', 8),\n",
       " ('opportunity', 8),\n",
       " ('LIKE', 8),\n",
       " ('finish', 8),\n",
       " ('cheating', 8),\n",
       " ('instagram', 8),\n",
       " ('partner', 8),\n",
       " ('→', 8),\n",
       " ('heaven', 8),\n",
       " ('attempt', 8),\n",
       " ('LOVE', 8),\n",
       " ('chill', 8),\n",
       " ('beds', 8),\n",
       " ('causing', 8),\n",
       " ('funeral', 8),\n",
       " ('pouting', 8),\n",
       " ('MUCH', 8),\n",
       " ('pray', 8),\n",
       " ('enjoy', 8),\n",
       " ('teacher', 8),\n",
       " ('additional', 8),\n",
       " ('approve', 8),\n",
       " ('dying', 8),\n",
       " ('exploding', 8),\n",
       " ('welcome', 8),\n",
       " ('HAVE', 8),\n",
       " ('terrible', 8),\n",
       " ('keeps', 8),\n",
       " ('FollowFriday', 8),\n",
       " ('governors', 8),\n",
       " ('relief', 8),\n",
       " ('relieved', 8),\n",
       " ('idiot', 8),\n",
       " ('lose', 8),\n",
       " ('apartment', 8),\n",
       " ('unamused', 8),\n",
       " ('crossed', 8),\n",
       " ('upset', 8),\n",
       " ('hundred', 8),\n",
       " ('sounds', 7),\n",
       " ('kitchen', 7),\n",
       " ('messages', 7),\n",
       " ('anxious', 7),\n",
       " ('OldRich', 7),\n",
       " ('tells', 7),\n",
       " ('joke', 7),\n",
       " ('gift', 7),\n",
       " ('NYC', 7),\n",
       " ('sending', 7),\n",
       " ('alive', 7),\n",
       " ('ONLY', 7),\n",
       " ('covering', 7),\n",
       " ('savoring', 7),\n",
       " ('dear', 7),\n",
       " ('dropped', 7),\n",
       " ('treating', 7),\n",
       " ('calls', 7),\n",
       " ('slid', 7),\n",
       " ('sauce', 7),\n",
       " ('stuck', 7),\n",
       " ('Lebron', 7),\n",
       " ('masks', 7),\n",
       " ('Genuinely', 7),\n",
       " ('Rashford', 7),\n",
       " ('clothes', 7),\n",
       " ('lately', 7),\n",
       " ('fraud', 7),\n",
       " ('discussion', 7),\n",
       " ('harder', 7),\n",
       " ('herself', 7),\n",
       " ('lucky', 7),\n",
       " ('incredibly', 7),\n",
       " ('expect', 7),\n",
       " ('glad', 7),\n",
       " ('RETWEET', 7),\n",
       " ('Zoom', 7),\n",
       " ('disgusting', 7),\n",
       " ('TESTING', 7),\n",
       " ('exam', 7),\n",
       " ('yours', 7),\n",
       " ('Been', 7),\n",
       " ('turning', 7),\n",
       " ('Birthday', 7),\n",
       " ('sparkling', 7),\n",
       " ('loves', 7),\n",
       " ('comedy', 7),\n",
       " ('evening', 7),\n",
       " ('complain', 7),\n",
       " ('waste', 7),\n",
       " ('songs', 7),\n",
       " ('handshake', 7),\n",
       " ('afternoon', 7),\n",
       " ('QUARANTINE', 7),\n",
       " ('hugging', 7),\n",
       " ('grimacing', 7),\n",
       " ('EVER', 7),\n",
       " ('FUCK', 7),\n",
       " ('slide', 7),\n",
       " ('apparently', 7),\n",
       " ('barely', 7),\n",
       " ('cuddle', 7),\n",
       " ('officials', 7),\n",
       " ('Respond', 7),\n",
       " ('immediate', 7),\n",
       " ('heavily', 7),\n",
       " ('awake', 7),\n",
       " ('blocked', 7),\n",
       " ('sexy', 7),\n",
       " ('clearly', 7),\n",
       " ('problems', 7),\n",
       " ('purple', 7),\n",
       " ('pics', 7),\n",
       " ('funds', 7),\n",
       " ('meme', 7),\n",
       " ('annoying', 7),\n",
       " ('KNOW', 7),\n",
       " ('appreciated', 7),\n",
       " ('seem', 7),\n",
       " ('surprise', 7),\n",
       " ('regional', 7),\n",
       " ('niggas', 6),\n",
       " ('everybody', 6),\n",
       " ('nightmare', 6),\n",
       " ('judging', 6),\n",
       " ('judgement', 6),\n",
       " ('HUNGRY', 6),\n",
       " ('worried', 6),\n",
       " ('yesterday', 6),\n",
       " ('denies', 6),\n",
       " ('extent', 6),\n",
       " ('outbreak', 6),\n",
       " ('smh', 6),\n",
       " ('extend', 6),\n",
       " ('lovely', 6),\n",
       " ('expecting', 6),\n",
       " ('Minister', 6),\n",
       " ('committed', 6),\n",
       " ('communist', 6),\n",
       " ('isolation', 6),\n",
       " ('shitty', 6),\n",
       " ('interview', 6),\n",
       " ('sleeping', 6),\n",
       " ('dangerous', 6),\n",
       " ('retweets', 6),\n",
       " ('difficult', 6),\n",
       " ('amwriting', 6),\n",
       " ('Neymar', 6),\n",
       " ('slightly', 6),\n",
       " ('starts', 6),\n",
       " ('senior', 6),\n",
       " ('makeup', 6),\n",
       " ('personally', 6),\n",
       " ('pictures', 6),\n",
       " ('experts', 6),\n",
       " ('lowkey', 6),\n",
       " ('dumb', 6),\n",
       " ('fellow', 6),\n",
       " ('blessed', 6),\n",
       " ('university', 6),\n",
       " ('Cassper', 6),\n",
       " ('survive', 6),\n",
       " ('thousand', 6),\n",
       " ('crush', 6),\n",
       " ('viewers', 6),\n",
       " ('Bailout', 6),\n",
       " ('Humans', 6),\n",
       " ('MUST', 6),\n",
       " ('Shout', 6),\n",
       " ('Quarantine', 6),\n",
       " ('Vikings', 6),\n",
       " ('scary', 6),\n",
       " ('groceries', 6),\n",
       " ('visit', 6),\n",
       " ('Lol', 6),\n",
       " ('strategy', 6),\n",
       " ('expressionless', 6),\n",
       " ('exclamation', 6),\n",
       " ('winking', 6),\n",
       " ('supporters', 6),\n",
       " ('breakfast', 6),\n",
       " ('suddenly', 6),\n",
       " ('miles', 6),\n",
       " ('voted', 6),\n",
       " ('ventilator', 6),\n",
       " ('unprecedented', 6),\n",
       " ('follows', 6),\n",
       " ('Retweet', 6),\n",
       " ('bunch', 6),\n",
       " ('vaccine', 6),\n",
       " ('chocolate', 6),\n",
       " ('milk', 6),\n",
       " ('missed', 6),\n",
       " ('employees', 6),\n",
       " ('possibility', 6),\n",
       " ('CoronaVirus', 6),\n",
       " ('Democrat', 6),\n",
       " ('asleep', 6),\n",
       " ('POTUS', 6),\n",
       " ('appointing', 6),\n",
       " ('pussy', 6),\n",
       " ('promise', 6),\n",
       " ('RIGHT', 6),\n",
       " ('boobs', 6),\n",
       " ('fist', 6),\n",
       " ('tho', 6),\n",
       " ('WAS', 6),\n",
       " ('flexed', 6),\n",
       " ('biceps', 6),\n",
       " ('Guess', 6),\n",
       " ('notifications', 6),\n",
       " ('tough', 6),\n",
       " ('dance', 6),\n",
       " ('COVIDLiar', 6),\n",
       " ('spirits', 6),\n",
       " ('indicator', 6),\n",
       " ('symbol', 6),\n",
       " ('discussing', 5),\n",
       " ('wtf', 5),\n",
       " ('cried', 5),\n",
       " ('hacked', 5),\n",
       " ('replying', 5),\n",
       " ('attacked', 5),\n",
       " ('stupidity', 5),\n",
       " ('\\u200d', 5),\n",
       " ('hiding', 5),\n",
       " ('prepare', 5),\n",
       " ('transition', 5),\n",
       " ('till', 5),\n",
       " ('Govt', 5),\n",
       " ('wonderful', 5),\n",
       " ('tbh', 5),\n",
       " ('fridge', 5),\n",
       " ('Parliament', 5),\n",
       " ('signs', 5),\n",
       " ('spending', 5),\n",
       " ('ridiculous', 5),\n",
       " ('star-struck', 5),\n",
       " ('memories', 5),\n",
       " ('debate', 5),\n",
       " ('happiness', 5),\n",
       " ('Feeling', 5),\n",
       " ('sober', 5),\n",
       " ('meetings', 5),\n",
       " ('hits', 5),\n",
       " ('prayers', 5),\n",
       " ('disease', 5),\n",
       " ('victory', 5),\n",
       " ('mention', 5),\n",
       " ('somebody', 5),\n",
       " ('drinks', 5),\n",
       " ('compassion', 5),\n",
       " ('Zack', 5),\n",
       " ('teams', 5),\n",
       " ('WILL', 5),\n",
       " ('BABY', 5),\n",
       " ('remain', 5),\n",
       " ('hearing', 5),\n",
       " ('huh', 5),\n",
       " ('Fauci', 5),\n",
       " ('boring', 5),\n",
       " ('waking', 5),\n",
       " ('doctors', 5),\n",
       " ('slowly', 5),\n",
       " ('expand', 5),\n",
       " ('beating', 5),\n",
       " ('cancelled', 5),\n",
       " ('sake', 5),\n",
       " ('Trey', 5),\n",
       " ('Burton', 5),\n",
       " ('cant', 5),\n",
       " ('selecting', 5),\n",
       " ('donate', 5),\n",
       " ('plenty', 5),\n",
       " ('laid', 5),\n",
       " ('journey', 5),\n",
       " ('peaceful', 5),\n",
       " ('beach', 5),\n",
       " ('apeopley', 5),\n",
       " ('mutuals', 5),\n",
       " ('anywhere', 5),\n",
       " ('choked', 5),\n",
       " ('homes', 5),\n",
       " ('cough', 5),\n",
       " ('bipartisan', 5),\n",
       " ('desk', 5),\n",
       " ('doubling', 5),\n",
       " ('Invisible', 5),\n",
       " ('Enemy', 5),\n",
       " ('concerned', 5),\n",
       " ('familiar', 5),\n",
       " ('YOUR', 5),\n",
       " ('WHY', 5),\n",
       " ('bitches', 5),\n",
       " ('challenge', 5),\n",
       " ('butter', 5),\n",
       " ('shoes', 5),\n",
       " ('10k', 5),\n",
       " ('GOOD', 5),\n",
       " ('pounds', 5),\n",
       " ('FIRST', 5),\n",
       " ('loud', 5),\n",
       " ('loan', 5),\n",
       " ('tiktok', 5),\n",
       " ('dudes', 5),\n",
       " ('streets', 5),\n",
       " ('timeline', 5),\n",
       " ('squinting', 5),\n",
       " ('freak', 5),\n",
       " ('haircut', 5),\n",
       " ('garden', 5),\n",
       " ('selfie', 5),\n",
       " ('DrOz', 5),\n",
       " ('imagine', 5),\n",
       " ('entering', 5),\n",
       " ('Dems', 5),\n",
       " ('realizing', 5),\n",
       " ('liquor', 5),\n",
       " ('RAT', 5),\n",
       " ('guest', 5),\n",
       " ('HIM', 5),\n",
       " ('rally', 5),\n",
       " ('naked', 5),\n",
       " ('horrible', 5),\n",
       " ('movies', 5),\n",
       " ('shopping', 5),\n",
       " ('roof', 5),\n",
       " ('Verge', 5),\n",
       " ('consistently', 5),\n",
       " ('mistake', 5),\n",
       " ('suspect', 5),\n",
       " ('furloughed', 5),\n",
       " ('records', 5),\n",
       " ('writerslift', 5),\n",
       " ('leaves', 5),\n",
       " ('everywhere', 5),\n",
       " ('followed', 5),\n",
       " ('govt', 5),\n",
       " ('LikewiseApp', 5),\n",
       " ('Yay', 5),\n",
       " ('infected', 5),\n",
       " ('attend', 5),\n",
       " ('Lockdown', 5),\n",
       " ('simply', 5),\n",
       " ('boo', 5),\n",
       " ('juliemac1000', 5),\n",
       " ('Congressional', 5),\n",
       " ('lawyer', 5),\n",
       " ('payments', 5),\n",
       " ('bored', 5),\n",
       " ('OKAY', 5),\n",
       " ('TODAY', 5),\n",
       " ('happens', 5),\n",
       " ('screenshot', 5),\n",
       " ('Uncle', 5),\n",
       " ('2021', 5),\n",
       " ('interact', 5),\n",
       " ('saved', 5),\n",
       " ('fuckin', 5),\n",
       " ('murder', 5),\n",
       " ('nursing', 5),\n",
       " ('jumping', 5),\n",
       " ('Wuhan', 5),\n",
       " ('teach', 5),\n",
       " ('memes', 5),\n",
       " ('swear', 5),\n",
       " ('cheer', 5),\n",
       " ('earlier', 5),\n",
       " ('apeopleause', 5),\n",
       " ('younger', 5),\n",
       " ('neighbor', 5),\n",
       " ('pushing', 5),\n",
       " ('WOW', 5),\n",
       " ('nail', 5),\n",
       " ('Kanye', 5),\n",
       " ('bills', 5),\n",
       " ('eggs', 5),\n",
       " ('sisters', 5),\n",
       " ('Couldn', 5),\n",
       " ('Lawrence', 5),\n",
       " ('sacrifice', 5),\n",
       " ('trading', 4),\n",
       " ('Might', 4),\n",
       " ('downcast', 4),\n",
       " ('hardest', 4),\n",
       " ('hospitals', 4),\n",
       " ('spamming', 4),\n",
       " ('confronting', 4),\n",
       " ('Doing', 4),\n",
       " ('eventually', 4),\n",
       " ('cancel', 4),\n",
       " ('lunch', 4),\n",
       " ('begins', 4),\n",
       " ('greatest', 4),\n",
       " ('shout', 4),\n",
       " ('teenage', 4),\n",
       " ('salt', 4),\n",
       " ('liberate', 4),\n",
       " ('talent', 4),\n",
       " ('theater', 4),\n",
       " ('struggling', 4),\n",
       " ('allowing', 4),\n",
       " ('Tune', 4),\n",
       " ('sperm', 4),\n",
       " ('moms', 4),\n",
       " ('Horny', 4),\n",
       " ('liked', 4),\n",
       " ('communities', 4),\n",
       " ('apologize', 4),\n",
       " ('admit', 4),\n",
       " ('afraid', 4),\n",
       " ('recovered', 4),\n",
       " ('appointment', 4),\n",
       " ('LOL', 4),\n",
       " ('Somebody', 4),\n",
       " ('irresponsible', 4),\n",
       " ('COVIDPandemic', 4),\n",
       " ('HIT', 4),\n",
       " ('stressed', 4),\n",
       " ('Yup', 4),\n",
       " ('busy', 4),\n",
       " ('pillow', 4),\n",
       " ('hella', 4),\n",
       " ('posting', 4),\n",
       " ('turns', 4),\n",
       " ('wins', 4),\n",
       " ('moves', 4),\n",
       " ('hurts', 4),\n",
       " ('THEY', 4),\n",
       " ('convo', 4),\n",
       " ('pronounced', 4),\n",
       " ('Lindsey', 4),\n",
       " ('exercise', 4),\n",
       " ('writingcommunity', 4),\n",
       " ('Giants', 4),\n",
       " ('libs', 4),\n",
       " ('sunglasses', 4),\n",
       " ('otherwise', 4),\n",
       " ('AEW', 4),\n",
       " ('Cody', 4),\n",
       " ('Suite', 4),\n",
       " ('lesson', 4),\n",
       " ('souls', 4),\n",
       " ('Thoughts', 4),\n",
       " ('spreading', 4),\n",
       " ('planning', 4),\n",
       " ('HATE', 4),\n",
       " ('slapped', 4),\n",
       " ('giveaways', 4),\n",
       " ('cherry', 4),\n",
       " ('mum', 4),\n",
       " ('wondering', 4),\n",
       " ('potential', 4),\n",
       " ('faster', 4),\n",
       " ('Raiders', 4),\n",
       " ('Ruggs', 4),\n",
       " ('Jeudy', 4),\n",
       " ('Lamb', 4),\n",
       " ('idiots', 4),\n",
       " ('tweeting', 4),\n",
       " ('VoteSafe', 4),\n",
       " ('polling', 4),\n",
       " ('→No', 4),\n",
       " ('absentee', 4),\n",
       " ('→At', 4),\n",
       " ('Voting', 4),\n",
       " ('fundamental', 4),\n",
       " ('globe', 4),\n",
       " ('REALLY', 4),\n",
       " ('Pls', 4),\n",
       " ('Bears', 4),\n",
       " ('shaking', 4),\n",
       " ('toxic', 4),\n",
       " ('throughout', 4),\n",
       " ('impossible', 4),\n",
       " ('4th', 4),\n",
       " ('see-no-evil', 4),\n",
       " ('SpeakerPelosi', 4),\n",
       " ('Ozark', 4),\n",
       " ('Creek', 4),\n",
       " ('texts', 4),\n",
       " ('creators', 4),\n",
       " ('conspiracy', 4),\n",
       " ('customers', 4),\n",
       " ('goodbye', 4),\n",
       " ('shutdown', 4),\n",
       " ('fever', 4),\n",
       " ('recently', 4),\n",
       " ('couch', 4),\n",
       " ('Explain', 4),\n",
       " ('PPP', 4),\n",
       " ('sink', 4),\n",
       " ('assignment', 4),\n",
       " ('symptoms', 4),\n",
       " ('hopefully', 4),\n",
       " ('Cowboys', 4),\n",
       " ('wanting', 4),\n",
       " ('positivity', 4),\n",
       " ('workout', 4),\n",
       " ('prepared', 4),\n",
       " ('peanut', 4),\n",
       " ('subscribers', 4),\n",
       " ('Walmart', 4),\n",
       " ('LockdownHouseParty', 4),\n",
       " ('affection', 4),\n",
       " ('arguments', 4),\n",
       " ('streamer', 4),\n",
       " ('depressed', 4),\n",
       " ('receiving', 4),\n",
       " ('porn', 4),\n",
       " ('tongue', 4),\n",
       " ('baseball', 4),\n",
       " ('strongly', 4),\n",
       " ('countries', 4),\n",
       " ('disapprove', 4),\n",
       " ('FCE', 4),\n",
       " ('protest', 4),\n",
       " ('Drew', 4),\n",
       " ('friday', 4),\n",
       " ('heroes', 4),\n",
       " ('NHS', 4),\n",
       " ('millions', 4),\n",
       " ('cleaned', 4),\n",
       " ('spit', 4),\n",
       " ('appearance', 4),\n",
       " ('BOY', 4),\n",
       " ('Titans', 4),\n",
       " ('WITH', 4),\n",
       " ('encourage', 4),\n",
       " ('2k', 4),\n",
       " ('swimming', 4),\n",
       " ('burden', 4),\n",
       " ('Watching', 4),\n",
       " ('CashApp', 4),\n",
       " ('paycheck', 4),\n",
       " ('HUGE', 4),\n",
       " ('daddy', 4),\n",
       " ('publicly', 4),\n",
       " ('screaming', 4),\n",
       " ('Rona', 4),\n",
       " ('friendship', 4),\n",
       " ('caused', 4),\n",
       " ('brilliant', 4),\n",
       " ('supeopley', 4),\n",
       " ('several', 4),\n",
       " ('easily', 4),\n",
       " ('wedding', 4),\n",
       " ('StayAtHome', 4),\n",
       " ('hugged', 4),\n",
       " ('OANN', 4),\n",
       " ('Carolina', 4),\n",
       " ('combination', 4),\n",
       " ('remembered', 4),\n",
       " ('Welp', 4),\n",
       " ('horror', 4),\n",
       " ('serve', 4),\n",
       " ('invited', 4),\n",
       " ('breath', 4),\n",
       " ('eyebrow', 4),\n",
       " ('hoping', 4),\n",
       " ('filing', 4),\n",
       " ('revive', 4),\n",
       " ('potato', 4),\n",
       " ('virologist', 4),\n",
       " ('puzzle', 4),\n",
       " ('proved', 4),\n",
       " ('taste', 4),\n",
       " ('EVERYONE', 4),\n",
       " ('companies', 4),\n",
       " ('regret', 4),\n",
       " ('provide', 4),\n",
       " ('Wish', 4),\n",
       " ('tired', 4),\n",
       " ('fandom', 4),\n",
       " ('imma', 4),\n",
       " ('chips', 4),\n",
       " ('gym', 4),\n",
       " ('OMG', 4),\n",
       " ('whilst', 4),\n",
       " ('Oprah', 4),\n",
       " ('heartbreaking', 4),\n",
       " ('kills', 4),\n",
       " ('replaced', 4),\n",
       " ('crack', 4),\n",
       " ('WENT', 4),\n",
       " ('BATHROOM', 4),\n",
       " ('HAD', 4),\n",
       " ('SWUM', 4),\n",
       " ('TOILET', 4),\n",
       " ('THOUGHT', 4),\n",
       " ('URBAN', 4),\n",
       " ('LEGEND', 4),\n",
       " ('MOVE', 4),\n",
       " ('nasty', 4),\n",
       " ('covid19', 4),\n",
       " ('restrictions', 4),\n",
       " ('tuned', 4),\n",
       " ('jail', 4),\n",
       " ('truck', 4),\n",
       " ('caught', 4),\n",
       " ('Apologies', 4),\n",
       " ('Lemme', 4),\n",
       " ('THANK', 4),\n",
       " ('fault', 4),\n",
       " ('divorce', 4),\n",
       " ('thick', 4),\n",
       " ('supporting', 4),\n",
       " ('cleaning', 4),\n",
       " ('Catch', 4),\n",
       " ('Fortnite', 4),\n",
       " ('joking', 4),\n",
       " ('whack', 4),\n",
       " ('artists', 4),\n",
       " ('nervous', 4),\n",
       " ('Drake', 4),\n",
       " ('discussed', 4),\n",
       " ('Newcastle', 4),\n",
       " ('exhausted', 4),\n",
       " ('WHEN', 4),\n",
       " ('Packers', 4),\n",
       " ('contest', 4),\n",
       " ('unemployed', 4),\n",
       " ('ideas', 4),\n",
       " ('germ', 4),\n",
       " ('talked', 4),\n",
       " ('receiver', 4),\n",
       " ('gimme', 4),\n",
       " ('receive', 4),\n",
       " ('opinions', 4),\n",
       " ('toes', 4),\n",
       " ('monthly', 4),\n",
       " ('twice', 4),\n",
       " ('realise', 4),\n",
       " ('warned', 4),\n",
       " ('beverage', 4),\n",
       " ('Apeoplee', 4),\n",
       " ('comfortable', 4),\n",
       " ('Trout', 4),\n",
       " ('12k', 4),\n",
       " ('exciting', 4),\n",
       " ('cheated', 4),\n",
       " ('snow', 4),\n",
       " ('walked', 4),\n",
       " ('choices', 4),\n",
       " ('denied', 4),\n",
       " ('ignoring', 4),\n",
       " ('SHIT', 4),\n",
       " ('considered', 4),\n",
       " ('keycap', 4),\n",
       " ('drank', 4),\n",
       " ('Sierra', 4),\n",
       " ('pulp', 4),\n",
       " ('geng', 4),\n",
       " ('restaurants', 4),\n",
       " ('Boom', 4),\n",
       " ('carti', 3),\n",
       " ('dababy', 3),\n",
       " ('Indians', 3),\n",
       " ('crap', 3),\n",
       " ('hacker', 3),\n",
       " ('PHYSICALLY', 3),\n",
       " ('spam', 3),\n",
       " ('therapist', 3),\n",
       " ('plans', 3),\n",
       " ('apologise', 3),\n",
       " ('frowning', 3),\n",
       " ('supportive', 3),\n",
       " ('kissed', 3),\n",
       " ('belongs', 3),\n",
       " ('spoilers', 3),\n",
       " ('hurtful', 3),\n",
       " ('lockdowns', 3),\n",
       " ('quarantining', 3),\n",
       " ('welcomed', 3),\n",
       " ('assume', 3),\n",
       " ('Rounds', 3),\n",
       " ('negotiations', 3),\n",
       " ('reiterate', 3),\n",
       " ('withdrawal', 3),\n",
       " ('Transition', 3),\n",
       " ('balloon', 3),\n",
       " ('Giveaway', 3),\n",
       " ('discuss', 3),\n",
       " ('whom', 3),\n",
       " ('famu', 3),\n",
       " ('30th', 3),\n",
       " ('COMING', 3),\n",
       " ('nudes', 3),\n",
       " ('JoeBiden', 3),\n",
       " ('suffering', 3),\n",
       " ('FOLLOWERS', 3),\n",
       " ('continues', 3),\n",
       " ('subs', 3),\n",
       " ('reminding', 3),\n",
       " ('Evening', 3),\n",
       " ('screamed', 3),\n",
       " ('stunned', 3),\n",
       " ('crawl', 3),\n",
       " ('mentally', 3),\n",
       " ('finale', 3),\n",
       " ('smoke', 3),\n",
       " ('providing', 3),\n",
       " ('OUSTDUTERENOW', 3),\n",
       " ('advantage', 3),\n",
       " ('confused', 3),\n",
       " ('Newsom', 3),\n",
       " ('recovery', 3),\n",
       " ('revealed', 3),\n",
       " ('zoom', 3),\n",
       " ('fart', 3),\n",
       " ('YALL', 3),\n",
       " ('4TH', 3),\n",
       " ('increase', 3),\n",
       " ('Dakota', 3),\n",
       " ('chick', 3),\n",
       " ('preview', 3),\n",
       " ('Loeffler', 3),\n",
       " ('shooting', 3),\n",
       " ('Minutes', 3),\n",
       " ('agreed', 3),\n",
       " ('concerns', 3),\n",
       " ('Wake', 3),\n",
       " ('Brooks', 3),\n",
       " ('millennials', 3),\n",
       " ('deserves', 3),\n",
       " ('stole', 3),\n",
       " ('junior', 3),\n",
       " ('drives', 3),\n",
       " ('manuscript', 3),\n",
       " ('Derrick', 3),\n",
       " ('MAGAts', 3),\n",
       " ('owning', 3),\n",
       " ('slaves', 3),\n",
       " ...]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(unknown_text.items(), key=lambda d: d[1], reverse=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store preprocessed results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "      <th>reply</th>\n",
       "      <th>categories</th>\n",
       "      <th>mp4</th>\n",
       "      <th>map_punc_text</th>\n",
       "      <th>map_punc_reply</th>\n",
       "      <th>map_more_punc_text</th>\n",
       "      <th>map_more_punc_reply</th>\n",
       "      <th>map_demojize_text</th>\n",
       "      <th>map_demojize_reply</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>we can all agree that any song by Niall Horan.</td>\n",
       "      <td>oui oui</td>\n",
       "      <td>[yes]</td>\n",
       "      <td>6dc39e96b11275f064fdaed88273b45e.mp4</td>\n",
       "      <td>we can all agree that any song by Niall Horan .</td>\n",
       "      <td>oui oui</td>\n",
       "      <td>we can all agree that any song by Niall Horan .</td>\n",
       "      <td>oui oui</td>\n",
       "      <td>we can all agree that any song by Niall Horan .</td>\n",
       "      <td>oui oui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Will you be installing #ScottyFromMarketing's ...</td>\n",
       "      <td></td>\n",
       "      <td>[no]</td>\n",
       "      <td>cfff051f05d8d3b7136c7d58ea6ad55f.mp4</td>\n",
       "      <td>Will you be installing  # ScottyFromMarketing ...</td>\n",
       "      <td></td>\n",
       "      <td>Will you be install  # ScottyFromMarketing  ' ...</td>\n",
       "      <td></td>\n",
       "      <td>Will you be install  # ScottyFromMarketing  ' ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Growing up my mum would call me a Nigga despit...</td>\n",
       "      <td>And he joins in??? Pour some hot grits on em</td>\n",
       "      <td>[smh]</td>\n",
       "      <td>bf39e7bd9ad24354ce3ba6822b0104af.mp4</td>\n",
       "      <td>Growing up my mum would call me a Nigga despit...</td>\n",
       "      <td>And he joins in ?  ?  ?  Pour some hot grits o...</td>\n",
       "      <td>Growing up my mum would call me a Nigga despit...</td>\n",
       "      <td>And he joins in ?  ?  ?  Pour some hot grits o...</td>\n",
       "      <td>Growing up my mum would call me a Nigga despit...</td>\n",
       "      <td>And he joins in ?  ?  ?  Pour some hot grits o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Rest your head on my chest when the world feel...</td>\n",
       "      <td>😂😂😂😂😂</td>\n",
       "      <td>[wink]</td>\n",
       "      <td>173a707a04c277354a2f23cf01d6151e.mp4</td>\n",
       "      <td>Rest your head on my chest when the world feel...</td>\n",
       "      <td>😂😂😂😂😂</td>\n",
       "      <td>Rest your head on my chest when the world feel...</td>\n",
       "      <td>😂😂😂😂😂</td>\n",
       "      <td>Rest your head on my chest when the world feel...</td>\n",
       "      <td>face with tears of joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Imagine Will Hernandez and Wills both doing a ...</td>\n",
       "      <td></td>\n",
       "      <td>[yes]</td>\n",
       "      <td>aab6d6bfb0c1382269ddba9b71cc8b7a.mp4</td>\n",
       "      <td>Imagine Will Hernandez and Wills both doing a ...</td>\n",
       "      <td></td>\n",
       "      <td>Imagine Will Hernandez and Wills both doing a ...</td>\n",
       "      <td></td>\n",
       "      <td>Imagine Will Hernandez and Wills both doing a ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx                                               text  \\\n",
       "0    0     we can all agree that any song by Niall Horan.   \n",
       "1    1  Will you be installing #ScottyFromMarketing's ...   \n",
       "2    2  Growing up my mum would call me a Nigga despit...   \n",
       "3    3  Rest your head on my chest when the world feel...   \n",
       "4    4  Imagine Will Hernandez and Wills both doing a ...   \n",
       "\n",
       "                                          reply categories  \\\n",
       "0                                       oui oui      [yes]   \n",
       "1                                                     [no]   \n",
       "2  And he joins in??? Pour some hot grits on em      [smh]   \n",
       "3                                         😂😂😂😂😂     [wink]   \n",
       "4                                                    [yes]   \n",
       "\n",
       "                                    mp4  \\\n",
       "0  6dc39e96b11275f064fdaed88273b45e.mp4   \n",
       "1  cfff051f05d8d3b7136c7d58ea6ad55f.mp4   \n",
       "2  bf39e7bd9ad24354ce3ba6822b0104af.mp4   \n",
       "3  173a707a04c277354a2f23cf01d6151e.mp4   \n",
       "4  aab6d6bfb0c1382269ddba9b71cc8b7a.mp4   \n",
       "\n",
       "                                       map_punc_text  \\\n",
       "0   we can all agree that any song by Niall Horan .    \n",
       "1  Will you be installing  # ScottyFromMarketing ...   \n",
       "2  Growing up my mum would call me a Nigga despit...   \n",
       "3  Rest your head on my chest when the world feel...   \n",
       "4  Imagine Will Hernandez and Wills both doing a ...   \n",
       "\n",
       "                                      map_punc_reply  \\\n",
       "0                                            oui oui   \n",
       "1                                                      \n",
       "2  And he joins in ?  ?  ?  Pour some hot grits o...   \n",
       "3                                              😂😂😂😂😂   \n",
       "4                                                      \n",
       "\n",
       "                                  map_more_punc_text  \\\n",
       "0   we can all agree that any song by Niall Horan .    \n",
       "1  Will you be install  # ScottyFromMarketing  ' ...   \n",
       "2  Growing up my mum would call me a Nigga despit...   \n",
       "3  Rest your head on my chest when the world feel...   \n",
       "4  Imagine Will Hernandez and Wills both doing a ...   \n",
       "\n",
       "                                 map_more_punc_reply  \\\n",
       "0                                            oui oui   \n",
       "1                                                      \n",
       "2  And he joins in ?  ?  ?  Pour some hot grits o...   \n",
       "3                                              😂😂😂😂😂   \n",
       "4                                                      \n",
       "\n",
       "                                   map_demojize_text  \\\n",
       "0   we can all agree that any song by Niall Horan .    \n",
       "1  Will you be install  # ScottyFromMarketing  ' ...   \n",
       "2  Growing up my mum would call me a Nigga despit...   \n",
       "3  Rest your head on my chest when the world feel...   \n",
       "4  Imagine Will Hernandez and Wills both doing a ...   \n",
       "\n",
       "                                  map_demojize_reply  \n",
       "0                                            oui oui  \n",
       "1                                                     \n",
       "2  And he joins in ?  ?  ?  Pour some hot grits o...  \n",
       "3                            face with tears of joy   \n",
       "4                                                     "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "      <th>reply</th>\n",
       "      <th>map_punc_text</th>\n",
       "      <th>map_punc_reply</th>\n",
       "      <th>map_more_punc_text</th>\n",
       "      <th>map_more_punc_reply</th>\n",
       "      <th>map_demojize_text</th>\n",
       "      <th>map_demojize_reply</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32000</td>\n",
       "      <td>Drop your cash app, use hashtag #BailoutHumansNow</td>\n",
       "      <td>$tyratomaro #BailoutHumans</td>\n",
       "      <td>Drop your cash app ,  use hashtag  # BailoutHu...</td>\n",
       "      <td>$ tyratomaro  # BailoutHumans</td>\n",
       "      <td>Drop your cash app ,  use hashtag  # BailoutHu...</td>\n",
       "      <td>$ tyratomaro  # BailoutHumans</td>\n",
       "      <td>Drop your cash app ,  use hashtag  # BailoutHu...</td>\n",
       "      <td>$ tyratomaro  # BailoutHumans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32001</td>\n",
       "      <td>After interviewing with a few incredible peopl...</td>\n",
       "      <td>CONGRATS!!!!!</td>\n",
       "      <td>After interviewing with a few incredible peopl...</td>\n",
       "      <td>CONGRATS !  !  !  !  !</td>\n",
       "      <td>After interviewing with a few incredible peopl...</td>\n",
       "      <td>CONGRATS !  !  !  !  !</td>\n",
       "      <td>After interviewing with a few incredible peopl...</td>\n",
       "      <td>CONGRATS !  !  !  !  !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32002</td>\n",
       "      <td>I know GTC festival not happening next month b...</td>\n",
       "      <td></td>\n",
       "      <td>I know GTC festival not happening next month b...</td>\n",
       "      <td></td>\n",
       "      <td>I know GTC festival not happening next month b...</td>\n",
       "      <td></td>\n",
       "      <td>I know GTC festival not happening next month b...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32003</td>\n",
       "      <td>Lordy, my daughter just said, “I wonder how th...</td>\n",
       "      <td></td>\n",
       "      <td>Lordy ,  my daughter just said ,    \"  I wonde...</td>\n",
       "      <td></td>\n",
       "      <td>Lordy ,  my daughter just said ,    \"  I wonde...</td>\n",
       "      <td></td>\n",
       "      <td>Lordy ,  my daughter just said ,    \"  I wonde...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32004</td>\n",
       "      <td>THE UNEMPLOYMENT CLAIM SYSTEM SUCKS SO MUCH DICK</td>\n",
       "      <td>Watching everyone else get their weekly unempl...</td>\n",
       "      <td>THE UNEMPLOYMENT CLAIM SYSTEM SUCKS SO MUCH DICK</td>\n",
       "      <td>Watching everyone else get their weekly unempl...</td>\n",
       "      <td>THE UNEMPLOYMENT CLAIM SYSTEM SUCKS SO MUCH DICK</td>\n",
       "      <td>Watching everyone else get their weekly unempl...</td>\n",
       "      <td>THE UNEMPLOYMENT CLAIM SYSTEM SUCKS SO MUCH DICK</td>\n",
       "      <td>Watching everyone else get their weekly unempl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     idx                                               text  \\\n",
       "0  32000  Drop your cash app, use hashtag #BailoutHumansNow   \n",
       "1  32001  After interviewing with a few incredible peopl...   \n",
       "2  32002  I know GTC festival not happening next month b...   \n",
       "3  32003  Lordy, my daughter just said, “I wonder how th...   \n",
       "4  32004   THE UNEMPLOYMENT CLAIM SYSTEM SUCKS SO MUCH DICK   \n",
       "\n",
       "                                               reply  \\\n",
       "0                         $tyratomaro #BailoutHumans   \n",
       "1                                      CONGRATS!!!!!   \n",
       "2                                                      \n",
       "3                                                      \n",
       "4  Watching everyone else get their weekly unempl...   \n",
       "\n",
       "                                       map_punc_text  \\\n",
       "0  Drop your cash app ,  use hashtag  # BailoutHu...   \n",
       "1  After interviewing with a few incredible peopl...   \n",
       "2  I know GTC festival not happening next month b...   \n",
       "3  Lordy ,  my daughter just said ,    \"  I wonde...   \n",
       "4   THE UNEMPLOYMENT CLAIM SYSTEM SUCKS SO MUCH DICK   \n",
       "\n",
       "                                      map_punc_reply  \\\n",
       "0                      $ tyratomaro  # BailoutHumans   \n",
       "1                            CONGRATS !  !  !  !  !    \n",
       "2                                                      \n",
       "3                                                      \n",
       "4  Watching everyone else get their weekly unempl...   \n",
       "\n",
       "                                  map_more_punc_text  \\\n",
       "0  Drop your cash app ,  use hashtag  # BailoutHu...   \n",
       "1  After interviewing with a few incredible peopl...   \n",
       "2  I know GTC festival not happening next month b...   \n",
       "3  Lordy ,  my daughter just said ,    \"  I wonde...   \n",
       "4   THE UNEMPLOYMENT CLAIM SYSTEM SUCKS SO MUCH DICK   \n",
       "\n",
       "                                 map_more_punc_reply  \\\n",
       "0                      $ tyratomaro  # BailoutHumans   \n",
       "1                            CONGRATS !  !  !  !  !    \n",
       "2                                                      \n",
       "3                                                      \n",
       "4  Watching everyone else get their weekly unempl...   \n",
       "\n",
       "                                   map_demojize_text  \\\n",
       "0  Drop your cash app ,  use hashtag  # BailoutHu...   \n",
       "1  After interviewing with a few incredible peopl...   \n",
       "2  I know GTC festival not happening next month b...   \n",
       "3  Lordy ,  my daughter just said ,    \"  I wonde...   \n",
       "4   THE UNEMPLOYMENT CLAIM SYSTEM SUCKS SO MUCH DICK   \n",
       "\n",
       "                                  map_demojize_reply  \n",
       "0                      $ tyratomaro  # BailoutHumans  \n",
       "1                            CONGRATS !  !  !  !  !   \n",
       "2                                                     \n",
       "3                                                     \n",
       "4  Watching everyone else get their weekly unempl...  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "      <th>reply</th>\n",
       "      <th>map_punc_text</th>\n",
       "      <th>map_punc_reply</th>\n",
       "      <th>map_more_punc_text</th>\n",
       "      <th>map_more_punc_reply</th>\n",
       "      <th>map_demojize_text</th>\n",
       "      <th>map_demojize_reply</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36000</td>\n",
       "      <td>@Youngdeji_ I think if uzi and carti dropping ...</td>\n",
       "      <td></td>\n",
       "      <td>@ Youngdeji  -   I think if uzi and carti dro...</td>\n",
       "      <td></td>\n",
       "      <td>@ Youngdeji  -   I think if uzi and carti dro...</td>\n",
       "      <td></td>\n",
       "      <td>@ Youngdeji  -   I think if uzi and carti dro...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36001</td>\n",
       "      <td>For the third year in a row we are discussing ...</td>\n",
       "      <td></td>\n",
       "      <td>For the third year in a row we are discussing ...</td>\n",
       "      <td></td>\n",
       "      <td>For the third year in a row we are discussing ...</td>\n",
       "      <td></td>\n",
       "      <td>For the third year in a row we are discussing ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36002</td>\n",
       "      <td>dababy album sounds like it was made for nigga...</td>\n",
       "      <td>That's why you bought it.</td>\n",
       "      <td>dababy album sounds like it was made for nigga...</td>\n",
       "      <td>That  '  s why you bought it .</td>\n",
       "      <td>dababy album sounds like it was made for nigga...</td>\n",
       "      <td>That  '  s why you buy it .</td>\n",
       "      <td>dababy album sounds like it was made for nigga...</td>\n",
       "      <td>That  '  s why you buy it .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36003</td>\n",
       "      <td>Majority of Indians do not watch any sport oth...</td>\n",
       "      <td>@ZairaWasimmm got a great story because of the...</td>\n",
       "      <td>Majority of Indians do not watch any sport oth...</td>\n",
       "      <td>@ ZairaWasimmm got a great story because of t...</td>\n",
       "      <td>Majority of Indians do not watch any sport oth...</td>\n",
       "      <td>@ ZairaWasimmm got a great story because of t...</td>\n",
       "      <td>Majority of Indians do not watch any sport oth...</td>\n",
       "      <td>@ ZairaWasimmm got a great story because of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36004</td>\n",
       "      <td>everybody is just now listening to @madisonbee...</td>\n",
       "      <td></td>\n",
       "      <td>everybody is just now listening to  @ madisonb...</td>\n",
       "      <td></td>\n",
       "      <td>everybody is just now listen to  @ madisonbeer...</td>\n",
       "      <td></td>\n",
       "      <td>everybody is just now listen to  @ madisonbeer...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     idx                                               text  \\\n",
       "0  36000  @Youngdeji_ I think if uzi and carti dropping ...   \n",
       "1  36001  For the third year in a row we are discussing ...   \n",
       "2  36002  dababy album sounds like it was made for nigga...   \n",
       "3  36003  Majority of Indians do not watch any sport oth...   \n",
       "4  36004  everybody is just now listening to @madisonbee...   \n",
       "\n",
       "                                               reply  \\\n",
       "0                                                      \n",
       "1                                                      \n",
       "2                          That's why you bought it.   \n",
       "3  @ZairaWasimmm got a great story because of the...   \n",
       "4                                                      \n",
       "\n",
       "                                       map_punc_text  \\\n",
       "0   @ Youngdeji  -   I think if uzi and carti dro...   \n",
       "1  For the third year in a row we are discussing ...   \n",
       "2  dababy album sounds like it was made for nigga...   \n",
       "3  Majority of Indians do not watch any sport oth...   \n",
       "4  everybody is just now listening to  @ madisonb...   \n",
       "\n",
       "                                      map_punc_reply  \\\n",
       "0                                                      \n",
       "1                                                      \n",
       "2                    That  '  s why you bought it .    \n",
       "3   @ ZairaWasimmm got a great story because of t...   \n",
       "4                                                      \n",
       "\n",
       "                                  map_more_punc_text  \\\n",
       "0   @ Youngdeji  -   I think if uzi and carti dro...   \n",
       "1  For the third year in a row we are discussing ...   \n",
       "2  dababy album sounds like it was made for nigga...   \n",
       "3  Majority of Indians do not watch any sport oth...   \n",
       "4  everybody is just now listen to  @ madisonbeer...   \n",
       "\n",
       "                                 map_more_punc_reply  \\\n",
       "0                                                      \n",
       "1                                                      \n",
       "2                       That  '  s why you buy it .    \n",
       "3   @ ZairaWasimmm got a great story because of t...   \n",
       "4                                                      \n",
       "\n",
       "                                   map_demojize_text  \\\n",
       "0   @ Youngdeji  -   I think if uzi and carti dro...   \n",
       "1  For the third year in a row we are discussing ...   \n",
       "2  dababy album sounds like it was made for nigga...   \n",
       "3  Majority of Indians do not watch any sport oth...   \n",
       "4  everybody is just now listen to  @ madisonbeer...   \n",
       "\n",
       "                                  map_demojize_reply  \n",
       "0                                                     \n",
       "1                                                     \n",
       "2                       That  '  s why you buy it .   \n",
       "3   @ ZairaWasimmm got a great story because of t...  \n",
       "4                                                     "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output preprocessed to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_preprocessed = df_train[['idx', 'map_more_punc_text', 'map_more_punc_reply', 'categories']].copy()\n",
    "df_preprocessed.columns = ['idx', 'text', 'reply', 'categories']\n",
    "df_preprocessed.to_json('./preprocessed/preprocess_train.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed_dev = df_dev[['idx', 'map_more_punc_text', 'map_more_punc_reply']].copy()\n",
    "df_preprocessed_dev.columns = ['idx', 'text', 'reply']\n",
    "df_preprocessed_dev.to_json('./preprocessed/preprocess_dev.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed_test = df_test[['idx', 'map_more_punc_text', 'map_more_punc_reply']].copy()\n",
    "df_preprocessed_test.columns = ['idx', 'text', 'reply']\n",
    "df_preprocessed_test.to_json('./preprocessed/preprocess_test.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Don't have time to test, so won't use in testing phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed = df_train[['idx', 'map_demojize_text', 'map_demojize_reply', 'categories']].copy()\n",
    "df_preprocessed.columns = ['idx', 'text', 'reply', 'categories']\n",
    "df_preprocessed.to_json('./preprocessed/preprocess_train.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed_dev = df_dev[['idx', 'map_demojize_text', 'map_demojize_reply']].copy()\n",
    "df_preprocessed_dev.columns = ['idx', 'text', 'reply']\n",
    "df_preprocessed_dev.to_json('./preprocessed/preprocess_dev.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed_test = df_test[['idx', 'map_demojize_text', 'map_demojize_reply']].copy()\n",
    "df_preprocessed_test.columns = ['idx', 'text', 'reply']\n",
    "df_preprocessed_test.to_json('./preprocessed/preprocess_test.json', orient='records', lines=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
