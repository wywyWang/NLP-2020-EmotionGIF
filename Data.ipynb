{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from random import random\n",
    "import emoji\n",
    "from tqdm import notebook\n",
    "def tqdm(x, **kargs):\n",
    "    return notebook.tqdm(x, leave=False, **kargs)\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter, defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 23:38:24.530949 140680772192064 file_utils.py:39] PyTorch version 1.5.0 available.\n",
      "/home/ino/anaconda3/envs/TrackNet/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ino/anaconda3/envs/TrackNet/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ino/anaconda3/envs/TrackNet/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ino/anaconda3/envs/TrackNet/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ino/anaconda3/envs/TrackNet/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ino/anaconda3/envs/TrackNet/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer, RobertaModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of text in training data: 32000\n",
      "Number of text in categories: 43\n",
      "Number of text in developing data: 4000\n",
      "Number of text in testing data: 4000\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_json('./source/train_gold.json', lines=True)\n",
    "categories_type = pd.read_json('./source/categories.json', lines=True)\n",
    "df_dev = pd.read_json('./source/dev_unlabeled.json', lines=True)\n",
    "df_test = pd.read_json('./source/test_unlabeled.json', lines=True)\n",
    "print(\"Number of text in training data: {}\".format(df_train.shape[0]))\n",
    "print(\"Number of text in categories: {}\".format(categories_type.shape[1]))\n",
    "print(\"Number of text in developing data: {}\".format(df_dev.shape[0]))\n",
    "print(\"Number of text in testing data: {}\".format(df_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 23:38:28.482975 140680772192064 tokenization_utils.py:1015] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /home/ino/.cache/torch/transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "I0604 23:38:28.484291 140680772192064 tokenization_utils.py:1015] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /home/ino/.cache/torch/transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "I0604 23:38:29.440285 140680772192064 configuration_utils.py:285] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at /home/ino/.cache/torch/transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690\n",
      "I0604 23:38:29.441653 140680772192064 configuration_utils.py:321] Model config RobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0604 23:38:29.474719 140680772192064 modeling_utils.py:650] loading weights file https://cdn.huggingface.co/roberta-base-pytorch_model.bin from cache at /home/ino/.cache/torch/transformers/80b4a484eddeb259bec2f06a6f2f05d90934111628e0e1c09a33bd4a121358e1.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "model = RobertaModel.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "roberta_vocab = pd.read_json('roberta_vocab/vocab.json', typ='series')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>',\n",
       " '<pad>',\n",
       " '</s>',\n",
       " '<unk>',\n",
       " '.',\n",
       " 'Ä the',\n",
       " ',',\n",
       " 'Ä to',\n",
       " 'Ä and',\n",
       " 'Ä of',\n",
       " 'Ä a',\n",
       " 'Ä in',\n",
       " '-',\n",
       " 'Ä for',\n",
       " 'Ä that',\n",
       " 'Ä on',\n",
       " 'Ä is',\n",
       " 'Ã¢Ä¢',\n",
       " \"'s\",\n",
       " 'Ä with',\n",
       " 'Ä The',\n",
       " 'Ä was',\n",
       " 'Ä \"',\n",
       " 'Ä at',\n",
       " 'Ä it',\n",
       " 'Ä as',\n",
       " 'Ä said',\n",
       " 'Ä»',\n",
       " 'Ä be',\n",
       " 's',\n",
       " 'Ä by',\n",
       " 'Ä from',\n",
       " 'Ä are',\n",
       " 'Ä have',\n",
       " 'Ä has',\n",
       " ':',\n",
       " 'Ä (',\n",
       " 'Ä he',\n",
       " 'Ä I',\n",
       " 'Ä his',\n",
       " 'Ä will',\n",
       " 'Ä an',\n",
       " 'Ä this',\n",
       " ')',\n",
       " 'Ä Ã¢Ä¢',\n",
       " 'Ä not',\n",
       " 'Ä¿',\n",
       " 'Ä you',\n",
       " 'Ä¾',\n",
       " 'Ä their',\n",
       " 'Ä or',\n",
       " 'Ä they',\n",
       " 'Ä we',\n",
       " 'Ä but',\n",
       " 'Ä who',\n",
       " 'Ä more',\n",
       " 'Ä had',\n",
       " 'Ä been',\n",
       " 'Ä were',\n",
       " 'Ä about',\n",
       " ',\"',\n",
       " 'Ä which',\n",
       " 'Ä up',\n",
       " 'Ä its',\n",
       " 'Ä can',\n",
       " 'Ä one',\n",
       " 'Ä out',\n",
       " 'Ä also',\n",
       " 'Ä $',\n",
       " 'Ä her',\n",
       " 'Ä all',\n",
       " 'Ä after',\n",
       " '.\"',\n",
       " '/',\n",
       " 'Ä would',\n",
       " \"'t\",\n",
       " 'Ä year',\n",
       " 'Ä when',\n",
       " 'Ä first',\n",
       " 'Ä she',\n",
       " 'Ä two',\n",
       " 'Ä over',\n",
       " 'Ä people',\n",
       " 'Ä A',\n",
       " 'Ä our',\n",
       " 'Ä It',\n",
       " 'Ä time',\n",
       " 'Ä than',\n",
       " 'Ä into',\n",
       " 'Ä there',\n",
       " 't',\n",
       " 'Ä He',\n",
       " 'Ä new',\n",
       " 'Ä Ã¢Ä¢Ä¶',\n",
       " 'Ä last',\n",
       " 'Ä just',\n",
       " 'Ä In',\n",
       " 'Ä other',\n",
       " 'Ä so',\n",
       " 'Ä what',\n",
       " 'I',\n",
       " 'Ä like',\n",
       " 'a',\n",
       " 'Ä some',\n",
       " 'S',\n",
       " 'ÃƒÂ«',\n",
       " 'Ä them',\n",
       " 'Ä years',\n",
       " \"'\",\n",
       " 'Ä do',\n",
       " 'Ä your',\n",
       " 'Ä -',\n",
       " 'Ä 1',\n",
       " '\"',\n",
       " 'Ä if',\n",
       " 'Ä could',\n",
       " '?',\n",
       " 'Ä no',\n",
       " 'i',\n",
       " 'm',\n",
       " 'Ä get',\n",
       " 'Ä U',\n",
       " 'Ä now',\n",
       " 'Ä him',\n",
       " 'Ä back',\n",
       " 'Ä But',\n",
       " 'Ä Ã¢Ä¢Äµ',\n",
       " 'Ä my',\n",
       " \"Ä '\",\n",
       " 'Ä only',\n",
       " 'Ä three',\n",
       " ';',\n",
       " 'Ä 2',\n",
       " 'The',\n",
       " '1',\n",
       " 'Ä percent',\n",
       " 'Ä against',\n",
       " 'Ä before',\n",
       " 'Ä company',\n",
       " 'o',\n",
       " 'Ä Trump',\n",
       " 'Ä how',\n",
       " 'Ä because',\n",
       " 'Ä any',\n",
       " 'Ä most',\n",
       " 'Ä being',\n",
       " 'Ä make',\n",
       " 'Ä where',\n",
       " 'Ä during',\n",
       " 'Ä through',\n",
       " 'Ä while',\n",
       " '000',\n",
       " 'Ä This',\n",
       " 'Ä million',\n",
       " 'ing',\n",
       " 'Ä 3',\n",
       " 'Ä made',\n",
       " 'Ä well',\n",
       " 'Ä 10',\n",
       " 'Ä down',\n",
       " 'Ä off',\n",
       " 'Ä says',\n",
       " 'Ä me',\n",
       " 'Ä B',\n",
       " 'Ä going',\n",
       " 'Ä team',\n",
       " 'Ä We',\n",
       " 'Ä those',\n",
       " 'Ä government',\n",
       " 'Ä way',\n",
       " 'We',\n",
       " 'Ä many',\n",
       " 'Ä then',\n",
       " 'Ä work',\n",
       " 'Ä told',\n",
       " 'com',\n",
       " '2',\n",
       " 'Ä game',\n",
       " 'Ä And',\n",
       " 'in',\n",
       " 'year',\n",
       " 'Ä p',\n",
       " 'Ä very',\n",
       " 'Ä day',\n",
       " 'Ä home',\n",
       " 'Ä take',\n",
       " 'Ä week',\n",
       " 'Ä since',\n",
       " 'Ä New',\n",
       " 'Ä may',\n",
       " 'Ä even',\n",
       " 'Ä season',\n",
       " 'Ä see',\n",
       " 'Ä 2017',\n",
       " 'Ä state',\n",
       " 'Ä 5',\n",
       " 'ed',\n",
       " 'Ä should',\n",
       " 'Ä around',\n",
       " 'Ä 2018',\n",
       " 'Ä second',\n",
       " 'Ä us',\n",
       " 'Ä still',\n",
       " 'Ä much',\n",
       " 'Ä 4',\n",
       " 'Ä good',\n",
       " 'Ä think',\n",
       " '%',\n",
       " 'Ä S',\n",
       " 'Ä these',\n",
       " 'Ä market',\n",
       " 'Ä D',\n",
       " 'th',\n",
       " 'Ä go',\n",
       " \"'re\",\n",
       " 'Ä such',\n",
       " 'Ä know',\n",
       " 'Ä including',\n",
       " 'Ä don',\n",
       " 'y',\n",
       " 'Ä next',\n",
       " 'Ä P',\n",
       " 'Ä did',\n",
       " 'Ä under',\n",
       " 'Ä say',\n",
       " 'en',\n",
       " 'Ä L',\n",
       " 'Ä between',\n",
       " 'Ä per',\n",
       " 'Ä K',\n",
       " 'Ä C',\n",
       " 'Ä 6',\n",
       " 'Ä world',\n",
       " 'Ä part',\n",
       " 'Ä N',\n",
       " 'Ä right',\n",
       " 'Ä want',\n",
       " 'Ä four',\n",
       " '),',\n",
       " 'Ä high',\n",
       " 'Ä need',\n",
       " 're',\n",
       " 'e',\n",
       " 'It',\n",
       " 'Ä help',\n",
       " '5',\n",
       " '3',\n",
       " 'Ä country',\n",
       " 'Ä R',\n",
       " 'Ä police',\n",
       " 'A',\n",
       " 'Ä long',\n",
       " 'Ä They',\n",
       " 'Ä end',\n",
       " 'er',\n",
       " 'Ä T',\n",
       " 'Ä M',\n",
       " 'u',\n",
       " 'Ä both',\n",
       " 'Ä here',\n",
       " 'an',\n",
       " 'on',\n",
       " 'Ä 7',\n",
       " 'Ä de',\n",
       " 'Ä She',\n",
       " 'Ä business',\n",
       " 'Ä report',\n",
       " 'j',\n",
       " 'ers',\n",
       " 'Ä really',\n",
       " 'Ä President',\n",
       " 'ar',\n",
       " 'Ä G',\n",
       " 'Ä Friday',\n",
       " 'Ä F',\n",
       " 'Ä best',\n",
       " 'Ä same',\n",
       " 'Ä another',\n",
       " 'Ä set',\n",
       " 'old',\n",
       " 'Ä That',\n",
       " 'as',\n",
       " 'n',\n",
       " 'Ä come',\n",
       " 'Ä family',\n",
       " 'Ä public',\n",
       " 'Ä For',\n",
       " 'Ä As',\n",
       " '0',\n",
       " 'Ä H',\n",
       " 'Ä 8',\n",
       " 'Ä 20',\n",
       " 'Ä five',\n",
       " 'es',\n",
       " 'Ä Tuesday',\n",
       " 'Ä n',\n",
       " 'Ä Thursday',\n",
       " 'Ä quarter',\n",
       " 'h',\n",
       " 'Ä top',\n",
       " 'Ä got',\n",
       " 'Ä life',\n",
       " 'Ä Monday',\n",
       " 'Ä found',\n",
       " 'Ä use',\n",
       " 'Ä W',\n",
       " '4',\n",
       " 'Ä Wednesday',\n",
       " 'Ä own',\n",
       " 'Ä according',\n",
       " 'Ä play',\n",
       " 'Ä show',\n",
       " 'Ä St',\n",
       " 'Ä man',\n",
       " 'Ä left',\n",
       " 'Ä United',\n",
       " 'Ä 12',\n",
       " 'Ä place',\n",
       " 'Ä If',\n",
       " 'Ä lot',\n",
       " 'Ä former',\n",
       " 'Ä 0',\n",
       " ').',\n",
       " 'Ä support',\n",
       " 'ie',\n",
       " 'Ä billion',\n",
       " 'Ä t',\n",
       " 'Ä shares',\n",
       " '!',\n",
       " 'z',\n",
       " 'k',\n",
       " 'Ä State',\n",
       " 'Ä points',\n",
       " 'Ä group',\n",
       " 'Ä school',\n",
       " 'Ä information',\n",
       " 'Ä 2016',\n",
       " 'al',\n",
       " 'r',\n",
       " 'Ä win',\n",
       " 'Ä news',\n",
       " 'Ä used',\n",
       " 'Ä put',\n",
       " 'Ä city',\n",
       " 'Ä J',\n",
       " 'Ä There',\n",
       " 'Ä number',\n",
       " 'C',\n",
       " \"'ve\",\n",
       " 'Ä each',\n",
       " 'Ä too',\n",
       " 'Ä won',\n",
       " 'ly',\n",
       " 'Ä month',\n",
       " 'is',\n",
       " 'Ä added',\n",
       " 'Ä look',\n",
       " 'Ä better',\n",
       " 'Ä every',\n",
       " 'Ä &',\n",
       " 'Ä days',\n",
       " 'Ä 9',\n",
       " 'Ä took',\n",
       " 'Ä night',\n",
       " 'Ä e',\n",
       " 'Ä 11',\n",
       " 'os',\n",
       " 'Ä few',\n",
       " 'or',\n",
       " 'Ä North',\n",
       " 'Ä You',\n",
       " 'Ä third',\n",
       " 'Ä great',\n",
       " 'Ä called',\n",
       " 'Ä On',\n",
       " 'Ä past',\n",
       " 'Ä came',\n",
       " 'Ä months',\n",
       " 'Ä Saturday',\n",
       " 'Ä 15',\n",
       " 'Ä big',\n",
       " 'Ä E',\n",
       " 'Ä US',\n",
       " 'Ä things',\n",
       " 'Ä O',\n",
       " 'Ä d',\n",
       " 'Ä start',\n",
       " 'B',\n",
       " 'Ä stock',\n",
       " 'Ä 30',\n",
       " 'Ä women',\n",
       " 'Ä South',\n",
       " 'Ä May',\n",
       " 'Ä never',\n",
       " 'Ä president',\n",
       " 'Ä Sunday',\n",
       " 'Ä without',\n",
       " 'man',\n",
       " '8',\n",
       " 'Ä didn',\n",
       " 'Ä local',\n",
       " '6',\n",
       " 'Ä something',\n",
       " 'Ä case',\n",
       " 'Ä All',\n",
       " 'it',\n",
       " '7',\n",
       " 'Ä So',\n",
       " 'Ä children',\n",
       " 'Ä away',\n",
       " 'Ä little',\n",
       " 'Ä six',\n",
       " 'Ä City',\n",
       " 'Ä County',\n",
       " 'Ä data',\n",
       " 'at',\n",
       " 'Ä already',\n",
       " 'd',\n",
       " 'Ä money',\n",
       " 'Ä early',\n",
       " 'Ä across',\n",
       " 'Ä expected',\n",
       " 'Ä run',\n",
       " 'Ä later',\n",
       " 'am',\n",
       " 'Ä price',\n",
       " 'Ä games',\n",
       " 'Ä Mr',\n",
       " 'b',\n",
       " 'Ä might',\n",
       " 'Ä different',\n",
       " 'Ä reported',\n",
       " 'Ä deal',\n",
       " 'Ä media',\n",
       " 'Ä growth',\n",
       " 'Ä community',\n",
       " 'Ä China',\n",
       " \"'m\",\n",
       " 'c',\n",
       " 'Ä went',\n",
       " 'Ä No',\n",
       " 'Ä able',\n",
       " 'Ä making',\n",
       " 'Ä area',\n",
       " 'Ä far',\n",
       " 'Ä statement',\n",
       " 'Ä House',\n",
       " 'Ä working',\n",
       " 'M',\n",
       " 'Ä k',\n",
       " 'Ä seen',\n",
       " 'Ä companies',\n",
       " 'Ä today',\n",
       " 'Ä members',\n",
       " 'Ä until',\n",
       " 'Ä full',\n",
       " 'Ä again',\n",
       " 'Ä half',\n",
       " 'Ä share',\n",
       " 'le',\n",
       " 'Ä always',\n",
       " 'Ä court',\n",
       " 'l',\n",
       " 'and',\n",
       " 'Ä change',\n",
       " 'Ä find',\n",
       " '9',\n",
       " 'Ä system',\n",
       " 'Ä V',\n",
       " 'Ä York',\n",
       " 'Ä American',\n",
       " 'Ä head',\n",
       " 'Ä players',\n",
       " 'Ä does',\n",
       " 'Ä health',\n",
       " 'Ä m',\n",
       " 'Ä power',\n",
       " 'Ä point',\n",
       " 'Ä hit',\n",
       " 'Ä .',\n",
       " 'Ä --',\n",
       " 'Ä free',\n",
       " '.,',\n",
       " 'Ä lead',\n",
       " 'Ä several',\n",
       " 'Ä recent',\n",
       " 'Ä call',\n",
       " 'N',\n",
       " 'Ä law',\n",
       " 'Ä keep',\n",
       " 'Ä open',\n",
       " 'Ä News',\n",
       " 'Ä give',\n",
       " 'ia',\n",
       " 'Ä March',\n",
       " 'D',\n",
       " 'Ä National',\n",
       " 'Ä At',\n",
       " 'Ä times',\n",
       " 'Ä future',\n",
       " 'R',\n",
       " 'Ä 14',\n",
       " 'Ä June',\n",
       " 'Ä officials',\n",
       " 'Ä 18',\n",
       " 'Ä important',\n",
       " 'f',\n",
       " 'Ä final',\n",
       " 'Ä 13',\n",
       " 'Ä One',\n",
       " 'P',\n",
       " 'Ä following',\n",
       " 'Ä car',\n",
       " 'Ä least',\n",
       " 'Ä water',\n",
       " 'Ä event',\n",
       " 'Ä line',\n",
       " 'Ä move',\n",
       " 'Ä services',\n",
       " 'Ä having',\n",
       " 'Ä When',\n",
       " 'Ä students',\n",
       " 'Ä Police',\n",
       " 'el',\n",
       " 'Ä am',\n",
       " 'Ä Z',\n",
       " 'Ä side',\n",
       " 'Ä story',\n",
       " 'Ä due',\n",
       " 'Ä meeting',\n",
       " 'K',\n",
       " 'Ä must',\n",
       " 'Ä States',\n",
       " 'Ä likely',\n",
       " 'G',\n",
       " 'Ä continue',\n",
       " 'Ä ago',\n",
       " 'Ä party',\n",
       " 'Ä major',\n",
       " 'Ä industry',\n",
       " 'Ä less',\n",
       " '30',\n",
       " 'Ä un',\n",
       " 'Ä hard',\n",
       " 'Ä service',\n",
       " 'Ä 16',\n",
       " 'Ä looking',\n",
       " 'Ä held',\n",
       " 've',\n",
       " 'Ä whether',\n",
       " 'Ä July',\n",
       " 'Ä taken',\n",
       " 'Ä along',\n",
       " 'Ä asked',\n",
       " 'Ä started',\n",
       " 'Ä become',\n",
       " 'Ä forward',\n",
       " 'Ä research',\n",
       " 'Ä office',\n",
       " 'Ä political',\n",
       " 'to',\n",
       " 'Ä together',\n",
       " 'Ä getting',\n",
       " 'Ä plan',\n",
       " 'Ä 25',\n",
       " 'T',\n",
       " 'Ä among',\n",
       " 'Ä coming',\n",
       " 'Ä decision',\n",
       " 'Ä video',\n",
       " 'Ä 2015',\n",
       " 'g',\n",
       " 'Ä After',\n",
       " 'Ä security',\n",
       " 'L',\n",
       " 'Ä care',\n",
       " 'Ä given',\n",
       " 'Ä available',\n",
       " 'Ã¢Ä¢Ä¶',\n",
       " 'Ä s',\n",
       " 'Ä West',\n",
       " \"'ll\",\n",
       " 'Ä pay',\n",
       " 'Ä near',\n",
       " 'Ä saying',\n",
       " 'Ä announced',\n",
       " 'Ä program',\n",
       " 'Ä April',\n",
       " 'Ä real',\n",
       " 'Ä University',\n",
       " 'Ä With',\n",
       " 'AP',\n",
       " 'Ä social',\n",
       " 'Ä close',\n",
       " 'et',\n",
       " 'Ä current',\n",
       " 'Ä why',\n",
       " 'F',\n",
       " 'Ä To',\n",
       " 'Ä Twitter',\n",
       " 'Ä though',\n",
       " 'Ä 17',\n",
       " 'Ä taking',\n",
       " 'Ä Inc',\n",
       " 'Ä men',\n",
       " 'w',\n",
       " 'Ä comes',\n",
       " 'ley',\n",
       " 'Ä doing',\n",
       " 'Ä process',\n",
       " 'Ä John',\n",
       " 'ch',\n",
       " '00',\n",
       " 'Ä financial',\n",
       " 'Ä low',\n",
       " 'Ä enough',\n",
       " 'Ä While',\n",
       " 'Ä further',\n",
       " 'Ä post',\n",
       " 'Ä feel',\n",
       " 'st',\n",
       " 'Ä person',\n",
       " 'Ä Facebook',\n",
       " 'Ä World',\n",
       " 'Ä within',\n",
       " 'ad',\n",
       " 'Ä done',\n",
       " 'the',\n",
       " 'Ä late',\n",
       " 'Ä tax',\n",
       " 'Ä doesn',\n",
       " 'Ä thing',\n",
       " 'Ä national',\n",
       " 'Ä job',\n",
       " 'Ä using',\n",
       " 'Ä However',\n",
       " 'ic',\n",
       " 'Ä campaign',\n",
       " 'Ä record',\n",
       " 'Ä behind',\n",
       " '://',\n",
       " 'Ä Department',\n",
       " 'p',\n",
       " 'Ä others',\n",
       " 'Ä January',\n",
       " 'Ä order',\n",
       " 'Ä [',\n",
       " 'Ä sales',\n",
       " 'Ä yet',\n",
       " 'Ã„',\n",
       " 'Ä small',\n",
       " 'Ä series',\n",
       " 'Ä face',\n",
       " 'Ä What',\n",
       " 'Ä 50',\n",
       " 'Ä ever',\n",
       " 'Ä earlier',\n",
       " 'Ä love',\n",
       " 'up',\n",
       " 'Ä rights',\n",
       " 'Ä An',\n",
       " 'ist',\n",
       " 'Ä morning',\n",
       " 'Ä Washington',\n",
       " 'Ä young',\n",
       " 'Ä latest',\n",
       " 'Ä India',\n",
       " 'Ä trying',\n",
       " 'Ä fire',\n",
       " 'Ä led',\n",
       " 'Ä strong',\n",
       " 'Ä return',\n",
       " 'Ä level',\n",
       " 'O',\n",
       " 'Ä average',\n",
       " 'Ä period',\n",
       " 'Ä experience',\n",
       " 'ak',\n",
       " 'Ä possible',\n",
       " 'Ä believe',\n",
       " 'Ä include',\n",
       " 'Ä oil',\n",
       " 'Ä recently',\n",
       " 'Ä once',\n",
       " 'Ä known',\n",
       " 'Ä lost',\n",
       " 'Ä sure',\n",
       " 'us',\n",
       " 'Ä weeks',\n",
       " 'Ä food',\n",
       " 'Ä reports',\n",
       " 'Ä rating',\n",
       " 'Ä Minister',\n",
       " 'Ä woman',\n",
       " 'Ä provide',\n",
       " 'Ä project',\n",
       " 'Ä issue',\n",
       " 'Ä live',\n",
       " '10',\n",
       " 'Ä clear',\n",
       " 'he',\n",
       " 'Ä cost',\n",
       " 'Ä played',\n",
       " 'Ä released',\n",
       " 'Ä coach',\n",
       " 'v',\n",
       " 'Ä 24',\n",
       " 'Ä seven',\n",
       " 'Ä plans',\n",
       " 'Ä development',\n",
       " 'ur',\n",
       " 'Äº',\n",
       " 'Ä increase',\n",
       " 'This',\n",
       " 'Ä policy',\n",
       " 'Ä cent',\n",
       " 'Ä based',\n",
       " 'E',\n",
       " 'il',\n",
       " 'Ä December',\n",
       " 'Ä global',\n",
       " 'Ä trade',\n",
       " 'Ä hours',\n",
       " 'Ä higher',\n",
       " 'Ä goal',\n",
       " 'H',\n",
       " 'Ä Al',\n",
       " 'Ä 100',\n",
       " 'Ä minutes',\n",
       " 'Ä election',\n",
       " 'Ä America',\n",
       " 'Ä rate',\n",
       " 'Ä Ch',\n",
       " 'Ä 21',\n",
       " '...',\n",
       " 'Ä White',\n",
       " 'Ä director',\n",
       " 'Ä position',\n",
       " 'Ä shot',\n",
       " 'Ä large',\n",
       " 'Ä c',\n",
       " 'Ä b',\n",
       " ']',\n",
       " 'Ä issues',\n",
       " 'Ä death',\n",
       " 'Ä building',\n",
       " 'Ä total',\n",
       " 'Ä often',\n",
       " 'Ä v',\n",
       " 'Ä countries',\n",
       " 'Ä history',\n",
       " 'Ä outside',\n",
       " 'Ä federal',\n",
       " 'Ä 19',\n",
       " 'Ä fact',\n",
       " 'Ä High',\n",
       " 'Ä career',\n",
       " 'im',\n",
       " 'Ä international',\n",
       " 'Ä November',\n",
       " 'Ä front',\n",
       " 'Ä kind',\n",
       " 'Ä key',\n",
       " 'ra',\n",
       " 'Ä San',\n",
       " 'Ä short',\n",
       " 'Ä name',\n",
       " 'Ä According',\n",
       " 'Ä course',\n",
       " 'Ä re',\n",
       " 'Ä wanted',\n",
       " 'W',\n",
       " 'Ä September',\n",
       " 'Ä interest',\n",
       " 'Ä role',\n",
       " 'Ä results',\n",
       " 'Ä economic',\n",
       " 'Ä 2014',\n",
       " 'Ä chance',\n",
       " 'Ä October',\n",
       " 'Ä special',\n",
       " 'Ä official',\n",
       " 'Ä needs',\n",
       " 'um',\n",
       " 'Ä l',\n",
       " 'Ä products',\n",
       " 'Ä non',\n",
       " 'Ä @',\n",
       " 'Ä Bank',\n",
       " 'Ä ahead',\n",
       " 'Ä house',\n",
       " 'U',\n",
       " 'Ä board',\n",
       " 'Ä old',\n",
       " 'Ä saw',\n",
       " 'Ä lower',\n",
       " 'Ä European',\n",
       " 'Ä control',\n",
       " 'Ä Russia',\n",
       " 'Ä eight',\n",
       " 'Ä release',\n",
       " 'Ä potential',\n",
       " 'Ä thought',\n",
       " 'Ä investigation',\n",
       " 'Ä online',\n",
       " 'based',\n",
       " 'Ä technology',\n",
       " 'Ä Donald',\n",
       " 'id',\n",
       " 'Ä body',\n",
       " 'Ä risk',\n",
       " 'ian',\n",
       " 'Ä capital',\n",
       " 'Ä staff',\n",
       " 'Ä action',\n",
       " 'Ä League',\n",
       " 'Ä playing',\n",
       " 'Ä makes',\n",
       " 'Ä almost',\n",
       " 'Ä performance',\n",
       " 'Ä 22',\n",
       " 'Ä g',\n",
       " 'Ä film',\n",
       " 'Ä nearly',\n",
       " 'Ä Center',\n",
       " 'Ä visit',\n",
       " 'Ä Group',\n",
       " 'Ä bank',\n",
       " 'Ä bit',\n",
       " 'Ä received',\n",
       " 'Ä August',\n",
       " 'Ä military',\n",
       " 'Ä His',\n",
       " 'ine',\n",
       " 'Ä chief',\n",
       " 'Ä School',\n",
       " 'Ä bring',\n",
       " 'Ä Court',\n",
       " 'Ä (@',\n",
       " 'Ä means',\n",
       " 'Ä Sh',\n",
       " 'Ä fans',\n",
       " 'Ä se',\n",
       " 'Ä 40',\n",
       " '20',\n",
       " '\".',\n",
       " 'V',\n",
       " 'Ä cut',\n",
       " 'Ä killed',\n",
       " 'Ä #',\n",
       " 'Ä prices',\n",
       " 'Ä gave',\n",
       " 'Ä Street',\n",
       " 'ir',\n",
       " 'Ä Y',\n",
       " 'Ä currently',\n",
       " 'Ä f',\n",
       " 'ay',\n",
       " 'ne',\n",
       " 'te',\n",
       " 'Ä try',\n",
       " 'Ä Park',\n",
       " 'Ä¥',\n",
       " 'J',\n",
       " 'Ä question',\n",
       " 'Ä hand',\n",
       " 'Ä economy',\n",
       " 'Ä investors',\n",
       " 'able',\n",
       " 'Ä player',\n",
       " 'Ä By',\n",
       " 'Ä David',\n",
       " 'Ä loss',\n",
       " 'ab',\n",
       " 'Ä below',\n",
       " 'Ä wrote',\n",
       " 'co',\n",
       " 'ate',\n",
       " 'Ä running',\n",
       " 'un',\n",
       " 'Ä began',\n",
       " 'Ä single',\n",
       " 'Ä field',\n",
       " 'Ä 23',\n",
       " 'Ä leader',\n",
       " 'Ä w',\n",
       " 'Ä California',\n",
       " 'Ä fourth',\n",
       " 'Ä actually',\n",
       " 'Ä list',\n",
       " 'll',\n",
       " 'Ä couple',\n",
       " 'Ä study',\n",
       " 'Ä teams',\n",
       " 'He',\n",
       " 'ah',\n",
       " 'Ä Canada',\n",
       " 'Ä la',\n",
       " 'Ä result',\n",
       " 'Ä access',\n",
       " 'Ä vote',\n",
       " 'Ä More',\n",
       " 'Ä February',\n",
       " 'Ä revenue',\n",
       " 'Ä offer',\n",
       " 'Ä let',\n",
       " 'ier',\n",
       " 'Ä buy',\n",
       " 'Ä attack',\n",
       " 'Ä black',\n",
       " 'Ä r',\n",
       " 'Ä areas',\n",
       " 'Ä stop',\n",
       " 'Ä impact',\n",
       " 'Ä match',\n",
       " 'Ä investment',\n",
       " 'Ä customers',\n",
       " 'Ä leaders',\n",
       " 'ies',\n",
       " 'Ä member',\n",
       " 'Ä child',\n",
       " 'Ä road',\n",
       " 'ul',\n",
       " 'Ä value',\n",
       " 'Ä shows',\n",
       " 'Ä Dr',\n",
       " 'Ä De',\n",
       " 'ant',\n",
       " 'Ä London',\n",
       " 'Ä room',\n",
       " 'Ä music',\n",
       " 'Ä production',\n",
       " 'Ä anything',\n",
       " 'Ä firm',\n",
       " 'Ä biggest',\n",
       " 'Ä air',\n",
       " 'Ä problem',\n",
       " 'Ä general',\n",
       " 'Ä wasn',\n",
       " 'Ä i',\n",
       " 'Ä private',\n",
       " 'Ä especially',\n",
       " 'Ä administration',\n",
       " 'Ä additional',\n",
       " 'Ä Co',\n",
       " 'Ä opportunity',\n",
       " 'Ä hold',\n",
       " '&',\n",
       " 'Ä matter',\n",
       " 'Ä senior',\n",
       " 'Ä club',\n",
       " 'Ä someone',\n",
       " 'Ä Ãƒ',\n",
       " 'Ä East',\n",
       " 'Ä 2019',\n",
       " \".'\",\n",
       " 'Ä needed',\n",
       " 'Ä James',\n",
       " 'time',\n",
       " 'Ä however',\n",
       " 'Ä everything',\n",
       " 'Ä everyone',\n",
       " 'Ä died',\n",
       " 'Ä involved',\n",
       " 'Ä friends',\n",
       " 'Ä isn',\n",
       " 'Ä worth',\n",
       " 'ik',\n",
       " 'Ä Cup',\n",
       " 'Ä showed',\n",
       " 'There',\n",
       " 'Ä 28',\n",
       " 'Ä meet',\n",
       " 'Ä 26',\n",
       " 'Ä 27',\n",
       " 'Y',\n",
       " 'Ä region',\n",
       " 'Ä Press',\n",
       " 'Ä Now',\n",
       " 'Ä son',\n",
       " 'Ä space',\n",
       " 'Ä leading',\n",
       " 'Ä states',\n",
       " 'Ä weekend',\n",
       " 'Ä Ã‚Â£',\n",
       " 'Ä mother',\n",
       " 'Ä previous',\n",
       " 'Ä UK',\n",
       " 'Ä Michael',\n",
       " 'Ä leave',\n",
       " 'est',\n",
       " 'em',\n",
       " 'Ä z',\n",
       " 'Ä Some',\n",
       " 'ors',\n",
       " 'out',\n",
       " '15',\n",
       " 'Ä war',\n",
       " 'Ä website',\n",
       " 'Ä star',\n",
       " ...]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(roberta_vocab.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab(corpus):\n",
    "    vocabulary = Counter()\n",
    "    for sentance in corpus:\n",
    "        for word in sentance.split():\n",
    "            vocabulary.update([word])\n",
    "    return vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_coverage(vocabs, roberta_vocab):\n",
    "    known_words = {}\n",
    "    unknown_words = {}\n",
    "    known_count = 0\n",
    "    unknown_count = 0\n",
    "    for word in tqdm(vocabs.keys(), desc='Checking: '):\n",
    "        if word in list(roberta_vocab.keys()):\n",
    "            known_words[word] = roberta_vocab[word]\n",
    "            known_count += vocabs[word]\n",
    "        else:\n",
    "            unknown_words[word] = vocabs[word]\n",
    "            unknown_count += vocabs[word]\n",
    "    print(\"Found embeddings for {:.3%} ({} / {}) of vocab\".format(len(known_words) / len(vocabs), len(known_words), len(vocabs)))\n",
    "    print(\"Found embeddings for {:.3%} ({} / {}) of all text\".format(known_count / (known_count + unknown_count), known_count, (known_count + unknown_count)))\n",
    "    return unknown_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train text unique vocab count is: 68961\n",
      "train reply unique vocab count is: 25542\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=68961.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 8.177% (5639 / 68961) of vocab\n",
      "Found embeddings for 65.985% (432177 / 654963) of all text\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=25542.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 14.451% (3691 / 25542) of vocab\n",
      "Found embeddings for 63.198% (68504 / 108395) of all text\n"
     ]
    }
   ],
   "source": [
    "train_text_vocab = get_vocab(df_train['text'].values)\n",
    "train_reply_vocab = get_vocab(df_train['reply'].values)\n",
    "print(\"train text unique vocab count is: {}\".format(len(train_text_vocab)))\n",
    "print(\"train reply unique vocab count is: {}\".format(len(train_reply_vocab)))\n",
    "unknown_text = check_coverage(train_text_vocab, roberta_vocab)\n",
    "print()\n",
    "unknown_reply = check_coverage(train_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev text unique vocab count is: 17684\n",
      "dev reply unique vocab count is: 5360\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=17684.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 17.830% (3153 / 17684) of vocab\n",
      "Found embeddings for 65.711% (54522 / 82972) of all text\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=5360.0, style=ProgressStyle(description_â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 26.978% (1446 / 5360) of vocab\n",
      "Found embeddings for 62.345% (8626 / 13836) of all text\n"
     ]
    }
   ],
   "source": [
    "dev_text_vocab = get_vocab(df_dev['text'].values)\n",
    "dev_reply_vocab = get_vocab(df_dev['reply'].values)\n",
    "print(\"dev text unique vocab count is: {}\".format(len(dev_text_vocab)))\n",
    "print(\"dev reply unique vocab count is: {}\".format(len(dev_reply_vocab)))\n",
    "unknown_text = check_coverage(dev_text_vocab, roberta_vocab)\n",
    "print()\n",
    "unknown_reply = check_coverage(dev_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test text unique vocab count is: 17338\n",
      "test reply unique vocab count is: 5187\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=17338.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 18.191% (3154 / 17338) of vocab\n",
      "Found embeddings for 66.134% (54166 / 81903) of all text\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=5187.0, style=ProgressStyle(description_â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 28.070% (1456 / 5187) of vocab\n",
      "Found embeddings for 63.152% (8360 / 13238) of all text\n"
     ]
    }
   ],
   "source": [
    "test_text_vocab = get_vocab(df_test['text'].values)\n",
    "test_reply_vocab = get_vocab(df_test['reply'].values)\n",
    "print(\"test text unique vocab count is: {}\".format(len(test_text_vocab)))\n",
    "print(\"test reply unique vocab count is: {}\".format(len(test_reply_vocab)))\n",
    "unknown_text = check_coverage(test_text_vocab, roberta_vocab)\n",
    "print()\n",
    "unknown_reply = check_coverage(test_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try to convert to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab_lower(corpus):\n",
    "    vocabulary = Counter()\n",
    "    for sentance in corpus:\n",
    "        for word in sentance.lower().split():\n",
    "            vocabulary.update([word])\n",
    "    return vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train text unique vocab count is: 60613\n",
      "train reply unique vocab count is: 22586\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=60613.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 6.301% (3819 / 60613) of vocab\n",
      "Found embeddings for 65.900% (431618 / 654963) of all text\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=22586.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 11.804% (2666 / 22586) of vocab\n",
      "Found embeddings for 63.508% (68840 / 108395) of all text\n"
     ]
    }
   ],
   "source": [
    "train_text_vocab = get_vocab_lower(df_train['text'].values)\n",
    "train_reply_vocab = get_vocab_lower(df_train['reply'].values)\n",
    "print(\"train text unique vocab count is: {}\".format(len(train_text_vocab)))\n",
    "print(\"train reply unique vocab count is: {}\".format(len(train_reply_vocab)))\n",
    "unknown_text_lower = check_coverage(train_text_vocab, roberta_vocab)\n",
    "print()\n",
    "unknown_reply_lower = check_coverage(train_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev text unique vocab count is: 15888\n",
      "dev reply unique vocab count is: 4818\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=15888.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 14.772% (2347 / 15888) of vocab\n",
      "Found embeddings for 65.687% (54502 / 82972) of all text\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=4818.0, style=ProgressStyle(description_â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 24.408% (1176 / 4818) of vocab\n",
      "Found embeddings for 63.075% (8727 / 13836) of all text\n"
     ]
    }
   ],
   "source": [
    "dev_text_vocab = get_vocab_lower(df_dev['text'].values)\n",
    "dev_reply_vocab = get_vocab_lower(df_dev['reply'].values)\n",
    "print(\"dev text unique vocab count is: {}\".format(len(dev_text_vocab)))\n",
    "print(\"dev reply unique vocab count is: {}\".format(len(dev_reply_vocab)))\n",
    "unknown_text = check_coverage(dev_text_vocab, roberta_vocab)\n",
    "print()\n",
    "unknown_reply = check_coverage(dev_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test text unique vocab count is: 15473\n",
      "test reply unique vocab count is: 4674\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=15473.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 15.130% (2341 / 15473) of vocab\n",
      "Found embeddings for 66.148% (54177 / 81903) of all text\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=4674.0, style=ProgressStyle(description_â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 25.246% (1180 / 4674) of vocab\n",
      "Found embeddings for 63.484% (8404 / 13238) of all text\n"
     ]
    }
   ],
   "source": [
    "test_text_vocab = get_vocab_lower(df_test['text'].values)\n",
    "test_reply_vocab = get_vocab_lower(df_test['reply'].values)\n",
    "print(\"test text unique vocab count is: {}\".format(len(test_text_vocab)))\n",
    "print(\"test reply unique vocab count is: {}\".format(len(test_reply_vocab)))\n",
    "unknown_text = check_coverage(test_text_vocab, roberta_vocab)\n",
    "print()\n",
    "unknown_reply = check_coverage(test_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add some known in tokenizer but unknown in lower case (zero is weird)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def add_lower(vocabs, roberta_vocab):\n",
    "#     count = 0\n",
    "#     add_tokens = []\n",
    "#     for word in tqdm(vocabs, desc='Searching: '):\n",
    "#         if word in list(roberta_vocab.keys()) and word.lower() not in list(roberta_vocab.keys()):\n",
    "#             add_tokens.append(word.lower())\n",
    "#             count += 1\n",
    "#     print(add_tokens)\n",
    "#     num_add = tokenizer.add_tokens(add_tokens)\n",
    "#     model.resize_token_embeddings(len(tokenizer))\n",
    "#     print(\"Added {} words to embedding\".format(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_lower(train_text_vocab, roberta_vocab)\n",
    "# add_lower(train_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show some unknown tokens!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'@youngdeji_': 1,\n",
       " 'uzi': 2,\n",
       " 'carti': 4,\n",
       " 'monday': 3,\n",
       " 'gotta': 18,\n",
       " 'lil': 11,\n",
       " 'woah': 1,\n",
       " 'weâ€™re': 27,\n",
       " 'discussing': 5,\n",
       " 'trading': 4,\n",
       " 'picks': 2,\n",
       " 'safety.': 1,\n",
       " 'dababy': 4,\n",
       " 'sounds': 6,\n",
       " 'niggas': 10,\n",
       " 'kitchen': 7,\n",
       " 'dennyâ€™s': 1,\n",
       " 'indians': 3,\n",
       " 'donâ€™t': 126,\n",
       " 'sport': 2,\n",
       " 'cricket.': 1,\n",
       " 'wouldâ€™ve': 3,\n",
       " 'came': 17,\n",
       " 'out.': 21,\n",
       " 'zaira': 1,\n",
       " 'wasim': 1,\n",
       " 'hardwork': 1,\n",
       " 'screen.': 1,\n",
       " 'justify': 2,\n",
       " 'mentality': 1,\n",
       " 'sick.': 4,\n",
       " 'everybody': 8,\n",
       " 'listening': 8,\n",
       " '@madisonbeer': 1,\n",
       " 'selfish': 1,\n",
       " 'iâ€™ve': 57,\n",
       " 'â€œas': 2,\n",
       " 'pleaseâ€': 1,\n",
       " 'wtf': 8,\n",
       " '@lupeloops': 1,\n",
       " 'weekend': 10,\n",
       " 'ğŸ˜“': 3,\n",
       " \"haven't\": 7,\n",
       " 'ops,': 1,\n",
       " \"ain't\": 6,\n",
       " 'biggest': 9,\n",
       " 'disappointments....': 1,\n",
       " 'hardest': 4,\n",
       " 'work.': 6,\n",
       " 'cried.': 1,\n",
       " 'hospitals': 4,\n",
       " 'settings,': 1,\n",
       " 'home,': 3,\n",
       " 'it.': 94,\n",
       " 'crap': 3,\n",
       " 'nightmare.': 3,\n",
       " 'accounts': 8,\n",
       " 'hacked': 5,\n",
       " 'spamming': 4,\n",
       " 'mad.': 4,\n",
       " 'couldnâ€™t': 10,\n",
       " 'back.': 14,\n",
       " 'tried': 14,\n",
       " 'confronting': 4,\n",
       " 'hacker': 3,\n",
       " 'replying': 5,\n",
       " 'â€œwho': 4,\n",
       " 'are?!â€': 3,\n",
       " 'physically': 5,\n",
       " 'attacked': 4,\n",
       " 'spam': 4,\n",
       " 'messages': 6,\n",
       " 'woke': 17,\n",
       " 'up.': 25,\n",
       " 'ğŸ˜°': 4,\n",
       " 'understands.': 1,\n",
       " 'prophet.': 1,\n",
       " 'forgive': 1,\n",
       " 'doing?': 4,\n",
       " 'iâ€™m': 263,\n",
       " 'quarantine': 44,\n",
       " 'therapist': 1,\n",
       " 'everyday': 9,\n",
       " 'trying': 37,\n",
       " 'navigate': 1,\n",
       " 'plans': 3,\n",
       " 'overwhelm': 1,\n",
       " 'overreacting,': 1,\n",
       " 'obsessing,': 1,\n",
       " 'worrying,': 1,\n",
       " 'eventually': 3,\n",
       " 'disassociating.': 1,\n",
       " 'here!': 2,\n",
       " 'gates': 15,\n",
       " 'covid-19': 34,\n",
       " 'vaccine?': 11,\n",
       " 'cancel': 6,\n",
       " 'myrtle': 1,\n",
       " 'am.': 3,\n",
       " 'spiraling.': 1,\n",
       " 'laughing': 8,\n",
       " 'strategically': 1,\n",
       " 'dynamically': 1,\n",
       " 'sucking': 8,\n",
       " 'dick': 20,\n",
       " 'grudges.': 1,\n",
       " 'so,': 7,\n",
       " 'mind,': 2,\n",
       " \"who's\": 9,\n",
       " 'apologise': 3,\n",
       " 'me?': 11,\n",
       " 'oldrich': 6,\n",
       " 'judging': 7,\n",
       " 'people,': 13,\n",
       " 'judgement,': 6,\n",
       " 'kindness,': 8,\n",
       " 'hungry': 7,\n",
       " 'followers': 23,\n",
       " '(now': 6,\n",
       " 'â€œteammatesâ€)!': 6,\n",
       " 'canâ€™t': 55,\n",
       " 'hyperventilate': 1,\n",
       " 'bag.': 2,\n",
       " 'â˜¹ï¸': 2,\n",
       " 'myself': 45,\n",
       " 'could.': 1,\n",
       " 'able,': 1,\n",
       " 'yeah?': 1,\n",
       " 'you.': 35,\n",
       " 'ğŸ’›': 2,\n",
       " 'supportive': 2,\n",
       " '\\U0001f97a': 14,\n",
       " 'hands,': 1,\n",
       " \"they're\": 12,\n",
       " \"you're\": 45,\n",
       " 'worried': 6,\n",
       " 'trumpâ€™s': 10,\n",
       " 'health?': 1,\n",
       " \"i'm\": 186,\n",
       " 'coffee': 11,\n",
       " 'lunch.': 1,\n",
       " \"who'd\": 1,\n",
       " 'join?': 1,\n",
       " 'guaging': 1,\n",
       " 'interest.': 2,\n",
       " 'trump,': 5,\n",
       " 'script,': 1,\n",
       " 'begins': 2,\n",
       " 'saying': 23,\n",
       " 'undertaken': 1,\n",
       " \"country's\": 1,\n",
       " 'greatest': 5,\n",
       " 'mobilization': 1,\n",
       " '\"since': 1,\n",
       " 'ii.\"': 1,\n",
       " 'says': 31,\n",
       " 'unleashed': 1,\n",
       " '\"most': 1,\n",
       " 'potent': 1,\n",
       " 'all\":': 1,\n",
       " \"americans'\": 1,\n",
       " 'courage.': 2,\n",
       " 'tells': 7,\n",
       " \"who've\": 2,\n",
       " 'loved': 10,\n",
       " 'pain.': 6,\n",
       " 'yesterday.': 2,\n",
       " 'screenshots': 2,\n",
       " 'idk': 13,\n",
       " 'hear': 22,\n",
       " 'proud': 12,\n",
       " 'blonde': 3,\n",
       " 'me.': 58,\n",
       " 'better.': 14,\n",
       " 'wna': 2,\n",
       " 'fucj': 1,\n",
       " 'bcs': 1,\n",
       " 'insecure': 1,\n",
       " 'relationship': 10,\n",
       " 'fucked': 14,\n",
       " 'shout': 10,\n",
       " 'trash.': 2,\n",
       " 'trash': 12,\n",
       " 'yourself.': 2,\n",
       " 'natin': 1,\n",
       " 'joke': 6,\n",
       " 'circulating': 1,\n",
       " 'germany:': 1,\n",
       " '\"what': 3,\n",
       " 'borders': 2,\n",
       " 'stupidity?\"': 1,\n",
       " '\"mexico': 1,\n",
       " 'canada!\"': 1,\n",
       " 'already': 18,\n",
       " 'taken': 10,\n",
       " 'what?!': 1,\n",
       " 'waiting': 20,\n",
       " '#whyruep12': 1,\n",
       " 'simpsons': 2,\n",
       " 'installing': 23,\n",
       " \"#scottyfrommarketing's\": 23,\n",
       " 'app.': 26,\n",
       " 'gif.': 26,\n",
       " 'hollyweird': 1,\n",
       " 'pedophile': 1,\n",
       " 'iâ€™ll': 47,\n",
       " 'grandiloquent': 1,\n",
       " 'hypocrites': 1,\n",
       " 'kissed': 3,\n",
       " 'joe': 24,\n",
       " 'biden,': 1,\n",
       " 'teenage': 4,\n",
       " 'â€œi': 7,\n",
       " 'jumpinâ€™': 1,\n",
       " 'lapâ€': 1,\n",
       " 'biden': 26,\n",
       " 'congress': 6,\n",
       " 'now,': 20,\n",
       " 'petulance,': 1,\n",
       " 'gridlock,': 1,\n",
       " 'vendettas': 1,\n",
       " 'downright': 1,\n",
       " 'belongs': 3,\n",
       " 'idea': 15,\n",
       " 'itâ€™s': 117,\n",
       " 'watches': 1,\n",
       " 'â€˜bates': 1,\n",
       " 'motelâ€™??': 1,\n",
       " 'spoilers!!': 1,\n",
       " '3.': 7,\n",
       " 'damn': 22,\n",
       " 'yâ€™all,': 1,\n",
       " 'normanâ€™s': 1,\n",
       " 'nerves.': 1,\n",
       " 'heâ€™s': 27,\n",
       " 'punch': 1,\n",
       " 'ğŸ¤·ğŸ»\\u200dâ™€ï¸ğŸ¤·ğŸ»\\u200dâ™€ï¸': 1,\n",
       " 'wanted': 25,\n",
       " 'tonight': 21,\n",
       " 'feelings': 5,\n",
       " 'hurt': 6,\n",
       " \"i've\": 31,\n",
       " 'hiding': 5,\n",
       " 'night.': 9,\n",
       " 'feeling': 42,\n",
       " 'bombarded': 2,\n",
       " 'hurtful': 3,\n",
       " 'words.': 2,\n",
       " 'sapped': 2,\n",
       " 'dry.': 2,\n",
       " '#salt': 2,\n",
       " 'fancy': 1,\n",
       " 'skateboard': 1,\n",
       " 'iâ€™d': 12,\n",
       " 'liberate': 16,\n",
       " 'ass.': 4,\n",
       " 'ğŸ™Œ': 2,\n",
       " 'york': 8,\n",
       " \"post's\": 1,\n",
       " \"halladay's\": 1,\n",
       " 'fucking': 46,\n",
       " 'garbage': 2,\n",
       " 'today.': 41,\n",
       " '\"some': 2,\n",
       " 'wonâ€™t': 9,\n",
       " 'halladay': 1,\n",
       " 'transportation': 2,\n",
       " 'fame': 2,\n",
       " 'pitcher': 1,\n",
       " 'amphetamines': 1,\n",
       " 'morphine\"': 1,\n",
       " '$$?': 2,\n",
       " '$200': 3,\n",
       " 'hours.': 14,\n",
       " '@loyalgiveaways': 2,\n",
       " ':)': 10,\n",
       " 'hug': 78,\n",
       " 'somn': 1,\n",
       " 'suck': 15,\n",
       " 'dick,': 3,\n",
       " 'ainâ€™t': 13,\n",
       " 'stopping': 2,\n",
       " \"don't\": 97,\n",
       " 'talent': 2,\n",
       " 'conversation': 7,\n",
       " 'going,': 3,\n",
       " 'lot.': 3,\n",
       " \"it's\": 125,\n",
       " 'reopen': 9,\n",
       " 'america.': 7,\n",
       " 'ğŸ™‹\\u200dâ™‚ï¸ğŸ™‹\\u200dâ™‚ï¸ğŸ™‹\\u200dâ™‚ï¸': 2,\n",
       " 'in:': 8,\n",
       " 'china': 27,\n",
       " 'denies': 6,\n",
       " 'extent': 6,\n",
       " 'coronavirus': 41,\n",
       " 'outbreak': 7,\n",
       " 'needğŸŒ¹solo': 1,\n",
       " 'ğŸŒ¹sanağŸŒ¹projectsğŸŒ¹': 1,\n",
       " 'knows': 10,\n",
       " 'rapists?': 1,\n",
       " 'em?': 1,\n",
       " 'morning!': 1,\n",
       " 'today!': 7,\n",
       " 'specifically?': 1,\n",
       " '#svtraintobusan': 1,\n",
       " 'hugs': 20,\n",
       " 'smh': 6,\n",
       " 'unlimited': 1,\n",
       " 'ğŸ˜­': 16,\n",
       " '2020!': 2,\n",
       " 'lockdowns': 3,\n",
       " 'quarantining.': 1,\n",
       " 'conflated.': 1,\n",
       " 'welcomed': 2,\n",
       " 'assume': 3,\n",
       " 'risk.': 1,\n",
       " '@dxvilishangxl': 1,\n",
       " 'cute': 12,\n",
       " 'honestly': 14,\n",
       " 'veniece': 1,\n",
       " 'drive-in': 1,\n",
       " 'theater': 4,\n",
       " 'punks': 1,\n",
       " 'nowadays': 1,\n",
       " 'smuggle': 1,\n",
       " 'trunk': 1,\n",
       " 'beers': 1,\n",
       " 'days!': 1,\n",
       " 'america': 65,\n",
       " 'up?': 10,\n",
       " 'no?': 11,\n",
       " 'prepare': 6,\n",
       " 'rounds': 3,\n",
       " 'negotiations,': 3,\n",
       " 'reiterate': 3,\n",
       " \"government's\": 3,\n",
       " 'transition': 8,\n",
       " 'following': 25,\n",
       " 'withdrawal': 3,\n",
       " 'eu.': 3,\n",
       " 'december': 6,\n",
       " 'year.': 10,\n",
       " 'extend': 6,\n",
       " 'no.': 12,\n",
       " '1/2': 4,\n",
       " 'app,': 24,\n",
       " 'hashtag': 26,\n",
       " '#bailouthumansnow': 25,\n",
       " '@shelleymcelyea1': 1,\n",
       " 'birthday,': 3,\n",
       " 'darling': 2,\n",
       " 'â¤ï¸ğŸ’‹ğŸğŸ‰ğŸ°ğŸˆ': 1,\n",
       " '#giveaway': 3,\n",
       " '$25': 4,\n",
       " '24hours..': 1,\n",
       " 'like/rt/tag': 1,\n",
       " '(must': 1,\n",
       " 'me)': 1,\n",
       " 'sponsor': 1,\n",
       " 'following?': 1,\n",
       " 'discuss': 3,\n",
       " 'grow!': 1,\n",
       " 'lovely': 6,\n",
       " 'quickly': 10,\n",
       " 'ğŸ”¥ğŸš€': 1,\n",
       " \"how's\": 4,\n",
       " 'experience': 10,\n",
       " 'flutter?': 1,\n",
       " 'gifs': 17,\n",
       " '\\U0001f91fğŸ¼': 1,\n",
       " '#flutter': 1,\n",
       " 'also,': 21,\n",
       " \"win's\": 1,\n",
       " '\"how': 2,\n",
       " 'till': 5,\n",
       " 'drop\"': 1,\n",
       " 'improvised': 1,\n",
       " 'struggling': 7,\n",
       " 'reconcile': 1,\n",
       " 'govt': 10,\n",
       " \"'stay\": 1,\n",
       " \"lives'\": 2,\n",
       " 'mantra': 1,\n",
       " 'allowing': 4,\n",
       " '15,000': 1,\n",
       " 'checks,': 4,\n",
       " 'worst-hit': 1,\n",
       " 'nyc': 4,\n",
       " 'italy.': 1,\n",
       " 'something?': 2,\n",
       " '@seanhannity': 18,\n",
       " 'minutes.': 4,\n",
       " 'tune': 5,\n",
       " 'in!': 4,\n",
       " 'believe': 36,\n",
       " 'himself': 8,\n",
       " 'power?': 4,\n",
       " 'â€˜promoter': 1,\n",
       " 'wholly': 1,\n",
       " 'unconvincing': 1,\n",
       " 'consoler': 1,\n",
       " 'chief.': 1,\n",
       " 'hugger,': 1,\n",
       " '~s': 1,\n",
       " 'news:': 2,\n",
       " 'wonderful': 5,\n",
       " 'years,': 2,\n",
       " 'leaving': 6,\n",
       " '@tes.': 1,\n",
       " 'director.': 1,\n",
       " 'organisation': 1,\n",
       " 'whom': 3,\n",
       " 'journalism.': 1,\n",
       " '1/': 1,\n",
       " 'sister': 6,\n",
       " 'didnâ€™t': 32,\n",
       " 'sister.': 3,\n",
       " '20â€™s': 2,\n",
       " 'sperm': 4,\n",
       " 'meeting': 12,\n",
       " 'moms': 4,\n",
       " '-famu': 3,\n",
       " 'sources': 3,\n",
       " 'cnbc': 1,\n",
       " 'aawaz': 1,\n",
       " 'announce': 8,\n",
       " 'stimulus': 20,\n",
       " 'package.': 3,\n",
       " '30th': 3,\n",
       " 'days.': 4,\n",
       " 'wanna': 46,\n",
       " 'took': 21,\n",
       " 'celebrate': 8,\n",
       " 'birthday.': 8,\n",
       " 'beautiful': 24,\n",
       " 'queen': 4,\n",
       " 'mercy': 1,\n",
       " 'eke,': 1,\n",
       " 'stylish': 1,\n",
       " 'uti,': 1,\n",
       " 'hardworking': 1,\n",
       " 'bobrisky,': 1,\n",
       " 'awesome': 13,\n",
       " 'enkayy': 1,\n",
       " 'amazing': 18,\n",
       " 'mercenaries': 1,\n",
       " 'spartans.': 1,\n",
       " 'bless': 2,\n",
       " 'â¤ï¸': 21,\n",
       " '#zenmagazine': 1,\n",
       " '@liberianboii': 1,\n",
       " 'twenties.': 1,\n",
       " 'married.': 2,\n",
       " 'people.': 18,\n",
       " 'follow.': 6,\n",
       " 'you,': 22,\n",
       " 'pineapple': 3,\n",
       " 'pizza': 11,\n",
       " 'decision': 10,\n",
       " 'there.': 8,\n",
       " 'horny': 23,\n",
       " 'day?': 4,\n",
       " 'shet': 1,\n",
       " 'disappointment': 1,\n",
       " 'ğŸ˜®ğŸ˜…': 1,\n",
       " 'ago,': 4,\n",
       " 'tinder': 2,\n",
       " 'discounted': 1,\n",
       " 'premium': 1,\n",
       " 'services.': 1,\n",
       " 'decided': 22,\n",
       " 'premium,': 1,\n",
       " 'liked': 5,\n",
       " 'profile,': 1,\n",
       " 'theirs.': 1,\n",
       " 'expecting': 5,\n",
       " 'celebratory': 1,\n",
       " 'dinner': 24,\n",
       " 'thereâ€™s': 21,\n",
       " 'stew': 2,\n",
       " 'ğŸ˜': 5,\n",
       " 'monday!': 2,\n",
       " 'ğŸ‘»ğŸ‘»ğŸ‘»': 2,\n",
       " 'hosted': 2,\n",
       " 'interacted': 1,\n",
       " 'communities': 3,\n",
       " 'various': 2,\n",
       " 'backgrounds': 1,\n",
       " 'disrespects': 1,\n",
       " 'sentiment': 1,\n",
       " 'religion.': 1,\n",
       " 'equivalent': 1,\n",
       " 'wasting': 1,\n",
       " 'sins': 1,\n",
       " 'tbh...at': 1,\n",
       " 'least': 33,\n",
       " 'sinning': 1,\n",
       " 'seala': 1,\n",
       " 'definitely': 10,\n",
       " 'putting': 12,\n",
       " 'reaction': 48,\n",
       " '@filmgob': 1,\n",
       " '@jodyscorner1': 1,\n",
       " 'nonsense.': 1,\n",
       " 'indeed': 2,\n",
       " 'filmgob': 1,\n",
       " 'jody': 1,\n",
       " 'there?': 1,\n",
       " 'interesting.': 4,\n",
       " 'supporter': 16,\n",
       " 'thankful': 20,\n",
       " '$1,200': 12,\n",
       " \"trump's\": 16,\n",
       " 'obama': 16,\n",
       " \"he's\": 23,\n",
       " 'socialist': 13,\n",
       " 'billionaire': 12,\n",
       " 'afford': 12,\n",
       " 'questionsâ€¦': 12,\n",
       " 'minister': 6,\n",
       " '(not': 4,\n",
       " \"isn't\": 17,\n",
       " 'ill,': 3,\n",
       " 'holiday,': 2,\n",
       " 'fridge)': 2,\n",
       " 'cabinet,': 3,\n",
       " 'parliament:': 2,\n",
       " 'pandemic': 16,\n",
       " 'crisis': 9,\n",
       " 'forthcoming': 2,\n",
       " 'brexit-induced': 2,\n",
       " 'crisis:': 3,\n",
       " 'competent': 2,\n",
       " 'steer': 2,\n",
       " 'through.': 2,\n",
       " 'apologize': 2,\n",
       " 'sending': 10,\n",
       " '\"\\U0001f97a\"': 1,\n",
       " 'emojis': 2,\n",
       " 'admit': 5,\n",
       " 'signs': 5,\n",
       " 'afraid': 3,\n",
       " 'up,': 13,\n",
       " 'down.': 9,\n",
       " 'overthinking': 1,\n",
       " 'takes': 8,\n",
       " 'away.': 5,\n",
       " 'guys..?': 1,\n",
       " 's/o': 1,\n",
       " 'loyal': 1,\n",
       " 'yâ€™all': 39,\n",
       " '13k+': 1,\n",
       " '#covid_19': 7,\n",
       " 'india,': 1,\n",
       " 'recovered.': 1,\n",
       " 'deaths': 12,\n",
       " '400+.': 1,\n",
       " 'situation,': 1,\n",
       " '@mohfw_india': 1,\n",
       " '@drharshvardhan': 1,\n",
       " '@pmoindia': 1,\n",
       " 'consider:': 1,\n",
       " 'decelerate': 1,\n",
       " 'panic,': 1,\n",
       " 'weigh': 1,\n",
       " 'prone,': 1,\n",
       " 'patients': 5,\n",
       " 'others': 9,\n",
       " 'neglected?': 1,\n",
       " 'am,': 1,\n",
       " 'overdue': 1,\n",
       " 'appointment': 3,\n",
       " 'tomorrow': 35,\n",
       " 'dreading,': 1,\n",
       " 'vibes': 5,\n",
       " 'nudes': 5,\n",
       " 'u.s': 2,\n",
       " 'it???': 1,\n",
       " 'attention': 7,\n",
       " 'despise': 1,\n",
       " 'intro.': 1,\n",
       " 'two.': 1,\n",
       " 'spending': 5,\n",
       " '50+': 1,\n",
       " 'secs': 1,\n",
       " 'â€”': 8,\n",
       " 'nope.': 3,\n",
       " '@kellyinvegas': 1,\n",
       " '@vegasmurray': 1,\n",
       " 'signed,': 1,\n",
       " 'producer': 1,\n",
       " 'rhode': 1,\n",
       " 'island': 2,\n",
       " 'jacob': 1,\n",
       " 'toppin': 1,\n",
       " 'committed': 6,\n",
       " 'kentucky,': 1,\n",
       " 'page.': 2,\n",
       " 'ğŸ˜­â¤ï¸': 1,\n",
       " 'somebody': 8,\n",
       " 'housekeeping': 1,\n",
       " 'yet.': 5,\n",
       " 'theyâ€™re': 12,\n",
       " 'in.': 4,\n",
       " 'decorate': 1,\n",
       " 'doesnâ€™t': 25,\n",
       " 'bland': 1,\n",
       " 'sad': 28,\n",
       " 'absurd': 1,\n",
       " 'ridiculous.': 1,\n",
       " 'ğŸ‘€': 8,\n",
       " '.@joebiden': 1,\n",
       " 'ğŸ¤”': 21,\n",
       " 'irresponsible': 4,\n",
       " 'chinese': 11,\n",
       " 'communist': 5,\n",
       " '#covid19pandemic': 4,\n",
       " 'thousands': 18,\n",
       " 'americans': 29,\n",
       " 'alive': 5,\n",
       " 'jobs.': 4,\n",
       " 'responsible.': 4,\n",
       " 'account.': 6,\n",
       " 'hourrrssss': 1,\n",
       " '@shmsaaldh': 1,\n",
       " 'wearing': 12,\n",
       " 'exact': 2,\n",
       " 'sweatshirt': 1,\n",
       " 'questions': 9,\n",
       " 'time.': 20,\n",
       " 'havenâ€™t': 14,\n",
       " 'hammock': 1,\n",
       " 'isolation,': 1,\n",
       " 'offers': 1,\n",
       " 'tests?': 1,\n",
       " 'fun:': 1,\n",
       " 'freely': 1,\n",
       " 'shehnaaz': 2,\n",
       " 'gill': 1,\n",
       " 'question,': 3,\n",
       " 'be.': 6,\n",
       " 'one.': 9,\n",
       " '#shehnaazgill': 1,\n",
       " '@ishehnaaz_gill': 1,\n",
       " '@kaushaljoshi15': 1,\n",
       " 'suffering': 3,\n",
       " 'depression.': 2,\n",
       " 'worse.': 9,\n",
       " 'hi.': 15,\n",
       " 'isnâ€™t': 13,\n",
       " 'covering': 7,\n",
       " 'nose....': 1,\n",
       " 'pointless.': 1,\n",
       " 'please.': 3,\n",
       " \"doesn't\": 24,\n",
       " 'exist;': 1,\n",
       " 'choose': 22,\n",
       " 'trump:': 15,\n",
       " '\"i': 17,\n",
       " 'campaigning.\"': 8,\n",
       " 'whoâ€™s': 11,\n",
       " 'goin': 1,\n",
       " 'thorpe': 1,\n",
       " 'park/alton': 1,\n",
       " 'towers': 3,\n",
       " 'yâ€™all!!!': 1,\n",
       " 'twitch!!!': 1,\n",
       " '\\U0001f973\\U0001f929': 1,\n",
       " 'continues': 2,\n",
       " 'me!': 10,\n",
       " 'yâ€™all!': 1,\n",
       " 'gifted': 1,\n",
       " 'subs': 4,\n",
       " 'donos': 1,\n",
       " 'ğŸ’—': 1,\n",
       " 'who-the-hell-even-knows-anymore': 18,\n",
       " 'quarantine:': 19,\n",
       " 'gif,': 21,\n",
       " 'honest': 22,\n",
       " 'read/hear': 18,\n",
       " '\"we\\'re': 18,\n",
       " 'together\".': 18,\n",
       " 'ğŸ‘‹ğŸ»': 1,\n",
       " 'stressed': 4,\n",
       " 'coloring': 2,\n",
       " 'meant': 2,\n",
       " 'relaxation?': 1,\n",
       " 'hunch': 1,\n",
       " 'page,': 1,\n",
       " 'pencil,': 1,\n",
       " 'choice.': 3,\n",
       " 'done,': 10,\n",
       " 'therapy.': 9,\n",
       " 'reminding': 3,\n",
       " 'invaded': 1,\n",
       " 'chickens': 1,\n",
       " '@the_badger_jm': 1,\n",
       " 'fsq!!': 1,\n",
       " 'retired': 1,\n",
       " 'players.': 2,\n",
       " 'not.': 11,\n",
       " 'memory?': 1,\n",
       " 'werenâ€™t': 4,\n",
       " 'great,': 2,\n",
       " 'nostalgia': 1,\n",
       " 'memories': 5,\n",
       " 'were?': 1,\n",
       " 'childhood:': 1,\n",
       " 'sprinkled': 1,\n",
       " 'sugar': 6,\n",
       " 'avocado': 2,\n",
       " 'ğŸ˜‹': 4,\n",
       " '65th': 2,\n",
       " 'birthday': 26,\n",
       " 'sonâ€™s': 5,\n",
       " 'yup': 2,\n",
       " 'gif?': 2,\n",
       " 'sick': 14,\n",
       " '$50,000': 2,\n",
       " 'run?': 2,\n",
       " '#btc': 3,\n",
       " 'debate': 5,\n",
       " 'biden?': 5,\n",
       " 'ggs': 1,\n",
       " '@cetralol': 1,\n",
       " 'maad': 1,\n",
       " '1-0': 2,\n",
       " 'prl!': 1,\n",
       " '9pm': 1,\n",
       " 'defiance.': 1,\n",
       " 'grateful': 12,\n",
       " 'passion/happiness': 1,\n",
       " 'life....or': 1,\n",
       " 'appreciate': 14,\n",
       " 'condescending!!': 1,\n",
       " 'evening': 6,\n",
       " 'everyone.': 5,\n",
       " 'awful.': 4,\n",
       " 'dear': 11,\n",
       " 'covid19.': 4,\n",
       " 'screamed': 3,\n",
       " 'minutes': 18,\n",
       " 'straight.': 5,\n",
       " 'stunned': 3,\n",
       " 'her.': 8,\n",
       " 'crawl': 3,\n",
       " 'forever.': 4,\n",
       " 'mentally': 3,\n",
       " 'unwell': 2,\n",
       " '@schittscreek': 1,\n",
       " 'finale': 1,\n",
       " 'disneyâ€™s': 1,\n",
       " 'shitty': 7,\n",
       " 'along...': 1,\n",
       " '@stageit': 2,\n",
       " 'week?': 3,\n",
       " '\"we\"': 2,\n",
       " 'we.': 2,\n",
       " \"can't\": 51,\n",
       " 'alone...that': 2,\n",
       " 'sad.': 3,\n",
       " 'dropped': 7,\n",
       " '4/20': 2,\n",
       " 'interview': 4,\n",
       " 'audacity': 1,\n",
       " 'skype': 1,\n",
       " '9am.': 1,\n",
       " 'sleeping': 4,\n",
       " '11am?': 1,\n",
       " 'busy': 4,\n",
       " 'letâ€™s': 15,\n",
       " 'volunteered': 1,\n",
       " 'reduce': 2,\n",
       " 'fantasized': 1,\n",
       " 'smothering': 1,\n",
       " 'pillow.': 2,\n",
       " 'karma': 1,\n",
       " 'scale?': 1,\n",
       " 'virginia,': 14,\n",
       " '2nd': 18,\n",
       " 'amendment.': 11,\n",
       " 'siege!': 11,\n",
       " 'while.': 6,\n",
       " 'hella': 4,\n",
       " 'now.': 21,\n",
       " 'verkis': 1,\n",
       " 'broke': 6,\n",
       " 'posting': 4,\n",
       " 'treating': 7,\n",
       " 'yâ€™all?': 1,\n",
       " 'pregnancy': 2,\n",
       " 'kicking': 2,\n",
       " 'assğŸ˜©': 1,\n",
       " 'scared': 8,\n",
       " 'nerds': 1,\n",
       " 'glasses,': 1,\n",
       " 'surgical': 2,\n",
       " 'creates': 1,\n",
       " 'visibility': 2,\n",
       " 'foggy': 1,\n",
       " 'specs!!!': 1,\n",
       " '#covid19': 16,\n",
       " 'smoke': 2,\n",
       " 'to,': 1,\n",
       " 'to.': 4,\n",
       " '.@who': 1,\n",
       " 'pandemic,': 3,\n",
       " 'providing': 3,\n",
       " 'advice,': 1,\n",
       " 'training,': 1,\n",
       " 'equipment': 1,\n",
       " 'crucial': 2,\n",
       " 'livesâ€”including': 1,\n",
       " 'americansâ€™.': 1,\n",
       " 'dangerousâ€”trump': 1,\n",
       " 'authority': 1,\n",
       " 'know:': 3,\n",
       " 'violating': 1,\n",
       " 'impeached.': 1,\n",
       " 'nigga': 6,\n",
       " 'aboogie': 1,\n",
       " 'prime,': 2,\n",
       " 'hurt.': 2,\n",
       " \"that's\": 30,\n",
       " 'redskins': 1,\n",
       " 'morning.': 12,\n",
       " 'uh.': 1,\n",
       " '#oustduterenow': 3,\n",
       " 'turns': 6,\n",
       " 'martial': 1,\n",
       " 'advantage': 3,\n",
       " 'inability': 2,\n",
       " 'mobilize': 1,\n",
       " '#oustdutertenow': 1,\n",
       " 'philippines': 1,\n",
       " 'dictator': 1,\n",
       " 'todd': 1,\n",
       " 'wins': 4,\n",
       " 'gamers': 1,\n",
       " '@coliathgaming': 1,\n",
       " '@baker_tv_': 1,\n",
       " '@vicdgordon': 1,\n",
       " '@streamgamma': 1,\n",
       " '@kedabosch': 1,\n",
       " '@day1negaming': 1,\n",
       " '@jxckwsw': 1,\n",
       " '@ncshredder_': 1,\n",
       " '@samurai_ree': 1,\n",
       " '@stardrix1': 1,\n",
       " '@gso_joey': 1,\n",
       " '@tsillysweat': 1,\n",
       " '@chloedonald_': 1,\n",
       " '@xlexry': 1,\n",
       " '@multynwolf': 1,\n",
       " '@saycredangel': 1,\n",
       " '@fuscyoface': 1,\n",
       " '@storkyyy1': 1,\n",
       " 'kamo': 1,\n",
       " 'mphela': 1,\n",
       " 'whole': 29,\n",
       " 'blueprint': 1,\n",
       " 'moves': 4,\n",
       " '\"she': 1,\n",
       " 'dances': 1,\n",
       " 'shit\"': 2,\n",
       " 'ğŸ˜•': 1,\n",
       " 'sober': 6,\n",
       " 'hurts': 4,\n",
       " 'intensions.': 1,\n",
       " 'learned': 8,\n",
       " 'actions.': 1,\n",
       " 'steyer': 1,\n",
       " 'lives.': 5,\n",
       " 'california.': 3,\n",
       " 'newsom': 2,\n",
       " 'recovery': 2,\n",
       " 'force,': 1,\n",
       " 'injustices': 1,\n",
       " 'revealed': 3,\n",
       " 'crisis.': 4,\n",
       " 'reasonable,': 1,\n",
       " 'zoom': 9,\n",
       " 'calls': 6,\n",
       " 'fart': 3,\n",
       " 'meetings': 2,\n",
       " 'mute': 2,\n",
       " 'know.': 9,\n",
       " 'ğŸ’¨ğŸ’¨': 1,\n",
       " 'yall': 15,\n",
       " 'caucasians': 1,\n",
       " '4th': 7,\n",
       " 'july?!!!!!': 1,\n",
       " 'convo': 4,\n",
       " 'meteoric': 1,\n",
       " 'again.': 21,\n",
       " 'soon.': 4,\n",
       " 'nathaniel': 14,\n",
       " 'cnn': 16,\n",
       " 'here.': 20,\n",
       " 'you?': 21,\n",
       " '7th': 8,\n",
       " 'slid': 7,\n",
       " 'dms?': 7,\n",
       " 'sweep': 2,\n",
       " 'did.': 3,\n",
       " 'bump': 2,\n",
       " 'pronounced': 4,\n",
       " 'orders.': 2,\n",
       " 'oklahoma': 1,\n",
       " '53%': 1,\n",
       " 'increase': 3,\n",
       " 'jumped': 1,\n",
       " '60%': 3,\n",
       " 'arkansas,': 1,\n",
       " '74%': 1,\n",
       " 'nebraska,': 1,\n",
       " '82%': 1,\n",
       " 'iowa.': 1,\n",
       " 'dakota': 3,\n",
       " 'whopping': 1,\n",
       " '205%': 1,\n",
       " 'spike.': 1,\n",
       " '#stayhomestaysafesavelives': 1,\n",
       " 'chick': 3,\n",
       " 'sauce': 4,\n",
       " 'body.': 4,\n",
       " \"what's\": 13,\n",
       " 'funny': 11,\n",
       " 'hurry': 2,\n",
       " 'asked': 20,\n",
       " 'first.': 4,\n",
       " '#smallvictory': 1,\n",
       " 'sucks': 2,\n",
       " 'decorating': 1,\n",
       " '#animalcrossing': 1,\n",
       " 'november': 5,\n",
       " 'headline': 2,\n",
       " 'preview:': 2,\n",
       " 'defeated': 18,\n",
       " 'landslide': 2,\n",
       " 'mitch': 2,\n",
       " 'mcconnell': 2,\n",
       " 'lindsey': 4,\n",
       " 'graham': 7,\n",
       " 'susan': 2,\n",
       " 'collins': 4,\n",
       " 'martha': 2,\n",
       " 'mcsally': 2,\n",
       " 'cory': 2,\n",
       " 'gardner': 2,\n",
       " 'kelly': 4,\n",
       " 'loeffler': 3,\n",
       " 'thom': 2,\n",
       " 'tillis': 2,\n",
       " 'yeah,': 6,\n",
       " 'night,': 2,\n",
       " 'dreamt': 1,\n",
       " 'journalists,': 2,\n",
       " 'uddhav': 1,\n",
       " 'pm.': 2,\n",
       " 'aide': 1,\n",
       " 'approaches': 1,\n",
       " 'informal': 1,\n",
       " 'mine,': 1,\n",
       " 'no,': 7,\n",
       " '#soproudofmyself': 1,\n",
       " 'bout': 8,\n",
       " 'shooting': 3,\n",
       " 'hooping': 1,\n",
       " '$50': 8,\n",
       " 'retweets': 6,\n",
       " '@k_9girl': 1,\n",
       " 'myself.': 11,\n",
       " 'sitting': 15,\n",
       " 'cocoa': 1,\n",
       " 'krispies': 2,\n",
       " 'strange': 2,\n",
       " 'hits': 6,\n",
       " 'this?': 4,\n",
       " 'wasted.': 1,\n",
       " 'finally': 27,\n",
       " 'agreed': 3,\n",
       " 'repaint': 1,\n",
       " 'stuck': 7,\n",
       " 'home.': 6,\n",
       " 'requesting': 2,\n",
       " 'thoughts': 10,\n",
       " 'prayers': 4,\n",
       " 'difficult': 5,\n",
       " 'ğŸ˜Š': 18,\n",
       " 'listen': 11,\n",
       " 'man-half': 1,\n",
       " 'assholes': 2,\n",
       " 'concerns': 3,\n",
       " 'exercise,': 1,\n",
       " 'shit,': 2,\n",
       " 'smoke,': 1,\n",
       " 'drink': 7,\n",
       " 'excessive': 1,\n",
       " ...}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unknown_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean weird punctuations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No significantly improve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_weird(text):\n",
    "    specials = [\"â€™\", \"â€˜\", \"Â´\", \"`\"]\n",
    "    text = text.replace(\"â€™\", \"'\")\n",
    "    text = text.replace(\"â€˜\", \"'\")\n",
    "    text = text.replace(\"Â´\", \"'\")\n",
    "    text = text.replace(\"`\", \"'\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['text'] = df_train.text.apply(clean_weird)\n",
    "df_train['reply'] = df_train.reply.apply(clean_weird)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev['text'] = df_dev.text.apply(clean_weird)\n",
    "df_dev['reply'] = df_dev.reply.apply(clean_weird)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['text'] = df_test.text.apply(clean_weird)\n",
    "df_test['reply'] = df_test.reply.apply(clean_weird)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train text unique vocab count is: 68710\n",
      "train reply unique vocab count is: 25436\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=68710.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 8.211% (5642 / 68710) of vocab\n",
      "Found embeddings for 65.987% (432193 / 654963) of all text\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=25436.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 14.519% (3693 / 25436) of vocab\n",
      "Found embeddings for 63.200% (68506 / 108395) of all text\n"
     ]
    }
   ],
   "source": [
    "train_text_vocab = get_vocab(df_train['text'].values)\n",
    "train_reply_vocab = get_vocab(df_train['reply'].values)\n",
    "print(\"train text unique vocab count is: {}\".format(len(train_text_vocab)))\n",
    "print(\"train reply unique vocab count is: {}\".format(len(train_reply_vocab)))\n",
    "unknown_text = check_coverage(train_text_vocab, roberta_vocab)\n",
    "print()\n",
    "unknown_reply = check_coverage(train_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev text unique vocab count is: 17597\n",
      "dev reply unique vocab count is: 5322\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=17597.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 17.918% (3153 / 17597) of vocab\n",
      "Found embeddings for 65.713% (54523 / 82972) of all text\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=5322.0, style=ProgressStyle(description_â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 27.189% (1447 / 5322) of vocab\n",
      "Found embeddings for 62.352% (8627 / 13836) of all text\n"
     ]
    }
   ],
   "source": [
    "dev_text_vocab = get_vocab(df_dev['text'].values)\n",
    "dev_reply_vocab = get_vocab(df_dev['reply'].values)\n",
    "print(\"dev text unique vocab count is: {}\".format(len(dev_text_vocab)))\n",
    "print(\"dev reply unique vocab count is: {}\".format(len(dev_reply_vocab)))\n",
    "unknown_text = check_coverage(dev_text_vocab, roberta_vocab)\n",
    "print()\n",
    "unknown_reply = check_coverage(dev_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test text unique vocab count is: 17246\n",
      "test reply unique vocab count is: 5152\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=17246.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 18.294% (3155 / 17246) of vocab\n",
      "Found embeddings for 66.136% (54167 / 81903) of all text\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=5152.0, style=ProgressStyle(description_â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 28.261% (1456 / 5152) of vocab\n",
      "Found embeddings for 63.152% (8360 / 13238) of all text\n"
     ]
    }
   ],
   "source": [
    "test_text_vocab = get_vocab(df_test['text'].values)\n",
    "test_reply_vocab = get_vocab(df_test['reply'].values)\n",
    "print(\"test text unique vocab count is: {}\".format(len(test_text_vocab)))\n",
    "print(\"test reply unique vocab count is: {}\".format(len(test_reply_vocab)))\n",
    "unknown_text = check_coverage(test_text_vocab, roberta_vocab)\n",
    "print()\n",
    "unknown_reply = check_coverage(test_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform apostrophes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "apostrophes = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\" }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_apostrophes(text):\n",
    "    # Replace apostrophes to original term\n",
    "    for key in apostrophes.keys():\n",
    "        text = text.replace(key, apostrophes[key])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train['text'] = df_train.text.apply(change_apostrophes)\n",
    "df_train['reply'] = df_train.reply.apply(change_apostrophes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev['text'] = df_dev.text.apply(change_apostrophes)\n",
    "df_dev['reply'] = df_dev.reply.apply(change_apostrophes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['text'] = df_test.text.apply(change_apostrophes)\n",
    "df_test['reply'] = df_test.reply.apply(change_apostrophes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train text unique vocab count is: 68558\n",
      "train reply unique vocab count is: 25352\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=68558.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 8.230% (5642 / 68558) of vocab\n",
      "Found embeddings for 68.765% (460202 / 669242) of all text\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=25352.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 14.571% (3694 / 25352) of vocab\n",
      "Found embeddings for 66.097% (73228 / 110789) of all text\n"
     ]
    }
   ],
   "source": [
    "train_text_vocab = get_vocab(df_train['text'].values)\n",
    "train_reply_vocab = get_vocab(df_train['reply'].values)\n",
    "print(\"train text unique vocab count is: {}\".format(len(train_text_vocab)))\n",
    "print(\"train reply unique vocab count is: {}\".format(len(train_reply_vocab)))\n",
    "unknown_text = check_coverage(train_text_vocab, roberta_vocab)\n",
    "print()\n",
    "unknown_reply = check_coverage(train_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev text unique vocab count is: 17524\n",
      "dev reply unique vocab count is: 5273\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=17524.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 18.004% (3155 / 17524) of vocab\n",
      "Found embeddings for 68.538% (58122 / 84802) of all text\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=5273.0, style=ProgressStyle(description_â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 27.442% (1447 / 5273) of vocab\n",
      "Found embeddings for 65.373% (9251 / 14151) of all text\n"
     ]
    }
   ],
   "source": [
    "dev_text_vocab = get_vocab(df_dev['text'].values)\n",
    "dev_reply_vocab = get_vocab(df_dev['reply'].values)\n",
    "print(\"dev text unique vocab count is: {}\".format(len(dev_text_vocab)))\n",
    "print(\"dev reply unique vocab count is: {}\".format(len(dev_reply_vocab)))\n",
    "unknown_text = check_coverage(dev_text_vocab, roberta_vocab)\n",
    "print()\n",
    "unknown_reply = check_coverage(dev_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test text unique vocab count is: 17171\n",
      "test reply unique vocab count is: 5108\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=17171.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 18.380% (3156 / 17171) of vocab\n",
      "Found embeddings for 68.775% (57497 / 83601) of all text\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=5108.0, style=ProgressStyle(description_â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 28.504% (1456 / 5108) of vocab\n",
      "Found embeddings for 66.051% (8938 / 13532) of all text\n"
     ]
    }
   ],
   "source": [
    "test_text_vocab = get_vocab(df_test['text'].values)\n",
    "test_reply_vocab = get_vocab(df_test['reply'].values)\n",
    "print(\"test text unique vocab count is: {}\".format(len(test_text_vocab)))\n",
    "print(\"test reply unique vocab count is: {}\".format(len(test_reply_vocab)))\n",
    "unknown_text = check_coverage(test_text_vocab, roberta_vocab)\n",
    "print()\n",
    "unknown_reply = check_coverage(test_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'@Youngdeji_': 1,\n",
       " 'uzi': 2,\n",
       " 'carti': 3,\n",
       " 'gotta': 16,\n",
       " 'lil': 10,\n",
       " 'woah': 1,\n",
       " 'discussing': 5,\n",
       " 'trading': 4,\n",
       " 'picks': 2,\n",
       " 'safety.': 1,\n",
       " 'dababy': 3,\n",
       " 'sounds': 5,\n",
       " 'niggas': 6,\n",
       " 'kitchen': 7,\n",
       " \"Denny's\": 1,\n",
       " 'Majority': 2,\n",
       " 'Indians': 3,\n",
       " 'sport': 2,\n",
       " 'cricket.': 1,\n",
       " 'came': 16,\n",
       " 'out.': 21,\n",
       " 'Zaira': 1,\n",
       " 'Wasim': 1,\n",
       " 'hardwork': 1,\n",
       " 'screen.': 1,\n",
       " 'justify': 2,\n",
       " 'mentality': 1,\n",
       " 'sick.': 4,\n",
       " 'everybody': 5,\n",
       " 'listening': 8,\n",
       " '@madisonbeer': 1,\n",
       " 'selfish': 1,\n",
       " 'â€œas': 2,\n",
       " 'pleaseâ€': 1,\n",
       " 'wtf': 5,\n",
       " 'Might': 4,\n",
       " '@LupeLoops': 1,\n",
       " 'weekend': 9,\n",
       " 'ğŸ˜“': 3,\n",
       " 'ops,': 1,\n",
       " 'biggest': 9,\n",
       " 'disappointments....': 1,\n",
       " 'hardest': 4,\n",
       " 'work.': 6,\n",
       " 'cried.': 1,\n",
       " 'hospitals': 4,\n",
       " 'settings,': 1,\n",
       " 'home,': 3,\n",
       " 'it.': 93,\n",
       " 'crap': 3,\n",
       " 'nightmare.': 3,\n",
       " 'accounts': 8,\n",
       " 'hacked': 5,\n",
       " 'spamming': 4,\n",
       " 'mad.': 4,\n",
       " 'back.': 13,\n",
       " 'tried': 13,\n",
       " 'confronting': 4,\n",
       " 'hacker': 3,\n",
       " 'replying': 5,\n",
       " 'â€œWho': 3,\n",
       " 'are?!â€': 3,\n",
       " 'PHYSICALLY': 3,\n",
       " 'attacked': 4,\n",
       " 'spam': 3,\n",
       " 'messages': 6,\n",
       " 'woke': 15,\n",
       " 'up.': 25,\n",
       " 'ğŸ˜°': 4,\n",
       " 'understands.': 1,\n",
       " 'prophet.': 1,\n",
       " 'forgive': 1,\n",
       " 'Doing?': 1,\n",
       " 'quarantine': 33,\n",
       " 'therapist': 1,\n",
       " 'everyday': 8,\n",
       " 'trying': 35,\n",
       " 'navigate': 1,\n",
       " 'plans': 3,\n",
       " 'overwhelm': 1,\n",
       " 'overreacting,': 1,\n",
       " 'obsessing,': 1,\n",
       " 'worrying,': 1,\n",
       " 'eventually': 3,\n",
       " 'disassociating.': 1,\n",
       " 'Doing': 3,\n",
       " 'here!': 2,\n",
       " 'Gates': 14,\n",
       " 'Covid-19': 15,\n",
       " 'Vaccine?': 11,\n",
       " 'cancel': 4,\n",
       " 'myrtle': 1,\n",
       " 'am.': 3,\n",
       " 'spiraling.': 1,\n",
       " 'laughing': 8,\n",
       " 'STRATEGICALLY': 1,\n",
       " 'DYNAMICALLY': 1,\n",
       " 'sucking': 8,\n",
       " 'dick': 16,\n",
       " 'grudges.': 1,\n",
       " 'So,': 5,\n",
       " 'mind,': 2,\n",
       " 'apologise': 3,\n",
       " 'me?': 9,\n",
       " 'OldRich': 6,\n",
       " 'judging': 6,\n",
       " 'people,': 12,\n",
       " 'judgement,': 6,\n",
       " 'kindness,': 8,\n",
       " 'HUNGRY': 6,\n",
       " 'followers': 20,\n",
       " '(now': 6,\n",
       " 'â€œteammatesâ€)!': 6,\n",
       " 'cannot': 87,\n",
       " 'hyperventilate': 1,\n",
       " 'bag.': 1,\n",
       " 'â˜¹ï¸': 2,\n",
       " 'myself': 44,\n",
       " 'could.': 1,\n",
       " 'able,': 1,\n",
       " 'yeah?': 1,\n",
       " 'you.': 33,\n",
       " 'ğŸ’›': 2,\n",
       " 'supportive': 2,\n",
       " '\\U0001f97a': 14,\n",
       " 'hands,': 1,\n",
       " \"You're\": 9,\n",
       " 'worried': 6,\n",
       " \"Trump's\": 25,\n",
       " 'health?': 1,\n",
       " 'coffee': 10,\n",
       " 'lunch.': 1,\n",
       " \"who'd\": 3,\n",
       " 'join?': 1,\n",
       " 'guaging': 1,\n",
       " 'interest.': 2,\n",
       " 'Trump,': 3,\n",
       " 'script,': 1,\n",
       " 'begins': 2,\n",
       " 'saying': 22,\n",
       " 'undertaken': 1,\n",
       " \"country's\": 3,\n",
       " 'greatest': 4,\n",
       " 'mobilization': 1,\n",
       " '\"since': 1,\n",
       " 'II.\"': 1,\n",
       " 'says': 29,\n",
       " 'unleashed': 1,\n",
       " '\"most': 1,\n",
       " 'potent': 1,\n",
       " 'all\":': 1,\n",
       " \"Americans'\": 1,\n",
       " 'courage.': 1,\n",
       " 'tells': 7,\n",
       " 'loved': 10,\n",
       " 'pain.': 6,\n",
       " 'yesterday.': 2,\n",
       " 'screenshots': 2,\n",
       " 'idk': 5,\n",
       " 'hear': 20,\n",
       " 'proud': 12,\n",
       " 'blonde': 1,\n",
       " 'me.': 56,\n",
       " 'better.': 14,\n",
       " 'wna': 2,\n",
       " 'fucj': 1,\n",
       " 'bcs': 1,\n",
       " 'insecure': 1,\n",
       " 'relationship': 9,\n",
       " 'fucked': 14,\n",
       " 'shout': 4,\n",
       " 'trash.': 2,\n",
       " 'trash': 11,\n",
       " 'yourself.': 2,\n",
       " 'natin': 1,\n",
       " 'joke': 6,\n",
       " 'circulating': 1,\n",
       " 'Germany:': 1,\n",
       " '\"What': 2,\n",
       " 'borders': 2,\n",
       " 'stupidity?\"': 1,\n",
       " '\"Mexico': 1,\n",
       " 'Canada!\"': 1,\n",
       " 'already': 18,\n",
       " 'taken': 9,\n",
       " 'what?!': 1,\n",
       " 'waiting': 18,\n",
       " '#WHYRUep12': 1,\n",
       " 'simpsons': 1,\n",
       " 'installing': 23,\n",
       " \"#ScottyFromMarketing's\": 23,\n",
       " 'app.': 25,\n",
       " 'gif.': 25,\n",
       " 'Hollyweird': 1,\n",
       " 'pedophile': 1,\n",
       " 'grandiloquent': 1,\n",
       " 'hypocrites': 1,\n",
       " 'kissed': 3,\n",
       " 'Biden,': 1,\n",
       " 'teenage': 4,\n",
       " 'THEIR': 2,\n",
       " 'â€œI': 7,\n",
       " \"jumpin'\": 1,\n",
       " 'lapâ€': 1,\n",
       " 'Biden': 23,\n",
       " 'now,': 17,\n",
       " 'petulance,': 1,\n",
       " 'gridlock,': 1,\n",
       " 'vendettas': 1,\n",
       " 'downright': 1,\n",
       " 'belongs': 3,\n",
       " 'idea': 15,\n",
       " 'watches': 1,\n",
       " \"'Bates\": 1,\n",
       " \"Motel'??\": 1,\n",
       " 'spoilers!!': 1,\n",
       " '3.': 7,\n",
       " 'damn': 14,\n",
       " 'all,': 8,\n",
       " \"Norman's\": 1,\n",
       " 'nerves.': 1,\n",
       " \"He's\": 16,\n",
       " 'punch': 1,\n",
       " 'ğŸ¤·ğŸ»\\u200dâ™€ï¸ğŸ¤·ğŸ»\\u200dâ™€ï¸': 1,\n",
       " 'wanted': 25,\n",
       " 'tonight': 21,\n",
       " 'feelings': 5,\n",
       " 'hurt': 6,\n",
       " 'hiding': 5,\n",
       " 'night.': 9,\n",
       " 'feeling': 36,\n",
       " 'bombarded': 2,\n",
       " 'hurtful': 3,\n",
       " 'words.': 2,\n",
       " 'sapped': 2,\n",
       " 'dry.': 2,\n",
       " '#salt': 2,\n",
       " 'fancy': 1,\n",
       " 'skateboard': 1,\n",
       " 'liberate': 3,\n",
       " 'ass.': 3,\n",
       " 'ğŸ™Œ': 2,\n",
       " \"Post's\": 1,\n",
       " \"Halladay's\": 1,\n",
       " 'fucking': 43,\n",
       " 'garbage': 2,\n",
       " 'today.': 41,\n",
       " '\"Some': 2,\n",
       " 'Halladay': 1,\n",
       " 'Transportation': 1,\n",
       " 'Fame': 1,\n",
       " 'pitcher': 1,\n",
       " 'amphetamines': 1,\n",
       " 'morphine\"': 1,\n",
       " '$$?': 2,\n",
       " '$200': 3,\n",
       " 'hours.': 14,\n",
       " '@LoyalGiveaways': 2,\n",
       " ':)': 10,\n",
       " 'hug': 78,\n",
       " 'somn': 1,\n",
       " 'suck': 13,\n",
       " 'dick,': 3,\n",
       " 'stopping': 2,\n",
       " 'talent': 2,\n",
       " 'conversation': 7,\n",
       " 'going,': 3,\n",
       " 'lot.': 3,\n",
       " 'Raise': 8,\n",
       " 'reopen': 8,\n",
       " 'America.': 7,\n",
       " 'ğŸ™‹\\u200dâ™‚ï¸ğŸ™‹\\u200dâ™‚ï¸ğŸ™‹\\u200dâ™‚ï¸': 2,\n",
       " 'IN:': 7,\n",
       " 'denies': 6,\n",
       " 'extent': 6,\n",
       " 'coronavirus': 27,\n",
       " 'outbreak': 6,\n",
       " 'NEEDğŸŒ¹SOLO': 1,\n",
       " 'ğŸŒ¹SANAğŸŒ¹PROJECTSğŸŒ¹': 1,\n",
       " 'knows': 9,\n",
       " 'rapists?': 1,\n",
       " 'em?': 1,\n",
       " 'morning!': 1,\n",
       " 'today!': 5,\n",
       " 'specifically?': 1,\n",
       " '#SVTrainToBusan': 1,\n",
       " 'hugs': 19,\n",
       " 'smh': 6,\n",
       " 'unlimited': 1,\n",
       " 'ğŸ˜­': 16,\n",
       " '2020!': 2,\n",
       " 'Ending': 1,\n",
       " 'lockdowns': 3,\n",
       " 'quarantining.': 1,\n",
       " 'conflated.': 1,\n",
       " 'welcomed': 2,\n",
       " 'assume': 3,\n",
       " 'risk.': 1,\n",
       " '@DxvilishAngxl': 1,\n",
       " 'cute': 10,\n",
       " 'Veniece': 1,\n",
       " 'Drive-In': 1,\n",
       " 'theater': 3,\n",
       " 'punks': 1,\n",
       " 'nowadays': 1,\n",
       " 'smuggle': 1,\n",
       " 'trunk': 1,\n",
       " 'beers': 1,\n",
       " 'THOSE': 1,\n",
       " 'days!': 1,\n",
       " 'up?': 10,\n",
       " 'no?': 10,\n",
       " 'prepare': 5,\n",
       " 'Rounds': 3,\n",
       " 'negotiations,': 3,\n",
       " 'reiterate': 3,\n",
       " \"Government's\": 3,\n",
       " 'transition': 5,\n",
       " 'following': 21,\n",
       " 'withdrawal': 3,\n",
       " 'EU.': 3,\n",
       " 'Transition': 3,\n",
       " 'year.': 10,\n",
       " 'extend': 6,\n",
       " 'no.': 6,\n",
       " '1/2': 4,\n",
       " 'app,': 24,\n",
       " 'hashtag': 26,\n",
       " '#BailoutHumansNow': 24,\n",
       " '@ShelleyMcElyea1': 1,\n",
       " 'birthday,': 3,\n",
       " 'darling': 2,\n",
       " 'â¤ï¸ğŸ’‹ğŸğŸ‰ğŸ°ğŸˆ': 1,\n",
       " '#Giveaway': 2,\n",
       " '$25': 4,\n",
       " '24hours..': 1,\n",
       " 'Like/RT/Tag': 1,\n",
       " '(must': 1,\n",
       " 'me)': 1,\n",
       " 'sponsor': 1,\n",
       " 'following?': 1,\n",
       " 'discuss': 3,\n",
       " 'grow!': 1,\n",
       " 'lovely': 6,\n",
       " 'quickly': 10,\n",
       " 'ğŸ”¥ğŸš€': 1,\n",
       " \"How's\": 6,\n",
       " 'experience': 10,\n",
       " 'Flutter?': 1,\n",
       " 'gifs': 12,\n",
       " '\\U0001f91fğŸ¼': 1,\n",
       " '#Flutter': 1,\n",
       " 'Also,': 21,\n",
       " \"Win's\": 1,\n",
       " '\"How': 2,\n",
       " 'till': 5,\n",
       " 'drop\"': 1,\n",
       " 'improvised': 1,\n",
       " 'struggling': 4,\n",
       " 'reconcile': 1,\n",
       " 'Govt': 5,\n",
       " \"'stay\": 1,\n",
       " \"lives'\": 1,\n",
       " 'mantra': 1,\n",
       " 'allowing': 4,\n",
       " '15,000': 1,\n",
       " 'checks,': 4,\n",
       " 'worst-hit': 1,\n",
       " 'NYC': 4,\n",
       " 'Italy.': 1,\n",
       " 'something?': 2,\n",
       " '@seanhannity': 18,\n",
       " 'minutes.': 2,\n",
       " 'Tune': 4,\n",
       " 'in!': 4,\n",
       " 'believe': 35,\n",
       " 'himself': 8,\n",
       " 'power?': 4,\n",
       " \"'promoter\": 1,\n",
       " 'wholly': 1,\n",
       " 'unconvincing': 1,\n",
       " 'consoler': 1,\n",
       " 'Chief.': 1,\n",
       " 'Hugger,': 1,\n",
       " '~S': 1,\n",
       " 'news:': 1,\n",
       " 'wonderful': 5,\n",
       " 'years,': 2,\n",
       " 'leaving': 6,\n",
       " '@Tes.': 1,\n",
       " 'director.': 1,\n",
       " 'organisation': 1,\n",
       " 'whom': 3,\n",
       " 'journalism.': 1,\n",
       " '1/': 1,\n",
       " 'sister': 6,\n",
       " 'sister.': 3,\n",
       " \"20's\": 2,\n",
       " 'sperm': 4,\n",
       " 'meeting': 12,\n",
       " 'moms': 4,\n",
       " '-famu': 3,\n",
       " 'CNBC': 1,\n",
       " 'AAWAZ': 1,\n",
       " 'announce': 8,\n",
       " 'Stimulus': 2,\n",
       " 'Package.': 1,\n",
       " '30th': 3,\n",
       " 'days.': 4,\n",
       " 'wanna': 43,\n",
       " 'took': 19,\n",
       " 'celebrate': 8,\n",
       " 'birthday.': 8,\n",
       " 'beautiful': 23,\n",
       " 'Mercy': 1,\n",
       " 'Eke,': 1,\n",
       " 'stylish': 1,\n",
       " 'Uti,': 1,\n",
       " 'hardworking': 1,\n",
       " 'BobRisky,': 1,\n",
       " 'awesome': 13,\n",
       " 'Enkayy': 1,\n",
       " 'amazing': 18,\n",
       " 'Mercenaries': 1,\n",
       " 'Spartans.': 1,\n",
       " 'bless': 2,\n",
       " 'â¤ï¸': 21,\n",
       " '#ZenMagazine': 1,\n",
       " '@liberianboii': 1,\n",
       " 'Twenties.': 1,\n",
       " 'married.': 2,\n",
       " 'people.': 18,\n",
       " 'follow.': 6,\n",
       " 'you,': 18,\n",
       " 'pineapple': 2,\n",
       " 'pizza': 11,\n",
       " 'decision': 10,\n",
       " 'there.': 8,\n",
       " 'Horny': 4,\n",
       " 'Day?': 1,\n",
       " \"It's\": 90,\n",
       " 'Shet': 1,\n",
       " 'disappointment': 1,\n",
       " 'ğŸ˜®ğŸ˜…': 1,\n",
       " 'ago,': 4,\n",
       " 'Tinder': 2,\n",
       " 'discounted': 1,\n",
       " 'premium': 1,\n",
       " 'services.': 1,\n",
       " 'decided': 21,\n",
       " 'premium,': 1,\n",
       " 'liked': 4,\n",
       " 'profile,': 1,\n",
       " 'theirs.': 1,\n",
       " 'expecting': 5,\n",
       " 'celebratory': 1,\n",
       " 'dinner': 23,\n",
       " 'stew': 2,\n",
       " 'ğŸ˜': 5,\n",
       " 'COMING': 3,\n",
       " 'MONDAY!': 2,\n",
       " 'ğŸ‘»ğŸ‘»ğŸ‘»': 2,\n",
       " 'hosted': 2,\n",
       " 'interacted': 1,\n",
       " 'communities': 3,\n",
       " 'various': 2,\n",
       " 'backgrounds': 1,\n",
       " 'disrespects': 1,\n",
       " 'sentiment': 1,\n",
       " 'religion.': 1,\n",
       " 'Trash': 1,\n",
       " 'equivalent': 1,\n",
       " 'wasting': 1,\n",
       " 'sins': 1,\n",
       " 'tbh...at': 1,\n",
       " 'least': 33,\n",
       " 'sinning': 1,\n",
       " 'Seala': 1,\n",
       " 'definitely': 10,\n",
       " 'putting': 11,\n",
       " 'reaction': 47,\n",
       " '@FilmGob': 1,\n",
       " '@jodyscorner1': 1,\n",
       " 'nonsense.': 1,\n",
       " 'indeed': 2,\n",
       " 'filmgob': 1,\n",
       " 'jody': 1,\n",
       " 'there?': 1,\n",
       " 'interesting.': 4,\n",
       " 'supporter': 16,\n",
       " 'thankful': 19,\n",
       " '$1,200': 12,\n",
       " 'socialist': 13,\n",
       " 'billionaire': 12,\n",
       " 'afford': 12,\n",
       " 'questionsâ€¦': 12,\n",
       " 'Minister': 6,\n",
       " '(not': 4,\n",
       " 'ill,': 3,\n",
       " 'holiday,': 2,\n",
       " 'fridge)': 2,\n",
       " 'Cabinet,': 2,\n",
       " 'Parliament:': 2,\n",
       " 'pandemic': 16,\n",
       " 'crisis': 7,\n",
       " 'forthcoming': 2,\n",
       " 'Brexit-induced': 2,\n",
       " 'crisis:': 3,\n",
       " 'competent': 2,\n",
       " 'steer': 2,\n",
       " 'through.': 2,\n",
       " 'apologize': 2,\n",
       " 'sending': 7,\n",
       " '\"\\U0001f97a\"': 1,\n",
       " 'emojis': 2,\n",
       " 'admit': 3,\n",
       " 'signs': 5,\n",
       " 'afraid': 3,\n",
       " 'up,': 13,\n",
       " 'down.': 9,\n",
       " 'overthinking': 1,\n",
       " 'takes': 8,\n",
       " 'away.': 5,\n",
       " 'guys..?': 1,\n",
       " 's/o': 1,\n",
       " 'loyal': 1,\n",
       " \"Y'all\": 16,\n",
       " '13k+': 1,\n",
       " '#Covid_19': 6,\n",
       " 'India,': 1,\n",
       " 'recovered.': 1,\n",
       " 'Deaths': 1,\n",
       " '400+.': 1,\n",
       " 'situation,': 1,\n",
       " '@MoHFW_INDIA': 1,\n",
       " '@drharshvardhan': 1,\n",
       " '@PMOIndia': 1,\n",
       " 'consider:': 1,\n",
       " 'decelerate': 1,\n",
       " 'panic,': 1,\n",
       " 'weigh': 1,\n",
       " 'prone,': 1,\n",
       " 'patients': 5,\n",
       " 'others': 9,\n",
       " 'neglected?': 1,\n",
       " 'am,': 1,\n",
       " 'overdue': 1,\n",
       " 'appointment': 3,\n",
       " 'tomorrow': 33,\n",
       " 'dreading,': 1,\n",
       " 'vibes': 4,\n",
       " 'nudes': 3,\n",
       " 'U.S': 2,\n",
       " 'it???': 1,\n",
       " 'LOL': 2,\n",
       " 'attention': 7,\n",
       " 'despise': 1,\n",
       " 'intro.': 1,\n",
       " 'two.': 1,\n",
       " 'spending': 5,\n",
       " '50+': 1,\n",
       " 'secs': 1,\n",
       " 'â€”': 8,\n",
       " 'nope.': 2,\n",
       " '@kellyinvegas': 1,\n",
       " '@vegasmurray': 1,\n",
       " 'Signed,': 1,\n",
       " 'Producer': 1,\n",
       " 'Rhode': 1,\n",
       " 'Island': 1,\n",
       " 'Toppin': 1,\n",
       " 'committed': 6,\n",
       " 'Kentucky,': 1,\n",
       " 'page.': 2,\n",
       " 'ğŸ˜­â¤ï¸': 1,\n",
       " 'Somebody': 4,\n",
       " 'housekeeping': 1,\n",
       " 'yet.': 5,\n",
       " \"They're\": 4,\n",
       " 'in.': 4,\n",
       " 'decorate': 1,\n",
       " 'bland': 1,\n",
       " 'sad': 26,\n",
       " 'absurd': 1,\n",
       " 'ridiculous.': 1,\n",
       " 'ğŸ‘€': 8,\n",
       " '.@JoeBiden': 1,\n",
       " 'ğŸ¤”': 21,\n",
       " 'irresponsible': 4,\n",
       " 'communist': 5,\n",
       " '#COVID19Pandemic': 4,\n",
       " 'alive': 5,\n",
       " 'jobs.': 4,\n",
       " 'responsible.': 4,\n",
       " 'account.': 6,\n",
       " 'HOURRRSSSS': 1,\n",
       " '@shmsaaldh': 1,\n",
       " 'wearing': 10,\n",
       " 'exact': 2,\n",
       " 'sweatshirt': 1,\n",
       " 'questions': 8,\n",
       " 'time.': 20,\n",
       " \"Can't\": 27,\n",
       " 'hammock': 1,\n",
       " 'isolation,': 1,\n",
       " 'offers': 1,\n",
       " 'tests?': 1,\n",
       " 'fun:': 1,\n",
       " 'freely': 1,\n",
       " 'Shehnaaz': 2,\n",
       " 'Gill': 1,\n",
       " 'question,': 3,\n",
       " 'be.': 6,\n",
       " 'ONLY': 6,\n",
       " 'ONE.': 1,\n",
       " '#ShehnaazGill': 1,\n",
       " '@ishehnaaz_gill': 1,\n",
       " '@KaushalJoshi15': 1,\n",
       " 'suffering': 3,\n",
       " 'depression.': 2,\n",
       " 'worse.': 9,\n",
       " 'Hi.': 15,\n",
       " 'covering': 7,\n",
       " 'nose....': 1,\n",
       " 'pointless.': 1,\n",
       " 'Wear': 1,\n",
       " 'please.': 3,\n",
       " 'exist;': 1,\n",
       " 'choose': 7,\n",
       " 'Trump:': 15,\n",
       " '\"I': 19,\n",
       " 'campaigning.\"': 8,\n",
       " 'goin': 1,\n",
       " 'Thorpe': 1,\n",
       " 'Park/Alton': 1,\n",
       " 'Towers': 1,\n",
       " \"Y'ALL!!!\": 1,\n",
       " 'HIT': 4,\n",
       " 'FOLLOWERS': 3,\n",
       " 'TWITCH!!!': 1,\n",
       " '\\U0001f973\\U0001f929': 1,\n",
       " 'continues': 2,\n",
       " 'me!': 10,\n",
       " 'all!': 5,\n",
       " 'gifted': 1,\n",
       " 'subs': 3,\n",
       " 'donos': 1,\n",
       " 'ğŸ’—': 1,\n",
       " 'who-the-hell-even-knows-anymore': 18,\n",
       " 'quarantine:': 19,\n",
       " 'GIF,': 19,\n",
       " 'honest': 20,\n",
       " 'read/hear': 18,\n",
       " '\"we': 19,\n",
       " 'together\".': 18,\n",
       " 'ğŸ‘‹ğŸ»': 1,\n",
       " 'stressed': 4,\n",
       " 'coloring': 2,\n",
       " 'meant': 2,\n",
       " 'relaxation?': 1,\n",
       " 'hunch': 1,\n",
       " 'page,': 1,\n",
       " 'pencil,': 1,\n",
       " 'choice.': 3,\n",
       " 'done,': 10,\n",
       " 'therapy.': 9,\n",
       " 'reminding': 3,\n",
       " 'invaded': 1,\n",
       " 'chickens': 1,\n",
       " '@The_Badger_jm': 1,\n",
       " 'FSQ!!': 1,\n",
       " 'Retired': 1,\n",
       " 'players.': 2,\n",
       " 'not.': 14,\n",
       " 'memory?': 1,\n",
       " 'great,': 2,\n",
       " 'nostalgia': 1,\n",
       " 'memories': 5,\n",
       " 'were?': 1,\n",
       " 'Childhood:': 1,\n",
       " 'sprinkled': 1,\n",
       " 'sugar': 6,\n",
       " 'avocado': 2,\n",
       " 'ğŸ˜‹': 4,\n",
       " '65th': 2,\n",
       " 'birthday': 20,\n",
       " \"son's\": 5,\n",
       " 'Yup': 2,\n",
       " 'GIF?': 2,\n",
       " 'sick': 13,\n",
       " '$50,000': 2,\n",
       " 'run?': 2,\n",
       " '#BTC': 3,\n",
       " 'debate': 5,\n",
       " 'Biden?': 5,\n",
       " 'GGs': 1,\n",
       " '@CetraLol': 1,\n",
       " 'mAAd': 1,\n",
       " '1-0': 2,\n",
       " 'PRL!': 1,\n",
       " '9PM': 1,\n",
       " 'Defiance.': 1,\n",
       " 'grateful': 10,\n",
       " 'passion/happiness': 1,\n",
       " 'life....or': 1,\n",
       " 'appreciate': 12,\n",
       " 'condescending!!': 1,\n",
       " 'Evening': 3,\n",
       " 'everyone.': 4,\n",
       " 'awful.': 4,\n",
       " 'dear': 4,\n",
       " 'Covid19.': 3,\n",
       " 'screamed': 3,\n",
       " 'minutes': 18,\n",
       " 'straight.': 5,\n",
       " 'stunned': 3,\n",
       " 'her.': 8,\n",
       " 'crawl': 3,\n",
       " 'forever.': 4,\n",
       " 'mentally': 3,\n",
       " 'unwell': 2,\n",
       " '@SchittsCreek': 1,\n",
       " 'finale': 1,\n",
       " \"Disney's\": 1,\n",
       " 'shitty': 6,\n",
       " 'along...': 1,\n",
       " '@stageit': 2,\n",
       " 'week?': 3,\n",
       " '\"we\"': 2,\n",
       " 'we.': 2,\n",
       " 'alone...that': 2,\n",
       " 'sad.': 3,\n",
       " 'dropped': 6,\n",
       " '4/20': 2,\n",
       " 'interview': 4,\n",
       " 'AUDACITY': 1,\n",
       " 'Skype': 1,\n",
       " '9am.': 1,\n",
       " 'sleeping': 4,\n",
       " '11am?': 1,\n",
       " 'busy': 4,\n",
       " \"Let's\": 31,\n",
       " 'volunteered': 1,\n",
       " 'reduce': 2,\n",
       " 'fantasized': 1,\n",
       " 'smothering': 1,\n",
       " 'pillow.': 2,\n",
       " 'karma': 1,\n",
       " 'scale?': 1,\n",
       " 'LIBERATE': 13,\n",
       " 'VIRGINIA,': 11,\n",
       " '2nd': 18,\n",
       " 'Amendment.': 11,\n",
       " 'siege!': 11,\n",
       " 'while.': 6,\n",
       " 'Feeling': 5,\n",
       " 'hella': 4,\n",
       " 'now.': 21,\n",
       " 'Verkis': 1,\n",
       " 'broke': 6,\n",
       " 'posting': 4,\n",
       " 'treating': 6,\n",
       " 'all?': 3,\n",
       " 'pregnancy': 2,\n",
       " 'kicking': 2,\n",
       " 'assğŸ˜©': 1,\n",
       " 'scared': 8,\n",
       " 'nerds': 1,\n",
       " 'glasses,': 1,\n",
       " 'surgical': 2,\n",
       " 'creates': 1,\n",
       " 'visibility': 2,\n",
       " 'foggy': 1,\n",
       " 'specs!!!': 1,\n",
       " '#COVID19': 16,\n",
       " 'smoke': 1,\n",
       " 'to,': 1,\n",
       " 'to.': 4,\n",
       " '.@WHO': 1,\n",
       " 'pandemic,': 3,\n",
       " 'providing': 3,\n",
       " 'advice,': 1,\n",
       " 'training,': 1,\n",
       " 'equipment': 1,\n",
       " 'crucial': 2,\n",
       " 'livesâ€”including': 1,\n",
       " \"Americans'.\": 1,\n",
       " 'Cutting': 1,\n",
       " 'dangerousâ€”Trump': 1,\n",
       " 'authority': 1,\n",
       " 'know:': 3,\n",
       " 'violating': 1,\n",
       " 'impeached.': 1,\n",
       " 'nigga': 6,\n",
       " 'aboogie': 1,\n",
       " 'prime,': 2,\n",
       " 'hurt.': 2,\n",
       " 'Redskins': 1,\n",
       " 'morning.': 10,\n",
       " 'Uh.': 1,\n",
       " '#OUSTDUTERENOW': 3,\n",
       " 'turns': 4,\n",
       " 'martial': 1,\n",
       " 'advantage': 3,\n",
       " 'inability': 2,\n",
       " 'mobilize': 1,\n",
       " '#OUSTDUTERTENOW': 1,\n",
       " 'thousands': 12,\n",
       " 'philippines': 1,\n",
       " 'dictator': 1,\n",
       " 'todd': 1,\n",
       " 'wins': 4,\n",
       " 'gamers': 1,\n",
       " '@COLIATHGAMING': 1,\n",
       " '@Baker_TV_': 1,\n",
       " '@vicdgordon': 1,\n",
       " '@StreamGamma': 1,\n",
       " '@kedabosch': 1,\n",
       " '@Day1neGaming': 1,\n",
       " '@JxckWSW': 1,\n",
       " '@Ncshredder_': 1,\n",
       " '@Samurai_Ree': 1,\n",
       " '@Stardrix1': 1,\n",
       " '@GSO_Joey': 1,\n",
       " '@TSillysweat': 1,\n",
       " '@ChloeDonald_': 1,\n",
       " '@xLexry': 1,\n",
       " '@MultynWolf': 1,\n",
       " '@SaycredAngel': 1,\n",
       " '@fuscyoface': 1,\n",
       " '@Storkyyy1': 1,\n",
       " 'Kamo': 1,\n",
       " 'Mphela': 1,\n",
       " 'whole': 29,\n",
       " 'blueprint': 1,\n",
       " 'moves': 4,\n",
       " '\"she': 1,\n",
       " 'dances': 1,\n",
       " 'shit\"': 2,\n",
       " 'ğŸ˜•': 1,\n",
       " 'sober': 5,\n",
       " 'hurts': 3,\n",
       " 'intensions.': 1,\n",
       " 'learned': 8,\n",
       " 'actions.': 1,\n",
       " 'Steyer': 1,\n",
       " 'lives.': 5,\n",
       " 'California.': 3,\n",
       " 'Named': 1,\n",
       " 'Newsom': 2,\n",
       " 'recovery': 2,\n",
       " 'force,': 1,\n",
       " 'injustices': 1,\n",
       " 'revealed': 3,\n",
       " 'crisis.': 4,\n",
       " 'reasonable,': 1,\n",
       " 'zoom': 3,\n",
       " 'calls': 6,\n",
       " 'fart': 3,\n",
       " 'meetings': 2,\n",
       " 'mute': 2,\n",
       " 'know.': 9,\n",
       " 'ğŸ’¨ğŸ’¨': 1,\n",
       " 'YALL': 3,\n",
       " 'READY': 1,\n",
       " 'CAUCASIANS': 1,\n",
       " 'THEY': 4,\n",
       " 'CANCEL': 1,\n",
       " '4TH': 3,\n",
       " 'JULY?!!!!!': 1,\n",
       " 'convo': 4,\n",
       " 'meteoric': 1,\n",
       " 'again.': 19,\n",
       " 'soon.': 4,\n",
       " 'Nathaniel': 14,\n",
       " 'here.': 20,\n",
       " 'you?': 19,\n",
       " '7th': 8,\n",
       " 'slid': 7,\n",
       " 'DMs?': 7,\n",
       " 'Sweep': 1,\n",
       " 'did.': 3,\n",
       " 'bump': 2,\n",
       " 'pronounced': 4,\n",
       " 'orders.': 2,\n",
       " 'Oklahoma': 1,\n",
       " '53%': 1,\n",
       " 'increase': 3,\n",
       " 'jumped': 1,\n",
       " '60%': 3,\n",
       " 'Arkansas,': 1,\n",
       " '74%': 1,\n",
       " 'Nebraska,': 1,\n",
       " '82%': 1,\n",
       " 'Iowa.': 1,\n",
       " 'Dakota': 3,\n",
       " 'whopping': 1,\n",
       " '205%': 1,\n",
       " 'spike.': 1,\n",
       " '#StayHomeStaySafeSaveLives': 1,\n",
       " 'chick': 3,\n",
       " 'sauce': 4,\n",
       " 'body.': 4,\n",
       " 'yall': 11,\n",
       " \"What's\": 15,\n",
       " 'funny': 9,\n",
       " 'hurry': 2,\n",
       " 'asked': 19,\n",
       " 'first.': 4,\n",
       " '#smallvictory': 1,\n",
       " 'sucks': 2,\n",
       " 'decorating': 1,\n",
       " '#AnimalCrossing': 1,\n",
       " 'NOVEMBER': 2,\n",
       " 'headline': 2,\n",
       " 'preview:': 2,\n",
       " 'defeated': 18,\n",
       " 'landslide': 2,\n",
       " 'Mitch': 2,\n",
       " 'McConnell': 2,\n",
       " 'Lindsey': 4,\n",
       " 'Martha': 2,\n",
       " 'McSally': 2,\n",
       " 'Cory': 2,\n",
       " 'Gardner': 2,\n",
       " 'Loeffler': 3,\n",
       " 'Tillis': 2,\n",
       " 'Yeah,': 3,\n",
       " 'night,': 2,\n",
       " 'dreamt': 1,\n",
       " 'journalists,': 1,\n",
       " 'Uddhav': 1,\n",
       " 'PM.': 2,\n",
       " 'aide': 1,\n",
       " 'approaches': 1,\n",
       " 'informal': 1,\n",
       " 'mine,': 1,\n",
       " 'no,': 3,\n",
       " '#soproudofmyself': 1,\n",
       " 'Niggas': 1,\n",
       " 'bout': 8,\n",
       " 'shooting': 3,\n",
       " 'hooping': 1,\n",
       " '$50': 8,\n",
       " 'retweets': 6,\n",
       " 'Minutes.': 2,\n",
       " '@K_9Girl': 1,\n",
       " 'Myself.': 2,\n",
       " 'sitting': 13,\n",
       " 'Cocoa': 1,\n",
       " 'Krispies': 2,\n",
       " 'strange': 2,\n",
       " 'Rice': 1,\n",
       " 'hits': 5,\n",
       " 'this?': 4,\n",
       " 'wasted.': 1,\n",
       " 'finally': 21,\n",
       " 'agreed': 3,\n",
       " 'repaint': 1,\n",
       " 'stuck': 7,\n",
       " 'home.': 5,\n",
       " 'requesting': 2,\n",
       " 'thoughts': 9,\n",
       " 'prayers': 3,\n",
       " 'difficult': 5,\n",
       " 'ğŸ˜Š': 18,\n",
       " 'man-half': 1,\n",
       " 'assholes': 2,\n",
       " 'concerns': 3,\n",
       " 'exercise,': 1,\n",
       " 'shit,': 2,\n",
       " 'smoke,': 1,\n",
       " 'drink': 7,\n",
       " 'excessive': 1,\n",
       " 'alcohol.': 2,\n",
       " 'helluva': 1,\n",
       " 'disease': 2,\n",
       " 'Covid.': 1,\n",
       " 'Wake': 3,\n",
       " 'Lebron': 7,\n",
       " 'MJ.': 7,\n",
       " \"That's\": 33,\n",
       " 'passing': 1,\n",
       " 'Moir.': 1,\n",
       " 'detox': 1,\n",
       " 'nowâœŒğŸ»': 1,\n",
       " 'Brooks': 3,\n",
       " 'hates': 22,\n",
       " 'millennials': 3,\n",
       " 'marry': 11,\n",
       " 'Sidharth': 1,\n",
       " 'mention': 5,\n",
       " 'please?': 3,\n",
       " 'deserves': 3,\n",
       " 'please.ğŸ˜­': 1,\n",
       " 'dont': 16,\n",
       " 'belive': 1,\n",
       " 'loosing': 2,\n",
       " '\"nah': 1,\n",
       " 'somebody': 4,\n",
       " ...}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unknown_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check punctuations that roberta unknown "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "punct = \"/-'?!.,#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~\" + '\"\"â€œâ€â€™' + 'âˆÎ¸Ã·Î±â€¢Ã âˆ’Î²âˆ…Â³Ï€â€˜â‚¹Â´Â°Â£â‚¬\\Ã—â„¢âˆšÂ²â€”â€“&'\n",
    "def unknown_punctuation(roberta_vocab):\n",
    "    unknown = ''\n",
    "    for char in punct:\n",
    "        if char not in list(roberta_vocab.keys()):\n",
    "            unknown += char\n",
    "            unknown += ' '\n",
    "    return unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Roberta unknown: \n",
      "â€œ â€ â€™ âˆ Î¸ Î± â€¢ âˆ’ Î² âˆ… Ï€ â€˜ â‚¹ â‚¬ â„¢ âˆš â€” â€“ \n"
     ]
    }
   ],
   "source": [
    "print(\"Roberta unknown: \")\n",
    "print(unknown_punctuation(roberta_vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping unknown to known punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_punc(text):\n",
    "    punct_mapping = {\"â€˜\": \"'\", \"â‚¹\": \"e\", \"Â´\": \"'\", \"Â°\": \"\", \"â‚¬\": \"e\", \"â„¢\": \"tm\", \"âˆš\": \" sqrt \", \"Ã—\": \"x\", \"Â²\": \"2\", \"â€”\": \"-\", \"â€“\": \"-\", \"â€™\": \"'\", \"_\": \"-\", \"`\": \"'\", 'â€œ': '\"', 'â€': '\"', 'â€œ': '\"', \"Â£\": \"e\", 'âˆ': 'infinity', 'Î¸': 'theta', 'Ã·': '/', 'Î±': 'alpha', 'â€¢': '.', 'Ã ': 'a', 'âˆ’': '-', 'Î²': 'beta', 'âˆ…': '', 'Â³': '3', 'Ï€': 'pi', }\n",
    "    for p in punct_mapping:\n",
    "        text = text.replace(p, punct_mapping[p])\n",
    "    for p in punct:\n",
    "        text = text.replace(p, ' {} '.format(p))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['map_punc_text'] = df_train.text.apply(change_punc)\n",
    "df_train['map_punc_reply'] = df_train.reply.apply(change_punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev['map_punc_text'] = df_dev.text.apply(change_punc)\n",
    "df_dev['map_punc_reply'] = df_dev.reply.apply(change_punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['map_punc_text'] = df_test.text.apply(change_punc)\n",
    "df_test['map_punc_reply'] = df_test.reply.apply(change_punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train text unique vocab count is: 46129\n",
      "train reply unique vocab count is: 18569\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=46129.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 13.464% (6211 / 46129) of vocab\n",
      "Found embeddings for 80.351% (645864 / 803801) of all text\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=18569.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 21.977% (4081 / 18569) of vocab\n",
      "Found embeddings for 79.704% (110219 / 138285) of all text\n"
     ]
    }
   ],
   "source": [
    "train_text_vocab = get_vocab(df_train['map_punc_text'].values)\n",
    "train_reply_vocab = get_vocab(df_train['map_punc_reply'].values)\n",
    "print(\"train text unique vocab count is: {}\".format(len(train_text_vocab)))\n",
    "print(\"train reply unique vocab count is: {}\".format(len(train_reply_vocab)))\n",
    "print()\n",
    "\n",
    "unknown_text = check_coverage(train_text_vocab, roberta_vocab)\n",
    "print()\n",
    "unknown_reply = check_coverage(train_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev text unique vocab count is: 13357\n",
      "dev reply unique vocab count is: 4473\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=13357.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 26.698% (3566 / 13357) of vocab\n",
      "Found embeddings for 80.274% (81844 / 101956) of all text\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=4473.0, style=ProgressStyle(description_â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 36.977% (1654 / 4473) of vocab\n",
      "Found embeddings for 78.665% (13797 / 17539) of all text\n"
     ]
    }
   ],
   "source": [
    "dev_text_vocab = get_vocab(df_dev['map_punc_text'].values)\n",
    "dev_reply_vocab = get_vocab(df_dev['map_punc_reply'].values)\n",
    "print(\"dev text unique vocab count is: {}\".format(len(dev_text_vocab)))\n",
    "print(\"dev reply unique vocab count is: {}\".format(len(dev_reply_vocab)))\n",
    "unknown_text = check_coverage(dev_text_vocab, roberta_vocab)\n",
    "print()\n",
    "unknown_reply = check_coverage(dev_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test text unique vocab count is: 13174\n",
      "test reply unique vocab count is: 4263\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=13174.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 27.228% (3587 / 13174) of vocab\n",
      "Found embeddings for 80.222% (80192 / 99962) of all text\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=4263.0, style=ProgressStyle(description_â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 39.268% (1674 / 4263) of vocab\n",
      "Found embeddings for 79.877% (13548 / 16961) of all text\n"
     ]
    }
   ],
   "source": [
    "test_text_vocab = get_vocab(df_test['map_punc_text'].values)\n",
    "test_reply_vocab = get_vocab(df_test['map_punc_reply'].values)\n",
    "print(\"test text unique vocab count is: {}\".format(len(test_text_vocab)))\n",
    "print(\"test reply unique vocab count is: {}\".format(len(test_reply_vocab)))\n",
    "unknown_text = check_coverage(test_text_vocab, roberta_vocab)\n",
    "print()\n",
    "unknown_reply = check_coverage(test_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hug', 96),\n",
       " ('cannot', 90),\n",
       " ('quarantine', 68),\n",
       " ('tonight', 64),\n",
       " ('myself', 58),\n",
       " ('gonna', 55),\n",
       " ('Biden', 52),\n",
       " ('reaction', 48),\n",
       " ('tomorrow', 47),\n",
       " ('fucking', 43),\n",
       " ('coronavirus', 43),\n",
       " ('wanna', 43),\n",
       " ('Pelosi', 42),\n",
       " ('Nancy', 40),\n",
       " ('hear', 39),\n",
       " ('feeling', 39),\n",
       " ('guys', 39),\n",
       " ('weeks', 39),\n",
       " ('Oz', 39),\n",
       " ('anyone', 39),\n",
       " ('COVID', 38),\n",
       " ('believe', 37),\n",
       " ('trying', 36),\n",
       " ('followers', 36),\n",
       " ('yourself', 36),\n",
       " ('tweet', 36),\n",
       " ('died', 36),\n",
       " ('lockdown', 36),\n",
       " ('least', 35),\n",
       " ('gave', 35),\n",
       " ('sad', 34),\n",
       " ('GIF', 34),\n",
       " ('hope', 34),\n",
       " ('birthday', 33),\n",
       " ('anymore', 33),\n",
       " ('Covid', 32),\n",
       " ('COVID19', 31),\n",
       " ('economy', 31),\n",
       " ('says', 30),\n",
       " ('whole', 30),\n",
       " ('wants', 29),\n",
       " ('virus', 29),\n",
       " ('already', 28),\n",
       " ('knows', 28),\n",
       " ('wanted', 27),\n",
       " ('pandemic', 27),\n",
       " ('fans', 27),\n",
       " ('hashtag', 26),\n",
       " ('beautiful', 26),\n",
       " ('dinner', 26),\n",
       " ('saying', 25),\n",
       " ('wish', 25),\n",
       " ('weekend', 24),\n",
       " ('hugs', 24),\n",
       " ('BailoutHumansNow', 24),\n",
       " ('totally', 24),\n",
       " ('dependable', 24),\n",
       " ('forget', 24),\n",
       " ('ğŸ˜‚', 24),\n",
       " ('installing', 23),\n",
       " ('ScottyFromMarketing', 23),\n",
       " ('lives', 23),\n",
       " ('minutes', 23),\n",
       " ('â¤ï¸', 23),\n",
       " ('ğŸ¤”', 23),\n",
       " ('honest', 23),\n",
       " ('career', 23),\n",
       " ('dick', 22),\n",
       " ('following', 22),\n",
       " ('finally', 22),\n",
       " ('hates', 22),\n",
       " ('explain', 22),\n",
       " ('decided', 21),\n",
       " ('tired', 21),\n",
       " ('Crazy', 21),\n",
       " ('numbers', 21),\n",
       " ('sick', 20),\n",
       " ('suck', 20),\n",
       " ('amazing', 20),\n",
       " ('thankful', 20),\n",
       " ('asked', 20),\n",
       " ('feels', 20),\n",
       " ('businesses', 20),\n",
       " ('horny', 20),\n",
       " ('Guys', 20),\n",
       " ('\\U0001f97a', 19),\n",
       " ('ğŸ˜­', 19),\n",
       " ('seanhannity', 19),\n",
       " ('took', 19),\n",
       " ('2nd', 19),\n",
       " ('politicians', 19),\n",
       " ('Radical', 19),\n",
       " ('WritingCommunity', 19),\n",
       " ('Cuomo', 19),\n",
       " ('moment', 19),\n",
       " ('teammates', 18),\n",
       " ('waiting', 18),\n",
       " ('defeated', 18),\n",
       " ('ğŸ˜Š', 18),\n",
       " ('pathetic', 18),\n",
       " ('stimulus', 18),\n",
       " ('idea', 17),\n",
       " ('gifs', 17),\n",
       " ('supporter', 17),\n",
       " ('crisis', 17),\n",
       " ('excited', 17),\n",
       " ('incompetent', 17),\n",
       " ('puppet', 17),\n",
       " ('giveaway', 17),\n",
       " ('guess', 17),\n",
       " ('deaths', 17),\n",
       " ('Conference', 17),\n",
       " ('AGAIN', 17),\n",
       " ('gotta', 16),\n",
       " ('came', 16),\n",
       " ('awesome', 16),\n",
       " ('dont', 16),\n",
       " ('become', 16),\n",
       " ('voting', 16),\n",
       " ('ğŸ˜”', 16),\n",
       " ('stupid', 16),\n",
       " ('describes', 16),\n",
       " ('bitch', 16),\n",
       " ('Guidelines', 16),\n",
       " ('OPENING', 16),\n",
       " ('AMERICA', 16),\n",
       " ('woke', 15),\n",
       " ('Gates', 15),\n",
       " ('fucked', 15),\n",
       " ('damn', 15),\n",
       " ('supposed', 15),\n",
       " ('distancing', 15),\n",
       " ('lonely', 15),\n",
       " ('cares', 15),\n",
       " ('trash', 14),\n",
       " ('cute', 14),\n",
       " ('quickly', 14),\n",
       " ('meeting', 14),\n",
       " ('socialist', 14),\n",
       " ('others', 14),\n",
       " ('LIBERATE', 14),\n",
       " ('Nathaniel', 14),\n",
       " ('sitting', 14),\n",
       " ('mood', 14),\n",
       " ('showed', 14),\n",
       " ('tears', 14),\n",
       " ('buying', 14),\n",
       " ('lmao', 14),\n",
       " ('helped', 14),\n",
       " ('happened', 14),\n",
       " ('ugly', 14),\n",
       " ('understand', 14),\n",
       " ('deserve', 14),\n",
       " ('tried', 13),\n",
       " ('proud', 13),\n",
       " ('worse', 13),\n",
       " ('yall', 13),\n",
       " ('thoughts', 13),\n",
       " ('marry', 13),\n",
       " ('longer', 13),\n",
       " ('ensure', 13),\n",
       " ('corona', 13),\n",
       " ('anxiety', 13),\n",
       " ('folks', 13),\n",
       " ('spend', 13),\n",
       " ('realize', 13),\n",
       " ('tweets', 13),\n",
       " ('safely', 13),\n",
       " ('6pm', 13),\n",
       " ('ğŸ™ƒ', 13),\n",
       " ('stopped', 13),\n",
       " ('Vaccine', 12),\n",
       " ('coffee', 12),\n",
       " ('pizza', 12),\n",
       " ('decision', 12),\n",
       " ('billionaire', 12),\n",
       " ('afford', 12),\n",
       " ('questionsâ€¦', 12),\n",
       " ('attention', 12),\n",
       " ('questions', 12),\n",
       " ('appreciate', 12),\n",
       " ('thousands', 12),\n",
       " ('funny', 12),\n",
       " ('covid', 12),\n",
       " ('approval', 12),\n",
       " ('students', 12),\n",
       " ('entire', 12),\n",
       " ('looks', 12),\n",
       " ('complaining', 12),\n",
       " ('truly', 12),\n",
       " ('thinks', 12),\n",
       " ('kinda', 12),\n",
       " ('loved', 11),\n",
       " ('reopen', 11),\n",
       " ('experience', 11),\n",
       " ('putting', 11),\n",
       " ('wearing', 11),\n",
       " ('grateful', 11),\n",
       " ('VIRGINIA', 11),\n",
       " ('Amendment', 11),\n",
       " ('siege', 11),\n",
       " ('scared', 11),\n",
       " ('DMs', 11),\n",
       " ('replies', 11),\n",
       " ('handling', 11),\n",
       " ('Dollar', 11),\n",
       " ('streaming', 11),\n",
       " ('possible', 11),\n",
       " ('nobody', 11),\n",
       " ('\\U0001f974', 11),\n",
       " ('knew', 11),\n",
       " ('boyfriend', 11),\n",
       " ('crying', 11),\n",
       " ('Ventilators', 11),\n",
       " ('leadership', 11),\n",
       " ('Governor', 11),\n",
       " ('ğŸ˜³', 11),\n",
       " ('1st', 11),\n",
       " ('spent', 11),\n",
       " ('means', 11),\n",
       " ('across', 11),\n",
       " ('listen', 11),\n",
       " ('couple', 11),\n",
       " ('lil', 10),\n",
       " ('everyday', 10),\n",
       " ('kindness', 10),\n",
       " ('relationship', 10),\n",
       " ('conversation', 10),\n",
       " ('sister', 10),\n",
       " ('definitely', 10),\n",
       " ('forever', 10),\n",
       " ('ventilators', 10),\n",
       " ('passed', 10),\n",
       " ('THAT', 10),\n",
       " ('goes', 10),\n",
       " ('summer', 10),\n",
       " ('disaster', 10),\n",
       " ('H1N1', 10),\n",
       " ('Swine', 10),\n",
       " ('Flu', 10),\n",
       " ('Polling', 10),\n",
       " ('disastrous', 10),\n",
       " ('unnecessarily', 10),\n",
       " ('incompetence', 10),\n",
       " ('Billion', 10),\n",
       " ('Obamacare', 10),\n",
       " ('website', 10),\n",
       " ('excuse', 10),\n",
       " ('moved', 10),\n",
       " ('randomly', 10),\n",
       " ('cuz', 10),\n",
       " ('ğŸ˜‚ğŸ˜‚ğŸ˜‚', 10),\n",
       " ('themselves', 10),\n",
       " ('reopening', 10),\n",
       " ('realized', 10),\n",
       " ('opinion', 10),\n",
       " ('BREAKING', 10),\n",
       " ('5k', 10),\n",
       " ('biggest', 9),\n",
       " ('laughing', 9),\n",
       " ('sucking', 9),\n",
       " ('taken', 9),\n",
       " ('hurt', 9),\n",
       " ('himself', 9),\n",
       " ('situation', 9),\n",
       " ('patients', 9),\n",
       " ('ğŸ‘€', 9),\n",
       " ('choose', 9),\n",
       " ('therapy', 9),\n",
       " ('awful', 9),\n",
       " ('ğŸ˜­ğŸ˜­', 9),\n",
       " ('difference', 9),\n",
       " ('3rd', 9),\n",
       " ('Idk', 9),\n",
       " ('drunk', 9),\n",
       " ('weird', 9),\n",
       " ('ğŸ™„', 9),\n",
       " ('wonder', 9),\n",
       " ('honestly', 9),\n",
       " ('NEED', 9),\n",
       " ('staying', 9),\n",
       " ('showing', 9),\n",
       " ('bought', 9),\n",
       " ('cheese', 9),\n",
       " ('okay', 9),\n",
       " ('expansive', 9),\n",
       " ('accurate', 9),\n",
       " ('reminds', 9),\n",
       " ('happen', 9),\n",
       " ('angry', 9),\n",
       " ('dude', 9),\n",
       " ('helping', 9),\n",
       " ('worry', 9),\n",
       " ('shower', 9),\n",
       " ('ppl', 9),\n",
       " ('seriously', 9),\n",
       " ('unemployment', 9),\n",
       " ('pls', 9),\n",
       " ('retweet', 9),\n",
       " ('grocery', 9),\n",
       " ('pregnant', 9),\n",
       " ('listening', 8),\n",
       " ('accounts', 8),\n",
       " ('idk', 8),\n",
       " ('Raise', 8),\n",
       " ('leaving', 8),\n",
       " ('announce', 8),\n",
       " ('celebrate', 8),\n",
       " ('takes', 8),\n",
       " ('depression', 8),\n",
       " ('campaigning', 8),\n",
       " ('sugar', 8),\n",
       " ('11am', 8),\n",
       " ('broke', 8),\n",
       " ('advice', 8),\n",
       " ('nigga', 8),\n",
       " ('learned', 8),\n",
       " ('7th', 8),\n",
       " ('sucks', 8),\n",
       " ('bout', 8),\n",
       " ('Frequently', 8),\n",
       " ('opportunity', 8),\n",
       " ('LIKE', 8),\n",
       " ('finish', 8),\n",
       " ('cheating', 8),\n",
       " ('partner', 8),\n",
       " ('â†’', 8),\n",
       " ('heaven', 8),\n",
       " ('attempt', 8),\n",
       " ('LOVE', 8),\n",
       " ('chill', 8),\n",
       " ('ğŸ’•', 8),\n",
       " ('beds', 8),\n",
       " ('causing', 8),\n",
       " ('funeral', 8),\n",
       " ('Coronavirus', 8),\n",
       " ('MUCH', 8),\n",
       " ('pray', 8),\n",
       " ('enjoy', 8),\n",
       " ('teacher', 8),\n",
       " ('Gif', 8),\n",
       " ('additional', 8),\n",
       " ('approve', 8),\n",
       " ('dying', 8),\n",
       " ('âœ…', 8),\n",
       " ('welcome', 8),\n",
       " ('HAVE', 8),\n",
       " ('ğŸ¤', 8),\n",
       " ('terrible', 8),\n",
       " ('keeps', 8),\n",
       " ('FollowFriday', 8),\n",
       " ('likes', 8),\n",
       " ('relief', 8),\n",
       " ('idiot', 8),\n",
       " ('apartment', 8),\n",
       " ('upset', 8),\n",
       " ('sounds', 7),\n",
       " ('kitchen', 7),\n",
       " ('messages', 7),\n",
       " ('OldRich', 7),\n",
       " ('tells', 7),\n",
       " ('joke', 7),\n",
       " ('NYC', 7),\n",
       " ('sending', 7),\n",
       " ('alive', 7),\n",
       " ('ONLY', 7),\n",
       " ('covering', 7),\n",
       " ('dear', 7),\n",
       " ('dropped', 7),\n",
       " ('treating', 7),\n",
       " ('calls', 7),\n",
       " ('slid', 7),\n",
       " ('sauce', 7),\n",
       " ('stuck', 7),\n",
       " ('drink', 7),\n",
       " ('Lebron', 7),\n",
       " ('masks', 7),\n",
       " ('Genuinely', 7),\n",
       " ('Rashford', 7),\n",
       " ('clothes', 7),\n",
       " ('lately', 7),\n",
       " ('fraud', 7),\n",
       " ('discussion', 7),\n",
       " ('harder', 7),\n",
       " ('Instagram', 7),\n",
       " ('herself', 7),\n",
       " ('lucky', 7),\n",
       " ('incredibly', 7),\n",
       " ('expect', 7),\n",
       " ('glad', 7),\n",
       " ('RETWEET', 7),\n",
       " ('Zoom', 7),\n",
       " ('disgusting', 7),\n",
       " ('TESTING', 7),\n",
       " ('exam', 7),\n",
       " ('yours', 7),\n",
       " ('Been', 7),\n",
       " ('turning', 7),\n",
       " ('Birthday', 7),\n",
       " ('loves', 7),\n",
       " ('comedy', 7),\n",
       " ('evening', 7),\n",
       " ('complain', 7),\n",
       " ('waste', 7),\n",
       " ('songs', 7),\n",
       " ('afternoon', 7),\n",
       " ('QUARANTINE', 7),\n",
       " ('EVER', 7),\n",
       " ('FUCK', 7),\n",
       " ('slide', 7),\n",
       " ('apparently', 7),\n",
       " ('barely', 7),\n",
       " ('officials', 7),\n",
       " ('Respond', 7),\n",
       " ('\\U0001f970', 7),\n",
       " ('heavily', 7),\n",
       " ('awake', 7),\n",
       " ('blocked', 7),\n",
       " ('sexy', 7),\n",
       " ('clearly', 7),\n",
       " ('problems', 7),\n",
       " ('pics', 7),\n",
       " ('officially', 7),\n",
       " ('funds', 7),\n",
       " ('meme', 7),\n",
       " ('annoying', 7),\n",
       " ('KNOW', 7),\n",
       " ('appreciated', 7),\n",
       " ('surprise', 7),\n",
       " ('ğŸ”‘', 7),\n",
       " ('niggas', 6),\n",
       " ('everybody', 6),\n",
       " ('nightmare', 6),\n",
       " ('judging', 6),\n",
       " ('judgement', 6),\n",
       " ('HUNGRY', 6),\n",
       " ('worried', 6),\n",
       " ('yesterday', 6),\n",
       " ('feelings', 6),\n",
       " ('denies', 6),\n",
       " ('extent', 6),\n",
       " ('outbreak', 6),\n",
       " ('smh', 6),\n",
       " ('extend', 6),\n",
       " ('lovely', 6),\n",
       " ('expecting', 6),\n",
       " ('Minister', 6),\n",
       " ('vibes', 6),\n",
       " ('committed', 6),\n",
       " ('communist', 6),\n",
       " ('isolation', 6),\n",
       " ('Covid19', 6),\n",
       " ('shitty', 6),\n",
       " ('interview', 6),\n",
       " ('dangerous', 6),\n",
       " ('retweets', 6),\n",
       " ('difficult', 6),\n",
       " ('ğŸ˜ª', 6),\n",
       " ('amwriting', 6),\n",
       " ('Neymar', 6),\n",
       " ('starts', 6),\n",
       " ('senior', 6),\n",
       " ('makeup', 6),\n",
       " ('personally', 6),\n",
       " ('pictures', 6),\n",
       " ('experts', 6),\n",
       " ('lowkey', 6),\n",
       " ('dumb', 6),\n",
       " ('fellow', 6),\n",
       " ('fear', 6),\n",
       " ('blessed', 6),\n",
       " ('university', 6),\n",
       " ('Cassper', 6),\n",
       " ('survive', 6),\n",
       " ('thousand', 6),\n",
       " ('crush', 6),\n",
       " ('viewers', 6),\n",
       " ('Bailout', 6),\n",
       " ('Humans', 6),\n",
       " ('MUST', 6),\n",
       " ('Shout', 6),\n",
       " ('ğŸ¤£', 6),\n",
       " ('Quarantine', 6),\n",
       " ('Vikings', 6),\n",
       " ('scary', 6),\n",
       " ('groceries', 6),\n",
       " ('visit', 6),\n",
       " ('Lol', 6),\n",
       " ('strategy', 6),\n",
       " ('watched', 6),\n",
       " ('supporters', 6),\n",
       " ('gift', 6),\n",
       " ('breakfast', 6),\n",
       " ('suddenly', 6),\n",
       " ('miles', 6),\n",
       " ('voted', 6),\n",
       " ('ventilator', 6),\n",
       " ('unprecedented', 6),\n",
       " ('follows', 6),\n",
       " ('bunch', 6),\n",
       " ('vaccine', 6),\n",
       " ('chocolate', 6),\n",
       " ('cuddle', 6),\n",
       " ('missed', 6),\n",
       " ('employees', 6),\n",
       " ('possibility', 6),\n",
       " ('CoronaVirus', 6),\n",
       " ('Democrat', 6),\n",
       " ('immediately', 6),\n",
       " ('asleep', 6),\n",
       " ('POTUS', 6),\n",
       " ('governors', 6),\n",
       " ('appointing', 6),\n",
       " ('pussy', 6),\n",
       " ('losing', 6),\n",
       " ('promise', 6),\n",
       " ('RIGHT', 6),\n",
       " ('boobs', 6),\n",
       " ('WAS', 6),\n",
       " ('governor', 6),\n",
       " ('Guess', 6),\n",
       " ('notifications', 6),\n",
       " ('families', 6),\n",
       " ('tough', 6),\n",
       " ('seems', 6),\n",
       " ('dance', 6),\n",
       " ('CoronavirusLiar', 6),\n",
       " ('spirits', 6),\n",
       " ('ğŸ‘ğŸ¼', 6),\n",
       " ('discussing', 5),\n",
       " ('wtf', 5),\n",
       " ('cried', 5),\n",
       " ('hacked', 5),\n",
       " ('replying', 5),\n",
       " ('attacked', 5),\n",
       " ('stupidity', 5),\n",
       " ('hiding', 5),\n",
       " ('prepare', 5),\n",
       " ('transition', 5),\n",
       " ('till', 5),\n",
       " ('Govt', 5),\n",
       " ('wonderful', 5),\n",
       " ('ğŸ˜', 5),\n",
       " ('tbh', 5),\n",
       " ('fridge', 5),\n",
       " ('Parliament', 5),\n",
       " ('signs', 5),\n",
       " ('spending', 5),\n",
       " ('ridiculous', 5),\n",
       " ('memories', 5),\n",
       " ('debate', 5),\n",
       " ('happiness', 5),\n",
       " ('Feeling', 5),\n",
       " ('sober', 5),\n",
       " ('meetings', 5),\n",
       " ('hits', 5),\n",
       " ('prayers', 5),\n",
       " ('disease', 5),\n",
       " ('mention', 5),\n",
       " ('somebody', 5),\n",
       " ('â˜ºï¸', 5),\n",
       " ('drinks', 5),\n",
       " ('compassion', 5),\n",
       " ('Zack', 5),\n",
       " ('teams', 5),\n",
       " ('WILL', 5),\n",
       " ('BABY', 5),\n",
       " ('remain', 5),\n",
       " ('hearing', 5),\n",
       " ('huh', 5),\n",
       " ('Fauci', 5),\n",
       " ('boring', 5),\n",
       " ('waking', 5),\n",
       " ('doctors', 5),\n",
       " ('slowly', 5),\n",
       " ('expand', 5),\n",
       " ('cancelled', 5),\n",
       " ('Trey', 5),\n",
       " ('Burton', 5),\n",
       " ('cant', 5),\n",
       " ('selecting', 5),\n",
       " ('donate', 5),\n",
       " ('winğŸ’°', 5),\n",
       " ('plenty', 5),\n",
       " ('laid', 5),\n",
       " ('journey', 5),\n",
       " ('peaceful', 5),\n",
       " ('beach', 5),\n",
       " ('mutuals', 5),\n",
       " ('anywhere', 5),\n",
       " ('choked', 5),\n",
       " ('politician', 5),\n",
       " ('homes', 5),\n",
       " ('ğŸ™', 5),\n",
       " ('cough', 5),\n",
       " ('bipartisan', 5),\n",
       " ('ğŸ‡ºğŸ‡¸', 5),\n",
       " ('desk', 5),\n",
       " ('doubling', 5),\n",
       " ('Invisible', 5),\n",
       " ('Enemy', 5),\n",
       " ('concerned', 5),\n",
       " ('YOUR', 5),\n",
       " ('WHY', 5),\n",
       " ('bitches', 5),\n",
       " ('challenge', 5),\n",
       " ('butter', 5),\n",
       " ('shoes', 5),\n",
       " ('10k', 5),\n",
       " ('GOOD', 5),\n",
       " ('pounds', 5),\n",
       " ('FIRST', 5),\n",
       " ('loud', 5),\n",
       " ('loan', 5),\n",
       " ('tiktok', 5),\n",
       " ('dudes', 5),\n",
       " ('streets', 5),\n",
       " ('timeline', 5),\n",
       " ('freak', 5),\n",
       " ('haircut', 5),\n",
       " ('garden', 5),\n",
       " ('selfie', 5),\n",
       " ('DrOz', 5),\n",
       " ('imagine', 5),\n",
       " ('entering', 5),\n",
       " ('Dems', 5),\n",
       " ('realizing', 5),\n",
       " ('liquor', 5),\n",
       " ('RAT', 5),\n",
       " ('guest', 5),\n",
       " ('HIM', 5),\n",
       " ('rally', 5),\n",
       " ('naked', 5),\n",
       " ('horrible', 5),\n",
       " ('Retweet', 5),\n",
       " ('movies', 5),\n",
       " ('shopping', 5),\n",
       " ('roof', 5),\n",
       " ('Verge', 5),\n",
       " ('consistently', 5),\n",
       " ('mistake', 5),\n",
       " ('suspect', 5),\n",
       " ('furloughed', 5),\n",
       " ('writerslift', 5),\n",
       " ('milk', 5),\n",
       " ('drinking', 5),\n",
       " ('leaves', 5),\n",
       " ('everywhere', 5),\n",
       " ('followed', 5),\n",
       " ('govt', 5),\n",
       " ('LikewiseApp', 5),\n",
       " ('Yay', 5),\n",
       " ('infected', 5),\n",
       " ('attend', 5),\n",
       " ('Lockdown', 5),\n",
       " ('simply', 5),\n",
       " ('boo', 5),\n",
       " ('âœ¨', 5),\n",
       " ('juliemac1000', 5),\n",
       " ('Congressional', 5),\n",
       " ('lawyer', 5),\n",
       " ('payments', 5),\n",
       " ('bored', 5),\n",
       " ('OKAY', 5),\n",
       " ('TODAY', 5),\n",
       " ('happens', 5),\n",
       " ('screenshot', 5),\n",
       " ('Uncle', 5),\n",
       " ('2021', 5),\n",
       " ('interact', 5),\n",
       " ('saved', 5),\n",
       " ('fuckin', 5),\n",
       " ('murder', 5),\n",
       " ('nursing', 5),\n",
       " ('jumping', 5),\n",
       " ('Wuhan', 5),\n",
       " ('teach', 5),\n",
       " ('memes', 5),\n",
       " ('swear', 5),\n",
       " ('cheer', 5),\n",
       " ('earlier', 5),\n",
       " ('applause', 5),\n",
       " ('younger', 5),\n",
       " ('ğŸ˜”ğŸ˜”', 5),\n",
       " ('neighbor', 5),\n",
       " ('pushing', 5),\n",
       " ('WOW', 5),\n",
       " ('Kanye', 5),\n",
       " ('bills', 5),\n",
       " ('eggs', 5),\n",
       " ('tho', 5),\n",
       " ('sisters', 5),\n",
       " ('Couldn', 5),\n",
       " ('Lawrence', 5),\n",
       " ('sacrifice', 5),\n",
       " ('trading', 4),\n",
       " ('Might', 4),\n",
       " ('hardest', 4),\n",
       " ('hospitals', 4),\n",
       " ('spamming', 4),\n",
       " ('confronting', 4),\n",
       " ('ğŸ˜°', 4),\n",
       " ('Doing', 4),\n",
       " ('eventually', 4),\n",
       " ('cancel', 4),\n",
       " ('lunch', 4),\n",
       " ('begins', 4),\n",
       " ('greatest', 4),\n",
       " ('shout', 4),\n",
       " ('teenage', 4),\n",
       " ('salt', 4),\n",
       " ('liberate', 4),\n",
       " ('talent', 4),\n",
       " ('theater', 4),\n",
       " ('struggling', 4),\n",
       " ('allowing', 4),\n",
       " ('Tune', 4),\n",
       " ('sperm', 4),\n",
       " ('moms', 4),\n",
       " ('Horny', 4),\n",
       " ('liked', 4),\n",
       " ('communities', 4),\n",
       " ('apologize', 4),\n",
       " ('admit', 4),\n",
       " ('afraid', 4),\n",
       " ('recovered', 4),\n",
       " ('appointment', 4),\n",
       " ('LOL', 4),\n",
       " ('Somebody', 4),\n",
       " ('irresponsible', 4),\n",
       " ('COVID19Pandemic', 4),\n",
       " ('nose', 4),\n",
       " ('HIT', 4),\n",
       " ('stressed', 4),\n",
       " ('ğŸ˜‹', 4),\n",
       " ('Yup', 4),\n",
       " ('sleeping', 4),\n",
       " ('busy', 4),\n",
       " ('pillow', 4),\n",
       " ('hella', 4),\n",
       " ('posting', 4),\n",
       " ('turns', 4),\n",
       " ('wins', 4),\n",
       " ('moves', 4),\n",
       " ('hurts', 4),\n",
       " ('THEY', 4),\n",
       " ('convo', 4),\n",
       " ('pronounced', 4),\n",
       " ('Lindsey', 4),\n",
       " ('exercise', 4),\n",
       " ('writingcommunity', 4),\n",
       " ('Giants', 4),\n",
       " ('libs', 4),\n",
       " ('otherwise', 4),\n",
       " ('AEW', 4),\n",
       " ('Cody', 4),\n",
       " ('Suite', 4),\n",
       " ('lesson', 4),\n",
       " ('souls', 4),\n",
       " ('Thoughts', 4),\n",
       " ('spreading', 4),\n",
       " ('planning', 4),\n",
       " ('decide', 4),\n",
       " ('HATE', 4),\n",
       " ('slapped', 4),\n",
       " ('giveaways', 4),\n",
       " ('mum', 4),\n",
       " ('wondering', 4),\n",
       " ('ğŸ˜…', 4),\n",
       " ('potential', 4),\n",
       " ('faster', 4),\n",
       " ('Raiders', 4),\n",
       " ('Ruggs', 4),\n",
       " ('Jeudy', 4),\n",
       " ('Lamb', 4),\n",
       " ('idiots', 4),\n",
       " ('tweeting', 4),\n",
       " ('VoteSafe', 4),\n",
       " ('polling', 4),\n",
       " ('â†’No', 4),\n",
       " ('absentee', 4),\n",
       " ('â†’At', 4),\n",
       " ('Voting', 4),\n",
       " ('fundamental', 4),\n",
       " ('REALLY', 4),\n",
       " ('ğŸ¤£ğŸ¤£ğŸ¤£', 4),\n",
       " ('ğŸ’”', 4),\n",
       " ('sake', 4),\n",
       " ('Pls', 4),\n",
       " ('Bears', 4),\n",
       " ('shaking', 4),\n",
       " ('toxic', 4),\n",
       " ('throughout', 4),\n",
       " ('impossible', 4),\n",
       " ('4th', 4),\n",
       " ('SpeakerPelosi', 4),\n",
       " ('Ozark', 4),\n",
       " ('Creek', 4),\n",
       " ('texts', 4),\n",
       " ('creators', 4),\n",
       " ('conspiracy', 4),\n",
       " ('customers', 4),\n",
       " ('goodbye', 4),\n",
       " ('shutdown', 4),\n",
       " ('fever', 4),\n",
       " ('recently', 4),\n",
       " ('couch', 4),\n",
       " ('Explain', 4),\n",
       " ('PPP', 4),\n",
       " ('sink', 4),\n",
       " ('assignment', 4),\n",
       " ('symptoms', 4),\n",
       " ('hopefully', 4),\n",
       " ('familiar', 4),\n",
       " ('ğŸ’€', 4),\n",
       " ('Cowboys', 4),\n",
       " ('wanting', 4),\n",
       " ('positivity', 4),\n",
       " ('workout', 4),\n",
       " ('prepared', 4),\n",
       " ('peanut', 4),\n",
       " ('subscribers', 4),\n",
       " ('ğŸ˜ˆ', 4),\n",
       " ('Walmart', 4),\n",
       " ('affection', 4),\n",
       " ('arguments', 4),\n",
       " ('streamer', 4),\n",
       " ('â˜€ï¸', 4),\n",
       " ('depressed', 4),\n",
       " ('\\U0001f973', 4),\n",
       " ('receiving', 4),\n",
       " ('porn', 4),\n",
       " ('ğŸ˜‰', 4),\n",
       " ('baseball', 4),\n",
       " ('strongly', 4),\n",
       " ('countries', 4),\n",
       " ('disapprove', 4),\n",
       " ('FCE', 4),\n",
       " ('protest', 4),\n",
       " ('Drew', 4),\n",
       " ('friday', 4),\n",
       " ('heroes', 4),\n",
       " ('NHS', 4),\n",
       " ('millions', 4),\n",
       " ('cleaned', 4),\n",
       " ('spit', 4),\n",
       " ('appearance', 4),\n",
       " ('BOY', 4),\n",
       " ('Titans', 4),\n",
       " ('WITH', 4),\n",
       " ('encourage', 4),\n",
       " ('ğŸ˜¢', 4),\n",
       " ('burden', 4),\n",
       " ('ğŸ˜˜', 4),\n",
       " ('Watching', 4),\n",
       " ('CashApp', 4),\n",
       " ('paycheck', 4),\n",
       " ('HUGE', 4),\n",
       " ('daddy', 4),\n",
       " ('records', 4),\n",
       " ('publicly', 4),\n",
       " ('Rona', 4),\n",
       " ('friendship', 4),\n",
       " ('caused', 4),\n",
       " ('brilliant', 4),\n",
       " ('supply', 4),\n",
       " ('several', 4),\n",
       " ('easily', 4),\n",
       " ('wedding', 4),\n",
       " ('StayAtHome', 4),\n",
       " ('ğŸ˜Œ', 4),\n",
       " ('hugged', 4),\n",
       " ('OANN', 4),\n",
       " ('Carolina', 4),\n",
       " ('combination', 4),\n",
       " ('remembered', 4),\n",
       " ('Welp', 4),\n",
       " ('horror', 4),\n",
       " ('serve', 4),\n",
       " ('invited', 4),\n",
       " ('breath', 4),\n",
       " ('hoping', 4),\n",
       " ('filing', 4),\n",
       " ('revive', 4),\n",
       " ('potato', 4),\n",
       " ('virologist', 4),\n",
       " ('puzzle', 4),\n",
       " ('proved', 4),\n",
       " ('taste', 4),\n",
       " ('EVERYONE', 4),\n",
       " ('companies', 4),\n",
       " ('regret', 4),\n",
       " ('provide', 4),\n",
       " ('Wish', 4),\n",
       " ('fandom', 4),\n",
       " ('imma', 4),\n",
       " ('chips', 4),\n",
       " ('gym', 4),\n",
       " ('OMG', 4),\n",
       " ('whilst', 4),\n",
       " ('Oprah', 4),\n",
       " ('heartbreaking', 4),\n",
       " ('kills', 4),\n",
       " ('replaced', 4),\n",
       " ('crack', 4),\n",
       " ('WENT', 4),\n",
       " ('BATHROOM', 4),\n",
       " ('HAD', 4),\n",
       " ('SWUM', 4),\n",
       " ('TOILET', 4),\n",
       " ('THOUGHT', 4),\n",
       " ('URBAN', 4),\n",
       " ('LEGEND', 4),\n",
       " ('MOVE', 4),\n",
       " ('nasty', 4),\n",
       " ('covid19', 4),\n",
       " ('restrictions', 4),\n",
       " ('tuned', 4),\n",
       " ('jail', 4),\n",
       " ('truck', 4),\n",
       " ('caught', 4),\n",
       " ('Apologies', 4),\n",
       " ('Lemme', 4),\n",
       " ('THANK', 4),\n",
       " ('fault', 4),\n",
       " ('divorce', 4),\n",
       " ('thick', 4),\n",
       " ('supporting', 4),\n",
       " ('cleaning', 4),\n",
       " ('Catch', 4),\n",
       " ('Fortnite', 4),\n",
       " ('joking', 4),\n",
       " ('whack', 4),\n",
       " ('artists', 4),\n",
       " ('nervous', 4),\n",
       " ('Drake', 4),\n",
       " ('discussed', 4),\n",
       " ('Newcastle', 4),\n",
       " ('ğŸ˜©', 4),\n",
       " ('exhausted', 4),\n",
       " ('WHEN', 4),\n",
       " ('Packers', 4),\n",
       " ('contest', 4),\n",
       " ('unemployed', 4),\n",
       " ('ideas', 4),\n",
       " ('germ', 4),\n",
       " ('hundred', 4),\n",
       " ('talked', 4),\n",
       " ('gimme', 4),\n",
       " ('receive', 4),\n",
       " ('opinions', 4),\n",
       " ('toes', 4),\n",
       " ('monthly', 4),\n",
       " ('twice', 4),\n",
       " ('realise', 4),\n",
       " ('warned', 4),\n",
       " ('comfortable', 4),\n",
       " ('Trout', 4),\n",
       " ('12k', 4),\n",
       " ('exciting', 4),\n",
       " ('ğŸ˜’', 4),\n",
       " ('cheated', 4),\n",
       " ('snow', 4),\n",
       " ('walked', 4),\n",
       " ('choices', 4),\n",
       " ('denied', 4),\n",
       " ('ğŸ‰', 4),\n",
       " ('ignoring', 4),\n",
       " ('SHIT', 4),\n",
       " ('considered', 4),\n",
       " ('ğŸ˜­ğŸ˜­ğŸ˜­', 4),\n",
       " ('ğŸ˜', 4),\n",
       " ('drank', 4),\n",
       " ('Sierra', 4),\n",
       " ('pulp', 4),\n",
       " ('ğŸ’°', 4),\n",
       " ('geng', 4),\n",
       " ('restaurants', 4),\n",
       " ('Boom', 4),\n",
       " ('carti', 3),\n",
       " ('dababy', 3),\n",
       " ('Indians', 3),\n",
       " ('ğŸ˜“', 3),\n",
       " ('crap', 3),\n",
       " ('hacker', 3),\n",
       " ('PHYSICALLY', 3),\n",
       " ('spam', 3),\n",
       " ('therapist', 3),\n",
       " ('plans', 3),\n",
       " ('apologise', 3),\n",
       " ('supportive', 3),\n",
       " ('kissed', 3),\n",
       " ('belongs', 3),\n",
       " ('spoilers', 3),\n",
       " ('hurtful', 3),\n",
       " ('lockdowns', 3),\n",
       " ('quarantining', 3),\n",
       " ('welcomed', 3),\n",
       " ('assume', 3),\n",
       " ('Rounds', 3),\n",
       " ...]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(unknown_text.items(), key=lambda d: d[1], reverse=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform more words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "more_apostrophes = {'cannot': \"can not\", 'gonna': \"go to\", 'wanna': \"want to\", 'coronavirus': \"COVID\", 'wanted': \"want\", 'weeks': \"week\", 'feeling': \"feel\", 'says': \"say\", 'yourself': \"your self\", 'saying': \"say\", 'says': \"say\", 'GIF': \"gif\", 'waiting': \"wait\", 'Covid': \"COVID\", 'hugs': \"hug\", 'gave': \"give\", 'COVID19': \"COVID\", 'installing': \"install\", 'wants': \"want\", 'knows': \"know\", 'describes': \"describe\", 'following': \"follow\", 'asked': \"ask\", 'amazing': \"amaze\", 'finally': \"final\", 'minutes': \"minute\", 'died': \"die\", 'tired': \"tire\", 'quickly': \"quick\", 'gotta': \"go to\", 'deaths': \"death\", 'means': \"mean\", 'took': \"take\", 'feels': \"feel\", 'fans': \"fan\", 'numbers': \"number\", 'lives': \"live\", 'safely': \"safe\", 'tried': \"try\", 'businesses': \"business\", '2nd': \"second\", 'decided': \"decide\", '3rd': \"third\", 'hates': \"hate\", 'dont': \"do not\", 'lonely': \"lone\", 'totally': \"total\", 'excited': \"excite\", 'BREAKING': \"break\", 'gifs': \"gif\", 'goes': \"go\", 'thoughts': \"thought\", 'campaigning': \"campaign\", 'immediately': \"immediate\", 'teammates': \"team mate\", 'knew': \"know\", 'politicians': \"politician\", 'distancing': \"distance\", 'reopening': \"reopen\", 'pls': \"please\", 'AGAIN': \"again\", 'tears': \"tear\", 'supposed': \"suppose\", 'loved': \"love\", 'ppl': \"people\", 'drinking': \"drink\", 'Guidelines': \"guide line\", 'losing': \"lose\", 'Conference': \"conference\", 'officially': \"official\", 'OPENING': \"open\", 'buying': \"buy\", 'Gif': \"gif\", 'looks': \"look\", 'bought': \"buy\", 'likes': \"like\", 'truely': \"true\", 'happened': \"happen\", 'putting': \"put\", 'families': \"family\", 'moved': \"move\", 'Raise': \"raise\", 'helped': \"help\", 'vibes': \"vibe\", 'voting': \"vote\", 'showed': \"show\", 'Instagram': \"instagram\", 'spent': \"spend\", 'watched': \"watch\", 'kinda': \"kind of\", 'Governor': \"governor\", 'Coronavirus': \"COVID\", 'lmao': \"laugh\", 'seems': \"seem\", 'staying': \"stay\", 'listening': \"listen\", 'accounts': \"account\"}\n",
    "def change_punc(text):\n",
    "    for key in more_apostrophes.keys():\n",
    "        text = text.replace(key, more_apostrophes[key])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.tokenize('guide lines')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['map_more_punc_text'] = df_train.map_punc_text.apply(change_punc)\n",
    "df_train['map_more_punc_reply'] = df_train.map_punc_reply.apply(change_punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev['map_more_punc_text'] = df_dev.map_punc_text.apply(change_punc)\n",
    "df_dev['map_more_punc_reply'] = df_dev.map_punc_reply.apply(change_punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['map_more_punc_text'] = df_test.map_punc_text.apply(change_punc)\n",
    "df_test['map_more_punc_reply'] = df_test.map_punc_reply.apply(change_punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train text unique vocab count is: 46010\n",
      "train reply unique vocab count is: 18481\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=46010.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 13.488% (6206 / 46010) of vocab\n",
      "Found embeddings for 81.730% (658910 / 806199) of all text\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=18481.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 22.066% (4078 / 18481) of vocab\n",
      "Found embeddings for 80.666% (111902 / 138723) of all text\n"
     ]
    }
   ],
   "source": [
    "train_text_vocab = get_vocab(df_train['map_more_punc_text'].values)\n",
    "train_reply_vocab = get_vocab(df_train['map_more_punc_reply'].values)\n",
    "print(\"train text unique vocab count is: {}\".format(len(train_text_vocab)))\n",
    "print(\"train reply unique vocab count is: {}\".format(len(train_reply_vocab)))\n",
    "print()\n",
    "\n",
    "unknown_text = check_coverage(train_text_vocab, roberta_vocab)\n",
    "print()\n",
    "unknown_reply = check_coverage(train_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev text unique vocab count is: 13257\n",
      "dev reply unique vocab count is: 4415\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=13257.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 26.869% (3562 / 13257) of vocab\n",
      "Found embeddings for 81.635% (83471 / 102249) of all text\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=4415.0, style=ProgressStyle(description_â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 37.531% (1657 / 4415) of vocab\n",
      "Found embeddings for 79.735% (14035 / 17602) of all text\n"
     ]
    }
   ],
   "source": [
    "dev_text_vocab = get_vocab(df_dev['map_more_punc_text'].values)\n",
    "dev_reply_vocab = get_vocab(df_dev['map_more_punc_reply'].values)\n",
    "print(\"dev text unique vocab count is: {}\".format(len(dev_text_vocab)))\n",
    "print(\"dev reply unique vocab count is: {}\".format(len(dev_reply_vocab)))\n",
    "unknown_text = check_coverage(dev_text_vocab, roberta_vocab)\n",
    "print()\n",
    "unknown_reply = check_coverage(dev_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test text unique vocab count is: 13076\n",
      "test reply unique vocab count is: 4209\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=13076.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 27.432% (3587 / 13076) of vocab\n",
      "Found embeddings for 81.643% (81863 / 100269) of all text\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=4209.0, style=ProgressStyle(description_â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 39.796% (1675 / 4209) of vocab\n",
      "Found embeddings for 80.731% (13734 / 17012) of all text\n"
     ]
    }
   ],
   "source": [
    "test_text_vocab = get_vocab(df_test['map_more_punc_text'].values)\n",
    "test_reply_vocab = get_vocab(df_test['map_more_punc_reply'].values)\n",
    "print(\"test text unique vocab count is: {}\".format(len(test_text_vocab)))\n",
    "print(\"test reply unique vocab count is: {}\".format(len(test_reply_vocab)))\n",
    "unknown_text = check_coverage(test_text_vocab, roberta_vocab)\n",
    "print()\n",
    "unknown_reply = check_coverage(test_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('COVID', 158),\n",
       " ('hug', 120),\n",
       " ('quarantine', 68),\n",
       " ('tonight', 64),\n",
       " ('myself', 58),\n",
       " ('Biden', 52),\n",
       " ('reaction', 48),\n",
       " ('tomorrow', 47),\n",
       " ('fucking', 43),\n",
       " ('Pelosi', 42),\n",
       " ('Nancy', 40),\n",
       " ('hear', 39),\n",
       " ('guys', 39),\n",
       " ('Oz', 39),\n",
       " ('anyone', 39),\n",
       " ('believe', 37),\n",
       " ('trying', 36),\n",
       " ('followers', 36),\n",
       " ('tweet', 36),\n",
       " ('lockdown', 36),\n",
       " ('least', 35),\n",
       " ('sad', 34),\n",
       " ('hope', 34),\n",
       " ('birthday', 33),\n",
       " ('anymore', 33),\n",
       " ('economy', 31),\n",
       " ('whole', 30),\n",
       " ('virus', 29),\n",
       " ('already', 28),\n",
       " ('pandemic', 27),\n",
       " ('hashtag', 26),\n",
       " ('beautiful', 26),\n",
       " ('dinner', 26),\n",
       " ('decide', 25),\n",
       " ('wish', 25),\n",
       " ('weekend', 24),\n",
       " ('BailoutHumansNow', 24),\n",
       " ('politician', 24),\n",
       " ('dependable', 24),\n",
       " ('forget', 24),\n",
       " ('ğŸ˜‚', 24),\n",
       " ('spend', 24),\n",
       " ('ScottyFromMarketing', 23),\n",
       " ('â¤ï¸', 23),\n",
       " ('ğŸ¤”', 23),\n",
       " ('honest', 23),\n",
       " ('career', 23),\n",
       " ('happen', 23),\n",
       " ('dick', 22),\n",
       " ('explain', 22),\n",
       " ('reopen', 21),\n",
       " ('amaze', 21),\n",
       " ('tire', 21),\n",
       " ('Crazy', 21),\n",
       " ('sick', 20),\n",
       " ('suck', 20),\n",
       " ('thankful', 20),\n",
       " ('horny', 20),\n",
       " ('Guys', 20),\n",
       " ('listen', 19),\n",
       " ('\\U0001f97a', 19),\n",
       " ('ğŸ˜­', 19),\n",
       " ('seanhannity', 19),\n",
       " ('Radical', 19),\n",
       " ('WritingCommunity', 19),\n",
       " ('Cuomo', 19),\n",
       " ('moment', 19),\n",
       " ('defeated', 18),\n",
       " ('ğŸ˜Š', 18),\n",
       " ('pathetic', 18),\n",
       " ('stimulus', 18),\n",
       " ('idea', 17),\n",
       " ('supporter', 17),\n",
       " ('crisis', 17),\n",
       " ('excite', 17),\n",
       " ('incompetent', 17),\n",
       " ('puppet', 17),\n",
       " ('describe', 17),\n",
       " ('giveaway', 17),\n",
       " ('guess', 17),\n",
       " ('governor', 17),\n",
       " ('came', 16),\n",
       " ('awesome', 16),\n",
       " ('become', 16),\n",
       " ('ğŸ˜”', 16),\n",
       " ('stupid', 16),\n",
       " ('bitch', 16),\n",
       " ('AMERICA', 16),\n",
       " ('lone', 16),\n",
       " ('woke', 15),\n",
       " ('Gates', 15),\n",
       " ('fucked', 15),\n",
       " ('damn', 15),\n",
       " ('suppose', 15),\n",
       " ('cares', 15),\n",
       " ('trash', 14),\n",
       " ('cute', 14),\n",
       " ('meeting', 14),\n",
       " ('socialist', 14),\n",
       " ('others', 14),\n",
       " ('LIBERATE', 14),\n",
       " ('Nathaniel', 14),\n",
       " ('sitting', 14),\n",
       " ('mood', 14),\n",
       " ('tear', 14),\n",
       " ('ugly', 14),\n",
       " ('understand', 14),\n",
       " ('deserve', 14),\n",
       " ('proud', 13),\n",
       " ('worse', 13),\n",
       " ('yall', 13),\n",
       " ('marry', 13),\n",
       " ('longer', 13),\n",
       " ('ensure', 13),\n",
       " ('corona', 13),\n",
       " ('anxiety', 13),\n",
       " ('folks', 13),\n",
       " ('realize', 13),\n",
       " ('tweets', 13),\n",
       " ('6pm', 13),\n",
       " ('ğŸ™ƒ', 13),\n",
       " ('stopped', 13),\n",
       " ('Vaccine', 12),\n",
       " ('coffee', 12),\n",
       " ('pizza', 12),\n",
       " ('decision', 12),\n",
       " ('billionaire', 12),\n",
       " ('afford', 12),\n",
       " ('questionsâ€¦', 12),\n",
       " ('attention', 12),\n",
       " ('questions', 12),\n",
       " ('appreciate', 12),\n",
       " ('thousands', 12),\n",
       " ('funny', 12),\n",
       " ('drink', 12),\n",
       " ('covid', 12),\n",
       " ('approval', 12),\n",
       " ('students', 12),\n",
       " ('entire', 12),\n",
       " ('complaining', 12),\n",
       " ('truly', 12),\n",
       " ('thinks', 12),\n",
       " ('experience', 11),\n",
       " ('wearing', 11),\n",
       " ('grateful', 11),\n",
       " ('VIRGINIA', 11),\n",
       " ('Amendment', 11),\n",
       " ('siege', 11),\n",
       " ('scared', 11),\n",
       " ('DMs', 11),\n",
       " ('replies', 11),\n",
       " ('handling', 11),\n",
       " ('Dollar', 11),\n",
       " ('streaming', 11),\n",
       " ('possible', 11),\n",
       " ('nobody', 11),\n",
       " ('\\U0001f974', 11),\n",
       " ('boyfriend', 11),\n",
       " ('crying', 11),\n",
       " ('Ventilators', 11),\n",
       " ('leadership', 11),\n",
       " ('ğŸ˜³', 11),\n",
       " ('1st', 11),\n",
       " ('across', 11),\n",
       " ('couple', 11),\n",
       " ('lil', 10),\n",
       " ('everyday', 10),\n",
       " ('kindness', 10),\n",
       " ('relationship', 10),\n",
       " ('conversation', 10),\n",
       " ('sister', 10),\n",
       " ('definitely', 10),\n",
       " ('forever', 10),\n",
       " ('ventilators', 10),\n",
       " ('passed', 10),\n",
       " ('THAT', 10),\n",
       " ('summer', 10),\n",
       " ('disaster', 10),\n",
       " ('H1N1', 10),\n",
       " ('Swine', 10),\n",
       " ('Flu', 10),\n",
       " ('Polling', 10),\n",
       " ('disastrous', 10),\n",
       " ('unnecessarily', 10),\n",
       " ('incompetence', 10),\n",
       " ('Billion', 10),\n",
       " ('Obamacare', 10),\n",
       " ('website', 10),\n",
       " ('excuse', 10),\n",
       " ('randomly', 10),\n",
       " ('cuz', 10),\n",
       " ('ğŸ˜‚ğŸ˜‚ğŸ˜‚', 10),\n",
       " ('themselves', 10),\n",
       " ('realized', 10),\n",
       " ('opinion', 10),\n",
       " ('5k', 10),\n",
       " ('biggest', 9),\n",
       " ('laughing', 9),\n",
       " ('sucking', 9),\n",
       " ('taken', 9),\n",
       " ('hurt', 9),\n",
       " ('himself', 9),\n",
       " ('situation', 9),\n",
       " ('patients', 9),\n",
       " ('vibe', 9),\n",
       " ('ğŸ‘€', 9),\n",
       " ('choose', 9),\n",
       " ('therapy', 9),\n",
       " ('awful', 9),\n",
       " ('ğŸ˜­ğŸ˜­', 9),\n",
       " ('difference', 9),\n",
       " ('Idk', 9),\n",
       " ('drunk', 9),\n",
       " ('weird', 9),\n",
       " ('ğŸ™„', 9),\n",
       " ('wonder', 9),\n",
       " ('honestly', 9),\n",
       " ('NEED', 9),\n",
       " ('showing', 9),\n",
       " ('cheese', 9),\n",
       " ('okay', 9),\n",
       " ('expansive', 9),\n",
       " ('accurate', 9),\n",
       " ('reminds', 9),\n",
       " ('angry', 9),\n",
       " ('dude', 9),\n",
       " ('helping', 9),\n",
       " ('worry', 9),\n",
       " ('shower', 9),\n",
       " ('seriously', 9),\n",
       " ('unemployment', 9),\n",
       " ('retweet', 9),\n",
       " ('grocery', 9),\n",
       " ('pregnant', 9),\n",
       " ('idk', 8),\n",
       " ('leaving', 8),\n",
       " ('announce', 8),\n",
       " ('celebrate', 8),\n",
       " ('takes', 8),\n",
       " ('depression', 8),\n",
       " ('sugar', 8),\n",
       " ('11am', 8),\n",
       " ('broke', 8),\n",
       " ('advice', 8),\n",
       " ('nigga', 8),\n",
       " ('learned', 8),\n",
       " ('7th', 8),\n",
       " ('sucks', 8),\n",
       " ('bout', 8),\n",
       " ('Frequently', 8),\n",
       " ('opportunity', 8),\n",
       " ('LIKE', 8),\n",
       " ('finish', 8),\n",
       " ('cheating', 8),\n",
       " ('instagram', 8),\n",
       " ('partner', 8),\n",
       " ('â†’', 8),\n",
       " ('heaven', 8),\n",
       " ('attempt', 8),\n",
       " ('LOVE', 8),\n",
       " ('chill', 8),\n",
       " ('ğŸ’•', 8),\n",
       " ('beds', 8),\n",
       " ('causing', 8),\n",
       " ('funeral', 8),\n",
       " ('MUCH', 8),\n",
       " ('pray', 8),\n",
       " ('enjoy', 8),\n",
       " ('teacher', 8),\n",
       " ('additional', 8),\n",
       " ('approve', 8),\n",
       " ('dying', 8),\n",
       " ('âœ…', 8),\n",
       " ('welcome', 8),\n",
       " ('HAVE', 8),\n",
       " ('ğŸ¤', 8),\n",
       " ('terrible', 8),\n",
       " ('keeps', 8),\n",
       " ('FollowFriday', 8),\n",
       " ('governors', 8),\n",
       " ('relief', 8),\n",
       " ('idiot', 8),\n",
       " ('lose', 8),\n",
       " ('apartment', 8),\n",
       " ('upset', 8),\n",
       " ('sounds', 7),\n",
       " ('kitchen', 7),\n",
       " ('messages', 7),\n",
       " ('OldRich', 7),\n",
       " ('tells', 7),\n",
       " ('joke', 7),\n",
       " ('NYC', 7),\n",
       " ('sending', 7),\n",
       " ('alive', 7),\n",
       " ('ONLY', 7),\n",
       " ('covering', 7),\n",
       " ('dear', 7),\n",
       " ('dropped', 7),\n",
       " ('treating', 7),\n",
       " ('calls', 7),\n",
       " ('slid', 7),\n",
       " ('sauce', 7),\n",
       " ('stuck', 7),\n",
       " ('Lebron', 7),\n",
       " ('masks', 7),\n",
       " ('Genuinely', 7),\n",
       " ('Rashford', 7),\n",
       " ('clothes', 7),\n",
       " ('lately', 7),\n",
       " ('fraud', 7),\n",
       " ('discussion', 7),\n",
       " ('harder', 7),\n",
       " ('herself', 7),\n",
       " ('lucky', 7),\n",
       " ('incredibly', 7),\n",
       " ('expect', 7),\n",
       " ('glad', 7),\n",
       " ('RETWEET', 7),\n",
       " ('Zoom', 7),\n",
       " ('disgusting', 7),\n",
       " ('TESTING', 7),\n",
       " ('exam', 7),\n",
       " ('yours', 7),\n",
       " ('Been', 7),\n",
       " ('turning', 7),\n",
       " ('Birthday', 7),\n",
       " ('loves', 7),\n",
       " ('comedy', 7),\n",
       " ('evening', 7),\n",
       " ('complain', 7),\n",
       " ('waste', 7),\n",
       " ('songs', 7),\n",
       " ('afternoon', 7),\n",
       " ('QUARANTINE', 7),\n",
       " ('EVER', 7),\n",
       " ('FUCK', 7),\n",
       " ('slide', 7),\n",
       " ('apparently', 7),\n",
       " ('barely', 7),\n",
       " ('officials', 7),\n",
       " ('Respond', 7),\n",
       " ('\\U0001f970', 7),\n",
       " ('immediate', 7),\n",
       " ('heavily', 7),\n",
       " ('awake', 7),\n",
       " ('blocked', 7),\n",
       " ('sexy', 7),\n",
       " ('clearly', 7),\n",
       " ('problems', 7),\n",
       " ('pics', 7),\n",
       " ('funds', 7),\n",
       " ('meme', 7),\n",
       " ('annoying', 7),\n",
       " ('KNOW', 7),\n",
       " ('appreciated', 7),\n",
       " ('seem', 7),\n",
       " ('surprise', 7),\n",
       " ('ğŸ”‘', 7),\n",
       " ('niggas', 6),\n",
       " ('everybody', 6),\n",
       " ('nightmare', 6),\n",
       " ('judging', 6),\n",
       " ('judgement', 6),\n",
       " ('HUNGRY', 6),\n",
       " ('worried', 6),\n",
       " ('yesterday', 6),\n",
       " ('denies', 6),\n",
       " ('extent', 6),\n",
       " ('outbreak', 6),\n",
       " ('smh', 6),\n",
       " ('extend', 6),\n",
       " ('lovely', 6),\n",
       " ('expecting', 6),\n",
       " ('Minister', 6),\n",
       " ('committed', 6),\n",
       " ('communist', 6),\n",
       " ('isolation', 6),\n",
       " ('shitty', 6),\n",
       " ('interview', 6),\n",
       " ('dangerous', 6),\n",
       " ('retweets', 6),\n",
       " ('difficult', 6),\n",
       " ('ğŸ˜ª', 6),\n",
       " ('amwriting', 6),\n",
       " ('Neymar', 6),\n",
       " ('starts', 6),\n",
       " ('senior', 6),\n",
       " ('makeup', 6),\n",
       " ('personally', 6),\n",
       " ('pictures', 6),\n",
       " ('experts', 6),\n",
       " ('lowkey', 6),\n",
       " ('dumb', 6),\n",
       " ('fellow', 6),\n",
       " ('fear', 6),\n",
       " ('blessed', 6),\n",
       " ('university', 6),\n",
       " ('Cassper', 6),\n",
       " ('survive', 6),\n",
       " ('thousand', 6),\n",
       " ('crush', 6),\n",
       " ('viewers', 6),\n",
       " ('Bailout', 6),\n",
       " ('Humans', 6),\n",
       " ('MUST', 6),\n",
       " ('Shout', 6),\n",
       " ('ğŸ¤£', 6),\n",
       " ('Quarantine', 6),\n",
       " ('Vikings', 6),\n",
       " ('scary', 6),\n",
       " ('groceries', 6),\n",
       " ('visit', 6),\n",
       " ('Lol', 6),\n",
       " ('strategy', 6),\n",
       " ('supporters', 6),\n",
       " ('gift', 6),\n",
       " ('breakfast', 6),\n",
       " ('suddenly', 6),\n",
       " ('miles', 6),\n",
       " ('voted', 6),\n",
       " ('ventilator', 6),\n",
       " ('unprecedented', 6),\n",
       " ('follows', 6),\n",
       " ('bunch', 6),\n",
       " ('vaccine', 6),\n",
       " ('chocolate', 6),\n",
       " ('cuddle', 6),\n",
       " ('missed', 6),\n",
       " ('employees', 6),\n",
       " ('possibility', 6),\n",
       " ('CoronaVirus', 6),\n",
       " ('Democrat', 6),\n",
       " ('asleep', 6),\n",
       " ('POTUS', 6),\n",
       " ('appointing', 6),\n",
       " ('pussy', 6),\n",
       " ('promise', 6),\n",
       " ('RIGHT', 6),\n",
       " ('boobs', 6),\n",
       " ('WAS', 6),\n",
       " ('Guess', 6),\n",
       " ('notifications', 6),\n",
       " ('tough', 6),\n",
       " ('dance', 6),\n",
       " ('COVIDLiar', 6),\n",
       " ('spirits', 6),\n",
       " ('ğŸ‘ğŸ¼', 6),\n",
       " ('discussing', 5),\n",
       " ('wtf', 5),\n",
       " ('cried', 5),\n",
       " ('hacked', 5),\n",
       " ('replying', 5),\n",
       " ('attacked', 5),\n",
       " ('stupidity', 5),\n",
       " ('hiding', 5),\n",
       " ('prepare', 5),\n",
       " ('transition', 5),\n",
       " ('till', 5),\n",
       " ('Govt', 5),\n",
       " ('wonderful', 5),\n",
       " ('ğŸ˜', 5),\n",
       " ('tbh', 5),\n",
       " ('fridge', 5),\n",
       " ('Parliament', 5),\n",
       " ('signs', 5),\n",
       " ('spending', 5),\n",
       " ('ridiculous', 5),\n",
       " ('memories', 5),\n",
       " ('debate', 5),\n",
       " ('happiness', 5),\n",
       " ('Feeling', 5),\n",
       " ('sober', 5),\n",
       " ('meetings', 5),\n",
       " ('hits', 5),\n",
       " ('prayers', 5),\n",
       " ('disease', 5),\n",
       " ('mention', 5),\n",
       " ('somebody', 5),\n",
       " ('â˜ºï¸', 5),\n",
       " ('drinks', 5),\n",
       " ('compassion', 5),\n",
       " ('Zack', 5),\n",
       " ('teams', 5),\n",
       " ('WILL', 5),\n",
       " ('BABY', 5),\n",
       " ('remain', 5),\n",
       " ('hearing', 5),\n",
       " ('huh', 5),\n",
       " ('Fauci', 5),\n",
       " ('boring', 5),\n",
       " ('waking', 5),\n",
       " ('doctors', 5),\n",
       " ('slowly', 5),\n",
       " ('expand', 5),\n",
       " ('cancelled', 5),\n",
       " ('Trey', 5),\n",
       " ('Burton', 5),\n",
       " ('cant', 5),\n",
       " ('selecting', 5),\n",
       " ('donate', 5),\n",
       " ('winğŸ’°', 5),\n",
       " ('plenty', 5),\n",
       " ('laid', 5),\n",
       " ('journey', 5),\n",
       " ('peaceful', 5),\n",
       " ('beach', 5),\n",
       " ('apeopley', 5),\n",
       " ('mutuals', 5),\n",
       " ('anywhere', 5),\n",
       " ('choked', 5),\n",
       " ('homes', 5),\n",
       " ('ğŸ™', 5),\n",
       " ('cough', 5),\n",
       " ('bipartisan', 5),\n",
       " ('ğŸ‡ºğŸ‡¸', 5),\n",
       " ('desk', 5),\n",
       " ('doubling', 5),\n",
       " ('Invisible', 5),\n",
       " ('Enemy', 5),\n",
       " ('concerned', 5),\n",
       " ('YOUR', 5),\n",
       " ('WHY', 5),\n",
       " ('bitches', 5),\n",
       " ('challenge', 5),\n",
       " ('butter', 5),\n",
       " ('shoes', 5),\n",
       " ('10k', 5),\n",
       " ('GOOD', 5),\n",
       " ('pounds', 5),\n",
       " ('FIRST', 5),\n",
       " ('loud', 5),\n",
       " ('loan', 5),\n",
       " ('tiktok', 5),\n",
       " ('dudes', 5),\n",
       " ('streets', 5),\n",
       " ('timeline', 5),\n",
       " ('freak', 5),\n",
       " ('haircut', 5),\n",
       " ('garden', 5),\n",
       " ('selfie', 5),\n",
       " ('DrOz', 5),\n",
       " ('imagine', 5),\n",
       " ('entering', 5),\n",
       " ('Dems', 5),\n",
       " ('realizing', 5),\n",
       " ('liquor', 5),\n",
       " ('RAT', 5),\n",
       " ('guest', 5),\n",
       " ('HIM', 5),\n",
       " ('rally', 5),\n",
       " ('naked', 5),\n",
       " ('horrible', 5),\n",
       " ('Retweet', 5),\n",
       " ('movies', 5),\n",
       " ('shopping', 5),\n",
       " ('roof', 5),\n",
       " ('Verge', 5),\n",
       " ('consistently', 5),\n",
       " ('mistake', 5),\n",
       " ('suspect', 5),\n",
       " ('furloughed', 5),\n",
       " ('writerslift', 5),\n",
       " ('milk', 5),\n",
       " ('leaves', 5),\n",
       " ('everywhere', 5),\n",
       " ('followed', 5),\n",
       " ('govt', 5),\n",
       " ('LikewiseApp', 5),\n",
       " ('Yay', 5),\n",
       " ('infected', 5),\n",
       " ('attend', 5),\n",
       " ('Lockdown', 5),\n",
       " ('simply', 5),\n",
       " ('boo', 5),\n",
       " ('âœ¨', 5),\n",
       " ('juliemac1000', 5),\n",
       " ('Congressional', 5),\n",
       " ('lawyer', 5),\n",
       " ('payments', 5),\n",
       " ('bored', 5),\n",
       " ('OKAY', 5),\n",
       " ('TODAY', 5),\n",
       " ('happens', 5),\n",
       " ('screenshot', 5),\n",
       " ('Uncle', 5),\n",
       " ('2021', 5),\n",
       " ('interact', 5),\n",
       " ('saved', 5),\n",
       " ('fuckin', 5),\n",
       " ('murder', 5),\n",
       " ('nursing', 5),\n",
       " ('jumping', 5),\n",
       " ('Wuhan', 5),\n",
       " ('teach', 5),\n",
       " ('memes', 5),\n",
       " ('swear', 5),\n",
       " ('cheer', 5),\n",
       " ('earlier', 5),\n",
       " ('apeopleause', 5),\n",
       " ('younger', 5),\n",
       " ('ğŸ˜”ğŸ˜”', 5),\n",
       " ('neighbor', 5),\n",
       " ('pushing', 5),\n",
       " ('WOW', 5),\n",
       " ('Kanye', 5),\n",
       " ('bills', 5),\n",
       " ('eggs', 5),\n",
       " ('tho', 5),\n",
       " ('sisters', 5),\n",
       " ('Couldn', 5),\n",
       " ('Lawrence', 5),\n",
       " ('sacrifice', 5),\n",
       " ('trading', 4),\n",
       " ('Might', 4),\n",
       " ('hardest', 4),\n",
       " ('hospitals', 4),\n",
       " ('spamming', 4),\n",
       " ('confronting', 4),\n",
       " ('ğŸ˜°', 4),\n",
       " ('Doing', 4),\n",
       " ('eventually', 4),\n",
       " ('cancel', 4),\n",
       " ('lunch', 4),\n",
       " ('begins', 4),\n",
       " ('greatest', 4),\n",
       " ('shout', 4),\n",
       " ('teenage', 4),\n",
       " ('salt', 4),\n",
       " ('liberate', 4),\n",
       " ('talent', 4),\n",
       " ('theater', 4),\n",
       " ('struggling', 4),\n",
       " ('allowing', 4),\n",
       " ('Tune', 4),\n",
       " ('sperm', 4),\n",
       " ('moms', 4),\n",
       " ('Horny', 4),\n",
       " ('liked', 4),\n",
       " ('communities', 4),\n",
       " ('apologize', 4),\n",
       " ('admit', 4),\n",
       " ('afraid', 4),\n",
       " ('recovered', 4),\n",
       " ('appointment', 4),\n",
       " ('LOL', 4),\n",
       " ('Somebody', 4),\n",
       " ('irresponsible', 4),\n",
       " ('COVIDPandemic', 4),\n",
       " ('nose', 4),\n",
       " ('HIT', 4),\n",
       " ('stressed', 4),\n",
       " ('ğŸ˜‹', 4),\n",
       " ('Yup', 4),\n",
       " ('sleeping', 4),\n",
       " ('busy', 4),\n",
       " ('pillow', 4),\n",
       " ('hella', 4),\n",
       " ('posting', 4),\n",
       " ('turns', 4),\n",
       " ('wins', 4),\n",
       " ('moves', 4),\n",
       " ('hurts', 4),\n",
       " ('THEY', 4),\n",
       " ('convo', 4),\n",
       " ('pronounced', 4),\n",
       " ('Lindsey', 4),\n",
       " ('exercise', 4),\n",
       " ('writingcommunity', 4),\n",
       " ('Giants', 4),\n",
       " ('libs', 4),\n",
       " ('otherwise', 4),\n",
       " ('AEW', 4),\n",
       " ('Cody', 4),\n",
       " ('Suite', 4),\n",
       " ('lesson', 4),\n",
       " ('souls', 4),\n",
       " ('Thoughts', 4),\n",
       " ('spreading', 4),\n",
       " ('planning', 4),\n",
       " ('HATE', 4),\n",
       " ('slapped', 4),\n",
       " ('giveaways', 4),\n",
       " ('mum', 4),\n",
       " ('wondering', 4),\n",
       " ('ğŸ˜…', 4),\n",
       " ('potential', 4),\n",
       " ('faster', 4),\n",
       " ('Raiders', 4),\n",
       " ('Ruggs', 4),\n",
       " ('Jeudy', 4),\n",
       " ('Lamb', 4),\n",
       " ('idiots', 4),\n",
       " ('tweeting', 4),\n",
       " ('VoteSafe', 4),\n",
       " ('polling', 4),\n",
       " ('â†’No', 4),\n",
       " ('absentee', 4),\n",
       " ('â†’At', 4),\n",
       " ('Voting', 4),\n",
       " ('fundamental', 4),\n",
       " ('REALLY', 4),\n",
       " ('ğŸ¤£ğŸ¤£ğŸ¤£', 4),\n",
       " ('ğŸ’”', 4),\n",
       " ('sake', 4),\n",
       " ('Pls', 4),\n",
       " ('Bears', 4),\n",
       " ('shaking', 4),\n",
       " ('toxic', 4),\n",
       " ('throughout', 4),\n",
       " ('impossible', 4),\n",
       " ('4th', 4),\n",
       " ('SpeakerPelosi', 4),\n",
       " ('Ozark', 4),\n",
       " ('Creek', 4),\n",
       " ('texts', 4),\n",
       " ('creators', 4),\n",
       " ('conspiracy', 4),\n",
       " ('customers', 4),\n",
       " ('goodbye', 4),\n",
       " ('shutdown', 4),\n",
       " ('fever', 4),\n",
       " ('recently', 4),\n",
       " ('couch', 4),\n",
       " ('Explain', 4),\n",
       " ('PPP', 4),\n",
       " ('sink', 4),\n",
       " ('assignment', 4),\n",
       " ('symptoms', 4),\n",
       " ('hopefully', 4),\n",
       " ('familiar', 4),\n",
       " ('ğŸ’€', 4),\n",
       " ('Cowboys', 4),\n",
       " ('wanting', 4),\n",
       " ('positivity', 4),\n",
       " ('workout', 4),\n",
       " ('prepared', 4),\n",
       " ('peanut', 4),\n",
       " ('subscribers', 4),\n",
       " ('ğŸ˜ˆ', 4),\n",
       " ('Walmart', 4),\n",
       " ('affection', 4),\n",
       " ('arguments', 4),\n",
       " ('streamer', 4),\n",
       " ('â˜€ï¸', 4),\n",
       " ('depressed', 4),\n",
       " ('\\U0001f973', 4),\n",
       " ('receiving', 4),\n",
       " ('porn', 4),\n",
       " ('ğŸ˜‰', 4),\n",
       " ('baseball', 4),\n",
       " ('strongly', 4),\n",
       " ('countries', 4),\n",
       " ('disapprove', 4),\n",
       " ('FCE', 4),\n",
       " ('protest', 4),\n",
       " ('Drew', 4),\n",
       " ('friday', 4),\n",
       " ('heroes', 4),\n",
       " ('NHS', 4),\n",
       " ('millions', 4),\n",
       " ('cleaned', 4),\n",
       " ('spit', 4),\n",
       " ('appearance', 4),\n",
       " ('BOY', 4),\n",
       " ('Titans', 4),\n",
       " ('WITH', 4),\n",
       " ('encourage', 4),\n",
       " ('ğŸ˜¢', 4),\n",
       " ('burden', 4),\n",
       " ('ğŸ˜˜', 4),\n",
       " ('Watching', 4),\n",
       " ('CashApp', 4),\n",
       " ('paycheck', 4),\n",
       " ('HUGE', 4),\n",
       " ('daddy', 4),\n",
       " ('records', 4),\n",
       " ('publicly', 4),\n",
       " ('Rona', 4),\n",
       " ('friendship', 4),\n",
       " ('caused', 4),\n",
       " ('brilliant', 4),\n",
       " ('supeopley', 4),\n",
       " ('several', 4),\n",
       " ('easily', 4),\n",
       " ('wedding', 4),\n",
       " ('StayAtHome', 4),\n",
       " ('ğŸ˜Œ', 4),\n",
       " ('hugged', 4),\n",
       " ('OANN', 4),\n",
       " ('Carolina', 4),\n",
       " ('combination', 4),\n",
       " ('remembered', 4),\n",
       " ('Welp', 4),\n",
       " ('horror', 4),\n",
       " ('serve', 4),\n",
       " ('invited', 4),\n",
       " ('breath', 4),\n",
       " ('hoping', 4),\n",
       " ('filing', 4),\n",
       " ('revive', 4),\n",
       " ('potato', 4),\n",
       " ('virologist', 4),\n",
       " ('puzzle', 4),\n",
       " ('proved', 4),\n",
       " ('taste', 4),\n",
       " ('EVERYONE', 4),\n",
       " ('companies', 4),\n",
       " ('regret', 4),\n",
       " ('provide', 4),\n",
       " ('Wish', 4),\n",
       " ('fandom', 4),\n",
       " ('imma', 4),\n",
       " ('chips', 4),\n",
       " ('gym', 4),\n",
       " ('OMG', 4),\n",
       " ('whilst', 4),\n",
       " ('Oprah', 4),\n",
       " ('heartbreaking', 4),\n",
       " ('kills', 4),\n",
       " ('replaced', 4),\n",
       " ('crack', 4),\n",
       " ('WENT', 4),\n",
       " ('BATHROOM', 4),\n",
       " ('HAD', 4),\n",
       " ('SWUM', 4),\n",
       " ('TOILET', 4),\n",
       " ('THOUGHT', 4),\n",
       " ('URBAN', 4),\n",
       " ('LEGEND', 4),\n",
       " ('MOVE', 4),\n",
       " ('nasty', 4),\n",
       " ('covid19', 4),\n",
       " ('restrictions', 4),\n",
       " ('tuned', 4),\n",
       " ('jail', 4),\n",
       " ('truck', 4),\n",
       " ('caught', 4),\n",
       " ('Apologies', 4),\n",
       " ('Lemme', 4),\n",
       " ('THANK', 4),\n",
       " ('fault', 4),\n",
       " ('divorce', 4),\n",
       " ('thick', 4),\n",
       " ('supporting', 4),\n",
       " ('cleaning', 4),\n",
       " ('Catch', 4),\n",
       " ('Fortnite', 4),\n",
       " ('joking', 4),\n",
       " ('whack', 4),\n",
       " ('artists', 4),\n",
       " ('nervous', 4),\n",
       " ('Drake', 4),\n",
       " ('discussed', 4),\n",
       " ('Newcastle', 4),\n",
       " ('ğŸ˜©', 4),\n",
       " ('exhausted', 4),\n",
       " ('WHEN', 4),\n",
       " ('Packers', 4),\n",
       " ('contest', 4),\n",
       " ('unemployed', 4),\n",
       " ('ideas', 4),\n",
       " ('germ', 4),\n",
       " ('hundred', 4),\n",
       " ('talked', 4),\n",
       " ('gimme', 4),\n",
       " ('receive', 4),\n",
       " ('opinions', 4),\n",
       " ('toes', 4),\n",
       " ('monthly', 4),\n",
       " ('twice', 4),\n",
       " ('realise', 4),\n",
       " ('warned', 4),\n",
       " ('Apeoplee', 4),\n",
       " ('comfortable', 4),\n",
       " ('Trout', 4),\n",
       " ('12k', 4),\n",
       " ('exciting', 4),\n",
       " ('ğŸ˜’', 4),\n",
       " ('cheated', 4),\n",
       " ('snow', 4),\n",
       " ('walked', 4),\n",
       " ('choices', 4),\n",
       " ('denied', 4),\n",
       " ('ğŸ‰', 4),\n",
       " ('ignoring', 4),\n",
       " ('SHIT', 4),\n",
       " ('considered', 4),\n",
       " ('ğŸ˜­ğŸ˜­ğŸ˜­', 4),\n",
       " ('ğŸ˜', 4),\n",
       " ('drank', 4),\n",
       " ('Sierra', 4),\n",
       " ('pulp', 4),\n",
       " ('ğŸ’°', 4),\n",
       " ('geng', 4),\n",
       " ('restaurants', 4),\n",
       " ('Boom', 4),\n",
       " ('carti', 3),\n",
       " ('dababy', 3),\n",
       " ('Indians', 3),\n",
       " ('ğŸ˜“', 3),\n",
       " ('crap', 3),\n",
       " ('hacker', 3),\n",
       " ('PHYSICALLY', 3),\n",
       " ('spam', 3),\n",
       " ('therapist', 3),\n",
       " ('plans', 3),\n",
       " ('apologise', 3),\n",
       " ('supportive', 3),\n",
       " ('kissed', 3),\n",
       " ('belongs', 3),\n",
       " ('spoilers', 3),\n",
       " ('hurtful', 3),\n",
       " ('lockdowns', 3),\n",
       " ('quarantining', 3),\n",
       " ('welcomed', 3),\n",
       " ('assume', 3),\n",
       " ('Rounds', 3),\n",
       " ('negotiations', 3),\n",
       " ('reiterate', 3),\n",
       " ('withdrawal', 3),\n",
       " ('Transition', 3),\n",
       " ('Giveaway', 3),\n",
       " ('discuss', 3),\n",
       " ('whom', 3),\n",
       " ('famu', 3),\n",
       " ('30th', 3),\n",
       " ('COMING', 3),\n",
       " ('nudes', 3),\n",
       " ('JoeBiden', 3),\n",
       " ('suffering', 3),\n",
       " ('FOLLOWERS', 3),\n",
       " ('continues', 3),\n",
       " ('subs', 3),\n",
       " ('reminding', 3),\n",
       " ('Evening', 3),\n",
       " ('screamed', 3),\n",
       " ('stunned', 3),\n",
       " ('crawl', 3),\n",
       " ('mentally', 3),\n",
       " ('finale', 3),\n",
       " ('smoke', 3),\n",
       " ('providing', 3),\n",
       " ('OUSTDUTERENOW', 3),\n",
       " ('advantage', 3),\n",
       " ('Newsom', 3),\n",
       " ('recovery', 3),\n",
       " ('revealed', 3),\n",
       " ('zoom', 3),\n",
       " ('fart', 3),\n",
       " ('YALL', 3),\n",
       " ('4TH', 3),\n",
       " ('increase', 3),\n",
       " ('Dakota', 3),\n",
       " ('chick', 3),\n",
       " ('preview', 3),\n",
       " ('Loeffler', 3),\n",
       " ('shooting', 3),\n",
       " ('Minutes', 3),\n",
       " ('agreed', 3),\n",
       " ('concerns', 3),\n",
       " ('Wake', 3),\n",
       " ('Brooks', 3),\n",
       " ('millennials', 3),\n",
       " ('deserves', 3),\n",
       " ('stole', 3),\n",
       " ('junior', 3),\n",
       " ('drives', 3),\n",
       " ('manuscript', 3),\n",
       " ('Derrick', 3),\n",
       " ('MAGAts', 3),\n",
       " ('owning', 3),\n",
       " ('slaves', 3),\n",
       " ('regarding', 3),\n",
       " ('Blonde', 3),\n",
       " ('cans', 3),\n",
       " ('Crossing', 3),\n",
       " ('NEVER', 3),\n",
       " ('clubs', 3),\n",
       " ('controversial', 3),\n",
       " ('proposal', 3),\n",
       " ('curious', 3),\n",
       " ('colors', 3),\n",
       " ('chosen', 3),\n",
       " ('prize', 3),\n",
       " ('switches', 3),\n",
       " ('commented', 3),\n",
       " ('disturbing', 3),\n",
       " ('horrific', 3),\n",
       " ('grieving', 3),\n",
       " ('emailed', 3),\n",
       " ('clap', 3),\n",
       " ('compared', 3),\n",
       " ('streamers', 3),\n",
       " ('AWAY', 3),\n",
       " ('yelling', 3),\n",
       " ('routine', 3),\n",
       " ('scientists', 3),\n",
       " ('Jefferson', 3),\n",
       " ('overall', 3),\n",
       " ('RaiderNation', 3),\n",
       " ...]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(unknown_text.items(), key=lambda d: d[1], reverse=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try demojize to text and unique same emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distinct_emoji_lis(string):\n",
    "    \"\"\"Resturns distinct list of emojis from the string\"\"\"\n",
    "    distinct_list = list({c for c in string if c in emoji.unicode_codes.UNICODE_EMOJI})\n",
    "    return distinct_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_emoji_to_text(text):\n",
    "    \"\"\"\n",
    "    Input: text\n",
    "    Output: demojize text\n",
    "    \"\"\"\n",
    "    ori_text = text\n",
    "    distinct_emoji = distinct_emoji_lis(text)\n",
    "    for each_emoji in distinct_emoji:\n",
    "        first_appear = ori_text.index(each_emoji)\n",
    "        new_text = ''\n",
    "        for tid, token in enumerate(ori_text):\n",
    "            if token == each_emoji and tid != first_appear:\n",
    "                new_text += ''\n",
    "            else:\n",
    "                new_text += token\n",
    "        ori_text = new_text\n",
    "    ori_text = emoji.demojize(ori_text).replace(':', ' ').replace('_', ' ')\n",
    "    return ori_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['map_demojize_text'] = df_train.map_more_punc_text.apply(change_emoji_to_text)\n",
    "df_train['map_demojize_reply'] = df_train.map_more_punc_reply.apply(change_emoji_to_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev['map_demojize_text'] = df_dev.map_more_punc_text.apply(change_emoji_to_text)\n",
    "df_dev['map_demojize_reply'] = df_dev.map_more_punc_reply.apply(change_emoji_to_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['map_demojize_text'] = df_test.map_more_punc_text.apply(change_emoji_to_text)\n",
    "df_test['map_demojize_reply'] = df_test.map_more_punc_reply.apply(change_emoji_to_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train text unique vocab count is: 43503\n",
      "train reply unique vocab count is: 17184\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=43503.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 14.300% (6221 / 43503) of vocab\n",
      "Found embeddings for 81.902% (674962 / 824110) of all text\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=17184.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 23.889% (4105 / 17184) of vocab\n",
      "Found embeddings for 81.091% (120173 / 148196) of all text\n"
     ]
    }
   ],
   "source": [
    "train_text_vocab = get_vocab(df_train['map_demojize_text'].values)\n",
    "train_reply_vocab = get_vocab(df_train['map_demojize_reply'].values)\n",
    "print(\"train text unique vocab count is: {}\".format(len(train_text_vocab)))\n",
    "print(\"train reply unique vocab count is: {}\".format(len(train_reply_vocab)))\n",
    "print()\n",
    "\n",
    "unknown_text = check_coverage(train_text_vocab, roberta_vocab)\n",
    "print()\n",
    "unknown_reply = check_coverage(train_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev text unique vocab count is: 12887\n",
      "dev reply unique vocab count is: 4312\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=12887.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 27.826% (3586 / 12887) of vocab\n",
      "Found embeddings for 81.828% (85413 / 104381) of all text\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=4312.0, style=ProgressStyle(description_â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 39.471% (1702 / 4312) of vocab\n",
      "Found embeddings for 80.221% (15153 / 18889) of all text\n"
     ]
    }
   ],
   "source": [
    "dev_text_vocab = get_vocab(df_dev['map_demojize_text'].values)\n",
    "dev_reply_vocab = get_vocab(df_dev['map_demojize_reply'].values)\n",
    "print(\"dev text unique vocab count is: {}\".format(len(dev_text_vocab)))\n",
    "print(\"dev reply unique vocab count is: {}\".format(len(dev_reply_vocab)))\n",
    "print()\n",
    "\n",
    "unknown_text = check_coverage(dev_text_vocab, roberta_vocab)\n",
    "print()\n",
    "unknown_reply = check_coverage(dev_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test text unique vocab count is: 12695\n",
      "test reply unique vocab count is: 4086\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=12695.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 28.452% (3612 / 12695) of vocab\n",
      "Found embeddings for 81.799% (83612 / 102217) of all text\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Checking: ', max=4086.0, style=ProgressStyle(description_â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 41.997% (1716 / 4086) of vocab\n",
      "Found embeddings for 81.206% (14682 / 18080) of all text\n"
     ]
    }
   ],
   "source": [
    "test_text_vocab = get_vocab(df_test['map_demojize_text'].values)\n",
    "test_reply_vocab = get_vocab(df_test['map_demojize_reply'].values)\n",
    "print(\"test text unique vocab count is: {}\".format(len(test_text_vocab)))\n",
    "print(\"test reply unique vocab count is: {}\".format(len(test_reply_vocab)))\n",
    "print()\n",
    "\n",
    "unknown_text = check_coverage(test_text_vocab, roberta_vocab)\n",
    "print()\n",
    "unknown_reply = check_coverage(test_reply_vocab, roberta_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('COVID', 158),\n",
       " ('hug', 121),\n",
       " ('smiling', 104),\n",
       " ('crying', 83),\n",
       " ('quarantine', 68),\n",
       " ('tonight', 64),\n",
       " ('tears', 63),\n",
       " ('loudly', 61),\n",
       " ('myself', 58),\n",
       " ('Biden', 52),\n",
       " ('reaction', 48),\n",
       " ('tomorrow', 47),\n",
       " ('pleading', 44),\n",
       " ('fucking', 43),\n",
       " ('Pelosi', 42),\n",
       " ('guys', 40),\n",
       " ('Nancy', 40),\n",
       " ('hear', 39),\n",
       " ('Oz', 39),\n",
       " ('anyone', 39),\n",
       " ('believe', 37),\n",
       " ('trying', 36),\n",
       " ('followers', 36),\n",
       " ('tweet', 36),\n",
       " ('lockdown', 36),\n",
       " ('least', 35),\n",
       " ('hearts', 35),\n",
       " ('birthday', 34),\n",
       " ('sad', 34),\n",
       " ('hope', 34),\n",
       " ('anymore', 33),\n",
       " ('economy', 31),\n",
       " ('whole', 30),\n",
       " ('virus', 29),\n",
       " ('already', 28),\n",
       " ('laughing', 27),\n",
       " ('pandemic', 27),\n",
       " ('hashtag', 26),\n",
       " ('beautiful', 26),\n",
       " ('dinner', 26),\n",
       " ('pensive', 26),\n",
       " ('decide', 25),\n",
       " ('wish', 25),\n",
       " ('weekend', 24),\n",
       " ('BailoutHumansNow', 24),\n",
       " ('politician', 24),\n",
       " ('dependable', 24),\n",
       " ('forget', 24),\n",
       " ('spend', 24),\n",
       " ('ScottyFromMarketing', 23),\n",
       " ('honest', 23),\n",
       " ('career', 23),\n",
       " ('happen', 23),\n",
       " ('dick', 22),\n",
       " ('explain', 22),\n",
       " ('reopen', 21),\n",
       " ('amaze', 21),\n",
       " ('tire', 21),\n",
       " ('Crazy', 21),\n",
       " ('sick', 20),\n",
       " ('listen', 20),\n",
       " ('sweat', 20),\n",
       " ('suck', 20),\n",
       " ('medium-light', 20),\n",
       " ('thankful', 20),\n",
       " ('flushed', 20),\n",
       " ('folded', 20),\n",
       " ('horny', 20),\n",
       " ('Guys', 20),\n",
       " ('seanhannity', 19),\n",
       " ('grinning', 19),\n",
       " ('Radical', 19),\n",
       " ('WritingCommunity', 19),\n",
       " ('Cuomo', 19),\n",
       " ('moment', 19),\n",
       " ('defeated', 18),\n",
       " ('pointing', 18),\n",
       " ('pathetic', 18),\n",
       " ('stimulus', 18),\n",
       " ('idea', 17),\n",
       " ('supporter', 17),\n",
       " ('crisis', 17),\n",
       " ('excite', 17),\n",
       " ('backhand', 17),\n",
       " ('incompetent', 17),\n",
       " ('puppet', 17),\n",
       " ('describe', 17),\n",
       " ('bitch', 17),\n",
       " ('giveaway', 17),\n",
       " ('guess', 17),\n",
       " ('governor', 17),\n",
       " ('came', 16),\n",
       " ('awesome', 16),\n",
       " ('become', 16),\n",
       " ('stupid', 16),\n",
       " ('AMERICA', 16),\n",
       " ('upside-down', 16),\n",
       " ('lone', 16),\n",
       " ('woke', 15),\n",
       " ('Gates', 15),\n",
       " ('fucked', 15),\n",
       " ('damn', 15),\n",
       " ('shrugging', 15),\n",
       " ('weary', 15),\n",
       " ('tear', 15),\n",
       " ('medium-dark', 15),\n",
       " ('suppose', 15),\n",
       " ('cares', 15),\n",
       " ('proud', 14),\n",
       " ('trash', 14),\n",
       " ('cute', 14),\n",
       " ('meeting', 14),\n",
       " ('socialist', 14),\n",
       " ('others', 14),\n",
       " ('LIBERATE', 14),\n",
       " ('Nathaniel', 14),\n",
       " ('sitting', 14),\n",
       " ('mood', 14),\n",
       " ('woozy', 14),\n",
       " ('clapping', 14),\n",
       " ('ugly', 14),\n",
       " ('understand', 14),\n",
       " ('deserve', 14),\n",
       " ('questions', 13),\n",
       " ('worse', 13),\n",
       " ('yall', 13),\n",
       " ('marry', 13),\n",
       " ('longer', 13),\n",
       " ('ensure', 13),\n",
       " ('corona', 13),\n",
       " ('anxiety', 13),\n",
       " ('facepalming', 13),\n",
       " ('folks', 13),\n",
       " ('blowing', 13),\n",
       " ('realize', 13),\n",
       " ('tweets', 13),\n",
       " ('6pm', 13),\n",
       " ('stopped', 13),\n",
       " ('Vaccine', 12),\n",
       " ('coffee', 12),\n",
       " ('pizza', 12),\n",
       " ('decision', 12),\n",
       " ('billionaire', 12),\n",
       " ('afford', 12),\n",
       " ('questionsâ€¦', 12),\n",
       " ('attention', 12),\n",
       " ('grateful', 12),\n",
       " ('appreciate', 12),\n",
       " ('thousands', 12),\n",
       " ('funny', 12),\n",
       " ('drink', 12),\n",
       " ('covid', 12),\n",
       " ('approval', 12),\n",
       " ('sparkles', 12),\n",
       " ('students', 12),\n",
       " ('entire', 12),\n",
       " ('beaming', 12),\n",
       " ('complaining', 12),\n",
       " ('heart-eyes', 12),\n",
       " ('truly', 12),\n",
       " ('thinks', 12),\n",
       " ('everyday', 11),\n",
       " ('experience', 11),\n",
       " ('wearing', 11),\n",
       " ('VIRGINIA', 11),\n",
       " ('Amendment', 11),\n",
       " ('siege', 11),\n",
       " ('scared', 11),\n",
       " ('DMs', 11),\n",
       " ('replies', 11),\n",
       " ('handling', 11),\n",
       " ('Dollar', 11),\n",
       " ('streaming', 11),\n",
       " ('showing', 11),\n",
       " ('possible', 11),\n",
       " ('nobody', 11),\n",
       " ('boyfriend', 11),\n",
       " ('Ventilators', 11),\n",
       " ('leadership', 11),\n",
       " ('1st', 11),\n",
       " ('angry', 11),\n",
       " ('across', 11),\n",
       " ('couple', 11),\n",
       " ('lil', 10),\n",
       " ('kindness', 10),\n",
       " ('relationship', 10),\n",
       " ('conversation', 10),\n",
       " ('NEED', 10),\n",
       " ('sister', 10),\n",
       " ('definitely', 10),\n",
       " ('nose', 10),\n",
       " ('forever', 10),\n",
       " ('ventilators', 10),\n",
       " ('passed', 10),\n",
       " ('THAT', 10),\n",
       " ('summer', 10),\n",
       " ('disaster', 10),\n",
       " ('H1N1', 10),\n",
       " ('Swine', 10),\n",
       " ('Flu', 10),\n",
       " ('Polling', 10),\n",
       " ('disastrous', 10),\n",
       " ('unnecessarily', 10),\n",
       " ('incompetence', 10),\n",
       " ('Billion', 10),\n",
       " ('Obamacare', 10),\n",
       " ('website', 10),\n",
       " ('excuse', 10),\n",
       " ('randomly', 10),\n",
       " ('cuz', 10),\n",
       " ('themselves', 10),\n",
       " ('realized', 10),\n",
       " ('opinion', 10),\n",
       " ('5k', 10),\n",
       " ('fingers', 10),\n",
       " ('biggest', 9),\n",
       " ('sucking', 9),\n",
       " ('idk', 9),\n",
       " ('taken', 9),\n",
       " ('hurt', 9),\n",
       " ('himself', 9),\n",
       " ('situation', 9),\n",
       " ('patients', 9),\n",
       " ('vibe', 9),\n",
       " ('choose', 9),\n",
       " ('partying', 9),\n",
       " ('therapy', 9),\n",
       " ('awful', 9),\n",
       " ('difference', 9),\n",
       " ('Idk', 9),\n",
       " ('drunk', 9),\n",
       " ('weird', 9),\n",
       " ('fear', 9),\n",
       " ('wonder', 9),\n",
       " ('honestly', 9),\n",
       " ('cheese', 9),\n",
       " ('okay', 9),\n",
       " ('expansive', 9),\n",
       " ('accurate', 9),\n",
       " ('thumbs', 9),\n",
       " ('skull', 9),\n",
       " ('horns', 9),\n",
       " ('reminds', 9),\n",
       " ('dude', 9),\n",
       " ('helping', 9),\n",
       " ('worry', 9),\n",
       " ('shower', 9),\n",
       " ('seriously', 9),\n",
       " ('unemployment', 9),\n",
       " ('retweet', 9),\n",
       " ('grocery', 9),\n",
       " ('pregnant', 9),\n",
       " ('popper', 8),\n",
       " ('leaving', 8),\n",
       " ('announce', 8),\n",
       " ('celebrate', 8),\n",
       " ('takes', 8),\n",
       " ('depression', 8),\n",
       " ('sugar', 8),\n",
       " ('11am', 8),\n",
       " ('broke', 8),\n",
       " ('advice', 8),\n",
       " ('nigga', 8),\n",
       " ('learned', 8),\n",
       " ('7th', 8),\n",
       " ('sucks', 8),\n",
       " ('bout', 8),\n",
       " ('sleepy', 8),\n",
       " ('Frequently', 8),\n",
       " ('opportunity', 8),\n",
       " ('LIKE', 8),\n",
       " ('finish', 8),\n",
       " ('cheating', 8),\n",
       " ('instagram', 8),\n",
       " ('partner', 8),\n",
       " ('â†’', 8),\n",
       " ('heaven', 8),\n",
       " ('attempt', 8),\n",
       " ('LOVE', 8),\n",
       " ('chill', 8),\n",
       " ('beds', 8),\n",
       " ('causing', 8),\n",
       " ('funeral', 8),\n",
       " ('pouting', 8),\n",
       " ('MUCH', 8),\n",
       " ('pray', 8),\n",
       " ('enjoy', 8),\n",
       " ('teacher', 8),\n",
       " ('additional', 8),\n",
       " ('approve', 8),\n",
       " ('dying', 8),\n",
       " ('exploding', 8),\n",
       " ('welcome', 8),\n",
       " ('HAVE', 8),\n",
       " ('terrible', 8),\n",
       " ('keeps', 8),\n",
       " ('FollowFriday', 8),\n",
       " ('governors', 8),\n",
       " ('relief', 8),\n",
       " ('relieved', 8),\n",
       " ('idiot', 8),\n",
       " ('lose', 8),\n",
       " ('apartment', 8),\n",
       " ('unamused', 8),\n",
       " ('crossed', 8),\n",
       " ('upset', 8),\n",
       " ('hundred', 8),\n",
       " ('sounds', 7),\n",
       " ('kitchen', 7),\n",
       " ('messages', 7),\n",
       " ('anxious', 7),\n",
       " ('OldRich', 7),\n",
       " ('tells', 7),\n",
       " ('joke', 7),\n",
       " ('gift', 7),\n",
       " ('NYC', 7),\n",
       " ('sending', 7),\n",
       " ('alive', 7),\n",
       " ('ONLY', 7),\n",
       " ('covering', 7),\n",
       " ('savoring', 7),\n",
       " ('dear', 7),\n",
       " ('dropped', 7),\n",
       " ('treating', 7),\n",
       " ('calls', 7),\n",
       " ('slid', 7),\n",
       " ('sauce', 7),\n",
       " ('stuck', 7),\n",
       " ('Lebron', 7),\n",
       " ('masks', 7),\n",
       " ('Genuinely', 7),\n",
       " ('Rashford', 7),\n",
       " ('clothes', 7),\n",
       " ('lately', 7),\n",
       " ('fraud', 7),\n",
       " ('discussion', 7),\n",
       " ('harder', 7),\n",
       " ('herself', 7),\n",
       " ('lucky', 7),\n",
       " ('incredibly', 7),\n",
       " ('expect', 7),\n",
       " ('glad', 7),\n",
       " ('RETWEET', 7),\n",
       " ('Zoom', 7),\n",
       " ('disgusting', 7),\n",
       " ('TESTING', 7),\n",
       " ('exam', 7),\n",
       " ('yours', 7),\n",
       " ('Been', 7),\n",
       " ('turning', 7),\n",
       " ('Birthday', 7),\n",
       " ('sparkling', 7),\n",
       " ('loves', 7),\n",
       " ('comedy', 7),\n",
       " ('evening', 7),\n",
       " ('complain', 7),\n",
       " ('waste', 7),\n",
       " ('songs', 7),\n",
       " ('handshake', 7),\n",
       " ('afternoon', 7),\n",
       " ('QUARANTINE', 7),\n",
       " ('hugging', 7),\n",
       " ('grimacing', 7),\n",
       " ('EVER', 7),\n",
       " ('FUCK', 7),\n",
       " ('slide', 7),\n",
       " ('apparently', 7),\n",
       " ('barely', 7),\n",
       " ('cuddle', 7),\n",
       " ('officials', 7),\n",
       " ('Respond', 7),\n",
       " ('immediate', 7),\n",
       " ('heavily', 7),\n",
       " ('awake', 7),\n",
       " ('blocked', 7),\n",
       " ('sexy', 7),\n",
       " ('clearly', 7),\n",
       " ('problems', 7),\n",
       " ('purple', 7),\n",
       " ('pics', 7),\n",
       " ('funds', 7),\n",
       " ('meme', 7),\n",
       " ('annoying', 7),\n",
       " ('KNOW', 7),\n",
       " ('appreciated', 7),\n",
       " ('seem', 7),\n",
       " ('surprise', 7),\n",
       " ('regional', 7),\n",
       " ('niggas', 6),\n",
       " ('everybody', 6),\n",
       " ('nightmare', 6),\n",
       " ('judging', 6),\n",
       " ('judgement', 6),\n",
       " ('HUNGRY', 6),\n",
       " ('worried', 6),\n",
       " ('yesterday', 6),\n",
       " ('denies', 6),\n",
       " ('extent', 6),\n",
       " ('outbreak', 6),\n",
       " ('smh', 6),\n",
       " ('extend', 6),\n",
       " ('lovely', 6),\n",
       " ('expecting', 6),\n",
       " ('Minister', 6),\n",
       " ('committed', 6),\n",
       " ('communist', 6),\n",
       " ('isolation', 6),\n",
       " ('shitty', 6),\n",
       " ('interview', 6),\n",
       " ('sleeping', 6),\n",
       " ('dangerous', 6),\n",
       " ('retweets', 6),\n",
       " ('difficult', 6),\n",
       " ('amwriting', 6),\n",
       " ('Neymar', 6),\n",
       " ('slightly', 6),\n",
       " ('starts', 6),\n",
       " ('senior', 6),\n",
       " ('makeup', 6),\n",
       " ('personally', 6),\n",
       " ('pictures', 6),\n",
       " ('experts', 6),\n",
       " ('lowkey', 6),\n",
       " ('dumb', 6),\n",
       " ('fellow', 6),\n",
       " ('blessed', 6),\n",
       " ('university', 6),\n",
       " ('Cassper', 6),\n",
       " ('survive', 6),\n",
       " ('thousand', 6),\n",
       " ('crush', 6),\n",
       " ('viewers', 6),\n",
       " ('Bailout', 6),\n",
       " ('Humans', 6),\n",
       " ('MUST', 6),\n",
       " ('Shout', 6),\n",
       " ('Quarantine', 6),\n",
       " ('Vikings', 6),\n",
       " ('scary', 6),\n",
       " ('groceries', 6),\n",
       " ('visit', 6),\n",
       " ('Lol', 6),\n",
       " ('strategy', 6),\n",
       " ('expressionless', 6),\n",
       " ('exclamation', 6),\n",
       " ('winking', 6),\n",
       " ('supporters', 6),\n",
       " ('breakfast', 6),\n",
       " ('suddenly', 6),\n",
       " ('miles', 6),\n",
       " ('voted', 6),\n",
       " ('ventilator', 6),\n",
       " ('unprecedented', 6),\n",
       " ('follows', 6),\n",
       " ('Retweet', 6),\n",
       " ('bunch', 6),\n",
       " ('vaccine', 6),\n",
       " ('chocolate', 6),\n",
       " ('milk', 6),\n",
       " ('missed', 6),\n",
       " ('employees', 6),\n",
       " ('possibility', 6),\n",
       " ('CoronaVirus', 6),\n",
       " ('Democrat', 6),\n",
       " ('asleep', 6),\n",
       " ('POTUS', 6),\n",
       " ('appointing', 6),\n",
       " ('pussy', 6),\n",
       " ('promise', 6),\n",
       " ('RIGHT', 6),\n",
       " ('boobs', 6),\n",
       " ('fist', 6),\n",
       " ('tho', 6),\n",
       " ('WAS', 6),\n",
       " ('flexed', 6),\n",
       " ('biceps', 6),\n",
       " ('Guess', 6),\n",
       " ('notifications', 6),\n",
       " ('tough', 6),\n",
       " ('dance', 6),\n",
       " ('COVIDLiar', 6),\n",
       " ('spirits', 6),\n",
       " ('indicator', 6),\n",
       " ('symbol', 6),\n",
       " ('discussing', 5),\n",
       " ('wtf', 5),\n",
       " ('cried', 5),\n",
       " ('hacked', 5),\n",
       " ('replying', 5),\n",
       " ('attacked', 5),\n",
       " ('stupidity', 5),\n",
       " ('\\u200d', 5),\n",
       " ('hiding', 5),\n",
       " ('prepare', 5),\n",
       " ('transition', 5),\n",
       " ('till', 5),\n",
       " ('Govt', 5),\n",
       " ('wonderful', 5),\n",
       " ('tbh', 5),\n",
       " ('fridge', 5),\n",
       " ('Parliament', 5),\n",
       " ('signs', 5),\n",
       " ('spending', 5),\n",
       " ('ridiculous', 5),\n",
       " ('star-struck', 5),\n",
       " ('memories', 5),\n",
       " ('debate', 5),\n",
       " ('happiness', 5),\n",
       " ('Feeling', 5),\n",
       " ('sober', 5),\n",
       " ('meetings', 5),\n",
       " ('hits', 5),\n",
       " ('prayers', 5),\n",
       " ('disease', 5),\n",
       " ('victory', 5),\n",
       " ('mention', 5),\n",
       " ('somebody', 5),\n",
       " ('drinks', 5),\n",
       " ('compassion', 5),\n",
       " ('Zack', 5),\n",
       " ('teams', 5),\n",
       " ('WILL', 5),\n",
       " ('BABY', 5),\n",
       " ('remain', 5),\n",
       " ('hearing', 5),\n",
       " ('huh', 5),\n",
       " ('Fauci', 5),\n",
       " ('boring', 5),\n",
       " ('waking', 5),\n",
       " ('doctors', 5),\n",
       " ('slowly', 5),\n",
       " ('expand', 5),\n",
       " ('beating', 5),\n",
       " ('cancelled', 5),\n",
       " ('sake', 5),\n",
       " ('Trey', 5),\n",
       " ('Burton', 5),\n",
       " ('cant', 5),\n",
       " ('selecting', 5),\n",
       " ('donate', 5),\n",
       " ('plenty', 5),\n",
       " ('laid', 5),\n",
       " ('journey', 5),\n",
       " ('peaceful', 5),\n",
       " ('beach', 5),\n",
       " ('apeopley', 5),\n",
       " ('mutuals', 5),\n",
       " ('anywhere', 5),\n",
       " ('choked', 5),\n",
       " ('homes', 5),\n",
       " ('cough', 5),\n",
       " ('bipartisan', 5),\n",
       " ('desk', 5),\n",
       " ('doubling', 5),\n",
       " ('Invisible', 5),\n",
       " ('Enemy', 5),\n",
       " ('concerned', 5),\n",
       " ('familiar', 5),\n",
       " ('YOUR', 5),\n",
       " ('WHY', 5),\n",
       " ('bitches', 5),\n",
       " ('challenge', 5),\n",
       " ('butter', 5),\n",
       " ('shoes', 5),\n",
       " ('10k', 5),\n",
       " ('GOOD', 5),\n",
       " ('pounds', 5),\n",
       " ('FIRST', 5),\n",
       " ('loud', 5),\n",
       " ('loan', 5),\n",
       " ('tiktok', 5),\n",
       " ('dudes', 5),\n",
       " ('streets', 5),\n",
       " ('timeline', 5),\n",
       " ('squinting', 5),\n",
       " ('freak', 5),\n",
       " ('haircut', 5),\n",
       " ('garden', 5),\n",
       " ('selfie', 5),\n",
       " ('DrOz', 5),\n",
       " ('imagine', 5),\n",
       " ('entering', 5),\n",
       " ('Dems', 5),\n",
       " ('realizing', 5),\n",
       " ('liquor', 5),\n",
       " ('RAT', 5),\n",
       " ('guest', 5),\n",
       " ('HIM', 5),\n",
       " ('rally', 5),\n",
       " ('naked', 5),\n",
       " ('horrible', 5),\n",
       " ('movies', 5),\n",
       " ('shopping', 5),\n",
       " ('roof', 5),\n",
       " ('Verge', 5),\n",
       " ('consistently', 5),\n",
       " ('mistake', 5),\n",
       " ('suspect', 5),\n",
       " ('furloughed', 5),\n",
       " ('records', 5),\n",
       " ('writerslift', 5),\n",
       " ('leaves', 5),\n",
       " ('everywhere', 5),\n",
       " ('followed', 5),\n",
       " ('govt', 5),\n",
       " ('LikewiseApp', 5),\n",
       " ('Yay', 5),\n",
       " ('infected', 5),\n",
       " ('attend', 5),\n",
       " ('Lockdown', 5),\n",
       " ('simply', 5),\n",
       " ('boo', 5),\n",
       " ('juliemac1000', 5),\n",
       " ('Congressional', 5),\n",
       " ('lawyer', 5),\n",
       " ('payments', 5),\n",
       " ('bored', 5),\n",
       " ('OKAY', 5),\n",
       " ('TODAY', 5),\n",
       " ('happens', 5),\n",
       " ('screenshot', 5),\n",
       " ('Uncle', 5),\n",
       " ('2021', 5),\n",
       " ('interact', 5),\n",
       " ('saved', 5),\n",
       " ('fuckin', 5),\n",
       " ('murder', 5),\n",
       " ('nursing', 5),\n",
       " ('jumping', 5),\n",
       " ('Wuhan', 5),\n",
       " ('teach', 5),\n",
       " ('memes', 5),\n",
       " ('swear', 5),\n",
       " ('cheer', 5),\n",
       " ('earlier', 5),\n",
       " ('apeopleause', 5),\n",
       " ('younger', 5),\n",
       " ('neighbor', 5),\n",
       " ('pushing', 5),\n",
       " ('WOW', 5),\n",
       " ('nail', 5),\n",
       " ('Kanye', 5),\n",
       " ('bills', 5),\n",
       " ('eggs', 5),\n",
       " ('sisters', 5),\n",
       " ('Couldn', 5),\n",
       " ('Lawrence', 5),\n",
       " ('sacrifice', 5),\n",
       " ('trading', 4),\n",
       " ('Might', 4),\n",
       " ('downcast', 4),\n",
       " ('hardest', 4),\n",
       " ('hospitals', 4),\n",
       " ('spamming', 4),\n",
       " ('confronting', 4),\n",
       " ('Doing', 4),\n",
       " ('eventually', 4),\n",
       " ('cancel', 4),\n",
       " ('lunch', 4),\n",
       " ('begins', 4),\n",
       " ('greatest', 4),\n",
       " ('shout', 4),\n",
       " ('teenage', 4),\n",
       " ('salt', 4),\n",
       " ('liberate', 4),\n",
       " ('talent', 4),\n",
       " ('theater', 4),\n",
       " ('struggling', 4),\n",
       " ('allowing', 4),\n",
       " ('Tune', 4),\n",
       " ('sperm', 4),\n",
       " ('moms', 4),\n",
       " ('Horny', 4),\n",
       " ('liked', 4),\n",
       " ('communities', 4),\n",
       " ('apologize', 4),\n",
       " ('admit', 4),\n",
       " ('afraid', 4),\n",
       " ('recovered', 4),\n",
       " ('appointment', 4),\n",
       " ('LOL', 4),\n",
       " ('Somebody', 4),\n",
       " ('irresponsible', 4),\n",
       " ('COVIDPandemic', 4),\n",
       " ('HIT', 4),\n",
       " ('stressed', 4),\n",
       " ('Yup', 4),\n",
       " ('busy', 4),\n",
       " ('pillow', 4),\n",
       " ('hella', 4),\n",
       " ('posting', 4),\n",
       " ('turns', 4),\n",
       " ('wins', 4),\n",
       " ('moves', 4),\n",
       " ('hurts', 4),\n",
       " ('THEY', 4),\n",
       " ('convo', 4),\n",
       " ('pronounced', 4),\n",
       " ('Lindsey', 4),\n",
       " ('exercise', 4),\n",
       " ('writingcommunity', 4),\n",
       " ('Giants', 4),\n",
       " ('libs', 4),\n",
       " ('sunglasses', 4),\n",
       " ('otherwise', 4),\n",
       " ('AEW', 4),\n",
       " ('Cody', 4),\n",
       " ('Suite', 4),\n",
       " ('lesson', 4),\n",
       " ('souls', 4),\n",
       " ('Thoughts', 4),\n",
       " ('spreading', 4),\n",
       " ('planning', 4),\n",
       " ('HATE', 4),\n",
       " ('slapped', 4),\n",
       " ('giveaways', 4),\n",
       " ('cherry', 4),\n",
       " ('mum', 4),\n",
       " ('wondering', 4),\n",
       " ('potential', 4),\n",
       " ('faster', 4),\n",
       " ('Raiders', 4),\n",
       " ('Ruggs', 4),\n",
       " ('Jeudy', 4),\n",
       " ('Lamb', 4),\n",
       " ('idiots', 4),\n",
       " ('tweeting', 4),\n",
       " ('VoteSafe', 4),\n",
       " ('polling', 4),\n",
       " ('â†’No', 4),\n",
       " ('absentee', 4),\n",
       " ('â†’At', 4),\n",
       " ('Voting', 4),\n",
       " ('fundamental', 4),\n",
       " ('globe', 4),\n",
       " ('REALLY', 4),\n",
       " ('Pls', 4),\n",
       " ('Bears', 4),\n",
       " ('shaking', 4),\n",
       " ('toxic', 4),\n",
       " ('throughout', 4),\n",
       " ('impossible', 4),\n",
       " ('4th', 4),\n",
       " ('see-no-evil', 4),\n",
       " ('SpeakerPelosi', 4),\n",
       " ('Ozark', 4),\n",
       " ('Creek', 4),\n",
       " ('texts', 4),\n",
       " ('creators', 4),\n",
       " ('conspiracy', 4),\n",
       " ('customers', 4),\n",
       " ('goodbye', 4),\n",
       " ('shutdown', 4),\n",
       " ('fever', 4),\n",
       " ('recently', 4),\n",
       " ('couch', 4),\n",
       " ('Explain', 4),\n",
       " ('PPP', 4),\n",
       " ('sink', 4),\n",
       " ('assignment', 4),\n",
       " ('symptoms', 4),\n",
       " ('hopefully', 4),\n",
       " ('Cowboys', 4),\n",
       " ('wanting', 4),\n",
       " ('positivity', 4),\n",
       " ('workout', 4),\n",
       " ('prepared', 4),\n",
       " ('peanut', 4),\n",
       " ('subscribers', 4),\n",
       " ('Walmart', 4),\n",
       " ('LockdownHouseParty', 4),\n",
       " ('affection', 4),\n",
       " ('arguments', 4),\n",
       " ('streamer', 4),\n",
       " ('depressed', 4),\n",
       " ('receiving', 4),\n",
       " ('porn', 4),\n",
       " ('tongue', 4),\n",
       " ('baseball', 4),\n",
       " ('strongly', 4),\n",
       " ('countries', 4),\n",
       " ('disapprove', 4),\n",
       " ('FCE', 4),\n",
       " ('protest', 4),\n",
       " ('Drew', 4),\n",
       " ('friday', 4),\n",
       " ('heroes', 4),\n",
       " ('NHS', 4),\n",
       " ('millions', 4),\n",
       " ('cleaned', 4),\n",
       " ('spit', 4),\n",
       " ('appearance', 4),\n",
       " ('BOY', 4),\n",
       " ('Titans', 4),\n",
       " ('WITH', 4),\n",
       " ('encourage', 4),\n",
       " ('2k', 4),\n",
       " ('swimming', 4),\n",
       " ('burden', 4),\n",
       " ('Watching', 4),\n",
       " ('CashApp', 4),\n",
       " ('paycheck', 4),\n",
       " ('HUGE', 4),\n",
       " ('daddy', 4),\n",
       " ('publicly', 4),\n",
       " ('screaming', 4),\n",
       " ('Rona', 4),\n",
       " ('friendship', 4),\n",
       " ('caused', 4),\n",
       " ('brilliant', 4),\n",
       " ('supeopley', 4),\n",
       " ('several', 4),\n",
       " ('easily', 4),\n",
       " ('wedding', 4),\n",
       " ('StayAtHome', 4),\n",
       " ('hugged', 4),\n",
       " ('OANN', 4),\n",
       " ('Carolina', 4),\n",
       " ('combination', 4),\n",
       " ('remembered', 4),\n",
       " ('Welp', 4),\n",
       " ('horror', 4),\n",
       " ('serve', 4),\n",
       " ('invited', 4),\n",
       " ('breath', 4),\n",
       " ('eyebrow', 4),\n",
       " ('hoping', 4),\n",
       " ('filing', 4),\n",
       " ('revive', 4),\n",
       " ('potato', 4),\n",
       " ('virologist', 4),\n",
       " ('puzzle', 4),\n",
       " ('proved', 4),\n",
       " ('taste', 4),\n",
       " ('EVERYONE', 4),\n",
       " ('companies', 4),\n",
       " ('regret', 4),\n",
       " ('provide', 4),\n",
       " ('Wish', 4),\n",
       " ('tired', 4),\n",
       " ('fandom', 4),\n",
       " ('imma', 4),\n",
       " ('chips', 4),\n",
       " ('gym', 4),\n",
       " ('OMG', 4),\n",
       " ('whilst', 4),\n",
       " ('Oprah', 4),\n",
       " ('heartbreaking', 4),\n",
       " ('kills', 4),\n",
       " ('replaced', 4),\n",
       " ('crack', 4),\n",
       " ('WENT', 4),\n",
       " ('BATHROOM', 4),\n",
       " ('HAD', 4),\n",
       " ('SWUM', 4),\n",
       " ('TOILET', 4),\n",
       " ('THOUGHT', 4),\n",
       " ('URBAN', 4),\n",
       " ('LEGEND', 4),\n",
       " ('MOVE', 4),\n",
       " ('nasty', 4),\n",
       " ('covid19', 4),\n",
       " ('restrictions', 4),\n",
       " ('tuned', 4),\n",
       " ('jail', 4),\n",
       " ('truck', 4),\n",
       " ('caught', 4),\n",
       " ('Apologies', 4),\n",
       " ('Lemme', 4),\n",
       " ('THANK', 4),\n",
       " ('fault', 4),\n",
       " ('divorce', 4),\n",
       " ('thick', 4),\n",
       " ('supporting', 4),\n",
       " ('cleaning', 4),\n",
       " ('Catch', 4),\n",
       " ('Fortnite', 4),\n",
       " ('joking', 4),\n",
       " ('whack', 4),\n",
       " ('artists', 4),\n",
       " ('nervous', 4),\n",
       " ('Drake', 4),\n",
       " ('discussed', 4),\n",
       " ('Newcastle', 4),\n",
       " ('exhausted', 4),\n",
       " ('WHEN', 4),\n",
       " ('Packers', 4),\n",
       " ('contest', 4),\n",
       " ('unemployed', 4),\n",
       " ('ideas', 4),\n",
       " ('germ', 4),\n",
       " ('talked', 4),\n",
       " ('receiver', 4),\n",
       " ('gimme', 4),\n",
       " ('receive', 4),\n",
       " ('opinions', 4),\n",
       " ('toes', 4),\n",
       " ('monthly', 4),\n",
       " ('twice', 4),\n",
       " ('realise', 4),\n",
       " ('warned', 4),\n",
       " ('beverage', 4),\n",
       " ('Apeoplee', 4),\n",
       " ('comfortable', 4),\n",
       " ('Trout', 4),\n",
       " ('12k', 4),\n",
       " ('exciting', 4),\n",
       " ('cheated', 4),\n",
       " ('snow', 4),\n",
       " ('walked', 4),\n",
       " ('choices', 4),\n",
       " ('denied', 4),\n",
       " ('ignoring', 4),\n",
       " ('SHIT', 4),\n",
       " ('considered', 4),\n",
       " ('keycap', 4),\n",
       " ('drank', 4),\n",
       " ('Sierra', 4),\n",
       " ('pulp', 4),\n",
       " ('geng', 4),\n",
       " ('restaurants', 4),\n",
       " ('Boom', 4),\n",
       " ('carti', 3),\n",
       " ('dababy', 3),\n",
       " ('Indians', 3),\n",
       " ('crap', 3),\n",
       " ('hacker', 3),\n",
       " ('PHYSICALLY', 3),\n",
       " ('spam', 3),\n",
       " ('therapist', 3),\n",
       " ('plans', 3),\n",
       " ('apologise', 3),\n",
       " ('frowning', 3),\n",
       " ('supportive', 3),\n",
       " ('kissed', 3),\n",
       " ('belongs', 3),\n",
       " ('spoilers', 3),\n",
       " ('hurtful', 3),\n",
       " ('lockdowns', 3),\n",
       " ('quarantining', 3),\n",
       " ('welcomed', 3),\n",
       " ('assume', 3),\n",
       " ('Rounds', 3),\n",
       " ('negotiations', 3),\n",
       " ('reiterate', 3),\n",
       " ('withdrawal', 3),\n",
       " ('Transition', 3),\n",
       " ('balloon', 3),\n",
       " ('Giveaway', 3),\n",
       " ('discuss', 3),\n",
       " ('whom', 3),\n",
       " ('famu', 3),\n",
       " ('30th', 3),\n",
       " ('COMING', 3),\n",
       " ('nudes', 3),\n",
       " ('JoeBiden', 3),\n",
       " ('suffering', 3),\n",
       " ('FOLLOWERS', 3),\n",
       " ('continues', 3),\n",
       " ('subs', 3),\n",
       " ('reminding', 3),\n",
       " ('Evening', 3),\n",
       " ('screamed', 3),\n",
       " ('stunned', 3),\n",
       " ('crawl', 3),\n",
       " ('mentally', 3),\n",
       " ('finale', 3),\n",
       " ('smoke', 3),\n",
       " ('providing', 3),\n",
       " ('OUSTDUTERENOW', 3),\n",
       " ('advantage', 3),\n",
       " ('confused', 3),\n",
       " ('Newsom', 3),\n",
       " ('recovery', 3),\n",
       " ('revealed', 3),\n",
       " ('zoom', 3),\n",
       " ('fart', 3),\n",
       " ('YALL', 3),\n",
       " ('4TH', 3),\n",
       " ('increase', 3),\n",
       " ('Dakota', 3),\n",
       " ('chick', 3),\n",
       " ('preview', 3),\n",
       " ('Loeffler', 3),\n",
       " ('shooting', 3),\n",
       " ('Minutes', 3),\n",
       " ('agreed', 3),\n",
       " ('concerns', 3),\n",
       " ('Wake', 3),\n",
       " ('Brooks', 3),\n",
       " ('millennials', 3),\n",
       " ('deserves', 3),\n",
       " ('stole', 3),\n",
       " ('junior', 3),\n",
       " ('drives', 3),\n",
       " ('manuscript', 3),\n",
       " ('Derrick', 3),\n",
       " ('MAGAts', 3),\n",
       " ('owning', 3),\n",
       " ('slaves', 3),\n",
       " ...]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(unknown_text.items(), key=lambda d: d[1], reverse=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store preprocessed results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "      <th>reply</th>\n",
       "      <th>categories</th>\n",
       "      <th>mp4</th>\n",
       "      <th>map_punc_text</th>\n",
       "      <th>map_punc_reply</th>\n",
       "      <th>map_more_punc_text</th>\n",
       "      <th>map_more_punc_reply</th>\n",
       "      <th>map_demojize_text</th>\n",
       "      <th>map_demojize_reply</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>we can all agree that any song by Niall Horan.</td>\n",
       "      <td>oui oui</td>\n",
       "      <td>[yes]</td>\n",
       "      <td>6dc39e96b11275f064fdaed88273b45e.mp4</td>\n",
       "      <td>we can all agree that any song by Niall Horan .</td>\n",
       "      <td>oui oui</td>\n",
       "      <td>we can all agree that any song by Niall Horan .</td>\n",
       "      <td>oui oui</td>\n",
       "      <td>we can all agree that any song by Niall Horan .</td>\n",
       "      <td>oui oui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Will you be installing #ScottyFromMarketing's ...</td>\n",
       "      <td></td>\n",
       "      <td>[no]</td>\n",
       "      <td>cfff051f05d8d3b7136c7d58ea6ad55f.mp4</td>\n",
       "      <td>Will you be installing  # ScottyFromMarketing ...</td>\n",
       "      <td></td>\n",
       "      <td>Will you be install  # ScottyFromMarketing  ' ...</td>\n",
       "      <td></td>\n",
       "      <td>Will you be install  # ScottyFromMarketing  ' ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Growing up my mum would call me a Nigga despit...</td>\n",
       "      <td>And he joins in??? Pour some hot grits on em</td>\n",
       "      <td>[smh]</td>\n",
       "      <td>bf39e7bd9ad24354ce3ba6822b0104af.mp4</td>\n",
       "      <td>Growing up my mum would call me a Nigga despit...</td>\n",
       "      <td>And he joins in ?  ?  ?  Pour some hot grits o...</td>\n",
       "      <td>Growing up my mum would call me a Nigga despit...</td>\n",
       "      <td>And he joins in ?  ?  ?  Pour some hot grits o...</td>\n",
       "      <td>Growing up my mum would call me a Nigga despit...</td>\n",
       "      <td>And he joins in ?  ?  ?  Pour some hot grits o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Rest your head on my chest when the world feel...</td>\n",
       "      <td>ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚</td>\n",
       "      <td>[wink]</td>\n",
       "      <td>173a707a04c277354a2f23cf01d6151e.mp4</td>\n",
       "      <td>Rest your head on my chest when the world feel...</td>\n",
       "      <td>ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚</td>\n",
       "      <td>Rest your head on my chest when the world feel...</td>\n",
       "      <td>ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚</td>\n",
       "      <td>Rest your head on my chest when the world feel...</td>\n",
       "      <td>face with tears of joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Imagine Will Hernandez and Wills both doing a ...</td>\n",
       "      <td></td>\n",
       "      <td>[yes]</td>\n",
       "      <td>aab6d6bfb0c1382269ddba9b71cc8b7a.mp4</td>\n",
       "      <td>Imagine Will Hernandez and Wills both doing a ...</td>\n",
       "      <td></td>\n",
       "      <td>Imagine Will Hernandez and Wills both doing a ...</td>\n",
       "      <td></td>\n",
       "      <td>Imagine Will Hernandez and Wills both doing a ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx                                               text  \\\n",
       "0    0     we can all agree that any song by Niall Horan.   \n",
       "1    1  Will you be installing #ScottyFromMarketing's ...   \n",
       "2    2  Growing up my mum would call me a Nigga despit...   \n",
       "3    3  Rest your head on my chest when the world feel...   \n",
       "4    4  Imagine Will Hernandez and Wills both doing a ...   \n",
       "\n",
       "                                          reply categories  \\\n",
       "0                                       oui oui      [yes]   \n",
       "1                                                     [no]   \n",
       "2  And he joins in??? Pour some hot grits on em      [smh]   \n",
       "3                                         ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚     [wink]   \n",
       "4                                                    [yes]   \n",
       "\n",
       "                                    mp4  \\\n",
       "0  6dc39e96b11275f064fdaed88273b45e.mp4   \n",
       "1  cfff051f05d8d3b7136c7d58ea6ad55f.mp4   \n",
       "2  bf39e7bd9ad24354ce3ba6822b0104af.mp4   \n",
       "3  173a707a04c277354a2f23cf01d6151e.mp4   \n",
       "4  aab6d6bfb0c1382269ddba9b71cc8b7a.mp4   \n",
       "\n",
       "                                       map_punc_text  \\\n",
       "0   we can all agree that any song by Niall Horan .    \n",
       "1  Will you be installing  # ScottyFromMarketing ...   \n",
       "2  Growing up my mum would call me a Nigga despit...   \n",
       "3  Rest your head on my chest when the world feel...   \n",
       "4  Imagine Will Hernandez and Wills both doing a ...   \n",
       "\n",
       "                                      map_punc_reply  \\\n",
       "0                                            oui oui   \n",
       "1                                                      \n",
       "2  And he joins in ?  ?  ?  Pour some hot grits o...   \n",
       "3                                              ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚   \n",
       "4                                                      \n",
       "\n",
       "                                  map_more_punc_text  \\\n",
       "0   we can all agree that any song by Niall Horan .    \n",
       "1  Will you be install  # ScottyFromMarketing  ' ...   \n",
       "2  Growing up my mum would call me a Nigga despit...   \n",
       "3  Rest your head on my chest when the world feel...   \n",
       "4  Imagine Will Hernandez and Wills both doing a ...   \n",
       "\n",
       "                                 map_more_punc_reply  \\\n",
       "0                                            oui oui   \n",
       "1                                                      \n",
       "2  And he joins in ?  ?  ?  Pour some hot grits o...   \n",
       "3                                              ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚   \n",
       "4                                                      \n",
       "\n",
       "                                   map_demojize_text  \\\n",
       "0   we can all agree that any song by Niall Horan .    \n",
       "1  Will you be install  # ScottyFromMarketing  ' ...   \n",
       "2  Growing up my mum would call me a Nigga despit...   \n",
       "3  Rest your head on my chest when the world feel...   \n",
       "4  Imagine Will Hernandez and Wills both doing a ...   \n",
       "\n",
       "                                  map_demojize_reply  \n",
       "0                                            oui oui  \n",
       "1                                                     \n",
       "2  And he joins in ?  ?  ?  Pour some hot grits o...  \n",
       "3                            face with tears of joy   \n",
       "4                                                     "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "      <th>reply</th>\n",
       "      <th>map_punc_text</th>\n",
       "      <th>map_punc_reply</th>\n",
       "      <th>map_more_punc_text</th>\n",
       "      <th>map_more_punc_reply</th>\n",
       "      <th>map_demojize_text</th>\n",
       "      <th>map_demojize_reply</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32000</td>\n",
       "      <td>Drop your cash app, use hashtag #BailoutHumansNow</td>\n",
       "      <td>$tyratomaro #BailoutHumans</td>\n",
       "      <td>Drop your cash app ,  use hashtag  # BailoutHu...</td>\n",
       "      <td>$ tyratomaro  # BailoutHumans</td>\n",
       "      <td>Drop your cash app ,  use hashtag  # BailoutHu...</td>\n",
       "      <td>$ tyratomaro  # BailoutHumans</td>\n",
       "      <td>Drop your cash app ,  use hashtag  # BailoutHu...</td>\n",
       "      <td>$ tyratomaro  # BailoutHumans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32001</td>\n",
       "      <td>After interviewing with a few incredible peopl...</td>\n",
       "      <td>CONGRATS!!!!!</td>\n",
       "      <td>After interviewing with a few incredible peopl...</td>\n",
       "      <td>CONGRATS !  !  !  !  !</td>\n",
       "      <td>After interviewing with a few incredible peopl...</td>\n",
       "      <td>CONGRATS !  !  !  !  !</td>\n",
       "      <td>After interviewing with a few incredible peopl...</td>\n",
       "      <td>CONGRATS !  !  !  !  !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32002</td>\n",
       "      <td>I know GTC festival not happening next month b...</td>\n",
       "      <td></td>\n",
       "      <td>I know GTC festival not happening next month b...</td>\n",
       "      <td></td>\n",
       "      <td>I know GTC festival not happening next month b...</td>\n",
       "      <td></td>\n",
       "      <td>I know GTC festival not happening next month b...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32003</td>\n",
       "      <td>Lordy, my daughter just said, â€œI wonder how th...</td>\n",
       "      <td></td>\n",
       "      <td>Lordy ,  my daughter just said ,    \"  I wonde...</td>\n",
       "      <td></td>\n",
       "      <td>Lordy ,  my daughter just said ,    \"  I wonde...</td>\n",
       "      <td></td>\n",
       "      <td>Lordy ,  my daughter just said ,    \"  I wonde...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32004</td>\n",
       "      <td>THE UNEMPLOYMENT CLAIM SYSTEM SUCKS SO MUCH DICK</td>\n",
       "      <td>Watching everyone else get their weekly unempl...</td>\n",
       "      <td>THE UNEMPLOYMENT CLAIM SYSTEM SUCKS SO MUCH DICK</td>\n",
       "      <td>Watching everyone else get their weekly unempl...</td>\n",
       "      <td>THE UNEMPLOYMENT CLAIM SYSTEM SUCKS SO MUCH DICK</td>\n",
       "      <td>Watching everyone else get their weekly unempl...</td>\n",
       "      <td>THE UNEMPLOYMENT CLAIM SYSTEM SUCKS SO MUCH DICK</td>\n",
       "      <td>Watching everyone else get their weekly unempl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     idx                                               text  \\\n",
       "0  32000  Drop your cash app, use hashtag #BailoutHumansNow   \n",
       "1  32001  After interviewing with a few incredible peopl...   \n",
       "2  32002  I know GTC festival not happening next month b...   \n",
       "3  32003  Lordy, my daughter just said, â€œI wonder how th...   \n",
       "4  32004   THE UNEMPLOYMENT CLAIM SYSTEM SUCKS SO MUCH DICK   \n",
       "\n",
       "                                               reply  \\\n",
       "0                         $tyratomaro #BailoutHumans   \n",
       "1                                      CONGRATS!!!!!   \n",
       "2                                                      \n",
       "3                                                      \n",
       "4  Watching everyone else get their weekly unempl...   \n",
       "\n",
       "                                       map_punc_text  \\\n",
       "0  Drop your cash app ,  use hashtag  # BailoutHu...   \n",
       "1  After interviewing with a few incredible peopl...   \n",
       "2  I know GTC festival not happening next month b...   \n",
       "3  Lordy ,  my daughter just said ,    \"  I wonde...   \n",
       "4   THE UNEMPLOYMENT CLAIM SYSTEM SUCKS SO MUCH DICK   \n",
       "\n",
       "                                      map_punc_reply  \\\n",
       "0                      $ tyratomaro  # BailoutHumans   \n",
       "1                            CONGRATS !  !  !  !  !    \n",
       "2                                                      \n",
       "3                                                      \n",
       "4  Watching everyone else get their weekly unempl...   \n",
       "\n",
       "                                  map_more_punc_text  \\\n",
       "0  Drop your cash app ,  use hashtag  # BailoutHu...   \n",
       "1  After interviewing with a few incredible peopl...   \n",
       "2  I know GTC festival not happening next month b...   \n",
       "3  Lordy ,  my daughter just said ,    \"  I wonde...   \n",
       "4   THE UNEMPLOYMENT CLAIM SYSTEM SUCKS SO MUCH DICK   \n",
       "\n",
       "                                 map_more_punc_reply  \\\n",
       "0                      $ tyratomaro  # BailoutHumans   \n",
       "1                            CONGRATS !  !  !  !  !    \n",
       "2                                                      \n",
       "3                                                      \n",
       "4  Watching everyone else get their weekly unempl...   \n",
       "\n",
       "                                   map_demojize_text  \\\n",
       "0  Drop your cash app ,  use hashtag  # BailoutHu...   \n",
       "1  After interviewing with a few incredible peopl...   \n",
       "2  I know GTC festival not happening next month b...   \n",
       "3  Lordy ,  my daughter just said ,    \"  I wonde...   \n",
       "4   THE UNEMPLOYMENT CLAIM SYSTEM SUCKS SO MUCH DICK   \n",
       "\n",
       "                                  map_demojize_reply  \n",
       "0                      $ tyratomaro  # BailoutHumans  \n",
       "1                            CONGRATS !  !  !  !  !   \n",
       "2                                                     \n",
       "3                                                     \n",
       "4  Watching everyone else get their weekly unempl...  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "      <th>reply</th>\n",
       "      <th>map_punc_text</th>\n",
       "      <th>map_punc_reply</th>\n",
       "      <th>map_more_punc_text</th>\n",
       "      <th>map_more_punc_reply</th>\n",
       "      <th>map_demojize_text</th>\n",
       "      <th>map_demojize_reply</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36000</td>\n",
       "      <td>@Youngdeji_ I think if uzi and carti dropping ...</td>\n",
       "      <td></td>\n",
       "      <td>@ Youngdeji  -   I think if uzi and carti dro...</td>\n",
       "      <td></td>\n",
       "      <td>@ Youngdeji  -   I think if uzi and carti dro...</td>\n",
       "      <td></td>\n",
       "      <td>@ Youngdeji  -   I think if uzi and carti dro...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36001</td>\n",
       "      <td>For the third year in a row we are discussing ...</td>\n",
       "      <td></td>\n",
       "      <td>For the third year in a row we are discussing ...</td>\n",
       "      <td></td>\n",
       "      <td>For the third year in a row we are discussing ...</td>\n",
       "      <td></td>\n",
       "      <td>For the third year in a row we are discussing ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36002</td>\n",
       "      <td>dababy album sounds like it was made for nigga...</td>\n",
       "      <td>That's why you bought it.</td>\n",
       "      <td>dababy album sounds like it was made for nigga...</td>\n",
       "      <td>That  '  s why you bought it .</td>\n",
       "      <td>dababy album sounds like it was made for nigga...</td>\n",
       "      <td>That  '  s why you buy it .</td>\n",
       "      <td>dababy album sounds like it was made for nigga...</td>\n",
       "      <td>That  '  s why you buy it .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36003</td>\n",
       "      <td>Majority of Indians do not watch any sport oth...</td>\n",
       "      <td>@ZairaWasimmm got a great story because of the...</td>\n",
       "      <td>Majority of Indians do not watch any sport oth...</td>\n",
       "      <td>@ ZairaWasimmm got a great story because of t...</td>\n",
       "      <td>Majority of Indians do not watch any sport oth...</td>\n",
       "      <td>@ ZairaWasimmm got a great story because of t...</td>\n",
       "      <td>Majority of Indians do not watch any sport oth...</td>\n",
       "      <td>@ ZairaWasimmm got a great story because of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36004</td>\n",
       "      <td>everybody is just now listening to @madisonbee...</td>\n",
       "      <td></td>\n",
       "      <td>everybody is just now listening to  @ madisonb...</td>\n",
       "      <td></td>\n",
       "      <td>everybody is just now listen to  @ madisonbeer...</td>\n",
       "      <td></td>\n",
       "      <td>everybody is just now listen to  @ madisonbeer...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     idx                                               text  \\\n",
       "0  36000  @Youngdeji_ I think if uzi and carti dropping ...   \n",
       "1  36001  For the third year in a row we are discussing ...   \n",
       "2  36002  dababy album sounds like it was made for nigga...   \n",
       "3  36003  Majority of Indians do not watch any sport oth...   \n",
       "4  36004  everybody is just now listening to @madisonbee...   \n",
       "\n",
       "                                               reply  \\\n",
       "0                                                      \n",
       "1                                                      \n",
       "2                          That's why you bought it.   \n",
       "3  @ZairaWasimmm got a great story because of the...   \n",
       "4                                                      \n",
       "\n",
       "                                       map_punc_text  \\\n",
       "0   @ Youngdeji  -   I think if uzi and carti dro...   \n",
       "1  For the third year in a row we are discussing ...   \n",
       "2  dababy album sounds like it was made for nigga...   \n",
       "3  Majority of Indians do not watch any sport oth...   \n",
       "4  everybody is just now listening to  @ madisonb...   \n",
       "\n",
       "                                      map_punc_reply  \\\n",
       "0                                                      \n",
       "1                                                      \n",
       "2                    That  '  s why you bought it .    \n",
       "3   @ ZairaWasimmm got a great story because of t...   \n",
       "4                                                      \n",
       "\n",
       "                                  map_more_punc_text  \\\n",
       "0   @ Youngdeji  -   I think if uzi and carti dro...   \n",
       "1  For the third year in a row we are discussing ...   \n",
       "2  dababy album sounds like it was made for nigga...   \n",
       "3  Majority of Indians do not watch any sport oth...   \n",
       "4  everybody is just now listen to  @ madisonbeer...   \n",
       "\n",
       "                                 map_more_punc_reply  \\\n",
       "0                                                      \n",
       "1                                                      \n",
       "2                       That  '  s why you buy it .    \n",
       "3   @ ZairaWasimmm got a great story because of t...   \n",
       "4                                                      \n",
       "\n",
       "                                   map_demojize_text  \\\n",
       "0   @ Youngdeji  -   I think if uzi and carti dro...   \n",
       "1  For the third year in a row we are discussing ...   \n",
       "2  dababy album sounds like it was made for nigga...   \n",
       "3  Majority of Indians do not watch any sport oth...   \n",
       "4  everybody is just now listen to  @ madisonbeer...   \n",
       "\n",
       "                                  map_demojize_reply  \n",
       "0                                                     \n",
       "1                                                     \n",
       "2                       That  '  s why you buy it .   \n",
       "3   @ ZairaWasimmm got a great story because of t...  \n",
       "4                                                     "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output preprocessed to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_preprocessed = df_train[['idx', 'map_more_punc_text', 'map_more_punc_reply', 'categories']].copy()\n",
    "df_preprocessed.columns = ['idx', 'text', 'reply', 'categories']\n",
    "df_preprocessed.to_json('./preprocessed/preprocess_train.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed_dev = df_dev[['idx', 'map_more_punc_text', 'map_more_punc_reply']].copy()\n",
    "df_preprocessed_dev.columns = ['idx', 'text', 'reply']\n",
    "df_preprocessed_dev.to_json('./preprocessed/preprocess_dev.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed_test = df_test[['idx', 'map_more_punc_text', 'map_more_punc_reply']].copy()\n",
    "df_preprocessed_test.columns = ['idx', 'text', 'reply']\n",
    "df_preprocessed_test.to_json('./preprocessed/preprocess_test.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Don't have time to test, so won't use in testing phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed = df_train[['idx', 'map_demojize_text', 'map_demojize_reply', 'categories']].copy()\n",
    "df_preprocessed.columns = ['idx', 'text', 'reply', 'categories']\n",
    "df_preprocessed.to_json('./preprocessed/preprocess_train.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed_dev = df_dev[['idx', 'map_demojize_text', 'map_demojize_reply']].copy()\n",
    "df_preprocessed_dev.columns = ['idx', 'text', 'reply']\n",
    "df_preprocessed_dev.to_json('./preprocessed/preprocess_dev.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed_test = df_test[['idx', 'map_demojize_text', 'map_demojize_reply']].copy()\n",
    "df_preprocessed_test.columns = ['idx', 'text', 'reply']\n",
    "df_preprocessed_test.to_json('./preprocessed/preprocess_test.json', orient='records', lines=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
